{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.3 64-bit (conda)",
      "metadata": {
        "interpreter": {
          "hash": "51c008122401afe5535fd6c3a84bd5dd8b8bd079df3baf2c4d203d1ed6e4d4a5"
        }
      }
    },
    "colab": {
      "name": "Burgers_Same.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6hx4sG_8ieS"
      },
      "source": [
        "# Burgers Equation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub5oHbXH8pkf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec2f8f68-5efc-43ce-e911-77e5c904bd67"
      },
      "source": [
        "!pip install pyDOE"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyDOE\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/ac/91fe4c039e2744466621343d3b8af4a485193ed0aab53af5b1db03be0989/pyDOE-0.3.8.zip\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyDOE) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyDOE) (1.4.1)\n",
            "Building wheels for collected packages: pyDOE\n",
            "  Building wheel for pyDOE (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyDOE: filename=pyDOE-0.3.8-cp37-none-any.whl size=18178 sha256=0fc7a0811d6ed490a70c311281b4b572ec73b15c1108239b577f41510173390c\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/c8/58/a6493bd415e8ba5735082b5e0c096d7c1f2933077a8ce34544\n",
            "Successfully built pyDOE\n",
            "Installing collected packages: pyDOE\n",
            "Successfully installed pyDOE-0.3.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeH35EQU8ieb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49d4d1d7-75ec-4dd3-8798-effded1bf3b7"
      },
      "source": [
        "%tensorflow_version 1.x ### to run on Google Colab: \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "from scipy.interpolate import griddata\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from pyDOE import lhs\n",
        "import time\n",
        "import matplotlib.gridspec as gridspec\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.x ### to run on Google Colab:`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioO_XM0H8iec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6043fd58-8a28-4786-f00c-16858ba27197"
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5bGi5OH8iee"
      },
      "source": [
        "###############################################################################\n",
        "############################## Helper Functions ###############################\n",
        "###############################################################################\n",
        "\n",
        "def initialize_NN(layers):\n",
        "    weights = []\n",
        "    biases = []\n",
        "    num_layers = len(layers) \n",
        "    for l in range(0,num_layers-1):\n",
        "        W = xavier_init(size=[layers[l], layers[l+1]])\n",
        "        b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
        "        weights.append(W)\n",
        "        biases.append(b)\n",
        "    return weights, biases\n",
        "    \n",
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    out_dim = size[1]\n",
        "    xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
        "    return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev, dtype=tf.float32), dtype=tf.float32)\n",
        "\n",
        "def neural_net(X, weights, biases):\n",
        "    num_layers = len(weights) + 1\n",
        "    H = X\n",
        "    for l in range(0,num_layers-2):\n",
        "        W = weights[l]\n",
        "        b = biases[l]\n",
        "        H = tf.sin(tf.add(tf.matmul(H, W), b))\n",
        "    W = weights[-1]\n",
        "    b = biases[-1]\n",
        "    Y = tf.add(tf.matmul(H, W), b)\n",
        "    return Y\n",
        "\n",
        "###############################################################################\n",
        "################################ DeepHPM Class ################################\n",
        "###############################################################################\n",
        "\n",
        "class DeepHPM:\n",
        "    def __init__(self, t, x, u,\n",
        "                       x0, u0, tb, X_f,\n",
        "                       u_layers, pde_layers,\n",
        "                       layers,\n",
        "                       lb_idn, ub_idn,\n",
        "                       lb_sol, ub_sol):\n",
        "        \n",
        "        # Domain Boundary\n",
        "        self.lb_idn = lb_idn\n",
        "        self.ub_idn = ub_idn\n",
        "        \n",
        "        self.lb_sol = lb_sol\n",
        "        self.ub_sol = ub_sol\n",
        "        \n",
        "        # Init for Identification\n",
        "        self.idn_init(t, x, u, u_layers, pde_layers)\n",
        "        \n",
        "        # Init for Solution\n",
        "        self.sol_init(x0, u0, tb, X_f, layers)\n",
        "        \n",
        "        # tf session\n",
        "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
        "                                                     log_device_placement=True))\n",
        "        \n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess.run(init)\n",
        "    \n",
        "    ###########################################################################\n",
        "    ############################# Identifier ##################################\n",
        "    ###########################################################################\n",
        "        \n",
        "    def idn_init(self, t, x, u, u_layers, pde_layers):\n",
        "        # Training Data for Identification\n",
        "        self.t = t\n",
        "        self.x = x\n",
        "        self.u = u\n",
        "        \n",
        "        # Layers for Identification\n",
        "        self.u_layers = u_layers\n",
        "        self.pde_layers = pde_layers\n",
        "        \n",
        "        # Initialize NNs for Identification\n",
        "        self.u_weights, self.u_biases = initialize_NN(u_layers)\n",
        "        self.pde_weights, self.pde_biases = initialize_NN(pde_layers)\n",
        "        \n",
        "        # tf placeholders for Identification\n",
        "        self.t_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.x_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.u_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.terms_tf = tf.placeholder(tf.float32, shape=[None, pde_layers[0]])\n",
        "        \n",
        "        # tf graphs for Identification\n",
        "        self.idn_u_pred = self.idn_net_u(self.t_tf, self.x_tf)\n",
        "        self.pde_pred = self.net_pde(self.terms_tf)\n",
        "        self.idn_f_pred = self.idn_net_f(self.t_tf, self.x_tf)\n",
        "        \n",
        "        # loss for Identification\n",
        "        reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES) ## L1 REGULARIZATION\n",
        "        reg_constant = 0.001  # Choose an appropriate one\n",
        "        self.idn_u_loss = tf.reduce_sum(tf.square(self.idn_u_pred - self.u_tf)) + reg_constant*sum(reg_losses)\n",
        "        self.idn_f_loss = tf.reduce_sum(tf.square(self.idn_f_pred)) + reg_constant*sum(reg_losses)\n",
        "        \n",
        "        # Optimizer for Identification\n",
        "        self.idn_u_optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.idn_u_loss,\n",
        "                               var_list = self.u_weights + self.u_biases,\n",
        "                               method = 'L-BFGS-B',\n",
        "                               options = {'maxiter': 50000,\n",
        "                                          'maxfun': 50000,\n",
        "                                          'maxcor': 50,\n",
        "                                          'maxls': 50,\n",
        "                                          'ftol': 1.0*np.finfo(float).eps})\n",
        "    \n",
        "        self.idn_f_optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.idn_f_loss,\n",
        "                               var_list = self.pde_weights + self.pde_biases,\n",
        "                               method = 'L-BFGS-B',\n",
        "                               options = {'maxiter': 50000,\n",
        "                                          'maxfun': 50000,\n",
        "                                          'maxcor': 50,\n",
        "                                          'maxls': 50,\n",
        "                                          'ftol': 1.0*np.finfo(float).eps})\n",
        "    \n",
        "        self.idn_u_optimizer_Adam = tf.train.AdamOptimizer()\n",
        "        self.idn_u_train_op_Adam = self.idn_u_optimizer_Adam.minimize(self.idn_u_loss, \n",
        "                                   var_list = self.u_weights + self.u_biases)\n",
        "        \n",
        "        self.idn_f_optimizer_Adam = tf.train.AdamOptimizer()\n",
        "        self.idn_f_train_op_Adam = self.idn_f_optimizer_Adam.minimize(self.idn_f_loss, \n",
        "                                   var_list = self.pde_weights + self.pde_biases)  \n",
        "    \n",
        "    def idn_net_u(self, t, x):\n",
        "        X = tf.concat([t,x],1)\n",
        "        H = 2.0*(X - self.lb_idn)/(self.ub_idn - self.lb_idn) - 1.0\n",
        "        u = neural_net(H, self.u_weights, self.u_biases)\n",
        "        return u\n",
        "    \n",
        "    def net_pde(self, terms):\n",
        "        pde = neural_net(terms, self.pde_weights, self.pde_biases)\n",
        "        return pde\n",
        "    \n",
        "    def idn_net_f(self, t, x):\n",
        "        u = self.idn_net_u(t, x)\n",
        "        \n",
        "        u_t = tf.gradients(u, t)[0]\n",
        "        \n",
        "        u_x = tf.gradients(u, x)[0]\n",
        "        u_xx = tf.gradients(u_x, x)[0]\n",
        "        \n",
        "        terms = tf.concat([u,u_x,u_xx],1)\n",
        "\n",
        "        \n",
        "        f = u_t - self.net_pde(terms)\n",
        "        \n",
        "        return f\n",
        "\n",
        "    def idn_u_train(self, N_iter):\n",
        "        tf_dict = {self.t_tf: self.t, self.x_tf: self.x, self.u_tf: self.u}\n",
        "        \n",
        "        start_time = time.time()\n",
        "        for it in range(N_iter):\n",
        "            \n",
        "            self.sess.run(self.idn_u_train_op_Adam, tf_dict)\n",
        "            \n",
        "            # Print\n",
        "            if it % 10 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                loss_value = self.sess.run(self.idn_u_loss, tf_dict)\n",
        "                print('It: %d, Loss: %.3e, Time: %.2f' % \n",
        "                      (it, loss_value, elapsed))\n",
        "                start_time = time.time()\n",
        "        \n",
        "        self.idn_u_optimizer.minimize(self.sess,\n",
        "                                      feed_dict = tf_dict,\n",
        "                                      fetches = [self.idn_u_loss],\n",
        "                                      loss_callback = self.callback)\n",
        "\n",
        "    def idn_f_train(self, N_iter):\n",
        "        tf_dict = {self.t_tf: self.t, self.x_tf: self.x}\n",
        "        \n",
        "        start_time = time.time()\n",
        "        for it in range(N_iter):\n",
        "            \n",
        "            self.sess.run(self.idn_f_train_op_Adam, tf_dict)\n",
        "            \n",
        "            # Print\n",
        "            if it % 10 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                loss_value = self.sess.run(self.idn_f_loss, tf_dict)\n",
        "                print('It: %d, Loss: %.3e, Time: %.2f' % \n",
        "                      (it, loss_value, elapsed))\n",
        "                start_time = time.time()\n",
        "        \n",
        "        self.idn_f_optimizer.minimize(self.sess,\n",
        "                                      feed_dict = tf_dict,\n",
        "                                      fetches = [self.idn_f_loss],\n",
        "                                      loss_callback = self.callback)\n",
        "\n",
        "    def idn_predict(self, t_star, x_star):\n",
        "        \n",
        "        tf_dict = {self.t_tf: t_star, self.x_tf: x_star}\n",
        "        \n",
        "        u_star = self.sess.run(self.idn_u_pred, tf_dict)\n",
        "        f_star = self.sess.run(self.idn_f_pred, tf_dict)\n",
        "        \n",
        "        return u_star, f_star\n",
        "    \n",
        "    def predict_pde(self, terms_star):\n",
        "        \n",
        "        tf_dict = {self.terms_tf: terms_star}\n",
        "        \n",
        "        pde_star = self.sess.run(self.pde_pred, tf_dict)\n",
        "        \n",
        "        return pde_star\n",
        "    \n",
        "    ###########################################################################\n",
        "    ############################### Solver ####################################\n",
        "    ###########################################################################\n",
        "    \n",
        "    def sol_init(self, x0, u0, tb, X_f, layers):\n",
        "        # Training Data for Solution\n",
        "        X0 = np.concatenate((0*x0, x0), 1) # (0, x0)\n",
        "        X_lb = np.concatenate((tb, 0*tb + self.lb_sol[1]), 1) # (tb, lb[1])\n",
        "        X_ub = np.concatenate((tb, 0*tb + self.ub_sol[1]), 1) # (tb, ub[1])\n",
        "                \n",
        "        self.X_f = X_f # Collocation Points\n",
        "        self.t0 = X0[:,0:1] # Initial Data (time)\n",
        "        self.x0 = X0[:,1:2] # Initial Data (space)\n",
        "        self.t_lb = X_lb[:,0:1] # Boundary Data (time) -- lower boundary\n",
        "        self.x_lb = X_lb[:,1:2] # Boundary Data (space) -- lower boundary\n",
        "        self.t_ub = X_ub[:,0:1] # Boundary Data (time) -- upper boundary\n",
        "        self.x_ub = X_ub[:,1:2] # Boundary Data (space) -- upper boundary\n",
        "        self.t_f = X_f[:,0:1] # Collocation Points (time)\n",
        "        self.x_f = X_f[:,1:2] # Collocation Points (space)\n",
        "        self.u0 = u0 # Boundary Data\n",
        "        \n",
        "        # Layers for Solution\n",
        "        self.layers = layers\n",
        "        \n",
        "        # Initialize NNs for Solution\n",
        "        self.weights, self.biases = initialize_NN(layers)\n",
        "        \n",
        "        # tf placeholders for Solution\n",
        "        self.t0_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.x0_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.u0_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.t_lb_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.x_lb_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.t_ub_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.x_ub_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.t_f_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.x_f_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        \n",
        "        # tf graphs for Solution\n",
        "        self.u0_pred, _  = self.sol_net_u(self.t0_tf, self.x0_tf)\n",
        "        self.u_lb_pred, self.u_x_lb_pred = self.sol_net_u(self.t_lb_tf, self.x_lb_tf)\n",
        "        self.u_ub_pred, self.u_x_ub_pred = self.sol_net_u(self.t_ub_tf, self.x_ub_tf)\n",
        "        self.sol_f_pred = self.sol_net_f(self.t_f_tf, self.x_f_tf)\n",
        "        \n",
        "        # loss for Solution\n",
        "        reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES) ## L1 REGULARIZATION\n",
        "        reg_constant = 0.001  # Choose an appropriate one\n",
        "        self.sol_loss = tf.reduce_sum(tf.square(self.u0_tf - self.u0_pred)) + \\\n",
        "                        tf.reduce_sum(tf.square(self.u_lb_pred - self.u_ub_pred)) + \\\n",
        "                        tf.reduce_sum(tf.square(self.u_x_lb_pred - self.u_x_ub_pred)) + \\\n",
        "                        tf.reduce_sum(tf.square(self.sol_f_pred)) + reg_constant*sum(reg_losses)\n",
        "        \n",
        "        # Optimizer for Solution\n",
        "        self.sol_optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.sol_loss,\n",
        "                             var_list = self.weights + self.biases,\n",
        "                             method = 'L-BFGS-B',\n",
        "                             options = {'maxiter': 50000,\n",
        "                                        'maxfun': 50000,\n",
        "                                        'maxcor': 50,\n",
        "                                        'maxls': 50,\n",
        "                                        'ftol': 1.0*np.finfo(float).eps})\n",
        "    \n",
        "        self.sol_optimizer_Adam = tf.train.AdamOptimizer()\n",
        "        self.sol_train_op_Adam = self.sol_optimizer_Adam.minimize(self.sol_loss,\n",
        "                                 var_list = self.weights + self.biases)\n",
        "    \n",
        "    def sol_net_u(self, t, x):\n",
        "        X = tf.concat([t,x],1)\n",
        "        H = 2.0*(X - self.lb_sol)/(self.ub_sol - self.lb_sol) - 1.0\n",
        "        u = neural_net(H, self.weights, self.biases)\n",
        "        u_x = tf.gradients(u, x)[0]\n",
        "        return u, u_x\n",
        "    \n",
        "    def sol_net_f(self, t, x):\n",
        "        u, _ = self.sol_net_u(t,x)\n",
        "        \n",
        "        u_t = tf.gradients(u, t)[0]\n",
        "        \n",
        "        u_x = tf.gradients(u, x)[0]\n",
        "        u_xx = tf.gradients(u_x, x)[0]\n",
        "        \n",
        "        terms = tf.concat([u,u_x,u_xx],1)\n",
        "        \n",
        "        f = u_t - self.net_pde(terms)\n",
        "        \n",
        "        return f\n",
        "    \n",
        "    def callback(self, loss):\n",
        "        print('Loss: %e' % (loss))\n",
        "        \n",
        "    def sol_train(self, N_iter):\n",
        "        tf_dict = {self.t0_tf: self.t0, self.x0_tf: self.x0,\n",
        "                   self.u0_tf: self.u0,\n",
        "                   self.t_lb_tf: self.t_lb, self.x_lb_tf: self.x_lb,\n",
        "                   self.t_ub_tf: self.t_ub, self.x_ub_tf: self.x_ub,\n",
        "                   self.t_f_tf: self.t_f, self.x_f_tf: self.x_f}\n",
        "        \n",
        "        start_time = time.time()\n",
        "        for it in range(N_iter):\n",
        "            \n",
        "            self.sess.run(self.sol_train_op_Adam, tf_dict)\n",
        "            \n",
        "            # Print\n",
        "            if it % 10 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                loss_value = self.sess.run(self.sol_loss, tf_dict)\n",
        "                print('It: %d, Loss: %.3e, Time: %.2f' % \n",
        "                      (it, loss_value, elapsed))\n",
        "                start_time = time.time()\n",
        "                \n",
        "        self.sol_optimizer.minimize(self.sess,\n",
        "                                    feed_dict = tf_dict,\n",
        "                                    fetches = [self.sol_loss],\n",
        "                                    loss_callback = self.callback)\n",
        "    \n",
        "    def sol_predict(self, t_star, x_star):\n",
        "        \n",
        "        u_star = self.sess.run(self.u0_pred, {self.t0_tf: t_star, self.x0_tf: x_star})  \n",
        "        f_star = self.sess.run(self.sol_f_pred, {self.t_f_tf: t_star, self.x_f_tf: x_star})\n",
        "               \n",
        "        return u_star, f_star    "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dJn1YsD8iem"
      },
      "source": [
        "## Problem Set-Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FFu1pR682CG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ae3dc05-7695-4231-8415-e788bf14d279"
      },
      "source": [
        "import os\n",
        "cwd = os.getcwd()\n",
        "print(cwd)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLTVx4zY8iet"
      },
      "source": [
        "   # Doman bounds\n",
        "lb_idn = np.array([0.0, -8.0])\n",
        "ub_idn = np.array([10.0, 8.0])\n",
        "    \n",
        "lb_sol = np.array([0.0, -8.0])\n",
        "ub_sol = np.array([10.0, 8.0])\n",
        "    \n",
        "    ### Load Data ###    \n",
        "data_idn = scipy.io.loadmat('/content/Data/burgers_sine.mat')\n",
        "#data_idn = scipy.io.loadmat('/content/Data/burgers_exp.mat')\n",
        "t_idn = data_idn['t'].flatten()[:,None]\n",
        "x_idn = data_idn['x'].flatten()[:,None]\n",
        "Exact_idn = np.real(data_idn['usol'])    \n",
        "T_idn, X_idn = np.meshgrid(t_idn,x_idn)\n",
        "keep = 2/3\n",
        "index = int(keep*t_idn.shape[0])\n",
        "T_idn = T_idn[:,0:index]\n",
        "X_idn = X_idn[:,0:index]\n",
        "Exact_idn = Exact_idn[:,0:index]\n",
        "    \n",
        "t_idn_star = T_idn.flatten()[:,None]\n",
        "x_idn_star = X_idn.flatten()[:,None]\n",
        "X_idn_star = np.hstack((t_idn_star, x_idn_star))\n",
        "u_idn_star = Exact_idn.flatten()[:,None]\n",
        "    \n",
        "    # Data Solution: \n",
        "data_sol = scipy.io.loadmat('/content/Data/burgers_sine.mat')\n",
        "#data_sol = scipy.io.loadmat('/content/Data/burgers_exp.mat')\n",
        "t_sol = data_sol['t'].flatten()[:,None]\n",
        "x_sol = data_sol['x'].flatten()[:,None]\n",
        "Exact_sol = np.real(data_sol['usol'])\n",
        "T_sol, X_sol = np.meshgrid(t_sol,x_sol)\n",
        "t_sol_star = T_sol.flatten()[:,None]\n",
        "x_sol_star = X_sol.flatten()[:,None]\n",
        "X_sol_star = np.hstack((t_sol_star, x_sol_star))\n",
        "u_sol_star = Exact_sol.flatten()[:,None]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2NDTJCt8iet"
      },
      "source": [
        "## Training Process: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eEyOSPy8iet",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44a6ebd9-ec9b-40c8-fcdf-66e011ca34a9"
      },
      "source": [
        "    ### Training Data ###\n",
        "    \n",
        "    # For identification\n",
        "N_train = 10000\n",
        "idx = np.random.choice(t_idn_star.shape[0], N_train, replace=False)    \n",
        "t_train = t_idn_star[idx,:]\n",
        "x_train = x_idn_star[idx,:]\n",
        "u_train = u_idn_star[idx,:]\n",
        "noise = 0.00 ## adjust this for different purposes \n",
        "u_train = u_train + noise*np.std(u_train)*np.random.randn(u_train.shape[0], u_train.shape[1])\n",
        "    \n",
        "# For solution\n",
        "N0 = Exact_sol.shape[0]\n",
        "N_b = Exact_sol.shape[1]\n",
        "N_f = 20000\n",
        "idx_x = np.random.choice(x_sol.shape[0], N0, replace=False)\n",
        "x0_train = x_sol[idx_x,:]\n",
        "u0_train = Exact_sol[idx_x,0:1]   \n",
        "idx_t = np.random.choice(t_sol.shape[0], N_b, replace=False)\n",
        "tb_train = t_sol[idx_t,:] \n",
        "X_f_train = lb_sol + (ub_sol-lb_sol)*lhs(2, N_f)\n",
        "        \n",
        "    # Layers\n",
        "u_layers = [2, 50, 50, 50, 50, 1]\n",
        "pde_layers = [3, 100, 100, 1]    \n",
        "layers = [2, 50, 50, 50, 50, 1]\n",
        "    # Model\n",
        "model = DeepHPM(t_train, x_train, u_train,x0_train, u0_train, tb_train, X_f_train,u_layers, pde_layers,\n",
        "                    layers,lb_idn, ub_idn,\n",
        "                    lb_sol,ub_sol)\n",
        "    # Train the identifier\n",
        "model.idn_u_train(N_iter=0)\n",
        "model.idn_f_train(N_iter=0)   \n",
        "u_pred_identifier, f_pred_identifier = model.idn_predict(t_idn_star, x_idn_star)  \n",
        "error_u_identifier = np.linalg.norm(u_idn_star-u_pred_identifier,2)/np.linalg.norm(u_idn_star,2)\n",
        "print('Error u: %e' % (error_u_identifier))\n",
        "\n",
        "    ### Solution ###\n",
        "    \n",
        "    # Train the solver\n",
        "model.sol_train(N_iter=0)\n",
        "u_pred, f_pred = model.sol_predict(t_sol_star, x_sol_star)   \n",
        "u_pred_idn, f_pred_idn = model.sol_predict(t_idn_star, x_idn_star)\n",
        "error_u = np.linalg.norm(u_sol_star-u_pred,2)/np.linalg.norm(u_sol_star,2)\n",
        "error_u_idn = np.linalg.norm(u_idn_star-u_pred_idn,2)/np.linalg.norm(u_idn_star,2)\n",
        "print('Error u: %e' % (error_u))\n",
        "print('Error u (idn): %e' % (error_u_idn))\n",
        "U_pred = griddata(X_sol_star, u_pred.flatten(), (T_sol, X_sol), method='cubic')\n",
        "    "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Loss: 8.635885e-02\n",
            "Loss: 8.634253e-02\n",
            "Loss: 8.632799e-02\n",
            "Loss: 8.632847e-02\n",
            "Loss: 8.631838e-02\n",
            "Loss: 8.630746e-02\n",
            "Loss: 8.629840e-02\n",
            "Loss: 8.627819e-02\n",
            "Loss: 8.625103e-02\n",
            "Loss: 8.625839e-02\n",
            "Loss: 8.623606e-02\n",
            "Loss: 8.622096e-02\n",
            "Loss: 8.620157e-02\n",
            "Loss: 8.618019e-02\n",
            "Loss: 8.615720e-02\n",
            "Loss: 8.617085e-02\n",
            "Loss: 8.614592e-02\n",
            "Loss: 8.613606e-02\n",
            "Loss: 8.612654e-02\n",
            "Loss: 8.611759e-02\n",
            "Loss: 8.609329e-02\n",
            "Loss: 8.629083e-02\n",
            "Loss: 8.608635e-02\n",
            "Loss: 8.606830e-02\n",
            "Loss: 8.605061e-02\n",
            "Loss: 8.603784e-02\n",
            "Loss: 8.602707e-02\n",
            "Loss: 8.600770e-02\n",
            "Loss: 8.598948e-02\n",
            "Loss: 8.597233e-02\n",
            "Loss: 8.595786e-02\n",
            "Loss: 8.594651e-02\n",
            "Loss: 8.593404e-02\n",
            "Loss: 8.592141e-02\n",
            "Loss: 8.590864e-02\n",
            "Loss: 8.589800e-02\n",
            "Loss: 8.589365e-02\n",
            "Loss: 8.588728e-02\n",
            "Loss: 8.588098e-02\n",
            "Loss: 8.587073e-02\n",
            "Loss: 8.585556e-02\n",
            "Loss: 8.604095e-02\n",
            "Loss: 8.585186e-02\n",
            "Loss: 8.583707e-02\n",
            "Loss: 8.582187e-02\n",
            "Loss: 8.580749e-02\n",
            "Loss: 8.579734e-02\n",
            "Loss: 8.582458e-02\n",
            "Loss: 8.579329e-02\n",
            "Loss: 8.578306e-02\n",
            "Loss: 8.577412e-02\n",
            "Loss: 8.576544e-02\n",
            "Loss: 8.575536e-02\n",
            "Loss: 8.575418e-02\n",
            "Loss: 8.574791e-02\n",
            "Loss: 8.573602e-02\n",
            "Loss: 8.572571e-02\n",
            "Loss: 8.571143e-02\n",
            "Loss: 8.569787e-02\n",
            "Loss: 8.568330e-02\n",
            "Loss: 8.566885e-02\n",
            "Loss: 8.564806e-02\n",
            "Loss: 8.564162e-02\n",
            "Loss: 8.563153e-02\n",
            "Loss: 8.562078e-02\n",
            "Loss: 8.561123e-02\n",
            "Loss: 8.559304e-02\n",
            "Loss: 8.564337e-02\n",
            "Loss: 8.558515e-02\n",
            "Loss: 8.557010e-02\n",
            "Loss: 8.554743e-02\n",
            "Loss: 8.552896e-02\n",
            "Loss: 8.550594e-02\n",
            "Loss: 8.552974e-02\n",
            "Loss: 8.549489e-02\n",
            "Loss: 8.547518e-02\n",
            "Loss: 8.546678e-02\n",
            "Loss: 8.545022e-02\n",
            "Loss: 8.543975e-02\n",
            "Loss: 8.542237e-02\n",
            "Loss: 8.540896e-02\n",
            "Loss: 8.539011e-02\n",
            "Loss: 8.537681e-02\n",
            "Loss: 8.537326e-02\n",
            "Loss: 8.536026e-02\n",
            "Loss: 8.535631e-02\n",
            "Loss: 8.535007e-02\n",
            "Loss: 8.533864e-02\n",
            "Loss: 8.532400e-02\n",
            "Loss: 8.531124e-02\n",
            "Loss: 8.530039e-02\n",
            "Loss: 8.528438e-02\n",
            "Loss: 8.527423e-02\n",
            "Loss: 8.526119e-02\n",
            "Loss: 8.524799e-02\n",
            "Loss: 8.526876e-02\n",
            "Loss: 8.524069e-02\n",
            "Loss: 8.522558e-02\n",
            "Loss: 8.521831e-02\n",
            "Loss: 8.520865e-02\n",
            "Loss: 8.520118e-02\n",
            "Loss: 8.519173e-02\n",
            "Loss: 8.518259e-02\n",
            "Loss: 8.517560e-02\n",
            "Loss: 8.529911e-02\n",
            "Loss: 8.517312e-02\n",
            "Loss: 8.516333e-02\n",
            "Loss: 8.515364e-02\n",
            "Loss: 8.514241e-02\n",
            "Loss: 8.513305e-02\n",
            "Loss: 8.515918e-02\n",
            "Loss: 8.512745e-02\n",
            "Loss: 8.511893e-02\n",
            "Loss: 8.510884e-02\n",
            "Loss: 8.509350e-02\n",
            "Loss: 8.507973e-02\n",
            "Loss: 8.506614e-02\n",
            "Loss: 8.505197e-02\n",
            "Loss: 8.503803e-02\n",
            "Loss: 8.503113e-02\n",
            "Loss: 8.501944e-02\n",
            "Loss: 8.501187e-02\n",
            "Loss: 8.500380e-02\n",
            "Loss: 8.498704e-02\n",
            "Loss: 8.498577e-02\n",
            "Loss: 8.497418e-02\n",
            "Loss: 8.495295e-02\n",
            "Loss: 8.494361e-02\n",
            "Loss: 8.492549e-02\n",
            "Loss: 8.491002e-02\n",
            "Loss: 8.489195e-02\n",
            "Loss: 8.488040e-02\n",
            "Loss: 8.486885e-02\n",
            "Loss: 8.486231e-02\n",
            "Loss: 8.485661e-02\n",
            "Loss: 8.483323e-02\n",
            "Loss: 8.488415e-02\n",
            "Loss: 8.482657e-02\n",
            "Loss: 8.481221e-02\n",
            "Loss: 8.479883e-02\n",
            "Loss: 8.480121e-02\n",
            "Loss: 8.479314e-02\n",
            "Loss: 8.478505e-02\n",
            "Loss: 8.477706e-02\n",
            "Loss: 8.476532e-02\n",
            "Loss: 8.474893e-02\n",
            "Loss: 8.472835e-02\n",
            "Loss: 8.470405e-02\n",
            "Loss: 8.469009e-02\n",
            "Loss: 8.467494e-02\n",
            "Loss: 8.466495e-02\n",
            "Loss: 8.465635e-02\n",
            "Loss: 8.463774e-02\n",
            "Loss: 8.462843e-02\n",
            "Loss: 8.461873e-02\n",
            "Loss: 8.460585e-02\n",
            "Loss: 8.460060e-02\n",
            "Loss: 8.459143e-02\n",
            "Loss: 8.458252e-02\n",
            "Loss: 8.457054e-02\n",
            "Loss: 8.457317e-02\n",
            "Loss: 8.456337e-02\n",
            "Loss: 8.455277e-02\n",
            "Loss: 8.454556e-02\n",
            "Loss: 8.453902e-02\n",
            "Loss: 8.453059e-02\n",
            "Loss: 8.451758e-02\n",
            "Loss: 8.452228e-02\n",
            "Loss: 8.451104e-02\n",
            "Loss: 8.449955e-02\n",
            "Loss: 8.448444e-02\n",
            "Loss: 8.447026e-02\n",
            "Loss: 8.444985e-02\n",
            "Loss: 8.442892e-02\n",
            "Loss: 8.443078e-02\n",
            "Loss: 8.441561e-02\n",
            "Loss: 8.440465e-02\n",
            "Loss: 8.439405e-02\n",
            "Loss: 8.438613e-02\n",
            "Loss: 8.437256e-02\n",
            "Loss: 8.435973e-02\n",
            "Loss: 8.434986e-02\n",
            "Loss: 8.433475e-02\n",
            "Loss: 8.432269e-02\n",
            "Loss: 8.429994e-02\n",
            "Loss: 8.436493e-02\n",
            "Loss: 8.429442e-02\n",
            "Loss: 8.428667e-02\n",
            "Loss: 8.427747e-02\n",
            "Loss: 8.426824e-02\n",
            "Loss: 8.426665e-02\n",
            "Loss: 8.425426e-02\n",
            "Loss: 8.424831e-02\n",
            "Loss: 8.424129e-02\n",
            "Loss: 8.423315e-02\n",
            "Loss: 8.423286e-02\n",
            "Loss: 8.422739e-02\n",
            "Loss: 8.422005e-02\n",
            "Loss: 8.421457e-02\n",
            "Loss: 8.421040e-02\n",
            "Loss: 8.420678e-02\n",
            "Loss: 8.419882e-02\n",
            "Loss: 8.419009e-02\n",
            "Loss: 8.418582e-02\n",
            "Loss: 8.417650e-02\n",
            "Loss: 8.415879e-02\n",
            "Loss: 8.416412e-02\n",
            "Loss: 8.414917e-02\n",
            "Loss: 8.414130e-02\n",
            "Loss: 8.413406e-02\n",
            "Loss: 8.412787e-02\n",
            "Loss: 8.411333e-02\n",
            "Loss: 8.436053e-02\n",
            "Loss: 8.411086e-02\n",
            "Loss: 8.410155e-02\n",
            "Loss: 8.409002e-02\n",
            "Loss: 8.407326e-02\n",
            "Loss: 8.405586e-02\n",
            "Loss: 8.404974e-02\n",
            "Loss: 8.404115e-02\n",
            "Loss: 8.403648e-02\n",
            "Loss: 8.403260e-02\n",
            "Loss: 8.402645e-02\n",
            "Loss: 8.401818e-02\n",
            "Loss: 8.400495e-02\n",
            "Loss: 8.399411e-02\n",
            "Loss: 8.398379e-02\n",
            "Loss: 8.397769e-02\n",
            "Loss: 8.396474e-02\n",
            "Loss: 8.394980e-02\n",
            "Loss: 8.393773e-02\n",
            "Loss: 8.392936e-02\n",
            "Loss: 8.391549e-02\n",
            "Loss: 8.390940e-02\n",
            "Loss: 8.390231e-02\n",
            "Loss: 8.389544e-02\n",
            "Loss: 8.388804e-02\n",
            "Loss: 8.388005e-02\n",
            "Loss: 8.387007e-02\n",
            "Loss: 8.385170e-02\n",
            "Loss: 8.383254e-02\n",
            "Loss: 8.389820e-02\n",
            "Loss: 8.382627e-02\n",
            "Loss: 8.381049e-02\n",
            "Loss: 8.379678e-02\n",
            "Loss: 8.377844e-02\n",
            "Loss: 8.377982e-02\n",
            "Loss: 8.377209e-02\n",
            "Loss: 8.376157e-02\n",
            "Loss: 8.375075e-02\n",
            "Loss: 8.373663e-02\n",
            "Loss: 8.371737e-02\n",
            "Loss: 8.371289e-02\n",
            "Loss: 8.369329e-02\n",
            "Loss: 8.368514e-02\n",
            "Loss: 8.367404e-02\n",
            "Loss: 8.366209e-02\n",
            "Loss: 8.365003e-02\n",
            "Loss: 8.364017e-02\n",
            "Loss: 8.363470e-02\n",
            "Loss: 8.363114e-02\n",
            "Loss: 8.362643e-02\n",
            "Loss: 8.361793e-02\n",
            "Loss: 8.361463e-02\n",
            "Loss: 8.360586e-02\n",
            "Loss: 8.360208e-02\n",
            "Loss: 8.359674e-02\n",
            "Loss: 8.358674e-02\n",
            "Loss: 8.362743e-02\n",
            "Loss: 8.358236e-02\n",
            "Loss: 8.357202e-02\n",
            "Loss: 8.356529e-02\n",
            "Loss: 8.355852e-02\n",
            "Loss: 8.354811e-02\n",
            "Loss: 8.357385e-02\n",
            "Loss: 8.354417e-02\n",
            "Loss: 8.353005e-02\n",
            "Loss: 8.351680e-02\n",
            "Loss: 8.350495e-02\n",
            "Loss: 8.349425e-02\n",
            "Loss: 8.348176e-02\n",
            "Loss: 8.348116e-02\n",
            "Loss: 8.347442e-02\n",
            "Loss: 8.346859e-02\n",
            "Loss: 8.346393e-02\n",
            "Loss: 8.346013e-02\n",
            "Loss: 8.344946e-02\n",
            "Loss: 8.344832e-02\n",
            "Loss: 8.343381e-02\n",
            "Loss: 8.342820e-02\n",
            "Loss: 8.342152e-02\n",
            "Loss: 8.341388e-02\n",
            "Loss: 8.340496e-02\n",
            "Loss: 8.340297e-02\n",
            "Loss: 8.339051e-02\n",
            "Loss: 8.338379e-02\n",
            "Loss: 8.337337e-02\n",
            "Loss: 8.335938e-02\n",
            "Loss: 8.334422e-02\n",
            "Loss: 8.333437e-02\n",
            "Loss: 8.332630e-02\n",
            "Loss: 8.331600e-02\n",
            "Loss: 8.332134e-02\n",
            "Loss: 8.331034e-02\n",
            "Loss: 8.329964e-02\n",
            "Loss: 8.327924e-02\n",
            "Loss: 8.326788e-02\n",
            "Loss: 8.324938e-02\n",
            "Loss: 8.323107e-02\n",
            "Loss: 8.322105e-02\n",
            "Loss: 8.321063e-02\n",
            "Loss: 8.320336e-02\n",
            "Loss: 8.319276e-02\n",
            "Loss: 8.317709e-02\n",
            "Loss: 8.316699e-02\n",
            "Loss: 8.315866e-02\n",
            "Loss: 8.315443e-02\n",
            "Loss: 8.314887e-02\n",
            "Loss: 8.313482e-02\n",
            "Loss: 8.315113e-02\n",
            "Loss: 8.313018e-02\n",
            "Loss: 8.311769e-02\n",
            "Loss: 8.311032e-02\n",
            "Loss: 8.310483e-02\n",
            "Loss: 8.309958e-02\n",
            "Loss: 8.309753e-02\n",
            "Loss: 8.308282e-02\n",
            "Loss: 8.307705e-02\n",
            "Loss: 8.306929e-02\n",
            "Loss: 8.305807e-02\n",
            "Loss: 8.312073e-02\n",
            "Loss: 8.305077e-02\n",
            "Loss: 8.303612e-02\n",
            "Loss: 8.302590e-02\n",
            "Loss: 8.301426e-02\n",
            "Loss: 8.300592e-02\n",
            "Loss: 8.298979e-02\n",
            "Loss: 8.298112e-02\n",
            "Loss: 8.296873e-02\n",
            "Loss: 8.296264e-02\n",
            "Loss: 8.294827e-02\n",
            "Loss: 8.294029e-02\n",
            "Loss: 8.292115e-02\n",
            "Loss: 8.291332e-02\n",
            "Loss: 8.290531e-02\n",
            "Loss: 8.289077e-02\n",
            "Loss: 8.287740e-02\n",
            "Loss: 8.287162e-02\n",
            "Loss: 8.285487e-02\n",
            "Loss: 8.284813e-02\n",
            "Loss: 8.283692e-02\n",
            "Loss: 8.282871e-02\n",
            "Loss: 8.281995e-02\n",
            "Loss: 8.280492e-02\n",
            "Loss: 8.279351e-02\n",
            "Loss: 8.279900e-02\n",
            "Loss: 8.278459e-02\n",
            "Loss: 8.277179e-02\n",
            "Loss: 8.275627e-02\n",
            "Loss: 8.275189e-02\n",
            "Loss: 8.274211e-02\n",
            "Loss: 8.273639e-02\n",
            "Loss: 8.272846e-02\n",
            "Loss: 8.271460e-02\n",
            "Loss: 8.269449e-02\n",
            "Loss: 8.268559e-02\n",
            "Loss: 8.266865e-02\n",
            "Loss: 8.266061e-02\n",
            "Loss: 8.265267e-02\n",
            "Loss: 8.264827e-02\n",
            "Loss: 8.263530e-02\n",
            "Loss: 8.262755e-02\n",
            "Loss: 8.261906e-02\n",
            "Loss: 8.261012e-02\n",
            "Loss: 8.265127e-02\n",
            "Loss: 8.260567e-02\n",
            "Loss: 8.259473e-02\n",
            "Loss: 8.258986e-02\n",
            "Loss: 8.257981e-02\n",
            "Loss: 8.256792e-02\n",
            "Loss: 8.255421e-02\n",
            "Loss: 8.259449e-02\n",
            "Loss: 8.254657e-02\n",
            "Loss: 8.253881e-02\n",
            "Loss: 8.253086e-02\n",
            "Loss: 8.252645e-02\n",
            "Loss: 8.252116e-02\n",
            "Loss: 8.251660e-02\n",
            "Loss: 8.251134e-02\n",
            "Loss: 8.250797e-02\n",
            "Loss: 8.249610e-02\n",
            "Loss: 8.248641e-02\n",
            "Loss: 8.247901e-02\n",
            "Loss: 8.247381e-02\n",
            "Loss: 8.246411e-02\n",
            "Loss: 8.245397e-02\n",
            "Loss: 8.244205e-02\n",
            "Loss: 8.243056e-02\n",
            "Loss: 8.242170e-02\n",
            "Loss: 8.241088e-02\n",
            "Loss: 8.239651e-02\n",
            "Loss: 8.237892e-02\n",
            "Loss: 8.237161e-02\n",
            "Loss: 8.236092e-02\n",
            "Loss: 8.235735e-02\n",
            "Loss: 8.234994e-02\n",
            "Loss: 8.233751e-02\n",
            "Loss: 8.235373e-02\n",
            "Loss: 8.232938e-02\n",
            "Loss: 8.231568e-02\n",
            "Loss: 8.230267e-02\n",
            "Loss: 8.229531e-02\n",
            "Loss: 8.228508e-02\n",
            "Loss: 8.227720e-02\n",
            "Loss: 8.226316e-02\n",
            "Loss: 8.225347e-02\n",
            "Loss: 8.224399e-02\n",
            "Loss: 8.223337e-02\n",
            "Loss: 8.222418e-02\n",
            "Loss: 8.221176e-02\n",
            "Loss: 8.220574e-02\n",
            "Loss: 8.219459e-02\n",
            "Loss: 8.218423e-02\n",
            "Loss: 8.217424e-02\n",
            "Loss: 8.216732e-02\n",
            "Loss: 8.216042e-02\n",
            "Loss: 8.215518e-02\n",
            "Loss: 8.215040e-02\n",
            "Loss: 8.214413e-02\n",
            "Loss: 8.214022e-02\n",
            "Loss: 8.213195e-02\n",
            "Loss: 8.212119e-02\n",
            "Loss: 8.211122e-02\n",
            "Loss: 8.210512e-02\n",
            "Loss: 8.210165e-02\n",
            "Loss: 8.209728e-02\n",
            "Loss: 8.208923e-02\n",
            "Loss: 8.224414e-02\n",
            "Loss: 8.208624e-02\n",
            "Loss: 8.207834e-02\n",
            "Loss: 8.206977e-02\n",
            "Loss: 8.206841e-02\n",
            "Loss: 8.206262e-02\n",
            "Loss: 8.206024e-02\n",
            "Loss: 8.205571e-02\n",
            "Loss: 8.205169e-02\n",
            "Loss: 8.204245e-02\n",
            "Loss: 8.203776e-02\n",
            "Loss: 8.202779e-02\n",
            "Loss: 8.202127e-02\n",
            "Loss: 8.201564e-02\n",
            "Loss: 8.200404e-02\n",
            "Loss: 8.201234e-02\n",
            "Loss: 8.199716e-02\n",
            "Loss: 8.198682e-02\n",
            "Loss: 8.197808e-02\n",
            "Loss: 8.196103e-02\n",
            "Loss: 8.195569e-02\n",
            "Loss: 8.193657e-02\n",
            "Loss: 8.192947e-02\n",
            "Loss: 8.192405e-02\n",
            "Loss: 8.191752e-02\n",
            "Loss: 8.190656e-02\n",
            "Loss: 8.189340e-02\n",
            "Loss: 8.188271e-02\n",
            "Loss: 8.187452e-02\n",
            "Loss: 8.186416e-02\n",
            "Loss: 8.185191e-02\n",
            "Loss: 8.184046e-02\n",
            "Loss: 8.183160e-02\n",
            "Loss: 8.182138e-02\n",
            "Loss: 8.182706e-02\n",
            "Loss: 8.181706e-02\n",
            "Loss: 8.180817e-02\n",
            "Loss: 8.178531e-02\n",
            "Loss: 8.176591e-02\n",
            "Loss: 8.175813e-02\n",
            "Loss: 8.174676e-02\n",
            "Loss: 8.174220e-02\n",
            "Loss: 8.173095e-02\n",
            "Loss: 8.172598e-02\n",
            "Loss: 8.171146e-02\n",
            "Loss: 8.170602e-02\n",
            "Loss: 8.170006e-02\n",
            "Loss: 8.169184e-02\n",
            "Loss: 8.167873e-02\n",
            "Loss: 8.177635e-02\n",
            "Loss: 8.167341e-02\n",
            "Loss: 8.166750e-02\n",
            "Loss: 8.165935e-02\n",
            "Loss: 8.165433e-02\n",
            "Loss: 8.164733e-02\n",
            "Loss: 8.163851e-02\n",
            "Loss: 8.162291e-02\n",
            "Loss: 8.174818e-02\n",
            "Loss: 8.161938e-02\n",
            "Loss: 8.161087e-02\n",
            "Loss: 8.160569e-02\n",
            "Loss: 8.159955e-02\n",
            "Loss: 8.159396e-02\n",
            "Loss: 8.158758e-02\n",
            "Loss: 8.157883e-02\n",
            "Loss: 8.157163e-02\n",
            "Loss: 8.156405e-02\n",
            "Loss: 8.156940e-02\n",
            "Loss: 8.155862e-02\n",
            "Loss: 8.154787e-02\n",
            "Loss: 8.153784e-02\n",
            "Loss: 8.152856e-02\n",
            "Loss: 8.151875e-02\n",
            "Loss: 8.152540e-02\n",
            "Loss: 8.151305e-02\n",
            "Loss: 8.150549e-02\n",
            "Loss: 8.149630e-02\n",
            "Loss: 8.148683e-02\n",
            "Loss: 8.147864e-02\n",
            "Loss: 8.147299e-02\n",
            "Loss: 8.146753e-02\n",
            "Loss: 8.146358e-02\n",
            "Loss: 8.145340e-02\n",
            "Loss: 8.143692e-02\n",
            "Loss: 8.144400e-02\n",
            "Loss: 8.142712e-02\n",
            "Loss: 8.141747e-02\n",
            "Loss: 8.141279e-02\n",
            "Loss: 8.140619e-02\n",
            "Loss: 8.139729e-02\n",
            "Loss: 8.138668e-02\n",
            "Loss: 8.137878e-02\n",
            "Loss: 8.137144e-02\n",
            "Loss: 8.136444e-02\n",
            "Loss: 8.136130e-02\n",
            "Loss: 8.134979e-02\n",
            "Loss: 8.134086e-02\n",
            "Loss: 8.133995e-02\n",
            "Loss: 8.133328e-02\n",
            "Loss: 8.132353e-02\n",
            "Loss: 8.131809e-02\n",
            "Loss: 8.130991e-02\n",
            "Loss: 8.130450e-02\n",
            "Loss: 8.129796e-02\n",
            "Loss: 8.129360e-02\n",
            "Loss: 8.128961e-02\n",
            "Loss: 8.128554e-02\n",
            "Loss: 8.127882e-02\n",
            "Loss: 8.140097e-02\n",
            "Loss: 8.127719e-02\n",
            "Loss: 8.127170e-02\n",
            "Loss: 8.126619e-02\n",
            "Loss: 8.126146e-02\n",
            "Loss: 8.125544e-02\n",
            "Loss: 8.124421e-02\n",
            "Loss: 8.128685e-02\n",
            "Loss: 8.124063e-02\n",
            "Loss: 8.122964e-02\n",
            "Loss: 8.122358e-02\n",
            "Loss: 8.121679e-02\n",
            "Loss: 8.121403e-02\n",
            "Loss: 8.120799e-02\n",
            "Loss: 8.120409e-02\n",
            "Loss: 8.119168e-02\n",
            "Loss: 8.118211e-02\n",
            "Loss: 8.117450e-02\n",
            "Loss: 8.116954e-02\n",
            "Loss: 8.116567e-02\n",
            "Loss: 8.116110e-02\n",
            "Loss: 8.115155e-02\n",
            "Loss: 8.113959e-02\n",
            "Loss: 8.114987e-02\n",
            "Loss: 8.113232e-02\n",
            "Loss: 8.112552e-02\n",
            "Loss: 8.112262e-02\n",
            "Loss: 8.111762e-02\n",
            "Loss: 8.111492e-02\n",
            "Loss: 8.110747e-02\n",
            "Loss: 8.110180e-02\n",
            "Loss: 8.109357e-02\n",
            "Loss: 8.108972e-02\n",
            "Loss: 8.108426e-02\n",
            "Loss: 8.108042e-02\n",
            "Loss: 8.107530e-02\n",
            "Loss: 8.106582e-02\n",
            "Loss: 8.105764e-02\n",
            "Loss: 8.106077e-02\n",
            "Loss: 8.105256e-02\n",
            "Loss: 8.104468e-02\n",
            "Loss: 8.103961e-02\n",
            "Loss: 8.102911e-02\n",
            "Loss: 8.102337e-02\n",
            "Loss: 8.101546e-02\n",
            "Loss: 8.100435e-02\n",
            "Loss: 8.100992e-02\n",
            "Loss: 8.099797e-02\n",
            "Loss: 8.099005e-02\n",
            "Loss: 8.098413e-02\n",
            "Loss: 8.097255e-02\n",
            "Loss: 8.099241e-02\n",
            "Loss: 8.096856e-02\n",
            "Loss: 8.095785e-02\n",
            "Loss: 8.094831e-02\n",
            "Loss: 8.093693e-02\n",
            "Loss: 8.092725e-02\n",
            "Loss: 8.091563e-02\n",
            "Loss: 8.092925e-02\n",
            "Loss: 8.090956e-02\n",
            "Loss: 8.089942e-02\n",
            "Loss: 8.089319e-02\n",
            "Loss: 8.088778e-02\n",
            "Loss: 8.087448e-02\n",
            "Loss: 8.087440e-02\n",
            "Loss: 8.086763e-02\n",
            "Loss: 8.085721e-02\n",
            "Loss: 8.085196e-02\n",
            "Loss: 8.084699e-02\n",
            "Loss: 8.084183e-02\n",
            "Loss: 8.083114e-02\n",
            "Loss: 8.082169e-02\n",
            "Loss: 8.081729e-02\n",
            "Loss: 8.081094e-02\n",
            "Loss: 8.080582e-02\n",
            "Loss: 8.082581e-02\n",
            "Loss: 8.080260e-02\n",
            "Loss: 8.079398e-02\n",
            "Loss: 8.078767e-02\n",
            "Loss: 8.078074e-02\n",
            "Loss: 8.077229e-02\n",
            "Loss: 8.076013e-02\n",
            "Loss: 8.076145e-02\n",
            "Loss: 8.075391e-02\n",
            "Loss: 8.074612e-02\n",
            "Loss: 8.074048e-02\n",
            "Loss: 8.073926e-02\n",
            "Loss: 8.073431e-02\n",
            "Loss: 8.073099e-02\n",
            "Loss: 8.072734e-02\n",
            "Loss: 8.071940e-02\n",
            "Loss: 8.070172e-02\n",
            "Loss: 8.068964e-02\n",
            "Loss: 8.067597e-02\n",
            "Loss: 8.066717e-02\n",
            "Loss: 8.065562e-02\n",
            "Loss: 8.064006e-02\n",
            "Loss: 8.063325e-02\n",
            "Loss: 8.062586e-02\n",
            "Loss: 8.062157e-02\n",
            "Loss: 8.062003e-02\n",
            "Loss: 8.061334e-02\n",
            "Loss: 8.060776e-02\n",
            "Loss: 8.060156e-02\n",
            "Loss: 8.059497e-02\n",
            "Loss: 8.058477e-02\n",
            "Loss: 8.057886e-02\n",
            "Loss: 8.057450e-02\n",
            "Loss: 8.057155e-02\n",
            "Loss: 8.056965e-02\n",
            "Loss: 8.056547e-02\n",
            "Loss: 8.055967e-02\n",
            "Loss: 8.055229e-02\n",
            "Loss: 8.055279e-02\n",
            "Loss: 8.054857e-02\n",
            "Loss: 8.054399e-02\n",
            "Loss: 8.054175e-02\n",
            "Loss: 8.053706e-02\n",
            "Loss: 8.052889e-02\n",
            "Loss: 8.051977e-02\n",
            "Loss: 8.054382e-02\n",
            "Loss: 8.051661e-02\n",
            "Loss: 8.051274e-02\n",
            "Loss: 8.050624e-02\n",
            "Loss: 8.049686e-02\n",
            "Loss: 8.048355e-02\n",
            "Loss: 8.048248e-02\n",
            "Loss: 8.047640e-02\n",
            "Loss: 8.046567e-02\n",
            "Loss: 8.046114e-02\n",
            "Loss: 8.045637e-02\n",
            "Loss: 8.044925e-02\n",
            "Loss: 8.045657e-02\n",
            "Loss: 8.044670e-02\n",
            "Loss: 8.044036e-02\n",
            "Loss: 8.043728e-02\n",
            "Loss: 8.043287e-02\n",
            "Loss: 8.042667e-02\n",
            "Loss: 8.041776e-02\n",
            "Loss: 8.042022e-02\n",
            "Loss: 8.041330e-02\n",
            "Loss: 8.040742e-02\n",
            "Loss: 8.040011e-02\n",
            "Loss: 8.039415e-02\n",
            "Loss: 8.039627e-02\n",
            "Loss: 8.039030e-02\n",
            "Loss: 8.038361e-02\n",
            "Loss: 8.038007e-02\n",
            "Loss: 8.037277e-02\n",
            "Loss: 8.036216e-02\n",
            "Loss: 8.036061e-02\n",
            "Loss: 8.034768e-02\n",
            "Loss: 8.034336e-02\n",
            "Loss: 8.033453e-02\n",
            "Loss: 8.032535e-02\n",
            "Loss: 8.031933e-02\n",
            "Loss: 8.031215e-02\n",
            "Loss: 8.030791e-02\n",
            "Loss: 8.029844e-02\n",
            "Loss: 8.029231e-02\n",
            "Loss: 8.028348e-02\n",
            "Loss: 8.027833e-02\n",
            "Loss: 8.026540e-02\n",
            "Loss: 8.025806e-02\n",
            "Loss: 8.024815e-02\n",
            "Loss: 8.024330e-02\n",
            "Loss: 8.023751e-02\n",
            "Loss: 8.022991e-02\n",
            "Loss: 8.022514e-02\n",
            "Loss: 8.021767e-02\n",
            "Loss: 8.020924e-02\n",
            "Loss: 8.021545e-02\n",
            "Loss: 8.020449e-02\n",
            "Loss: 8.019771e-02\n",
            "Loss: 8.019508e-02\n",
            "Loss: 8.019179e-02\n",
            "Loss: 8.018628e-02\n",
            "Loss: 8.018377e-02\n",
            "Loss: 8.017515e-02\n",
            "Loss: 8.017044e-02\n",
            "Loss: 8.016525e-02\n",
            "Loss: 8.015937e-02\n",
            "Loss: 8.015567e-02\n",
            "Loss: 8.014072e-02\n",
            "Loss: 8.013621e-02\n",
            "Loss: 8.012789e-02\n",
            "Loss: 8.013167e-02\n",
            "Loss: 8.012192e-02\n",
            "Loss: 8.011238e-02\n",
            "Loss: 8.010802e-02\n",
            "Loss: 8.010188e-02\n",
            "Loss: 8.009788e-02\n",
            "Loss: 8.009534e-02\n",
            "Loss: 8.009002e-02\n",
            "Loss: 8.008385e-02\n",
            "Loss: 8.007295e-02\n",
            "Loss: 8.009454e-02\n",
            "Loss: 8.006689e-02\n",
            "Loss: 8.005961e-02\n",
            "Loss: 8.005079e-02\n",
            "Loss: 8.004251e-02\n",
            "Loss: 8.003506e-02\n",
            "Loss: 8.002834e-02\n",
            "Loss: 8.002279e-02\n",
            "Loss: 8.001912e-02\n",
            "Loss: 8.000728e-02\n",
            "Loss: 7.999174e-02\n",
            "Loss: 7.998215e-02\n",
            "Loss: 7.997415e-02\n",
            "Loss: 7.996919e-02\n",
            "Loss: 7.996375e-02\n",
            "Loss: 7.995871e-02\n",
            "Loss: 7.995024e-02\n",
            "Loss: 7.994780e-02\n",
            "Loss: 7.994177e-02\n",
            "Loss: 7.993145e-02\n",
            "Loss: 8.008235e-02\n",
            "Loss: 7.992799e-02\n",
            "Loss: 7.991561e-02\n",
            "Loss: 7.990393e-02\n",
            "Loss: 7.989479e-02\n",
            "Loss: 7.988498e-02\n",
            "Loss: 7.987858e-02\n",
            "Loss: 7.987063e-02\n",
            "Loss: 7.986590e-02\n",
            "Loss: 7.986197e-02\n",
            "Loss: 7.985693e-02\n",
            "Loss: 7.985530e-02\n",
            "Loss: 7.985068e-02\n",
            "Loss: 7.984766e-02\n",
            "Loss: 7.984386e-02\n",
            "Loss: 7.983821e-02\n",
            "Loss: 7.982853e-02\n",
            "Loss: 7.982326e-02\n",
            "Loss: 7.981327e-02\n",
            "Loss: 7.980842e-02\n",
            "Loss: 7.980207e-02\n",
            "Loss: 7.979321e-02\n",
            "Loss: 7.979529e-02\n",
            "Loss: 7.978880e-02\n",
            "Loss: 7.978395e-02\n",
            "Loss: 7.978068e-02\n",
            "Loss: 7.977391e-02\n",
            "Loss: 7.976226e-02\n",
            "Loss: 7.982162e-02\n",
            "Loss: 7.975842e-02\n",
            "Loss: 7.975197e-02\n",
            "Loss: 7.974536e-02\n",
            "Loss: 7.973793e-02\n",
            "Loss: 7.972877e-02\n",
            "Loss: 7.971599e-02\n",
            "Loss: 7.969377e-02\n",
            "Loss: 7.968938e-02\n",
            "Loss: 7.967771e-02\n",
            "Loss: 7.967330e-02\n",
            "Loss: 7.966851e-02\n",
            "Loss: 7.967640e-02\n",
            "Loss: 7.966564e-02\n",
            "Loss: 7.966010e-02\n",
            "Loss: 7.964365e-02\n",
            "Loss: 7.962468e-02\n",
            "Loss: 7.961059e-02\n",
            "Loss: 7.960089e-02\n",
            "Loss: 7.959297e-02\n",
            "Loss: 7.958702e-02\n",
            "Loss: 7.957890e-02\n",
            "Loss: 7.957080e-02\n",
            "Loss: 7.956354e-02\n",
            "Loss: 7.955581e-02\n",
            "Loss: 7.955161e-02\n",
            "Loss: 7.954504e-02\n",
            "Loss: 7.953946e-02\n",
            "Loss: 7.953793e-02\n",
            "Loss: 7.953209e-02\n",
            "Loss: 7.952935e-02\n",
            "Loss: 7.952645e-02\n",
            "Loss: 7.952117e-02\n",
            "Loss: 7.953362e-02\n",
            "Loss: 7.951948e-02\n",
            "Loss: 7.951413e-02\n",
            "Loss: 7.951035e-02\n",
            "Loss: 7.950578e-02\n",
            "Loss: 7.950014e-02\n",
            "Loss: 7.949236e-02\n",
            "Loss: 7.949314e-02\n",
            "Loss: 7.948633e-02\n",
            "Loss: 7.948024e-02\n",
            "Loss: 7.947450e-02\n",
            "Loss: 7.947131e-02\n",
            "Loss: 7.946508e-02\n",
            "Loss: 7.945745e-02\n",
            "Loss: 7.945044e-02\n",
            "Loss: 7.944860e-02\n",
            "Loss: 7.944208e-02\n",
            "Loss: 7.944078e-02\n",
            "Loss: 7.943583e-02\n",
            "Loss: 7.943429e-02\n",
            "Loss: 7.943203e-02\n",
            "Loss: 7.942883e-02\n",
            "Loss: 7.942698e-02\n",
            "Loss: 7.942426e-02\n",
            "Loss: 7.942598e-02\n",
            "Loss: 7.942204e-02\n",
            "Loss: 7.941926e-02\n",
            "Loss: 7.941318e-02\n",
            "Loss: 7.941084e-02\n",
            "Loss: 7.940505e-02\n",
            "Loss: 7.939886e-02\n",
            "Loss: 7.939335e-02\n",
            "Loss: 7.938733e-02\n",
            "Loss: 7.938570e-02\n",
            "Loss: 7.938366e-02\n",
            "Loss: 7.937949e-02\n",
            "Loss: 7.937717e-02\n",
            "Loss: 7.937136e-02\n",
            "Loss: 7.936535e-02\n",
            "Loss: 7.935428e-02\n",
            "Loss: 7.938775e-02\n",
            "Loss: 7.935169e-02\n",
            "Loss: 7.934406e-02\n",
            "Loss: 7.934006e-02\n",
            "Loss: 7.933615e-02\n",
            "Loss: 7.933259e-02\n",
            "Loss: 7.932834e-02\n",
            "Loss: 7.932155e-02\n",
            "Loss: 7.932577e-02\n",
            "Loss: 7.931923e-02\n",
            "Loss: 7.931574e-02\n",
            "Loss: 7.931048e-02\n",
            "Loss: 7.930283e-02\n",
            "Loss: 7.929529e-02\n",
            "Loss: 7.928580e-02\n",
            "Loss: 7.928207e-02\n",
            "Loss: 7.927672e-02\n",
            "Loss: 7.927415e-02\n",
            "Loss: 7.927016e-02\n",
            "Loss: 7.926587e-02\n",
            "Loss: 7.926145e-02\n",
            "Loss: 7.925578e-02\n",
            "Loss: 7.924521e-02\n",
            "Loss: 7.925349e-02\n",
            "Loss: 7.924031e-02\n",
            "Loss: 7.923336e-02\n",
            "Loss: 7.922939e-02\n",
            "Loss: 7.922504e-02\n",
            "Loss: 7.922151e-02\n",
            "Loss: 7.921698e-02\n",
            "Loss: 7.920901e-02\n",
            "Loss: 7.920705e-02\n",
            "Loss: 7.919919e-02\n",
            "Loss: 7.919724e-02\n",
            "Loss: 7.919401e-02\n",
            "Loss: 7.919124e-02\n",
            "Loss: 7.918760e-02\n",
            "Loss: 7.918231e-02\n",
            "Loss: 7.917954e-02\n",
            "Loss: 7.917422e-02\n",
            "Loss: 7.917441e-02\n",
            "Loss: 7.917194e-02\n",
            "Loss: 7.916868e-02\n",
            "Loss: 7.916567e-02\n",
            "Loss: 7.916063e-02\n",
            "Loss: 7.915561e-02\n",
            "Loss: 7.915010e-02\n",
            "Loss: 7.914016e-02\n",
            "Loss: 7.913256e-02\n",
            "Loss: 7.914858e-02\n",
            "Loss: 7.912987e-02\n",
            "Loss: 7.912346e-02\n",
            "Loss: 7.912029e-02\n",
            "Loss: 7.911632e-02\n",
            "Loss: 7.911324e-02\n",
            "Loss: 7.910934e-02\n",
            "Loss: 7.910547e-02\n",
            "Loss: 7.910287e-02\n",
            "Loss: 7.909567e-02\n",
            "Loss: 7.909150e-02\n",
            "Loss: 7.908737e-02\n",
            "Loss: 7.908249e-02\n",
            "Loss: 7.907315e-02\n",
            "Loss: 7.907757e-02\n",
            "Loss: 7.907060e-02\n",
            "Loss: 7.906576e-02\n",
            "Loss: 7.906084e-02\n",
            "Loss: 7.905738e-02\n",
            "Loss: 7.905246e-02\n",
            "Loss: 7.905027e-02\n",
            "Loss: 7.904869e-02\n",
            "Loss: 7.904535e-02\n",
            "Loss: 7.904229e-02\n",
            "Loss: 7.903667e-02\n",
            "Loss: 7.909338e-02\n",
            "Loss: 7.903536e-02\n",
            "Loss: 7.903033e-02\n",
            "Loss: 7.902613e-02\n",
            "Loss: 7.902336e-02\n",
            "Loss: 7.902028e-02\n",
            "Loss: 7.901802e-02\n",
            "Loss: 7.901403e-02\n",
            "Loss: 7.901164e-02\n",
            "Loss: 7.900924e-02\n",
            "Loss: 7.900565e-02\n",
            "Loss: 7.900022e-02\n",
            "Loss: 7.899815e-02\n",
            "Loss: 7.899370e-02\n",
            "Loss: 7.899057e-02\n",
            "Loss: 7.898598e-02\n",
            "Loss: 7.897938e-02\n",
            "Loss: 7.897250e-02\n",
            "Loss: 7.896872e-02\n",
            "Loss: 7.896895e-02\n",
            "Loss: 7.896709e-02\n",
            "Loss: 7.896540e-02\n",
            "Loss: 7.895726e-02\n",
            "Loss: 7.896969e-02\n",
            "Loss: 7.895576e-02\n",
            "Loss: 7.895415e-02\n",
            "Loss: 7.895167e-02\n",
            "Loss: 7.894823e-02\n",
            "Loss: 7.894228e-02\n",
            "Loss: 7.893889e-02\n",
            "Loss: 7.893600e-02\n",
            "Loss: 7.893311e-02\n",
            "Loss: 7.892947e-02\n",
            "Loss: 7.892375e-02\n",
            "Loss: 7.892906e-02\n",
            "Loss: 7.892090e-02\n",
            "Loss: 7.891766e-02\n",
            "Loss: 7.891469e-02\n",
            "Loss: 7.891294e-02\n",
            "Loss: 7.890900e-02\n",
            "Loss: 7.890661e-02\n",
            "Loss: 7.890477e-02\n",
            "Loss: 7.890164e-02\n",
            "Loss: 7.889753e-02\n",
            "Loss: 7.889146e-02\n",
            "Loss: 7.888547e-02\n",
            "Loss: 7.888021e-02\n",
            "Loss: 7.887622e-02\n",
            "Loss: 7.887270e-02\n",
            "Loss: 7.886858e-02\n",
            "Loss: 7.887056e-02\n",
            "Loss: 7.886638e-02\n",
            "Loss: 7.886247e-02\n",
            "Loss: 7.885958e-02\n",
            "Loss: 7.885709e-02\n",
            "Loss: 7.885384e-02\n",
            "Loss: 7.884912e-02\n",
            "Loss: 7.884758e-02\n",
            "Loss: 7.884210e-02\n",
            "Loss: 7.883904e-02\n",
            "Loss: 7.883569e-02\n",
            "Loss: 7.883365e-02\n",
            "Loss: 7.882874e-02\n",
            "Loss: 7.882334e-02\n",
            "Loss: 7.881778e-02\n",
            "Loss: 7.880995e-02\n",
            "Loss: 7.880416e-02\n",
            "Loss: 7.879825e-02\n",
            "Loss: 7.879540e-02\n",
            "Loss: 7.881357e-02\n",
            "Loss: 7.879283e-02\n",
            "Loss: 7.878999e-02\n",
            "Loss: 7.878652e-02\n",
            "Loss: 7.878153e-02\n",
            "Loss: 7.877550e-02\n",
            "Loss: 7.876587e-02\n",
            "Loss: 7.878157e-02\n",
            "Loss: 7.876039e-02\n",
            "Loss: 7.875221e-02\n",
            "Loss: 7.874589e-02\n",
            "Loss: 7.873905e-02\n",
            "Loss: 7.873404e-02\n",
            "Loss: 7.872924e-02\n",
            "Loss: 7.872564e-02\n",
            "Loss: 7.872295e-02\n",
            "Loss: 7.871975e-02\n",
            "Loss: 7.871601e-02\n",
            "Loss: 7.871220e-02\n",
            "Loss: 7.870549e-02\n",
            "Loss: 7.870579e-02\n",
            "Loss: 7.870198e-02\n",
            "Loss: 7.869837e-02\n",
            "Loss: 7.869489e-02\n",
            "Loss: 7.869103e-02\n",
            "Loss: 7.868084e-02\n",
            "Loss: 7.867139e-02\n",
            "Loss: 7.866263e-02\n",
            "Loss: 7.865783e-02\n",
            "Loss: 7.865416e-02\n",
            "Loss: 7.864921e-02\n",
            "Loss: 7.864240e-02\n",
            "Loss: 7.864197e-02\n",
            "Loss: 7.863866e-02\n",
            "Loss: 7.863149e-02\n",
            "Loss: 7.862767e-02\n",
            "Loss: 7.862234e-02\n",
            "Loss: 7.862318e-02\n",
            "Loss: 7.862038e-02\n",
            "Loss: 7.861754e-02\n",
            "Loss: 7.861324e-02\n",
            "Loss: 7.860929e-02\n",
            "Loss: 7.859950e-02\n",
            "Loss: 7.859144e-02\n",
            "Loss: 7.858580e-02\n",
            "Loss: 7.857978e-02\n",
            "Loss: 7.857443e-02\n",
            "Loss: 7.857039e-02\n",
            "Loss: 7.856639e-02\n",
            "Loss: 7.856397e-02\n",
            "Loss: 7.856236e-02\n",
            "Loss: 7.855960e-02\n",
            "Loss: 7.855582e-02\n",
            "Loss: 7.855376e-02\n",
            "Loss: 7.854808e-02\n",
            "Loss: 7.854415e-02\n",
            "Loss: 7.853900e-02\n",
            "Loss: 7.853412e-02\n",
            "Loss: 7.852964e-02\n",
            "Loss: 7.852136e-02\n",
            "Loss: 7.851730e-02\n",
            "Loss: 7.851253e-02\n",
            "Loss: 7.850799e-02\n",
            "Loss: 7.850131e-02\n",
            "Loss: 7.849075e-02\n",
            "Loss: 7.847861e-02\n",
            "Loss: 7.847009e-02\n",
            "Loss: 7.846472e-02\n",
            "Loss: 7.845860e-02\n",
            "Loss: 7.845431e-02\n",
            "Loss: 7.845009e-02\n",
            "Loss: 7.844880e-02\n",
            "Loss: 7.844177e-02\n",
            "Loss: 7.843921e-02\n",
            "Loss: 7.843553e-02\n",
            "Loss: 7.843022e-02\n",
            "Loss: 7.842147e-02\n",
            "Loss: 7.842388e-02\n",
            "Loss: 7.841711e-02\n",
            "Loss: 7.841235e-02\n",
            "Loss: 7.840803e-02\n",
            "Loss: 7.840572e-02\n",
            "Loss: 7.840221e-02\n",
            "Loss: 7.839891e-02\n",
            "Loss: 7.839654e-02\n",
            "Loss: 7.839240e-02\n",
            "Loss: 7.838427e-02\n",
            "Loss: 7.842668e-02\n",
            "Loss: 7.838129e-02\n",
            "Loss: 7.837520e-02\n",
            "Loss: 7.836854e-02\n",
            "Loss: 7.836227e-02\n",
            "Loss: 7.835712e-02\n",
            "Loss: 7.835146e-02\n",
            "Loss: 7.834789e-02\n",
            "Loss: 7.834595e-02\n",
            "Loss: 7.834423e-02\n",
            "Loss: 7.834184e-02\n",
            "Loss: 7.833867e-02\n",
            "Loss: 7.833610e-02\n",
            "Loss: 7.833312e-02\n",
            "Loss: 7.833005e-02\n",
            "Loss: 7.832716e-02\n",
            "Loss: 7.832364e-02\n",
            "Loss: 7.831963e-02\n",
            "Loss: 7.831579e-02\n",
            "Loss: 7.831345e-02\n",
            "Loss: 7.830977e-02\n",
            "Loss: 7.830755e-02\n",
            "Loss: 7.830273e-02\n",
            "Loss: 7.829793e-02\n",
            "Loss: 7.828629e-02\n",
            "Loss: 7.827934e-02\n",
            "Loss: 7.827275e-02\n",
            "Loss: 7.826615e-02\n",
            "Loss: 7.826152e-02\n",
            "Loss: 7.824823e-02\n",
            "Loss: 7.823607e-02\n",
            "Loss: 7.825655e-02\n",
            "Loss: 7.822930e-02\n",
            "Loss: 7.822251e-02\n",
            "Loss: 7.821874e-02\n",
            "Loss: 7.821602e-02\n",
            "Loss: 7.821190e-02\n",
            "Loss: 7.821021e-02\n",
            "Loss: 7.820766e-02\n",
            "Loss: 7.820400e-02\n",
            "Loss: 7.820184e-02\n",
            "Loss: 7.819711e-02\n",
            "Loss: 7.819274e-02\n",
            "Loss: 7.818731e-02\n",
            "Loss: 7.818157e-02\n",
            "Loss: 7.817722e-02\n",
            "Loss: 7.817006e-02\n",
            "Loss: 7.816611e-02\n",
            "Loss: 7.816254e-02\n",
            "Loss: 7.816297e-02\n",
            "Loss: 7.816026e-02\n",
            "Loss: 7.815618e-02\n",
            "Loss: 7.815112e-02\n",
            "Loss: 7.814524e-02\n",
            "Loss: 7.814144e-02\n",
            "Loss: 7.813613e-02\n",
            "Loss: 7.813123e-02\n",
            "Loss: 7.812732e-02\n",
            "Loss: 7.812110e-02\n",
            "Loss: 7.811744e-02\n",
            "Loss: 7.811308e-02\n",
            "Loss: 7.811664e-02\n",
            "Loss: 7.811197e-02\n",
            "Loss: 7.810941e-02\n",
            "Loss: 7.810786e-02\n",
            "Loss: 7.810611e-02\n",
            "Loss: 7.810353e-02\n",
            "Loss: 7.810070e-02\n",
            "Loss: 7.809856e-02\n",
            "Loss: 7.809397e-02\n",
            "Loss: 7.808900e-02\n",
            "Loss: 7.809258e-02\n",
            "Loss: 7.808688e-02\n",
            "Loss: 7.808310e-02\n",
            "Loss: 7.808071e-02\n",
            "Loss: 7.807886e-02\n",
            "Loss: 7.807761e-02\n",
            "Loss: 7.807586e-02\n",
            "Loss: 7.807450e-02\n",
            "Loss: 7.806949e-02\n",
            "Loss: 7.806726e-02\n",
            "Loss: 7.806173e-02\n",
            "Loss: 7.805848e-02\n",
            "Loss: 7.805318e-02\n",
            "Loss: 7.805414e-02\n",
            "Loss: 7.804966e-02\n",
            "Loss: 7.804500e-02\n",
            "Loss: 7.803893e-02\n",
            "Loss: 7.803630e-02\n",
            "Loss: 7.803047e-02\n",
            "Loss: 7.803391e-02\n",
            "Loss: 7.802783e-02\n",
            "Loss: 7.802423e-02\n",
            "Loss: 7.801959e-02\n",
            "Loss: 7.801471e-02\n",
            "Loss: 7.801363e-02\n",
            "Loss: 7.800807e-02\n",
            "Loss: 7.800648e-02\n",
            "Loss: 7.800388e-02\n",
            "Loss: 7.800207e-02\n",
            "Loss: 7.799684e-02\n",
            "Loss: 7.799481e-02\n",
            "Loss: 7.799125e-02\n",
            "Loss: 7.798686e-02\n",
            "Loss: 7.798136e-02\n",
            "Loss: 7.797559e-02\n",
            "Loss: 7.797279e-02\n",
            "Loss: 7.796900e-02\n",
            "Loss: 7.796623e-02\n",
            "Loss: 7.796338e-02\n",
            "Loss: 7.795677e-02\n",
            "Loss: 7.795112e-02\n",
            "Loss: 7.794620e-02\n",
            "Loss: 7.794303e-02\n",
            "Loss: 7.793597e-02\n",
            "Loss: 7.793082e-02\n",
            "Loss: 7.792439e-02\n",
            "Loss: 7.792021e-02\n",
            "Loss: 7.791648e-02\n",
            "Loss: 7.791468e-02\n",
            "Loss: 7.791087e-02\n",
            "Loss: 7.791394e-02\n",
            "Loss: 7.790764e-02\n",
            "Loss: 7.790470e-02\n",
            "Loss: 7.789786e-02\n",
            "Loss: 7.789148e-02\n",
            "Loss: 7.788302e-02\n",
            "Loss: 7.791530e-02\n",
            "Loss: 7.788101e-02\n",
            "Loss: 7.787812e-02\n",
            "Loss: 7.787573e-02\n",
            "Loss: 7.787439e-02\n",
            "Loss: 7.787132e-02\n",
            "Loss: 7.786935e-02\n",
            "Loss: 7.786790e-02\n",
            "Loss: 7.786267e-02\n",
            "Loss: 7.785694e-02\n",
            "Loss: 7.786170e-02\n",
            "Loss: 7.785258e-02\n",
            "Loss: 7.784938e-02\n",
            "Loss: 7.784511e-02\n",
            "Loss: 7.784086e-02\n",
            "Loss: 7.784942e-02\n",
            "Loss: 7.783889e-02\n",
            "Loss: 7.783587e-02\n",
            "Loss: 7.783312e-02\n",
            "Loss: 7.783008e-02\n",
            "Loss: 7.782498e-02\n",
            "Loss: 7.783144e-02\n",
            "Loss: 7.782143e-02\n",
            "Loss: 7.781460e-02\n",
            "Loss: 7.780696e-02\n",
            "Loss: 7.780153e-02\n",
            "Loss: 7.779680e-02\n",
            "Loss: 7.780670e-02\n",
            "Loss: 7.779462e-02\n",
            "Loss: 7.779102e-02\n",
            "Loss: 7.778808e-02\n",
            "Loss: 7.778526e-02\n",
            "Loss: 7.778330e-02\n",
            "Loss: 7.778008e-02\n",
            "Loss: 7.777810e-02\n",
            "Loss: 7.777566e-02\n",
            "Loss: 7.777094e-02\n",
            "Loss: 7.776563e-02\n",
            "Loss: 7.775990e-02\n",
            "Loss: 7.775548e-02\n",
            "Loss: 7.775171e-02\n",
            "Loss: 7.774875e-02\n",
            "Loss: 7.774597e-02\n",
            "Loss: 7.774112e-02\n",
            "Loss: 7.773829e-02\n",
            "Loss: 7.773206e-02\n",
            "Loss: 7.772867e-02\n",
            "Loss: 7.771970e-02\n",
            "Loss: 7.771279e-02\n",
            "Loss: 7.770690e-02\n",
            "Loss: 7.770019e-02\n",
            "Loss: 7.769523e-02\n",
            "Loss: 7.769007e-02\n",
            "Loss: 7.768606e-02\n",
            "Loss: 7.768069e-02\n",
            "Loss: 7.767709e-02\n",
            "Loss: 7.767185e-02\n",
            "Loss: 7.767911e-02\n",
            "Loss: 7.767014e-02\n",
            "Loss: 7.766812e-02\n",
            "Loss: 7.766660e-02\n",
            "Loss: 7.766450e-02\n",
            "Loss: 7.767295e-02\n",
            "Loss: 7.766353e-02\n",
            "Loss: 7.766077e-02\n",
            "Loss: 7.765789e-02\n",
            "Loss: 7.765549e-02\n",
            "Loss: 7.765358e-02\n",
            "Loss: 7.764976e-02\n",
            "Loss: 7.764543e-02\n",
            "Loss: 7.763942e-02\n",
            "Loss: 7.763608e-02\n",
            "Loss: 7.763287e-02\n",
            "Loss: 7.766733e-02\n",
            "Loss: 7.763183e-02\n",
            "Loss: 7.763082e-02\n",
            "Loss: 7.762336e-02\n",
            "Loss: 7.761762e-02\n",
            "Loss: 7.760672e-02\n",
            "Loss: 7.763574e-02\n",
            "Loss: 7.760216e-02\n",
            "Loss: 7.759104e-02\n",
            "Loss: 7.758611e-02\n",
            "Loss: 7.758032e-02\n",
            "Loss: 7.757749e-02\n",
            "Loss: 7.757295e-02\n",
            "Loss: 7.756799e-02\n",
            "Loss: 7.756199e-02\n",
            "Loss: 7.755621e-02\n",
            "Loss: 7.754632e-02\n",
            "Loss: 7.754308e-02\n",
            "Loss: 7.753779e-02\n",
            "Loss: 7.753160e-02\n",
            "Loss: 7.753780e-02\n",
            "Loss: 7.752718e-02\n",
            "Loss: 7.751895e-02\n",
            "Loss: 7.751486e-02\n",
            "Loss: 7.750893e-02\n",
            "Loss: 7.750635e-02\n",
            "Loss: 7.750032e-02\n",
            "Loss: 7.749704e-02\n",
            "Loss: 7.749292e-02\n",
            "Loss: 7.748579e-02\n",
            "Loss: 7.748720e-02\n",
            "Loss: 7.748050e-02\n",
            "Loss: 7.747122e-02\n",
            "Loss: 7.746676e-02\n",
            "Loss: 7.746127e-02\n",
            "Loss: 7.745580e-02\n",
            "Loss: 7.745005e-02\n",
            "Loss: 7.744845e-02\n",
            "Loss: 7.744095e-02\n",
            "Loss: 7.743728e-02\n",
            "Loss: 7.743384e-02\n",
            "Loss: 7.742736e-02\n",
            "Loss: 7.743743e-02\n",
            "Loss: 7.742541e-02\n",
            "Loss: 7.742043e-02\n",
            "Loss: 7.741772e-02\n",
            "Loss: 7.741325e-02\n",
            "Loss: 7.741446e-02\n",
            "Loss: 7.741186e-02\n",
            "Loss: 7.740849e-02\n",
            "Loss: 7.740600e-02\n",
            "Loss: 7.739887e-02\n",
            "Loss: 7.738844e-02\n",
            "Loss: 7.737739e-02\n",
            "Loss: 7.736836e-02\n",
            "Loss: 7.736459e-02\n",
            "Loss: 7.736142e-02\n",
            "Loss: 7.735918e-02\n",
            "Loss: 7.735290e-02\n",
            "Loss: 7.735798e-02\n",
            "Loss: 7.735124e-02\n",
            "Loss: 7.734739e-02\n",
            "Loss: 7.734442e-02\n",
            "Loss: 7.734121e-02\n",
            "Loss: 7.733826e-02\n",
            "Loss: 7.733360e-02\n",
            "Loss: 7.733384e-02\n",
            "Loss: 7.733126e-02\n",
            "Loss: 7.732791e-02\n",
            "Loss: 7.732689e-02\n",
            "Loss: 7.732387e-02\n",
            "Loss: 7.731946e-02\n",
            "Loss: 7.731840e-02\n",
            "Loss: 7.731107e-02\n",
            "Loss: 7.730775e-02\n",
            "Loss: 7.730401e-02\n",
            "Loss: 7.729993e-02\n",
            "Loss: 7.729528e-02\n",
            "Loss: 7.728770e-02\n",
            "Loss: 7.728259e-02\n",
            "Loss: 7.727936e-02\n",
            "Loss: 7.727534e-02\n",
            "Loss: 7.727112e-02\n",
            "Loss: 7.725981e-02\n",
            "Loss: 7.725726e-02\n",
            "Loss: 7.724894e-02\n",
            "Loss: 7.724628e-02\n",
            "Loss: 7.724386e-02\n",
            "Loss: 7.723957e-02\n",
            "Loss: 7.723422e-02\n",
            "Loss: 7.722772e-02\n",
            "Loss: 7.722479e-02\n",
            "Loss: 7.722256e-02\n",
            "Loss: 7.722052e-02\n",
            "Loss: 7.721916e-02\n",
            "Loss: 7.721134e-02\n",
            "Loss: 7.720459e-02\n",
            "Loss: 7.719388e-02\n",
            "Loss: 7.718915e-02\n",
            "Loss: 7.718349e-02\n",
            "Loss: 7.717974e-02\n",
            "Loss: 7.717711e-02\n",
            "Loss: 7.717236e-02\n",
            "Loss: 7.716959e-02\n",
            "Loss: 7.716726e-02\n",
            "Loss: 7.716287e-02\n",
            "Loss: 7.715870e-02\n",
            "Loss: 7.714872e-02\n",
            "Loss: 7.713533e-02\n",
            "Loss: 7.715249e-02\n",
            "Loss: 7.712951e-02\n",
            "Loss: 7.712327e-02\n",
            "Loss: 7.711992e-02\n",
            "Loss: 7.711700e-02\n",
            "Loss: 7.711361e-02\n",
            "Loss: 7.710838e-02\n",
            "Loss: 7.710445e-02\n",
            "Loss: 7.710177e-02\n",
            "Loss: 7.709434e-02\n",
            "Loss: 7.708718e-02\n",
            "Loss: 7.708146e-02\n",
            "Loss: 7.707630e-02\n",
            "Loss: 7.707281e-02\n",
            "Loss: 7.706568e-02\n",
            "Loss: 7.705846e-02\n",
            "Loss: 7.705000e-02\n",
            "Loss: 7.704332e-02\n",
            "Loss: 7.703444e-02\n",
            "Loss: 7.702927e-02\n",
            "Loss: 7.702443e-02\n",
            "Loss: 7.701865e-02\n",
            "Loss: 7.701205e-02\n",
            "Loss: 7.700488e-02\n",
            "Loss: 7.699614e-02\n",
            "Loss: 7.698994e-02\n",
            "Loss: 7.698455e-02\n",
            "Loss: 7.697484e-02\n",
            "Loss: 7.697126e-02\n",
            "Loss: 7.696524e-02\n",
            "Loss: 7.696271e-02\n",
            "Loss: 7.695644e-02\n",
            "Loss: 7.694907e-02\n",
            "Loss: 7.694551e-02\n",
            "Loss: 7.693785e-02\n",
            "Loss: 7.693479e-02\n",
            "Loss: 7.693167e-02\n",
            "Loss: 7.692660e-02\n",
            "Loss: 7.692014e-02\n",
            "Loss: 7.691392e-02\n",
            "Loss: 7.690698e-02\n",
            "Loss: 7.690156e-02\n",
            "Loss: 7.689692e-02\n",
            "Loss: 7.689350e-02\n",
            "Loss: 7.688996e-02\n",
            "Loss: 7.688715e-02\n",
            "Loss: 7.688054e-02\n",
            "Loss: 7.687685e-02\n",
            "Loss: 7.686940e-02\n",
            "Loss: 7.686581e-02\n",
            "Loss: 7.686245e-02\n",
            "Loss: 7.685897e-02\n",
            "Loss: 7.685421e-02\n",
            "Loss: 7.685056e-02\n",
            "Loss: 7.684559e-02\n",
            "Loss: 7.684143e-02\n",
            "Loss: 7.683747e-02\n",
            "Loss: 7.683415e-02\n",
            "Loss: 7.682660e-02\n",
            "Loss: 7.682226e-02\n",
            "Loss: 7.681830e-02\n",
            "Loss: 7.681451e-02\n",
            "Loss: 7.680653e-02\n",
            "Loss: 7.681476e-02\n",
            "Loss: 7.680406e-02\n",
            "Loss: 7.679877e-02\n",
            "Loss: 7.679240e-02\n",
            "Loss: 7.678176e-02\n",
            "Loss: 7.677153e-02\n",
            "Loss: 7.675886e-02\n",
            "Loss: 7.675155e-02\n",
            "Loss: 7.674484e-02\n",
            "Loss: 7.674207e-02\n",
            "Loss: 7.673764e-02\n",
            "Loss: 7.673375e-02\n",
            "Loss: 7.672900e-02\n",
            "Loss: 7.672271e-02\n",
            "Loss: 7.672127e-02\n",
            "Loss: 7.671576e-02\n",
            "Loss: 7.671274e-02\n",
            "Loss: 7.670695e-02\n",
            "Loss: 7.670548e-02\n",
            "Loss: 7.670077e-02\n",
            "Loss: 7.669926e-02\n",
            "Loss: 7.669549e-02\n",
            "Loss: 7.668848e-02\n",
            "Loss: 7.668087e-02\n",
            "Loss: 7.667257e-02\n",
            "Loss: 7.666751e-02\n",
            "Loss: 7.666368e-02\n",
            "Loss: 7.666098e-02\n",
            "Loss: 7.665610e-02\n",
            "Loss: 7.665019e-02\n",
            "Loss: 7.664321e-02\n",
            "Loss: 7.663902e-02\n",
            "Loss: 7.663679e-02\n",
            "Loss: 7.663139e-02\n",
            "Loss: 7.662515e-02\n",
            "Loss: 7.662103e-02\n",
            "Loss: 7.661079e-02\n",
            "Loss: 7.659664e-02\n",
            "Loss: 7.658677e-02\n",
            "Loss: 7.658225e-02\n",
            "Loss: 7.657617e-02\n",
            "Loss: 7.657132e-02\n",
            "Loss: 7.656611e-02\n",
            "Loss: 7.656198e-02\n",
            "Loss: 7.655606e-02\n",
            "Loss: 7.654846e-02\n",
            "Loss: 7.654098e-02\n",
            "Loss: 7.653708e-02\n",
            "Loss: 7.653487e-02\n",
            "Loss: 7.653175e-02\n",
            "Loss: 7.652438e-02\n",
            "Loss: 7.651831e-02\n",
            "Loss: 7.651307e-02\n",
            "Loss: 7.650956e-02\n",
            "Loss: 7.650518e-02\n",
            "Loss: 7.650049e-02\n",
            "Loss: 7.649294e-02\n",
            "Loss: 7.648590e-02\n",
            "Loss: 7.648154e-02\n",
            "Loss: 7.647871e-02\n",
            "Loss: 7.647485e-02\n",
            "Loss: 7.646865e-02\n",
            "Loss: 7.646099e-02\n",
            "Loss: 7.645200e-02\n",
            "Loss: 7.644168e-02\n",
            "Loss: 7.643683e-02\n",
            "Loss: 7.643431e-02\n",
            "Loss: 7.642600e-02\n",
            "Loss: 7.642048e-02\n",
            "Loss: 7.641528e-02\n",
            "Loss: 7.641058e-02\n",
            "Loss: 7.640575e-02\n",
            "Loss: 7.640113e-02\n",
            "Loss: 7.639245e-02\n",
            "Loss: 7.638703e-02\n",
            "Loss: 7.638051e-02\n",
            "Loss: 7.637551e-02\n",
            "Loss: 7.637262e-02\n",
            "Loss: 7.637278e-02\n",
            "Loss: 7.637078e-02\n",
            "Loss: 7.636917e-02\n",
            "Loss: 7.636487e-02\n",
            "Loss: 7.636235e-02\n",
            "Loss: 7.635452e-02\n",
            "Loss: 7.635667e-02\n",
            "Loss: 7.635000e-02\n",
            "Loss: 7.634308e-02\n",
            "Loss: 7.633992e-02\n",
            "Loss: 7.633541e-02\n",
            "Loss: 7.632811e-02\n",
            "Loss: 7.632087e-02\n",
            "Loss: 7.631512e-02\n",
            "Loss: 7.631123e-02\n",
            "Loss: 7.630745e-02\n",
            "Loss: 7.630216e-02\n",
            "Loss: 7.629962e-02\n",
            "Loss: 7.629556e-02\n",
            "Loss: 7.629200e-02\n",
            "Loss: 7.628812e-02\n",
            "Loss: 7.628030e-02\n",
            "Loss: 7.628240e-02\n",
            "Loss: 7.627603e-02\n",
            "Loss: 7.626665e-02\n",
            "Loss: 7.626285e-02\n",
            "Loss: 7.625987e-02\n",
            "Loss: 7.625818e-02\n",
            "Loss: 7.625436e-02\n",
            "Loss: 7.624999e-02\n",
            "Loss: 7.624315e-02\n",
            "Loss: 7.623537e-02\n",
            "Loss: 7.622776e-02\n",
            "Loss: 7.622032e-02\n",
            "Loss: 7.621550e-02\n",
            "Loss: 7.621080e-02\n",
            "Loss: 7.620706e-02\n",
            "Loss: 7.619703e-02\n",
            "Loss: 7.618713e-02\n",
            "Loss: 7.618177e-02\n",
            "Loss: 7.617774e-02\n",
            "Loss: 7.617380e-02\n",
            "Loss: 7.616860e-02\n",
            "Loss: 7.616308e-02\n",
            "Loss: 7.615735e-02\n",
            "Loss: 7.615428e-02\n",
            "Loss: 7.614906e-02\n",
            "Loss: 7.614492e-02\n",
            "Loss: 7.613769e-02\n",
            "Loss: 7.613445e-02\n",
            "Loss: 7.612988e-02\n",
            "Loss: 7.612534e-02\n",
            "Loss: 7.613336e-02\n",
            "Loss: 7.612124e-02\n",
            "Loss: 7.611507e-02\n",
            "Loss: 7.610929e-02\n",
            "Loss: 7.610492e-02\n",
            "Loss: 7.610063e-02\n",
            "Loss: 7.609744e-02\n",
            "Loss: 7.609347e-02\n",
            "Loss: 7.608794e-02\n",
            "Loss: 7.607904e-02\n",
            "Loss: 7.606938e-02\n",
            "Loss: 7.606645e-02\n",
            "Loss: 7.606164e-02\n",
            "Loss: 7.605889e-02\n",
            "Loss: 7.605508e-02\n",
            "Loss: 7.604940e-02\n",
            "Loss: 7.604103e-02\n",
            "Loss: 7.606689e-02\n",
            "Loss: 7.603891e-02\n",
            "Loss: 7.603435e-02\n",
            "Loss: 7.602804e-02\n",
            "Loss: 7.602236e-02\n",
            "Loss: 7.601674e-02\n",
            "Loss: 7.601345e-02\n",
            "Loss: 7.600735e-02\n",
            "Loss: 7.600360e-02\n",
            "Loss: 7.599989e-02\n",
            "Loss: 7.599596e-02\n",
            "Loss: 7.599175e-02\n",
            "Loss: 7.598601e-02\n",
            "Loss: 7.598293e-02\n",
            "Loss: 7.597990e-02\n",
            "Loss: 7.597589e-02\n",
            "Loss: 7.597288e-02\n",
            "Loss: 7.596317e-02\n",
            "Loss: 7.597987e-02\n",
            "Loss: 7.595987e-02\n",
            "Loss: 7.595523e-02\n",
            "Loss: 7.595301e-02\n",
            "Loss: 7.595079e-02\n",
            "Loss: 7.594608e-02\n",
            "Loss: 7.593554e-02\n",
            "Loss: 7.592511e-02\n",
            "Loss: 7.592142e-02\n",
            "Loss: 7.591595e-02\n",
            "Loss: 7.591401e-02\n",
            "Loss: 7.591180e-02\n",
            "Loss: 7.590823e-02\n",
            "Loss: 7.590640e-02\n",
            "Loss: 7.590100e-02\n",
            "Loss: 7.589737e-02\n",
            "Loss: 7.589258e-02\n",
            "Loss: 7.588868e-02\n",
            "Loss: 7.588720e-02\n",
            "Loss: 7.588059e-02\n",
            "Loss: 7.587850e-02\n",
            "Loss: 7.587407e-02\n",
            "Loss: 7.587194e-02\n",
            "Loss: 7.586694e-02\n",
            "Loss: 7.586368e-02\n",
            "Loss: 7.586142e-02\n",
            "Loss: 7.585790e-02\n",
            "Loss: 7.585266e-02\n",
            "Loss: 7.584797e-02\n",
            "Loss: 7.584115e-02\n",
            "Loss: 7.583825e-02\n",
            "Loss: 7.583576e-02\n",
            "Loss: 7.583255e-02\n",
            "Loss: 7.582958e-02\n",
            "Loss: 7.582603e-02\n",
            "Loss: 7.582121e-02\n",
            "Loss: 7.581872e-02\n",
            "Loss: 7.581607e-02\n",
            "Loss: 7.581409e-02\n",
            "Loss: 7.581020e-02\n",
            "Loss: 7.580949e-02\n",
            "Loss: 7.580565e-02\n",
            "Loss: 7.580405e-02\n",
            "Loss: 7.580193e-02\n",
            "Loss: 7.579911e-02\n",
            "Loss: 7.580145e-02\n",
            "Loss: 7.579739e-02\n",
            "Loss: 7.579452e-02\n",
            "Loss: 7.579119e-02\n",
            "Loss: 7.578820e-02\n",
            "Loss: 7.578655e-02\n",
            "Loss: 7.578391e-02\n",
            "Loss: 7.578132e-02\n",
            "Loss: 7.577693e-02\n",
            "Loss: 7.577366e-02\n",
            "Loss: 7.577203e-02\n",
            "Loss: 7.576983e-02\n",
            "Loss: 7.576843e-02\n",
            "Loss: 7.576714e-02\n",
            "Loss: 7.576340e-02\n",
            "Loss: 7.575773e-02\n",
            "Loss: 7.575793e-02\n",
            "Loss: 7.575478e-02\n",
            "Loss: 7.574884e-02\n",
            "Loss: 7.574550e-02\n",
            "Loss: 7.574486e-02\n",
            "Loss: 7.574155e-02\n",
            "Loss: 7.573999e-02\n",
            "Loss: 7.573877e-02\n",
            "Loss: 7.573780e-02\n",
            "Loss: 7.573441e-02\n",
            "Loss: 7.574977e-02\n",
            "Loss: 7.573320e-02\n",
            "Loss: 7.572785e-02\n",
            "Loss: 7.572532e-02\n",
            "Loss: 7.572309e-02\n",
            "Loss: 7.572023e-02\n",
            "Loss: 7.571621e-02\n",
            "Loss: 7.571316e-02\n",
            "Loss: 7.570621e-02\n",
            "Loss: 7.570272e-02\n",
            "Loss: 7.569767e-02\n",
            "Loss: 7.569321e-02\n",
            "Loss: 7.569169e-02\n",
            "Loss: 7.568813e-02\n",
            "Loss: 7.568699e-02\n",
            "Loss: 7.568531e-02\n",
            "Loss: 7.568151e-02\n",
            "Loss: 7.568365e-02\n",
            "Loss: 7.567935e-02\n",
            "Loss: 7.567547e-02\n",
            "Loss: 7.567243e-02\n",
            "Loss: 7.566957e-02\n",
            "Loss: 7.566695e-02\n",
            "Loss: 7.566662e-02\n",
            "Loss: 7.566442e-02\n",
            "Loss: 7.566066e-02\n",
            "Loss: 7.565692e-02\n",
            "Loss: 7.565535e-02\n",
            "Loss: 7.565264e-02\n",
            "Loss: 7.564777e-02\n",
            "Loss: 7.564209e-02\n",
            "Loss: 7.563758e-02\n",
            "Loss: 7.563511e-02\n",
            "Loss: 7.563236e-02\n",
            "Loss: 7.563063e-02\n",
            "Loss: 7.562754e-02\n",
            "Loss: 7.562414e-02\n",
            "Loss: 7.561978e-02\n",
            "Loss: 7.561816e-02\n",
            "Loss: 7.561618e-02\n",
            "Loss: 7.561384e-02\n",
            "Loss: 7.561953e-02\n",
            "Loss: 7.561237e-02\n",
            "Loss: 7.561039e-02\n",
            "Loss: 7.560621e-02\n",
            "Loss: 7.560137e-02\n",
            "Loss: 7.559638e-02\n",
            "Loss: 7.559140e-02\n",
            "Loss: 7.558784e-02\n",
            "Loss: 7.558555e-02\n",
            "Loss: 7.558323e-02\n",
            "Loss: 7.558030e-02\n",
            "Loss: 7.560509e-02\n",
            "Loss: 7.557961e-02\n",
            "Loss: 7.557774e-02\n",
            "Loss: 7.557601e-02\n",
            "Loss: 7.557340e-02\n",
            "Loss: 7.557064e-02\n",
            "Loss: 7.556814e-02\n",
            "Loss: 7.556231e-02\n",
            "Loss: 7.556006e-02\n",
            "Loss: 7.555804e-02\n",
            "Loss: 7.555544e-02\n",
            "Loss: 7.554996e-02\n",
            "Loss: 7.554674e-02\n",
            "Loss: 7.554217e-02\n",
            "Loss: 7.553856e-02\n",
            "Loss: 7.553497e-02\n",
            "Loss: 7.553159e-02\n",
            "Loss: 7.552870e-02\n",
            "Loss: 7.552690e-02\n",
            "Loss: 7.552454e-02\n",
            "Loss: 7.552090e-02\n",
            "Loss: 7.551622e-02\n",
            "Loss: 7.552750e-02\n",
            "Loss: 7.551387e-02\n",
            "Loss: 7.551062e-02\n",
            "Loss: 7.550756e-02\n",
            "Loss: 7.550587e-02\n",
            "Loss: 7.550082e-02\n",
            "Loss: 7.550870e-02\n",
            "Loss: 7.549898e-02\n",
            "Loss: 7.549489e-02\n",
            "Loss: 7.548998e-02\n",
            "Loss: 7.548360e-02\n",
            "Loss: 7.548138e-02\n",
            "Loss: 7.547556e-02\n",
            "Loss: 7.547287e-02\n",
            "Loss: 7.546853e-02\n",
            "Loss: 7.546715e-02\n",
            "Loss: 7.546008e-02\n",
            "Loss: 7.545805e-02\n",
            "Loss: 7.545621e-02\n",
            "Loss: 7.545760e-02\n",
            "Loss: 7.545545e-02\n",
            "Loss: 7.545402e-02\n",
            "Loss: 7.544705e-02\n",
            "Loss: 7.543924e-02\n",
            "Loss: 7.543875e-02\n",
            "Loss: 7.543426e-02\n",
            "Loss: 7.542472e-02\n",
            "Loss: 7.541854e-02\n",
            "Loss: 7.541174e-02\n",
            "Loss: 7.540705e-02\n",
            "Loss: 7.540962e-02\n",
            "Loss: 7.540411e-02\n",
            "Loss: 7.539922e-02\n",
            "Loss: 7.539611e-02\n",
            "Loss: 7.539275e-02\n",
            "Loss: 7.538813e-02\n",
            "Loss: 7.539193e-02\n",
            "Loss: 7.538481e-02\n",
            "Loss: 7.537712e-02\n",
            "Loss: 7.537221e-02\n",
            "Loss: 7.536681e-02\n",
            "Loss: 7.536338e-02\n",
            "Loss: 7.535581e-02\n",
            "Loss: 7.534797e-02\n",
            "Loss: 7.533949e-02\n",
            "Loss: 7.533698e-02\n",
            "Loss: 7.533308e-02\n",
            "Loss: 7.532743e-02\n",
            "Loss: 7.531886e-02\n",
            "Loss: 7.532027e-02\n",
            "Loss: 7.531390e-02\n",
            "Loss: 7.530669e-02\n",
            "Loss: 7.530256e-02\n",
            "Loss: 7.529589e-02\n",
            "Loss: 7.529067e-02\n",
            "Loss: 7.528399e-02\n",
            "Loss: 7.528047e-02\n",
            "Loss: 7.527208e-02\n",
            "Loss: 7.526584e-02\n",
            "Loss: 7.525955e-02\n",
            "Loss: 7.525090e-02\n",
            "Loss: 7.524750e-02\n",
            "Loss: 7.524312e-02\n",
            "Loss: 7.523701e-02\n",
            "Loss: 7.531904e-02\n",
            "Loss: 7.523552e-02\n",
            "Loss: 7.522978e-02\n",
            "Loss: 7.522682e-02\n",
            "Loss: 7.522273e-02\n",
            "Loss: 7.521801e-02\n",
            "Loss: 7.521541e-02\n",
            "Loss: 7.521197e-02\n",
            "Loss: 7.521025e-02\n",
            "Loss: 7.520927e-02\n",
            "Loss: 7.520421e-02\n",
            "Loss: 7.520419e-02\n",
            "Loss: 7.520118e-02\n",
            "Loss: 7.519455e-02\n",
            "Loss: 7.519631e-02\n",
            "Loss: 7.519153e-02\n",
            "Loss: 7.518665e-02\n",
            "Loss: 7.518157e-02\n",
            "Loss: 7.517388e-02\n",
            "Loss: 7.516650e-02\n",
            "Loss: 7.516394e-02\n",
            "Loss: 7.515889e-02\n",
            "Loss: 7.515606e-02\n",
            "Loss: 7.515227e-02\n",
            "Loss: 7.514630e-02\n",
            "Loss: 7.514544e-02\n",
            "Loss: 7.513805e-02\n",
            "Loss: 7.513648e-02\n",
            "Loss: 7.513393e-02\n",
            "Loss: 7.513104e-02\n",
            "Loss: 7.512665e-02\n",
            "Loss: 7.512315e-02\n",
            "Loss: 7.511582e-02\n",
            "Loss: 7.511045e-02\n",
            "Loss: 7.510665e-02\n",
            "Loss: 7.510447e-02\n",
            "Loss: 7.510074e-02\n",
            "Loss: 7.509878e-02\n",
            "Loss: 7.509459e-02\n",
            "Loss: 7.508656e-02\n",
            "Loss: 7.507574e-02\n",
            "Loss: 7.510765e-02\n",
            "Loss: 7.507238e-02\n",
            "Loss: 7.506552e-02\n",
            "Loss: 7.506003e-02\n",
            "Loss: 7.505496e-02\n",
            "Loss: 7.505022e-02\n",
            "Loss: 7.504044e-02\n",
            "Loss: 7.503645e-02\n",
            "Loss: 7.503175e-02\n",
            "Loss: 7.502622e-02\n",
            "Loss: 7.502669e-02\n",
            "Loss: 7.502415e-02\n",
            "Loss: 7.502097e-02\n",
            "Loss: 7.501874e-02\n",
            "Loss: 7.501535e-02\n",
            "Loss: 7.501152e-02\n",
            "Loss: 7.500684e-02\n",
            "Loss: 7.500213e-02\n",
            "Loss: 7.499835e-02\n",
            "Loss: 7.499188e-02\n",
            "Loss: 7.498570e-02\n",
            "Loss: 7.499183e-02\n",
            "Loss: 7.498330e-02\n",
            "Loss: 7.497969e-02\n",
            "Loss: 7.497714e-02\n",
            "Loss: 7.497528e-02\n",
            "Loss: 7.496990e-02\n",
            "Loss: 7.496382e-02\n",
            "Loss: 7.495900e-02\n",
            "Loss: 7.495404e-02\n",
            "Loss: 7.495202e-02\n",
            "Loss: 7.495032e-02\n",
            "Loss: 7.494675e-02\n",
            "Loss: 7.493936e-02\n",
            "Loss: 7.493655e-02\n",
            "Loss: 7.493394e-02\n",
            "Loss: 7.493147e-02\n",
            "Loss: 7.492901e-02\n",
            "Loss: 7.492744e-02\n",
            "Loss: 7.492428e-02\n",
            "Loss: 7.492017e-02\n",
            "Loss: 7.491677e-02\n",
            "Loss: 7.491457e-02\n",
            "Loss: 7.491244e-02\n",
            "Loss: 7.490993e-02\n",
            "Loss: 7.490508e-02\n",
            "Loss: 7.490128e-02\n",
            "Loss: 7.489705e-02\n",
            "Loss: 7.489434e-02\n",
            "Loss: 7.489247e-02\n",
            "Loss: 7.488659e-02\n",
            "Loss: 7.488329e-02\n",
            "Loss: 7.487740e-02\n",
            "Loss: 7.487430e-02\n",
            "Loss: 7.487036e-02\n",
            "Loss: 7.486778e-02\n",
            "Loss: 7.486238e-02\n",
            "Loss: 7.485880e-02\n",
            "Loss: 7.485445e-02\n",
            "Loss: 7.485021e-02\n",
            "Loss: 7.484493e-02\n",
            "Loss: 7.484160e-02\n",
            "Loss: 7.483684e-02\n",
            "Loss: 7.483259e-02\n",
            "Loss: 7.484091e-02\n",
            "Loss: 7.483090e-02\n",
            "Loss: 7.482693e-02\n",
            "Loss: 7.482373e-02\n",
            "Loss: 7.482045e-02\n",
            "Loss: 7.481547e-02\n",
            "Loss: 7.481765e-02\n",
            "Loss: 7.481232e-02\n",
            "Loss: 7.480906e-02\n",
            "Loss: 7.480653e-02\n",
            "Loss: 7.480239e-02\n",
            "Loss: 7.479566e-02\n",
            "Loss: 7.479713e-02\n",
            "Loss: 7.479396e-02\n",
            "Loss: 7.479053e-02\n",
            "Loss: 7.478865e-02\n",
            "Loss: 7.478509e-02\n",
            "Loss: 7.477859e-02\n",
            "Loss: 7.477851e-02\n",
            "Loss: 7.477389e-02\n",
            "Loss: 7.476809e-02\n",
            "Loss: 7.476294e-02\n",
            "Loss: 7.475899e-02\n",
            "Loss: 7.475466e-02\n",
            "Loss: 7.474903e-02\n",
            "Loss: 7.474554e-02\n",
            "Loss: 7.474266e-02\n",
            "Loss: 7.473908e-02\n",
            "Loss: 7.473762e-02\n",
            "Loss: 7.473264e-02\n",
            "Loss: 7.473068e-02\n",
            "Loss: 7.472623e-02\n",
            "Loss: 7.472907e-02\n",
            "Loss: 7.472557e-02\n",
            "Loss: 7.472298e-02\n",
            "Loss: 7.472049e-02\n",
            "Loss: 7.471727e-02\n",
            "Loss: 7.471441e-02\n",
            "Loss: 7.471082e-02\n",
            "Loss: 7.470908e-02\n",
            "Loss: 7.470597e-02\n",
            "Loss: 7.470464e-02\n",
            "Loss: 7.470283e-02\n",
            "Loss: 7.469971e-02\n",
            "Loss: 7.469905e-02\n",
            "Loss: 7.469532e-02\n",
            "Loss: 7.469411e-02\n",
            "Loss: 7.469203e-02\n",
            "Loss: 7.469005e-02\n",
            "Loss: 7.468883e-02\n",
            "Loss: 7.468323e-02\n",
            "Loss: 7.468023e-02\n",
            "Loss: 7.467632e-02\n",
            "Loss: 7.467244e-02\n",
            "Loss: 7.468432e-02\n",
            "Loss: 7.466994e-02\n",
            "Loss: 7.466257e-02\n",
            "Loss: 7.465745e-02\n",
            "Loss: 7.465320e-02\n",
            "Loss: 7.465153e-02\n",
            "Loss: 7.464954e-02\n",
            "Loss: 7.464761e-02\n",
            "Loss: 7.464637e-02\n",
            "Loss: 7.464351e-02\n",
            "Loss: 7.464008e-02\n",
            "Loss: 7.463824e-02\n",
            "Loss: 7.463403e-02\n",
            "Loss: 7.463104e-02\n",
            "Loss: 7.462721e-02\n",
            "Loss: 7.462081e-02\n",
            "Loss: 7.464761e-02\n",
            "Loss: 7.461839e-02\n",
            "Loss: 7.461199e-02\n",
            "Loss: 7.460699e-02\n",
            "Loss: 7.460120e-02\n",
            "Loss: 7.459550e-02\n",
            "Loss: 7.458874e-02\n",
            "Loss: 7.460567e-02\n",
            "Loss: 7.458508e-02\n",
            "Loss: 7.458207e-02\n",
            "Loss: 7.457904e-02\n",
            "Loss: 7.457356e-02\n",
            "Loss: 7.456928e-02\n",
            "Loss: 7.455897e-02\n",
            "Loss: 7.455473e-02\n",
            "Loss: 7.455140e-02\n",
            "Loss: 7.454542e-02\n",
            "Loss: 7.454325e-02\n",
            "Loss: 7.454024e-02\n",
            "Loss: 7.453854e-02\n",
            "Loss: 7.453442e-02\n",
            "Loss: 7.453226e-02\n",
            "Loss: 7.453012e-02\n",
            "Loss: 7.452492e-02\n",
            "Loss: 7.452171e-02\n",
            "Loss: 7.451873e-02\n",
            "Loss: 7.451659e-02\n",
            "Loss: 7.451352e-02\n",
            "Loss: 7.450977e-02\n",
            "Loss: 7.450849e-02\n",
            "Loss: 7.450381e-02\n",
            "Loss: 7.450214e-02\n",
            "Loss: 7.449880e-02\n",
            "Loss: 7.449543e-02\n",
            "Loss: 7.448981e-02\n",
            "Loss: 7.449013e-02\n",
            "Loss: 7.448632e-02\n",
            "Loss: 7.448288e-02\n",
            "Loss: 7.447889e-02\n",
            "Loss: 7.447489e-02\n",
            "Loss: 7.447726e-02\n",
            "Loss: 7.447066e-02\n",
            "Loss: 7.446508e-02\n",
            "Loss: 7.446203e-02\n",
            "Loss: 7.445942e-02\n",
            "Loss: 7.445800e-02\n",
            "Loss: 7.445539e-02\n",
            "Loss: 7.445234e-02\n",
            "Loss: 7.444931e-02\n",
            "Loss: 7.444695e-02\n",
            "Loss: 7.444501e-02\n",
            "Loss: 7.444272e-02\n",
            "Loss: 7.443694e-02\n",
            "Loss: 7.445302e-02\n",
            "Loss: 7.443478e-02\n",
            "Loss: 7.442811e-02\n",
            "Loss: 7.442288e-02\n",
            "Loss: 7.443965e-02\n",
            "Loss: 7.442109e-02\n",
            "Loss: 7.441667e-02\n",
            "Loss: 7.441361e-02\n",
            "Loss: 7.440834e-02\n",
            "Loss: 7.440388e-02\n",
            "Loss: 7.440133e-02\n",
            "Loss: 7.439511e-02\n",
            "Loss: 7.439268e-02\n",
            "Loss: 7.438800e-02\n",
            "Loss: 7.438864e-02\n",
            "Loss: 7.438505e-02\n",
            "Loss: 7.438277e-02\n",
            "Loss: 7.437851e-02\n",
            "Loss: 7.437475e-02\n",
            "Loss: 7.437100e-02\n",
            "Loss: 7.437052e-02\n",
            "Loss: 7.436936e-02\n",
            "Loss: 7.436694e-02\n",
            "Loss: 7.436401e-02\n",
            "Loss: 7.436034e-02\n",
            "Loss: 7.435993e-02\n",
            "Loss: 7.435860e-02\n",
            "Loss: 7.435665e-02\n",
            "Loss: 7.435508e-02\n",
            "Loss: 7.435261e-02\n",
            "Loss: 7.434933e-02\n",
            "Loss: 7.434617e-02\n",
            "Loss: 7.434378e-02\n",
            "Loss: 7.434053e-02\n",
            "Loss: 7.433805e-02\n",
            "Loss: 7.433479e-02\n",
            "Loss: 7.433048e-02\n",
            "Loss: 7.432882e-02\n",
            "Loss: 7.432645e-02\n",
            "Loss: 7.432435e-02\n",
            "Loss: 7.431935e-02\n",
            "Loss: 7.431901e-02\n",
            "Loss: 7.431482e-02\n",
            "Loss: 7.431345e-02\n",
            "Loss: 7.430999e-02\n",
            "Loss: 7.430518e-02\n",
            "Loss: 7.430093e-02\n",
            "Loss: 7.429756e-02\n",
            "Loss: 7.429513e-02\n",
            "Loss: 7.429324e-02\n",
            "Loss: 7.429068e-02\n",
            "Loss: 7.428723e-02\n",
            "Loss: 7.428521e-02\n",
            "Loss: 7.428239e-02\n",
            "Loss: 7.428084e-02\n",
            "Loss: 7.427906e-02\n",
            "Loss: 7.427644e-02\n",
            "Loss: 7.427420e-02\n",
            "Loss: 7.426795e-02\n",
            "Loss: 7.428607e-02\n",
            "Loss: 7.426573e-02\n",
            "Loss: 7.426091e-02\n",
            "Loss: 7.425746e-02\n",
            "Loss: 7.425484e-02\n",
            "Loss: 7.425199e-02\n",
            "Loss: 7.424726e-02\n",
            "Loss: 7.425836e-02\n",
            "Loss: 7.424577e-02\n",
            "Loss: 7.424167e-02\n",
            "Loss: 7.423829e-02\n",
            "Loss: 7.423367e-02\n",
            "Loss: 7.422803e-02\n",
            "Loss: 7.424180e-02\n",
            "Loss: 7.422510e-02\n",
            "Loss: 7.422000e-02\n",
            "Loss: 7.421501e-02\n",
            "Loss: 7.421027e-02\n",
            "Loss: 7.420477e-02\n",
            "Loss: 7.421573e-02\n",
            "Loss: 7.420231e-02\n",
            "Loss: 7.419655e-02\n",
            "Loss: 7.419335e-02\n",
            "Loss: 7.419359e-02\n",
            "Loss: 7.419181e-02\n",
            "Loss: 7.418917e-02\n",
            "Loss: 7.418487e-02\n",
            "Loss: 7.417800e-02\n",
            "Loss: 7.417178e-02\n",
            "Loss: 7.417188e-02\n",
            "Loss: 7.416839e-02\n",
            "Loss: 7.416404e-02\n",
            "Loss: 7.416078e-02\n",
            "Loss: 7.415724e-02\n",
            "Loss: 7.415471e-02\n",
            "Loss: 7.415209e-02\n",
            "Loss: 7.415027e-02\n",
            "Loss: 7.414605e-02\n",
            "Loss: 7.414076e-02\n",
            "Loss: 7.413317e-02\n",
            "Loss: 7.412747e-02\n",
            "Loss: 7.412302e-02\n",
            "Loss: 7.411885e-02\n",
            "Loss: 7.411529e-02\n",
            "Loss: 7.411224e-02\n",
            "Loss: 7.410736e-02\n",
            "Loss: 7.410793e-02\n",
            "Loss: 7.410448e-02\n",
            "Loss: 7.410169e-02\n",
            "Loss: 7.409973e-02\n",
            "Loss: 7.409833e-02\n",
            "Loss: 7.409590e-02\n",
            "Loss: 7.409354e-02\n",
            "Loss: 7.409379e-02\n",
            "Loss: 7.409297e-02\n",
            "Loss: 7.409220e-02\n",
            "Loss: 7.409045e-02\n",
            "Loss: 7.408865e-02\n",
            "Loss: 7.408403e-02\n",
            "Loss: 7.407812e-02\n",
            "Loss: 7.409867e-02\n",
            "Loss: 7.407625e-02\n",
            "Loss: 7.407357e-02\n",
            "Loss: 7.407163e-02\n",
            "Loss: 7.406988e-02\n",
            "Loss: 7.406596e-02\n",
            "Loss: 7.406253e-02\n",
            "Loss: 7.405700e-02\n",
            "Loss: 7.405302e-02\n",
            "Loss: 7.405137e-02\n",
            "Loss: 7.404587e-02\n",
            "Loss: 7.404293e-02\n",
            "Loss: 7.403588e-02\n",
            "Loss: 7.403359e-02\n",
            "Loss: 7.403091e-02\n",
            "Loss: 7.403150e-02\n",
            "Loss: 7.402934e-02\n",
            "Loss: 7.402654e-02\n",
            "Loss: 7.402444e-02\n",
            "Loss: 7.402276e-02\n",
            "Loss: 7.402170e-02\n",
            "Loss: 7.402402e-02\n",
            "Loss: 7.402032e-02\n",
            "Loss: 7.401751e-02\n",
            "Loss: 7.401595e-02\n",
            "Loss: 7.401286e-02\n",
            "Loss: 7.400887e-02\n",
            "Loss: 7.400283e-02\n",
            "Loss: 7.400166e-02\n",
            "Loss: 7.399505e-02\n",
            "Loss: 7.399286e-02\n",
            "Loss: 7.399086e-02\n",
            "Loss: 7.398992e-02\n",
            "Loss: 7.398848e-02\n",
            "Loss: 7.398708e-02\n",
            "Loss: 7.398592e-02\n",
            "Loss: 7.398368e-02\n",
            "Loss: 7.397937e-02\n",
            "Loss: 7.398121e-02\n",
            "Loss: 7.397680e-02\n",
            "Loss: 7.397418e-02\n",
            "Loss: 7.397212e-02\n",
            "Loss: 7.397036e-02\n",
            "Loss: 7.396747e-02\n",
            "Loss: 7.396351e-02\n",
            "Loss: 7.395956e-02\n",
            "Loss: 7.395618e-02\n",
            "Loss: 7.395261e-02\n",
            "Loss: 7.395007e-02\n",
            "Loss: 7.394639e-02\n",
            "Loss: 7.394710e-02\n",
            "Loss: 7.394546e-02\n",
            "Loss: 7.394412e-02\n",
            "Loss: 7.394263e-02\n",
            "Loss: 7.393960e-02\n",
            "Loss: 7.393444e-02\n",
            "Loss: 7.393455e-02\n",
            "Loss: 7.393173e-02\n",
            "Loss: 7.392728e-02\n",
            "Loss: 7.392486e-02\n",
            "Loss: 7.392289e-02\n",
            "Loss: 7.392012e-02\n",
            "Loss: 7.391729e-02\n",
            "Loss: 7.391380e-02\n",
            "Loss: 7.391244e-02\n",
            "Loss: 7.391021e-02\n",
            "Loss: 7.390893e-02\n",
            "Loss: 7.390728e-02\n",
            "Loss: 7.390514e-02\n",
            "Loss: 7.390106e-02\n",
            "Loss: 7.390466e-02\n",
            "Loss: 7.389937e-02\n",
            "Loss: 7.389583e-02\n",
            "Loss: 7.389351e-02\n",
            "Loss: 7.389184e-02\n",
            "Loss: 7.389028e-02\n",
            "Loss: 7.388772e-02\n",
            "Loss: 7.388443e-02\n",
            "Loss: 7.388346e-02\n",
            "Loss: 7.388019e-02\n",
            "Loss: 7.387900e-02\n",
            "Loss: 7.387670e-02\n",
            "Loss: 7.387239e-02\n",
            "Loss: 7.386971e-02\n",
            "Loss: 7.386355e-02\n",
            "Loss: 7.386140e-02\n",
            "Loss: 7.385667e-02\n",
            "Loss: 7.385364e-02\n",
            "Loss: 7.384993e-02\n",
            "Loss: 7.385205e-02\n",
            "Loss: 7.384857e-02\n",
            "Loss: 7.384689e-02\n",
            "Loss: 7.384463e-02\n",
            "Loss: 7.384282e-02\n",
            "Loss: 7.383898e-02\n",
            "Loss: 7.384191e-02\n",
            "Loss: 7.383641e-02\n",
            "Loss: 7.383155e-02\n",
            "Loss: 7.382789e-02\n",
            "Loss: 7.382563e-02\n",
            "Loss: 7.382162e-02\n",
            "Loss: 7.381807e-02\n",
            "Loss: 7.381295e-02\n",
            "Loss: 7.380895e-02\n",
            "Loss: 7.380469e-02\n",
            "Loss: 7.380096e-02\n",
            "Loss: 7.379857e-02\n",
            "Loss: 7.379596e-02\n",
            "Loss: 7.379402e-02\n",
            "Loss: 7.379109e-02\n",
            "Loss: 7.378516e-02\n",
            "Loss: 7.378089e-02\n",
            "Loss: 7.378145e-02\n",
            "Loss: 7.377794e-02\n",
            "Loss: 7.377290e-02\n",
            "Loss: 7.377059e-02\n",
            "Loss: 7.376564e-02\n",
            "Loss: 7.376214e-02\n",
            "Loss: 7.375866e-02\n",
            "Loss: 7.375591e-02\n",
            "Loss: 7.375201e-02\n",
            "Loss: 7.374894e-02\n",
            "Loss: 7.374544e-02\n",
            "Loss: 7.374327e-02\n",
            "Loss: 7.373995e-02\n",
            "Loss: 7.373454e-02\n",
            "Loss: 7.373466e-02\n",
            "Loss: 7.373221e-02\n",
            "Loss: 7.373001e-02\n",
            "Loss: 7.372744e-02\n",
            "Loss: 7.372475e-02\n",
            "Loss: 7.372024e-02\n",
            "Loss: 7.377427e-02\n",
            "Loss: 7.371906e-02\n",
            "Loss: 7.371511e-02\n",
            "Loss: 7.371110e-02\n",
            "Loss: 7.370627e-02\n",
            "Loss: 7.370791e-02\n",
            "Loss: 7.370365e-02\n",
            "Loss: 7.370020e-02\n",
            "Loss: 7.369509e-02\n",
            "Loss: 7.369135e-02\n",
            "Loss: 7.368561e-02\n",
            "Loss: 7.368380e-02\n",
            "Loss: 7.368009e-02\n",
            "Loss: 7.367794e-02\n",
            "Loss: 7.367487e-02\n",
            "Loss: 7.368299e-02\n",
            "Loss: 7.367460e-02\n",
            "Loss: 7.367282e-02\n",
            "Loss: 7.366946e-02\n",
            "Loss: 7.366415e-02\n",
            "Loss: 7.365938e-02\n",
            "Loss: 7.365632e-02\n",
            "Loss: 7.365192e-02\n",
            "Loss: 7.365000e-02\n",
            "Loss: 7.364607e-02\n",
            "Loss: 7.363969e-02\n",
            "Loss: 7.363565e-02\n",
            "Loss: 7.363233e-02\n",
            "Loss: 7.362922e-02\n",
            "Loss: 7.362707e-02\n",
            "Loss: 7.362438e-02\n",
            "Loss: 7.362086e-02\n",
            "Loss: 7.363309e-02\n",
            "Loss: 7.361887e-02\n",
            "Loss: 7.361542e-02\n",
            "Loss: 7.361327e-02\n",
            "Loss: 7.361036e-02\n",
            "Loss: 7.360671e-02\n",
            "Loss: 7.362445e-02\n",
            "Loss: 7.360532e-02\n",
            "Loss: 7.360177e-02\n",
            "Loss: 7.359957e-02\n",
            "Loss: 7.359681e-02\n",
            "Loss: 7.359436e-02\n",
            "Loss: 7.358906e-02\n",
            "Loss: 7.358420e-02\n",
            "Loss: 7.358021e-02\n",
            "Loss: 7.357758e-02\n",
            "Loss: 7.357544e-02\n",
            "Loss: 7.357016e-02\n",
            "Loss: 7.356862e-02\n",
            "Loss: 7.356454e-02\n",
            "Loss: 7.356232e-02\n",
            "Loss: 7.355881e-02\n",
            "Loss: 7.356265e-02\n",
            "Loss: 7.355723e-02\n",
            "Loss: 7.355510e-02\n",
            "Loss: 7.355372e-02\n",
            "Loss: 7.355234e-02\n",
            "Loss: 7.355215e-02\n",
            "Loss: 7.354846e-02\n",
            "Loss: 7.354599e-02\n",
            "Loss: 7.354336e-02\n",
            "Loss: 7.354027e-02\n",
            "Loss: 7.353339e-02\n",
            "Loss: 7.354713e-02\n",
            "Loss: 7.352936e-02\n",
            "Loss: 7.352582e-02\n",
            "Loss: 7.352139e-02\n",
            "Loss: 7.351863e-02\n",
            "Loss: 7.351618e-02\n",
            "Loss: 7.351393e-02\n",
            "Loss: 7.351230e-02\n",
            "Loss: 7.350925e-02\n",
            "Loss: 7.350643e-02\n",
            "Loss: 7.350414e-02\n",
            "Loss: 7.350165e-02\n",
            "Loss: 7.349724e-02\n",
            "Loss: 7.349786e-02\n",
            "Loss: 7.349572e-02\n",
            "Loss: 7.349439e-02\n",
            "Loss: 7.349255e-02\n",
            "Loss: 7.348974e-02\n",
            "Loss: 7.348683e-02\n",
            "Loss: 7.349326e-02\n",
            "Loss: 7.348499e-02\n",
            "Loss: 7.348246e-02\n",
            "Loss: 7.348026e-02\n",
            "Loss: 7.347793e-02\n",
            "Loss: 7.347456e-02\n",
            "Loss: 7.347051e-02\n",
            "Loss: 7.346667e-02\n",
            "Loss: 7.346518e-02\n",
            "Loss: 7.346157e-02\n",
            "Loss: 7.345933e-02\n",
            "Loss: 7.345425e-02\n",
            "Loss: 7.345125e-02\n",
            "Loss: 7.344663e-02\n",
            "Loss: 7.344223e-02\n",
            "Loss: 7.343583e-02\n",
            "Loss: 7.343166e-02\n",
            "Loss: 7.342970e-02\n",
            "Loss: 7.342827e-02\n",
            "Loss: 7.342533e-02\n",
            "Loss: 7.342134e-02\n",
            "Loss: 7.341716e-02\n",
            "Loss: 7.343028e-02\n",
            "Loss: 7.341472e-02\n",
            "Loss: 7.341222e-02\n",
            "Loss: 7.341097e-02\n",
            "Loss: 7.340824e-02\n",
            "Loss: 7.340353e-02\n",
            "Loss: 7.339983e-02\n",
            "Loss: 7.339715e-02\n",
            "Loss: 7.339479e-02\n",
            "Loss: 7.339300e-02\n",
            "Loss: 7.338788e-02\n",
            "Loss: 7.339790e-02\n",
            "Loss: 7.338555e-02\n",
            "Loss: 7.338011e-02\n",
            "Loss: 7.337596e-02\n",
            "Loss: 7.337327e-02\n",
            "Loss: 7.337091e-02\n",
            "Loss: 7.336966e-02\n",
            "Loss: 7.336656e-02\n",
            "Loss: 7.336498e-02\n",
            "Loss: 7.336137e-02\n",
            "Loss: 7.335833e-02\n",
            "Loss: 7.335501e-02\n",
            "Loss: 7.335172e-02\n",
            "Loss: 7.334962e-02\n",
            "Loss: 7.334724e-02\n",
            "Loss: 7.334166e-02\n",
            "Loss: 7.333683e-02\n",
            "Loss: 7.333174e-02\n",
            "Loss: 7.332878e-02\n",
            "Loss: 7.332512e-02\n",
            "Loss: 7.331898e-02\n",
            "Loss: 7.331330e-02\n",
            "Loss: 7.330769e-02\n",
            "Loss: 7.330347e-02\n",
            "Loss: 7.330190e-02\n",
            "Loss: 7.329949e-02\n",
            "Loss: 7.329728e-02\n",
            "Loss: 7.329502e-02\n",
            "Loss: 7.329203e-02\n",
            "Loss: 7.328936e-02\n",
            "Loss: 7.328545e-02\n",
            "Loss: 7.328086e-02\n",
            "Loss: 7.327812e-02\n",
            "Loss: 7.327586e-02\n",
            "Loss: 7.327473e-02\n",
            "Loss: 7.327251e-02\n",
            "Loss: 7.326867e-02\n",
            "Loss: 7.327195e-02\n",
            "Loss: 7.326786e-02\n",
            "Loss: 7.326578e-02\n",
            "Loss: 7.326455e-02\n",
            "Loss: 7.326300e-02\n",
            "Loss: 7.326121e-02\n",
            "Loss: 7.325955e-02\n",
            "Loss: 7.325839e-02\n",
            "Loss: 7.325759e-02\n",
            "Loss: 7.325391e-02\n",
            "Loss: 7.325201e-02\n",
            "Loss: 7.324904e-02\n",
            "Loss: 7.324266e-02\n",
            "Loss: 7.326129e-02\n",
            "Loss: 7.323992e-02\n",
            "Loss: 7.323383e-02\n",
            "Loss: 7.323106e-02\n",
            "Loss: 7.322785e-02\n",
            "Loss: 7.322940e-02\n",
            "Loss: 7.322669e-02\n",
            "Loss: 7.322465e-02\n",
            "Loss: 7.322235e-02\n",
            "Loss: 7.322008e-02\n",
            "Loss: 7.321601e-02\n",
            "Loss: 7.321090e-02\n",
            "Loss: 7.320874e-02\n",
            "Loss: 7.320047e-02\n",
            "Loss: 7.319666e-02\n",
            "Loss: 7.319250e-02\n",
            "Loss: 7.318956e-02\n",
            "Loss: 7.318597e-02\n",
            "Loss: 7.318226e-02\n",
            "Loss: 7.317924e-02\n",
            "Loss: 7.317399e-02\n",
            "Loss: 7.317103e-02\n",
            "Loss: 7.316924e-02\n",
            "Loss: 7.316662e-02\n",
            "Loss: 7.316356e-02\n",
            "Loss: 7.316049e-02\n",
            "Loss: 7.315621e-02\n",
            "Loss: 7.315412e-02\n",
            "Loss: 7.315119e-02\n",
            "Loss: 7.314862e-02\n",
            "Loss: 7.314646e-02\n",
            "Loss: 7.315090e-02\n",
            "Loss: 7.314481e-02\n",
            "Loss: 7.314236e-02\n",
            "Loss: 7.313912e-02\n",
            "Loss: 7.313579e-02\n",
            "Loss: 7.313225e-02\n",
            "Loss: 7.313070e-02\n",
            "Loss: 7.312761e-02\n",
            "Loss: 7.312614e-02\n",
            "Loss: 7.312418e-02\n",
            "Loss: 7.312153e-02\n",
            "Loss: 7.311641e-02\n",
            "Loss: 7.312124e-02\n",
            "Loss: 7.311311e-02\n",
            "Loss: 7.310952e-02\n",
            "Loss: 7.310598e-02\n",
            "Loss: 7.311038e-02\n",
            "Loss: 7.310455e-02\n",
            "Loss: 7.310272e-02\n",
            "Loss: 7.309903e-02\n",
            "Loss: 7.309469e-02\n",
            "Loss: 7.309103e-02\n",
            "Loss: 7.308877e-02\n",
            "Loss: 7.308680e-02\n",
            "Loss: 7.308498e-02\n",
            "Loss: 7.308250e-02\n",
            "Loss: 7.308261e-02\n",
            "Loss: 7.308039e-02\n",
            "Loss: 7.307678e-02\n",
            "Loss: 7.307551e-02\n",
            "Loss: 7.307339e-02\n",
            "Loss: 7.307106e-02\n",
            "Loss: 7.307480e-02\n",
            "Loss: 7.306975e-02\n",
            "Loss: 7.306822e-02\n",
            "Loss: 7.306689e-02\n",
            "Loss: 7.306515e-02\n",
            "Loss: 7.306305e-02\n",
            "Loss: 7.306000e-02\n",
            "Loss: 7.306419e-02\n",
            "Loss: 7.305782e-02\n",
            "Loss: 7.305480e-02\n",
            "Loss: 7.305194e-02\n",
            "Loss: 7.304846e-02\n",
            "Loss: 7.304610e-02\n",
            "Loss: 7.304133e-02\n",
            "Loss: 7.303742e-02\n",
            "Loss: 7.303330e-02\n",
            "Loss: 7.303056e-02\n",
            "Loss: 7.302064e-02\n",
            "Loss: 7.301691e-02\n",
            "Loss: 7.301315e-02\n",
            "Loss: 7.300980e-02\n",
            "Loss: 7.300651e-02\n",
            "Loss: 7.300355e-02\n",
            "Loss: 7.300074e-02\n",
            "Loss: 7.299817e-02\n",
            "Loss: 7.299490e-02\n",
            "Loss: 7.299290e-02\n",
            "Loss: 7.298774e-02\n",
            "Loss: 7.298599e-02\n",
            "Loss: 7.298299e-02\n",
            "Loss: 7.297704e-02\n",
            "Loss: 7.297799e-02\n",
            "Loss: 7.297517e-02\n",
            "Loss: 7.297169e-02\n",
            "Loss: 7.296979e-02\n",
            "Loss: 7.296620e-02\n",
            "Loss: 7.296134e-02\n",
            "Loss: 7.295781e-02\n",
            "Loss: 7.295411e-02\n",
            "Loss: 7.295241e-02\n",
            "Loss: 7.295063e-02\n",
            "Loss: 7.294840e-02\n",
            "Loss: 7.294576e-02\n",
            "Loss: 7.294229e-02\n",
            "Loss: 7.294071e-02\n",
            "Loss: 7.293719e-02\n",
            "Loss: 7.294246e-02\n",
            "Loss: 7.293528e-02\n",
            "Loss: 7.293141e-02\n",
            "Loss: 7.292815e-02\n",
            "Loss: 7.292533e-02\n",
            "Loss: 7.292485e-02\n",
            "Loss: 7.292260e-02\n",
            "Loss: 7.292078e-02\n",
            "Loss: 7.291936e-02\n",
            "Loss: 7.291811e-02\n",
            "Loss: 7.291494e-02\n",
            "Loss: 7.291063e-02\n",
            "Loss: 7.290770e-02\n",
            "Loss: 7.290503e-02\n",
            "Loss: 7.290009e-02\n",
            "Loss: 7.289493e-02\n",
            "Loss: 7.288953e-02\n",
            "Loss: 7.288256e-02\n",
            "Loss: 7.289437e-02\n",
            "Loss: 7.288068e-02\n",
            "Loss: 7.287871e-02\n",
            "Loss: 7.287564e-02\n",
            "Loss: 7.287198e-02\n",
            "Loss: 7.286777e-02\n",
            "Loss: 7.286572e-02\n",
            "Loss: 7.286231e-02\n",
            "Loss: 7.286063e-02\n",
            "Loss: 7.285859e-02\n",
            "Loss: 7.285529e-02\n",
            "Loss: 7.285054e-02\n",
            "Loss: 7.285617e-02\n",
            "Loss: 7.284877e-02\n",
            "Loss: 7.284541e-02\n",
            "Loss: 7.284377e-02\n",
            "Loss: 7.284134e-02\n",
            "Loss: 7.283898e-02\n",
            "Loss: 7.284261e-02\n",
            "Loss: 7.283726e-02\n",
            "Loss: 7.283355e-02\n",
            "Loss: 7.283200e-02\n",
            "Loss: 7.283030e-02\n",
            "Loss: 7.282662e-02\n",
            "Loss: 7.282457e-02\n",
            "Loss: 7.281996e-02\n",
            "Loss: 7.281669e-02\n",
            "Loss: 7.281481e-02\n",
            "Loss: 7.281178e-02\n",
            "Loss: 7.280632e-02\n",
            "Loss: 7.280713e-02\n",
            "Loss: 7.280394e-02\n",
            "Loss: 7.280057e-02\n",
            "Loss: 7.279739e-02\n",
            "Loss: 7.279444e-02\n",
            "Loss: 7.279546e-02\n",
            "Loss: 7.279287e-02\n",
            "Loss: 7.278894e-02\n",
            "Loss: 7.278587e-02\n",
            "Loss: 7.278387e-02\n",
            "Loss: 7.278275e-02\n",
            "Loss: 7.278067e-02\n",
            "Loss: 7.277889e-02\n",
            "Loss: 7.277670e-02\n",
            "Loss: 7.277370e-02\n",
            "Loss: 7.277213e-02\n",
            "Loss: 7.277022e-02\n",
            "Loss: 7.276798e-02\n",
            "Loss: 7.276711e-02\n",
            "Loss: 7.276575e-02\n",
            "Loss: 7.276413e-02\n",
            "Loss: 7.276384e-02\n",
            "Loss: 7.276231e-02\n",
            "Loss: 7.276160e-02\n",
            "Loss: 7.275888e-02\n",
            "Loss: 7.275670e-02\n",
            "Loss: 7.275588e-02\n",
            "Loss: 7.275377e-02\n",
            "Loss: 7.275216e-02\n",
            "Loss: 7.275096e-02\n",
            "Loss: 7.274874e-02\n",
            "Loss: 7.274660e-02\n",
            "Loss: 7.274307e-02\n",
            "Loss: 7.273930e-02\n",
            "Loss: 7.274292e-02\n",
            "Loss: 7.273800e-02\n",
            "Loss: 7.273515e-02\n",
            "Loss: 7.273215e-02\n",
            "Loss: 7.272740e-02\n",
            "Loss: 7.272332e-02\n",
            "Loss: 7.272226e-02\n",
            "Loss: 7.271948e-02\n",
            "Loss: 7.271750e-02\n",
            "Loss: 7.271572e-02\n",
            "Loss: 7.271239e-02\n",
            "Loss: 7.271636e-02\n",
            "Loss: 7.271070e-02\n",
            "Loss: 7.270724e-02\n",
            "Loss: 7.270462e-02\n",
            "Loss: 7.270164e-02\n",
            "Loss: 7.269865e-02\n",
            "Loss: 7.269586e-02\n",
            "Loss: 7.269333e-02\n",
            "Loss: 7.269129e-02\n",
            "Loss: 7.268912e-02\n",
            "Loss: 7.268568e-02\n",
            "Loss: 7.268272e-02\n",
            "Loss: 7.268087e-02\n",
            "Loss: 7.267798e-02\n",
            "Loss: 7.267539e-02\n",
            "Loss: 7.267167e-02\n",
            "Loss: 7.273483e-02\n",
            "Loss: 7.267079e-02\n",
            "Loss: 7.266892e-02\n",
            "Loss: 7.266655e-02\n",
            "Loss: 7.266404e-02\n",
            "Loss: 7.266503e-02\n",
            "Loss: 7.266215e-02\n",
            "Loss: 7.265988e-02\n",
            "Loss: 7.265806e-02\n",
            "Loss: 7.265554e-02\n",
            "Loss: 7.265341e-02\n",
            "Loss: 7.265050e-02\n",
            "Loss: 7.265059e-02\n",
            "Loss: 7.264956e-02\n",
            "Loss: 7.264861e-02\n",
            "Loss: 7.264692e-02\n",
            "Loss: 7.264530e-02\n",
            "Loss: 7.264265e-02\n",
            "Loss: 7.264310e-02\n",
            "Loss: 7.264118e-02\n",
            "Loss: 7.263858e-02\n",
            "Loss: 7.263709e-02\n",
            "Loss: 7.263499e-02\n",
            "Loss: 7.263172e-02\n",
            "Loss: 7.265318e-02\n",
            "Loss: 7.262998e-02\n",
            "Loss: 7.262614e-02\n",
            "Loss: 7.262269e-02\n",
            "Loss: 7.262078e-02\n",
            "Loss: 7.261813e-02\n",
            "Loss: 7.261559e-02\n",
            "Loss: 7.261396e-02\n",
            "Loss: 7.261088e-02\n",
            "Loss: 7.264796e-02\n",
            "Loss: 7.260989e-02\n",
            "Loss: 7.260656e-02\n",
            "Loss: 7.260265e-02\n",
            "Loss: 7.259788e-02\n",
            "Loss: 7.259745e-02\n",
            "Loss: 7.259445e-02\n",
            "Loss: 7.259289e-02\n",
            "Loss: 7.258826e-02\n",
            "Loss: 7.258528e-02\n",
            "Loss: 7.258382e-02\n",
            "Loss: 7.258128e-02\n",
            "Loss: 7.257992e-02\n",
            "Loss: 7.257847e-02\n",
            "Loss: 7.257611e-02\n",
            "Loss: 7.257424e-02\n",
            "Loss: 7.257241e-02\n",
            "Loss: 7.257092e-02\n",
            "Loss: 7.257047e-02\n",
            "Loss: 7.256721e-02\n",
            "Loss: 7.256848e-02\n",
            "Loss: 7.256632e-02\n",
            "Loss: 7.256274e-02\n",
            "Loss: 7.255977e-02\n",
            "Loss: 7.255583e-02\n",
            "Loss: 7.255458e-02\n",
            "Loss: 7.255252e-02\n",
            "Loss: 7.255103e-02\n",
            "Loss: 7.254834e-02\n",
            "Loss: 7.254586e-02\n",
            "Loss: 7.254408e-02\n",
            "Loss: 7.253999e-02\n",
            "Loss: 7.253835e-02\n",
            "Loss: 7.253539e-02\n",
            "Loss: 7.253395e-02\n",
            "Loss: 7.253228e-02\n",
            "Loss: 7.253078e-02\n",
            "Loss: 7.252846e-02\n",
            "Loss: 7.252555e-02\n",
            "Loss: 7.252263e-02\n",
            "Loss: 7.252020e-02\n",
            "Loss: 7.251733e-02\n",
            "Loss: 7.251559e-02\n",
            "Loss: 7.251140e-02\n",
            "Loss: 7.253160e-02\n",
            "Loss: 7.250999e-02\n",
            "Loss: 7.250768e-02\n",
            "Loss: 7.250500e-02\n",
            "Loss: 7.250294e-02\n",
            "Loss: 7.250039e-02\n",
            "Loss: 7.249831e-02\n",
            "Loss: 7.249603e-02\n",
            "Loss: 7.249690e-02\n",
            "Loss: 7.249525e-02\n",
            "Loss: 7.249364e-02\n",
            "Loss: 7.249188e-02\n",
            "Loss: 7.248823e-02\n",
            "Loss: 7.248846e-02\n",
            "Loss: 7.248603e-02\n",
            "Loss: 7.248118e-02\n",
            "Loss: 7.247444e-02\n",
            "Loss: 7.246997e-02\n",
            "Loss: 7.246945e-02\n",
            "Loss: 7.246246e-02\n",
            "Loss: 7.245880e-02\n",
            "Loss: 7.245450e-02\n",
            "Loss: 7.245095e-02\n",
            "Loss: 7.245099e-02\n",
            "Loss: 7.244757e-02\n",
            "Loss: 7.244200e-02\n",
            "Loss: 7.243908e-02\n",
            "Loss: 7.243673e-02\n",
            "Loss: 7.243585e-02\n",
            "Loss: 7.243397e-02\n",
            "Loss: 7.243244e-02\n",
            "Loss: 7.243098e-02\n",
            "Loss: 7.242943e-02\n",
            "Loss: 7.242814e-02\n",
            "Loss: 7.242578e-02\n",
            "Loss: 7.242279e-02\n",
            "Loss: 7.241942e-02\n",
            "Loss: 7.241415e-02\n",
            "Loss: 7.244023e-02\n",
            "Loss: 7.241250e-02\n",
            "Loss: 7.240868e-02\n",
            "Loss: 7.240502e-02\n",
            "Loss: 7.240091e-02\n",
            "Loss: 7.239990e-02\n",
            "Loss: 7.239769e-02\n",
            "Loss: 7.239647e-02\n",
            "Loss: 7.239523e-02\n",
            "Loss: 7.239319e-02\n",
            "Loss: 7.239111e-02\n",
            "Loss: 7.238950e-02\n",
            "Loss: 7.238749e-02\n",
            "Loss: 7.238591e-02\n",
            "Loss: 7.238404e-02\n",
            "Loss: 7.238279e-02\n",
            "Loss: 7.238077e-02\n",
            "Loss: 7.237890e-02\n",
            "Loss: 7.237513e-02\n",
            "Loss: 7.237120e-02\n",
            "Loss: 7.236960e-02\n",
            "Loss: 7.236616e-02\n",
            "Loss: 7.236483e-02\n",
            "Loss: 7.236269e-02\n",
            "Loss: 7.236102e-02\n",
            "Loss: 7.235823e-02\n",
            "Loss: 7.235703e-02\n",
            "Loss: 7.235547e-02\n",
            "Loss: 7.235315e-02\n",
            "Loss: 7.234970e-02\n",
            "Loss: 7.236094e-02\n",
            "Loss: 7.234859e-02\n",
            "Loss: 7.234582e-02\n",
            "Loss: 7.234288e-02\n",
            "Loss: 7.234077e-02\n",
            "Loss: 7.233851e-02\n",
            "Loss: 7.233703e-02\n",
            "Loss: 7.233382e-02\n",
            "Loss: 7.233188e-02\n",
            "Loss: 7.232998e-02\n",
            "Loss: 7.232675e-02\n",
            "Loss: 7.232936e-02\n",
            "Loss: 7.232498e-02\n",
            "Loss: 7.232192e-02\n",
            "Loss: 7.232061e-02\n",
            "Loss: 7.232356e-02\n",
            "Loss: 7.231933e-02\n",
            "Loss: 7.231686e-02\n",
            "Loss: 7.231571e-02\n",
            "Loss: 7.231390e-02\n",
            "Loss: 7.231220e-02\n",
            "Loss: 7.230940e-02\n",
            "Loss: 7.230665e-02\n",
            "Loss: 7.230509e-02\n",
            "Loss: 7.230253e-02\n",
            "Loss: 7.230032e-02\n",
            "Loss: 7.229687e-02\n",
            "Loss: 7.229456e-02\n",
            "Loss: 7.229243e-02\n",
            "Loss: 7.228958e-02\n",
            "Loss: 7.228390e-02\n",
            "Loss: 7.228390e-02\n",
            "Loss: 7.228108e-02\n",
            "Loss: 7.227582e-02\n",
            "Loss: 7.226961e-02\n",
            "Loss: 7.226362e-02\n",
            "Loss: 7.226955e-02\n",
            "Loss: 7.226183e-02\n",
            "Loss: 7.225966e-02\n",
            "Loss: 7.225732e-02\n",
            "Loss: 7.225449e-02\n",
            "Loss: 7.225220e-02\n",
            "Loss: 7.225059e-02\n",
            "Loss: 7.224885e-02\n",
            "Loss: 7.224812e-02\n",
            "Loss: 7.224681e-02\n",
            "Loss: 7.224417e-02\n",
            "Loss: 7.224411e-02\n",
            "Loss: 7.224023e-02\n",
            "Loss: 7.223956e-02\n",
            "Loss: 7.223727e-02\n",
            "Loss: 7.223479e-02\n",
            "Loss: 7.224088e-02\n",
            "Loss: 7.223414e-02\n",
            "Loss: 7.223153e-02\n",
            "Loss: 7.222955e-02\n",
            "Loss: 7.222656e-02\n",
            "Loss: 7.222357e-02\n",
            "Loss: 7.222012e-02\n",
            "Loss: 7.221588e-02\n",
            "Loss: 7.221329e-02\n",
            "Loss: 7.221068e-02\n",
            "Loss: 7.220645e-02\n",
            "Loss: 7.220449e-02\n",
            "Loss: 7.220191e-02\n",
            "Loss: 7.219928e-02\n",
            "Loss: 7.219540e-02\n",
            "Loss: 7.219086e-02\n",
            "Loss: 7.218763e-02\n",
            "Loss: 7.218534e-02\n",
            "Loss: 7.218331e-02\n",
            "Loss: 7.218297e-02\n",
            "Loss: 7.218000e-02\n",
            "Loss: 7.217784e-02\n",
            "Loss: 7.217547e-02\n",
            "Loss: 7.217358e-02\n",
            "Loss: 7.217097e-02\n",
            "Loss: 7.216872e-02\n",
            "Loss: 7.216756e-02\n",
            "Loss: 7.216325e-02\n",
            "Loss: 7.216947e-02\n",
            "Loss: 7.216264e-02\n",
            "Loss: 7.215985e-02\n",
            "Loss: 7.215844e-02\n",
            "Loss: 7.215579e-02\n",
            "Loss: 7.215128e-02\n",
            "Loss: 7.215605e-02\n",
            "Loss: 7.214941e-02\n",
            "Loss: 7.214555e-02\n",
            "Loss: 7.214193e-02\n",
            "Loss: 7.213702e-02\n",
            "Loss: 7.213338e-02\n",
            "Loss: 7.213181e-02\n",
            "Loss: 7.212922e-02\n",
            "Loss: 7.212754e-02\n",
            "Loss: 7.212586e-02\n",
            "Loss: 7.212215e-02\n",
            "Loss: 7.212363e-02\n",
            "Loss: 7.212055e-02\n",
            "Loss: 7.211744e-02\n",
            "Loss: 7.211542e-02\n",
            "Loss: 7.211319e-02\n",
            "Loss: 7.210904e-02\n",
            "Loss: 7.211048e-02\n",
            "Loss: 7.210790e-02\n",
            "Loss: 7.210514e-02\n",
            "Loss: 7.210350e-02\n",
            "Loss: 7.210063e-02\n",
            "Loss: 7.209875e-02\n",
            "Loss: 7.209735e-02\n",
            "Loss: 7.209639e-02\n",
            "Loss: 7.209449e-02\n",
            "Loss: 7.209226e-02\n",
            "Loss: 7.209067e-02\n",
            "Loss: 7.208791e-02\n",
            "Loss: 7.208576e-02\n",
            "Loss: 7.208194e-02\n",
            "Loss: 7.207974e-02\n",
            "Loss: 7.207704e-02\n",
            "Loss: 7.207747e-02\n",
            "Loss: 7.207527e-02\n",
            "Loss: 7.207358e-02\n",
            "Loss: 7.207145e-02\n",
            "Loss: 7.206830e-02\n",
            "Loss: 7.206234e-02\n",
            "Loss: 7.212107e-02\n",
            "Loss: 7.206137e-02\n",
            "Loss: 7.205748e-02\n",
            "Loss: 7.205532e-02\n",
            "Loss: 7.205390e-02\n",
            "Loss: 7.205495e-02\n",
            "Loss: 7.205313e-02\n",
            "Loss: 7.205192e-02\n",
            "Loss: 7.205071e-02\n",
            "Loss: 7.204965e-02\n",
            "Loss: 7.204779e-02\n",
            "Loss: 7.204747e-02\n",
            "Loss: 7.204449e-02\n",
            "Loss: 7.204369e-02\n",
            "Loss: 7.204206e-02\n",
            "Loss: 7.204214e-02\n",
            "Loss: 7.204112e-02\n",
            "Loss: 7.204025e-02\n",
            "Loss: 7.203959e-02\n",
            "Loss: 7.203884e-02\n",
            "Loss: 7.203696e-02\n",
            "Loss: 7.204133e-02\n",
            "Loss: 7.203547e-02\n",
            "Loss: 7.203228e-02\n",
            "Loss: 7.202899e-02\n",
            "Loss: 7.202619e-02\n",
            "Loss: 7.202545e-02\n",
            "Loss: 7.202338e-02\n",
            "Loss: 7.202236e-02\n",
            "Loss: 7.202145e-02\n",
            "Loss: 7.201970e-02\n",
            "Loss: 7.201826e-02\n",
            "Loss: 7.201591e-02\n",
            "Loss: 7.201537e-02\n",
            "Loss: 7.201390e-02\n",
            "Loss: 7.201268e-02\n",
            "Loss: 7.201020e-02\n",
            "Loss: 7.200650e-02\n",
            "Loss: 7.200358e-02\n",
            "Loss: 7.200143e-02\n",
            "Loss: 7.200011e-02\n",
            "Loss: 7.199924e-02\n",
            "Loss: 7.199787e-02\n",
            "Loss: 7.199626e-02\n",
            "Loss: 7.199474e-02\n",
            "Loss: 7.199290e-02\n",
            "Loss: 7.199145e-02\n",
            "Loss: 7.198880e-02\n",
            "Loss: 7.198776e-02\n",
            "Loss: 7.198658e-02\n",
            "Loss: 7.198574e-02\n",
            "Loss: 7.198502e-02\n",
            "Loss: 7.198424e-02\n",
            "Loss: 7.198304e-02\n",
            "Loss: 7.198168e-02\n",
            "Loss: 7.198095e-02\n",
            "Loss: 7.197996e-02\n",
            "Loss: 7.197603e-02\n",
            "Loss: 7.199792e-02\n",
            "Loss: 7.197535e-02\n",
            "Loss: 7.197221e-02\n",
            "Loss: 7.196932e-02\n",
            "Loss: 7.197049e-02\n",
            "Loss: 7.196857e-02\n",
            "Loss: 7.196680e-02\n",
            "Loss: 7.196566e-02\n",
            "Loss: 7.196297e-02\n",
            "Loss: 7.196043e-02\n",
            "Loss: 7.196057e-02\n",
            "Loss: 7.195877e-02\n",
            "Loss: 7.195773e-02\n",
            "Loss: 7.195688e-02\n",
            "Loss: 7.195749e-02\n",
            "Loss: 7.195634e-02\n",
            "Loss: 7.195578e-02\n",
            "Loss: 7.195341e-02\n",
            "Loss: 7.195055e-02\n",
            "Loss: 7.194853e-02\n",
            "Loss: 7.194515e-02\n",
            "Loss: 7.194344e-02\n",
            "Loss: 7.194150e-02\n",
            "Loss: 7.193977e-02\n",
            "Loss: 7.193754e-02\n",
            "Loss: 7.193558e-02\n",
            "Loss: 7.193476e-02\n",
            "Loss: 7.193312e-02\n",
            "Loss: 7.193072e-02\n",
            "Loss: 7.192878e-02\n",
            "Loss: 7.192574e-02\n",
            "Loss: 7.192389e-02\n",
            "Loss: 7.192182e-02\n",
            "Loss: 7.192043e-02\n",
            "Loss: 7.191575e-02\n",
            "Loss: 7.191499e-02\n",
            "Loss: 7.191022e-02\n",
            "Loss: 7.190800e-02\n",
            "Loss: 7.190713e-02\n",
            "Loss: 7.190495e-02\n",
            "Loss: 7.190347e-02\n",
            "Loss: 7.190014e-02\n",
            "Loss: 7.189873e-02\n",
            "Loss: 7.189570e-02\n",
            "Loss: 7.189479e-02\n",
            "Loss: 7.189302e-02\n",
            "Loss: 7.189220e-02\n",
            "Loss: 7.188924e-02\n",
            "Loss: 7.188752e-02\n",
            "Loss: 7.188572e-02\n",
            "Loss: 7.188461e-02\n",
            "Loss: 7.189127e-02\n",
            "Loss: 7.188356e-02\n",
            "Loss: 7.188161e-02\n",
            "Loss: 7.188094e-02\n",
            "Loss: 7.188036e-02\n",
            "Loss: 7.187892e-02\n",
            "Loss: 7.187626e-02\n",
            "Loss: 7.187607e-02\n",
            "Loss: 7.187460e-02\n",
            "Loss: 7.187347e-02\n",
            "Loss: 7.187207e-02\n",
            "Loss: 7.187218e-02\n",
            "Loss: 7.187206e-02\n",
            "Loss: 7.187139e-02\n",
            "Loss: 7.186923e-02\n",
            "Loss: 7.186663e-02\n",
            "Loss: 7.186556e-02\n",
            "Loss: 7.186264e-02\n",
            "Loss: 7.186144e-02\n",
            "Loss: 7.186094e-02\n",
            "Loss: 7.186011e-02\n",
            "Loss: 7.185888e-02\n",
            "Loss: 7.185768e-02\n",
            "Loss: 7.185477e-02\n",
            "Loss: 7.185318e-02\n",
            "Loss: 7.185012e-02\n",
            "Loss: 7.184912e-02\n",
            "Loss: 7.184829e-02\n",
            "Loss: 7.184751e-02\n",
            "Loss: 7.184665e-02\n",
            "Loss: 7.184531e-02\n",
            "Loss: 7.184438e-02\n",
            "Loss: 7.184373e-02\n",
            "Loss: 7.184263e-02\n",
            "Loss: 7.184324e-02\n",
            "Loss: 7.184217e-02\n",
            "Loss: 7.184146e-02\n",
            "Loss: 7.184060e-02\n",
            "Loss: 7.183973e-02\n",
            "Loss: 7.183728e-02\n",
            "Loss: 7.183530e-02\n",
            "Loss: 7.183213e-02\n",
            "Loss: 7.183018e-02\n",
            "Loss: 7.182786e-02\n",
            "Loss: 7.182723e-02\n",
            "Loss: 7.182555e-02\n",
            "Loss: 7.182415e-02\n",
            "Loss: 7.182282e-02\n",
            "Loss: 7.182014e-02\n",
            "Loss: 7.181607e-02\n",
            "Loss: 7.182015e-02\n",
            "Loss: 7.181407e-02\n",
            "Loss: 7.181225e-02\n",
            "Loss: 7.181004e-02\n",
            "Loss: 7.180895e-02\n",
            "Loss: 7.180554e-02\n",
            "Loss: 7.180379e-02\n",
            "Loss: 7.180194e-02\n",
            "Loss: 7.180088e-02\n",
            "Loss: 7.179914e-02\n",
            "Loss: 7.179753e-02\n",
            "Loss: 7.179624e-02\n",
            "Loss: 7.179460e-02\n",
            "Loss: 7.178906e-02\n",
            "Loss: 7.182648e-02\n",
            "Loss: 7.178818e-02\n",
            "Loss: 7.178679e-02\n",
            "Loss: 7.178639e-02\n",
            "Loss: 7.178496e-02\n",
            "Loss: 7.178280e-02\n",
            "Loss: 7.177983e-02\n",
            "Loss: 7.177860e-02\n",
            "Loss: 7.177725e-02\n",
            "Loss: 7.177651e-02\n",
            "Loss: 7.177535e-02\n",
            "Loss: 7.177424e-02\n",
            "Loss: 7.177284e-02\n",
            "Loss: 7.177167e-02\n",
            "Loss: 7.177065e-02\n",
            "Loss: 7.176995e-02\n",
            "Loss: 7.176746e-02\n",
            "Loss: 7.176706e-02\n",
            "Loss: 7.176395e-02\n",
            "Loss: 7.176309e-02\n",
            "Loss: 7.176108e-02\n",
            "Loss: 7.176067e-02\n",
            "Loss: 7.175884e-02\n",
            "Loss: 7.175817e-02\n",
            "Loss: 7.175730e-02\n",
            "Loss: 7.175627e-02\n",
            "Loss: 7.175609e-02\n",
            "Loss: 7.175505e-02\n",
            "Loss: 7.175249e-02\n",
            "Loss: 7.175147e-02\n",
            "Loss: 7.174999e-02\n",
            "Loss: 7.174927e-02\n",
            "Loss: 7.174797e-02\n",
            "Loss: 7.174681e-02\n",
            "Loss: 7.174567e-02\n",
            "Loss: 7.174365e-02\n",
            "Loss: 7.175596e-02\n",
            "Loss: 7.174297e-02\n",
            "Loss: 7.174160e-02\n",
            "Loss: 7.173927e-02\n",
            "Loss: 7.173728e-02\n",
            "Loss: 7.173555e-02\n",
            "Loss: 7.173356e-02\n",
            "Loss: 7.173228e-02\n",
            "Loss: 7.173035e-02\n",
            "Loss: 7.172912e-02\n",
            "Loss: 7.173546e-02\n",
            "Loss: 7.172823e-02\n",
            "Loss: 7.172626e-02\n",
            "Loss: 7.172488e-02\n",
            "Loss: 7.172326e-02\n",
            "Loss: 7.172173e-02\n",
            "Loss: 7.172069e-02\n",
            "Loss: 7.171953e-02\n",
            "Loss: 7.171869e-02\n",
            "Loss: 7.171723e-02\n",
            "Loss: 7.171607e-02\n",
            "Loss: 7.171339e-02\n",
            "Loss: 7.171262e-02\n",
            "Loss: 7.171082e-02\n",
            "Loss: 7.170919e-02\n",
            "Loss: 7.170669e-02\n",
            "Loss: 7.170507e-02\n",
            "Loss: 7.170407e-02\n",
            "Loss: 7.170272e-02\n",
            "Loss: 7.170121e-02\n",
            "Loss: 7.169966e-02\n",
            "Loss: 7.170591e-02\n",
            "Loss: 7.169946e-02\n",
            "Loss: 7.169880e-02\n",
            "Loss: 7.169713e-02\n",
            "Loss: 7.169592e-02\n",
            "Loss: 7.169507e-02\n",
            "Loss: 7.169732e-02\n",
            "Loss: 7.169475e-02\n",
            "Loss: 7.169382e-02\n",
            "Loss: 7.169282e-02\n",
            "Loss: 7.169163e-02\n",
            "Loss: 7.169019e-02\n",
            "Loss: 7.168886e-02\n",
            "Loss: 7.168767e-02\n",
            "Loss: 7.168629e-02\n",
            "Loss: 7.168462e-02\n",
            "Loss: 7.168446e-02\n",
            "Loss: 7.168359e-02\n",
            "Loss: 7.168296e-02\n",
            "Loss: 7.168236e-02\n",
            "Loss: 7.168080e-02\n",
            "Loss: 7.167940e-02\n",
            "Loss: 7.167713e-02\n",
            "Loss: 7.167526e-02\n",
            "Loss: 7.167350e-02\n",
            "Loss: 7.167178e-02\n",
            "Loss: 7.166878e-02\n",
            "Loss: 7.166848e-02\n",
            "Loss: 7.166626e-02\n",
            "Loss: 7.166582e-02\n",
            "Loss: 7.166488e-02\n",
            "Loss: 7.166463e-02\n",
            "Loss: 7.166378e-02\n",
            "Loss: 7.166288e-02\n",
            "Loss: 7.166217e-02\n",
            "Loss: 7.166065e-02\n",
            "Loss: 7.165663e-02\n",
            "Loss: 7.166755e-02\n",
            "Loss: 7.165607e-02\n",
            "Loss: 7.165406e-02\n",
            "Loss: 7.165305e-02\n",
            "Loss: 7.165174e-02\n",
            "Loss: 7.165053e-02\n",
            "Loss: 7.164876e-02\n",
            "Loss: 7.164596e-02\n",
            "Loss: 7.164654e-02\n",
            "Loss: 7.164504e-02\n",
            "Loss: 7.164379e-02\n",
            "Loss: 7.164233e-02\n",
            "Loss: 7.164004e-02\n",
            "Loss: 7.163855e-02\n",
            "Loss: 7.163753e-02\n",
            "Loss: 7.163613e-02\n",
            "Loss: 7.163499e-02\n",
            "Loss: 7.163259e-02\n",
            "Loss: 7.163025e-02\n",
            "Loss: 7.162878e-02\n",
            "Loss: 7.162791e-02\n",
            "Loss: 7.162459e-02\n",
            "Loss: 7.162239e-02\n",
            "Loss: 7.162064e-02\n",
            "Loss: 7.161914e-02\n",
            "Loss: 7.162476e-02\n",
            "Loss: 7.161826e-02\n",
            "Loss: 7.161706e-02\n",
            "Loss: 7.161637e-02\n",
            "Loss: 7.161557e-02\n",
            "Loss: 7.161396e-02\n",
            "Loss: 7.161317e-02\n",
            "Loss: 7.161175e-02\n",
            "Loss: 7.161081e-02\n",
            "Loss: 7.160889e-02\n",
            "Loss: 7.160746e-02\n",
            "Loss: 7.160546e-02\n",
            "Loss: 7.160378e-02\n",
            "Loss: 7.160283e-02\n",
            "Loss: 7.160100e-02\n",
            "Loss: 7.160955e-02\n",
            "Loss: 7.160030e-02\n",
            "Loss: 7.159873e-02\n",
            "Loss: 7.159726e-02\n",
            "Loss: 7.159486e-02\n",
            "Loss: 7.159206e-02\n",
            "Loss: 7.159452e-02\n",
            "Loss: 7.159121e-02\n",
            "Loss: 7.158852e-02\n",
            "Loss: 7.158657e-02\n",
            "Loss: 7.158389e-02\n",
            "Loss: 7.158218e-02\n",
            "Loss: 7.158104e-02\n",
            "Loss: 7.157871e-02\n",
            "Loss: 7.157715e-02\n",
            "Loss: 7.157496e-02\n",
            "Loss: 7.157196e-02\n",
            "Loss: 7.158883e-02\n",
            "Loss: 7.157118e-02\n",
            "Loss: 7.156919e-02\n",
            "Loss: 7.156777e-02\n",
            "Loss: 7.156590e-02\n",
            "Loss: 7.156458e-02\n",
            "Loss: 7.156255e-02\n",
            "Loss: 7.156028e-02\n",
            "Loss: 7.155868e-02\n",
            "Loss: 7.155595e-02\n",
            "Loss: 7.158040e-02\n",
            "Loss: 7.155553e-02\n",
            "Loss: 7.155282e-02\n",
            "Loss: 7.155050e-02\n",
            "Loss: 7.154932e-02\n",
            "Loss: 7.154804e-02\n",
            "Loss: 7.154637e-02\n",
            "Loss: 7.154471e-02\n",
            "Loss: 7.154255e-02\n",
            "Loss: 7.154057e-02\n",
            "Loss: 7.153939e-02\n",
            "Loss: 7.154087e-02\n",
            "Loss: 7.153915e-02\n",
            "Loss: 7.153752e-02\n",
            "Loss: 7.153583e-02\n",
            "Loss: 7.153355e-02\n",
            "Loss: 7.153513e-02\n",
            "Loss: 7.153273e-02\n",
            "Loss: 7.153168e-02\n",
            "Loss: 7.152990e-02\n",
            "Loss: 7.152793e-02\n",
            "Loss: 7.152940e-02\n",
            "Loss: 7.152722e-02\n",
            "Loss: 7.152446e-02\n",
            "Loss: 7.152387e-02\n",
            "Loss: 7.152250e-02\n",
            "Loss: 7.151992e-02\n",
            "Loss: 7.151797e-02\n",
            "Loss: 7.151572e-02\n",
            "Loss: 7.151469e-02\n",
            "Loss: 7.151454e-02\n",
            "Loss: 7.151298e-02\n",
            "Loss: 7.151263e-02\n",
            "Loss: 7.151150e-02\n",
            "Loss: 7.150968e-02\n",
            "Loss: 7.150812e-02\n",
            "Loss: 7.150639e-02\n",
            "Loss: 7.150410e-02\n",
            "Loss: 7.151591e-02\n",
            "Loss: 7.150311e-02\n",
            "Loss: 7.150111e-02\n",
            "Loss: 7.150013e-02\n",
            "Loss: 7.149920e-02\n",
            "Loss: 7.149799e-02\n",
            "Loss: 7.149656e-02\n",
            "Loss: 7.149710e-02\n",
            "Loss: 7.149559e-02\n",
            "Loss: 7.149337e-02\n",
            "Loss: 7.148986e-02\n",
            "Loss: 7.148717e-02\n",
            "Loss: 7.151552e-02\n",
            "Loss: 7.148699e-02\n",
            "Loss: 7.148554e-02\n",
            "Loss: 7.148433e-02\n",
            "Loss: 7.148275e-02\n",
            "Loss: 7.148181e-02\n",
            "Loss: 7.148053e-02\n",
            "Loss: 7.148229e-02\n",
            "Loss: 7.147936e-02\n",
            "Loss: 7.147793e-02\n",
            "Loss: 7.147710e-02\n",
            "Loss: 7.147536e-02\n",
            "Loss: 7.147557e-02\n",
            "Loss: 7.147455e-02\n",
            "Loss: 7.147354e-02\n",
            "Loss: 7.147206e-02\n",
            "Loss: 7.147127e-02\n",
            "Loss: 7.146881e-02\n",
            "Loss: 7.146762e-02\n",
            "Loss: 7.146497e-02\n",
            "Loss: 7.146324e-02\n",
            "Loss: 7.146180e-02\n",
            "Loss: 7.146282e-02\n",
            "Loss: 7.146074e-02\n",
            "Loss: 7.146005e-02\n",
            "Loss: 7.145937e-02\n",
            "Loss: 7.145794e-02\n",
            "Loss: 7.146079e-02\n",
            "Loss: 7.145763e-02\n",
            "Loss: 7.145710e-02\n",
            "Loss: 7.145569e-02\n",
            "Loss: 7.145431e-02\n",
            "Loss: 7.145342e-02\n",
            "Loss: 7.145183e-02\n",
            "Loss: 7.145054e-02\n",
            "Loss: 7.144795e-02\n",
            "Loss: 7.144507e-02\n",
            "Loss: 7.144393e-02\n",
            "Loss: 7.144184e-02\n",
            "Loss: 7.143969e-02\n",
            "Loss: 7.143900e-02\n",
            "Loss: 7.143638e-02\n",
            "Loss: 7.143383e-02\n",
            "Loss: 7.143817e-02\n",
            "Loss: 7.143289e-02\n",
            "Loss: 7.143100e-02\n",
            "Loss: 7.142920e-02\n",
            "Loss: 7.142670e-02\n",
            "Loss: 7.142538e-02\n",
            "Loss: 7.142466e-02\n",
            "Loss: 7.142375e-02\n",
            "Loss: 7.142314e-02\n",
            "Loss: 7.142267e-02\n",
            "Loss: 7.142083e-02\n",
            "Loss: 7.142127e-02\n",
            "Loss: 7.142013e-02\n",
            "Loss: 7.141863e-02\n",
            "Loss: 7.141745e-02\n",
            "Loss: 7.141676e-02\n",
            "Loss: 7.141606e-02\n",
            "Loss: 7.141573e-02\n",
            "Loss: 7.141449e-02\n",
            "Loss: 7.141365e-02\n",
            "Loss: 7.141158e-02\n",
            "Loss: 7.141007e-02\n",
            "Loss: 7.140839e-02\n",
            "Loss: 7.140769e-02\n",
            "Loss: 7.140624e-02\n",
            "Loss: 7.140546e-02\n",
            "Loss: 7.140476e-02\n",
            "Loss: 7.140416e-02\n",
            "Loss: 7.140349e-02\n",
            "Loss: 7.140237e-02\n",
            "Loss: 7.140265e-02\n",
            "Loss: 7.140139e-02\n",
            "Loss: 7.140038e-02\n",
            "Loss: 7.139891e-02\n",
            "Loss: 7.139793e-02\n",
            "Loss: 7.139678e-02\n",
            "Loss: 7.139797e-02\n",
            "Loss: 7.139643e-02\n",
            "Loss: 7.139505e-02\n",
            "Loss: 7.139349e-02\n",
            "Loss: 7.139192e-02\n",
            "Loss: 7.139382e-02\n",
            "Loss: 7.139198e-02\n",
            "Loss: 7.139228e-02\n",
            "Loss: 7.139178e-02\n",
            "Loss: 7.139177e-02\n",
            "Loss: 7.139224e-02\n",
            "Loss: 7.139166e-02\n",
            "Loss: 7.139155e-02\n",
            "Loss: 7.139208e-02\n",
            "Loss: 7.139193e-02\n",
            "Loss: 7.139155e-02\n",
            "Loss: 7.139146e-02\n",
            "Loss: 7.139093e-02\n",
            "Loss: 7.138939e-02\n",
            "Loss: 7.138867e-02\n",
            "Loss: 7.138625e-02\n",
            "Loss: 7.138509e-02\n",
            "Loss: 7.138359e-02\n",
            "Loss: 7.138181e-02\n",
            "Loss: 7.138427e-02\n",
            "Loss: 7.138106e-02\n",
            "Loss: 7.137952e-02\n",
            "Loss: 7.137801e-02\n",
            "Loss: 7.137594e-02\n",
            "Loss: 7.137400e-02\n",
            "Loss: 7.137236e-02\n",
            "Loss: 7.137070e-02\n",
            "Loss: 7.136988e-02\n",
            "Loss: 7.136928e-02\n",
            "Loss: 7.136817e-02\n",
            "Loss: 7.136708e-02\n",
            "Loss: 7.136549e-02\n",
            "Loss: 7.136506e-02\n",
            "Loss: 7.136407e-02\n",
            "Loss: 7.136351e-02\n",
            "Loss: 7.136219e-02\n",
            "Loss: 7.136017e-02\n",
            "Loss: 7.135984e-02\n",
            "Loss: 7.135860e-02\n",
            "Loss: 7.135786e-02\n",
            "Loss: 7.135740e-02\n",
            "Loss: 7.135640e-02\n",
            "Loss: 7.135552e-02\n",
            "Loss: 7.135423e-02\n",
            "Loss: 7.135374e-02\n",
            "Loss: 7.135242e-02\n",
            "Loss: 7.135171e-02\n",
            "Loss: 7.134981e-02\n",
            "Loss: 7.134995e-02\n",
            "Loss: 7.134848e-02\n",
            "Loss: 7.134771e-02\n",
            "Loss: 7.134660e-02\n",
            "Loss: 7.134648e-02\n",
            "Loss: 7.134479e-02\n",
            "Loss: 7.134371e-02\n",
            "Loss: 7.134234e-02\n",
            "Loss: 7.134127e-02\n",
            "Loss: 7.133952e-02\n",
            "Loss: 7.133906e-02\n",
            "Loss: 7.133673e-02\n",
            "Loss: 7.133569e-02\n",
            "Loss: 7.133494e-02\n",
            "Loss: 7.133472e-02\n",
            "Loss: 7.133377e-02\n",
            "Loss: 7.133339e-02\n",
            "Loss: 7.133251e-02\n",
            "Loss: 7.133184e-02\n",
            "Loss: 7.133590e-02\n",
            "Loss: 7.133157e-02\n",
            "Loss: 7.133004e-02\n",
            "Loss: 7.132927e-02\n",
            "Loss: 7.132833e-02\n",
            "Loss: 7.132737e-02\n",
            "Loss: 7.132515e-02\n",
            "Loss: 7.132250e-02\n",
            "Loss: 7.132159e-02\n",
            "Loss: 7.131887e-02\n",
            "Loss: 7.131797e-02\n",
            "Loss: 7.131681e-02\n",
            "Loss: 7.131530e-02\n",
            "Loss: 7.131328e-02\n",
            "Loss: 7.131193e-02\n",
            "Loss: 7.131120e-02\n",
            "Loss: 7.131048e-02\n",
            "Loss: 7.130884e-02\n",
            "Loss: 7.130707e-02\n",
            "Loss: 7.130558e-02\n",
            "Loss: 7.130335e-02\n",
            "Loss: 7.130208e-02\n",
            "Loss: 7.130092e-02\n",
            "Loss: 7.129850e-02\n",
            "Loss: 7.129449e-02\n",
            "Loss: 7.129891e-02\n",
            "Loss: 7.129324e-02\n",
            "Loss: 7.129057e-02\n",
            "Loss: 7.128898e-02\n",
            "Loss: 7.128584e-02\n",
            "Loss: 7.128930e-02\n",
            "Loss: 7.128475e-02\n",
            "Loss: 7.128296e-02\n",
            "Loss: 7.128008e-02\n",
            "Loss: 7.127731e-02\n",
            "Loss: 7.127221e-02\n",
            "Loss: 7.127097e-02\n",
            "Loss: 7.126676e-02\n",
            "Loss: 7.126523e-02\n",
            "Loss: 7.126321e-02\n",
            "Loss: 7.126144e-02\n",
            "Loss: 7.125849e-02\n",
            "Loss: 7.125609e-02\n",
            "Loss: 7.125391e-02\n",
            "Loss: 7.125195e-02\n",
            "Loss: 7.125007e-02\n",
            "Loss: 7.124705e-02\n",
            "Loss: 7.125377e-02\n",
            "Loss: 7.124604e-02\n",
            "Loss: 7.124418e-02\n",
            "Loss: 7.124218e-02\n",
            "Loss: 7.124008e-02\n",
            "Loss: 7.124320e-02\n",
            "Loss: 7.123939e-02\n",
            "Loss: 7.123759e-02\n",
            "Loss: 7.123700e-02\n",
            "Loss: 7.123586e-02\n",
            "Loss: 7.123309e-02\n",
            "Loss: 7.123478e-02\n",
            "Loss: 7.123233e-02\n",
            "Loss: 7.123016e-02\n",
            "Loss: 7.122909e-02\n",
            "Loss: 7.122818e-02\n",
            "Loss: 7.122735e-02\n",
            "Loss: 7.122523e-02\n",
            "Loss: 7.122406e-02\n",
            "Loss: 7.122186e-02\n",
            "Loss: 7.122277e-02\n",
            "Loss: 7.122118e-02\n",
            "Loss: 7.121903e-02\n",
            "Loss: 7.121795e-02\n",
            "Loss: 7.121560e-02\n",
            "Loss: 7.121491e-02\n",
            "Loss: 7.121214e-02\n",
            "Loss: 7.120951e-02\n",
            "Loss: 7.120788e-02\n",
            "Loss: 7.120650e-02\n",
            "Loss: 7.120499e-02\n",
            "Loss: 7.121147e-02\n",
            "Loss: 7.120445e-02\n",
            "Loss: 7.120297e-02\n",
            "Loss: 7.120224e-02\n",
            "Loss: 7.120001e-02\n",
            "Loss: 7.119799e-02\n",
            "Loss: 7.119782e-02\n",
            "Loss: 7.119507e-02\n",
            "Loss: 7.119419e-02\n",
            "Loss: 7.119284e-02\n",
            "Loss: 7.119133e-02\n",
            "Loss: 7.119103e-02\n",
            "Loss: 7.119027e-02\n",
            "Loss: 7.118864e-02\n",
            "Loss: 7.118645e-02\n",
            "Loss: 7.119054e-02\n",
            "Loss: 7.118534e-02\n",
            "Loss: 7.118353e-02\n",
            "Loss: 7.118239e-02\n",
            "Loss: 7.118114e-02\n",
            "Loss: 7.117997e-02\n",
            "Loss: 7.117915e-02\n",
            "Loss: 7.117727e-02\n",
            "Loss: 7.117662e-02\n",
            "Loss: 7.117641e-02\n",
            "Loss: 7.117423e-02\n",
            "Loss: 7.117259e-02\n",
            "Loss: 7.117110e-02\n",
            "Loss: 7.116955e-02\n",
            "Loss: 7.116786e-02\n",
            "Loss: 7.116634e-02\n",
            "Loss: 7.116555e-02\n",
            "Loss: 7.116449e-02\n",
            "Loss: 7.116374e-02\n",
            "Loss: 7.116336e-02\n",
            "Loss: 7.116211e-02\n",
            "Loss: 7.116326e-02\n",
            "Loss: 7.116142e-02\n",
            "Loss: 7.116030e-02\n",
            "Loss: 7.115892e-02\n",
            "Loss: 7.115716e-02\n",
            "Loss: 7.115678e-02\n",
            "Loss: 7.115639e-02\n",
            "Loss: 7.115550e-02\n",
            "Loss: 7.115506e-02\n",
            "Loss: 7.115393e-02\n",
            "Loss: 7.115401e-02\n",
            "Loss: 7.115348e-02\n",
            "Loss: 7.115319e-02\n",
            "Loss: 7.115196e-02\n",
            "Loss: 7.115103e-02\n",
            "Loss: 7.114874e-02\n",
            "Loss: 7.114661e-02\n",
            "Loss: 7.114606e-02\n",
            "Loss: 7.114332e-02\n",
            "Loss: 7.114233e-02\n",
            "Loss: 7.114204e-02\n",
            "Loss: 7.114028e-02\n",
            "Loss: 7.113959e-02\n",
            "Loss: 7.113804e-02\n",
            "Loss: 7.113715e-02\n",
            "Loss: 7.113524e-02\n",
            "Loss: 7.113417e-02\n",
            "Loss: 7.113194e-02\n",
            "Loss: 7.113572e-02\n",
            "Loss: 7.113155e-02\n",
            "Loss: 7.113042e-02\n",
            "Loss: 7.112953e-02\n",
            "Loss: 7.112787e-02\n",
            "Loss: 7.112665e-02\n",
            "Loss: 7.112551e-02\n",
            "Loss: 7.112388e-02\n",
            "Loss: 7.112209e-02\n",
            "Loss: 7.112113e-02\n",
            "Loss: 7.111939e-02\n",
            "Loss: 7.111665e-02\n",
            "Loss: 7.112560e-02\n",
            "Loss: 7.111573e-02\n",
            "Loss: 7.111399e-02\n",
            "Loss: 7.111185e-02\n",
            "Loss: 7.111113e-02\n",
            "Loss: 7.111015e-02\n",
            "Loss: 7.110914e-02\n",
            "Loss: 7.110749e-02\n",
            "Loss: 7.110564e-02\n",
            "Loss: 7.110460e-02\n",
            "Loss: 7.110332e-02\n",
            "Loss: 7.110289e-02\n",
            "Loss: 7.110224e-02\n",
            "Loss: 7.110015e-02\n",
            "Loss: 7.109890e-02\n",
            "Loss: 7.109791e-02\n",
            "Loss: 7.109711e-02\n",
            "Loss: 7.109626e-02\n",
            "Loss: 7.109551e-02\n",
            "Loss: 7.109407e-02\n",
            "Loss: 7.109758e-02\n",
            "Loss: 7.109300e-02\n",
            "Loss: 7.109118e-02\n",
            "Loss: 7.108976e-02\n",
            "Loss: 7.108745e-02\n",
            "Loss: 7.108808e-02\n",
            "Loss: 7.108691e-02\n",
            "Loss: 7.108528e-02\n",
            "Loss: 7.108356e-02\n",
            "Loss: 7.108196e-02\n",
            "Loss: 7.108007e-02\n",
            "Loss: 7.107852e-02\n",
            "Loss: 7.107656e-02\n",
            "Loss: 7.107610e-02\n",
            "Loss: 7.107497e-02\n",
            "Loss: 7.107671e-02\n",
            "Loss: 7.107449e-02\n",
            "Loss: 7.107305e-02\n",
            "Loss: 7.107255e-02\n",
            "Loss: 7.107195e-02\n",
            "Loss: 7.107131e-02\n",
            "Loss: 7.107046e-02\n",
            "Loss: 7.106968e-02\n",
            "Loss: 7.106771e-02\n",
            "Loss: 7.106659e-02\n",
            "Loss: 7.106443e-02\n",
            "Loss: 7.106221e-02\n",
            "Loss: 7.106121e-02\n",
            "Loss: 7.106026e-02\n",
            "Loss: 7.105825e-02\n",
            "Loss: 7.105719e-02\n",
            "Loss: 7.105511e-02\n",
            "Loss: 7.105421e-02\n",
            "Loss: 7.105225e-02\n",
            "Loss: 7.105204e-02\n",
            "Loss: 7.105113e-02\n",
            "Loss: 7.105025e-02\n",
            "Loss: 7.104973e-02\n",
            "Loss: 7.104926e-02\n",
            "Loss: 7.104856e-02\n",
            "Loss: 7.104695e-02\n",
            "Loss: 7.104541e-02\n",
            "Loss: 7.104443e-02\n",
            "Loss: 7.104309e-02\n",
            "Loss: 7.104029e-02\n",
            "Loss: 7.104200e-02\n",
            "Loss: 7.103971e-02\n",
            "Loss: 7.103840e-02\n",
            "Loss: 7.103667e-02\n",
            "Loss: 7.103460e-02\n",
            "Loss: 7.103281e-02\n",
            "Loss: 7.103099e-02\n",
            "Loss: 7.102943e-02\n",
            "Loss: 7.102863e-02\n",
            "Loss: 7.102702e-02\n",
            "Loss: 7.102535e-02\n",
            "Loss: 7.102577e-02\n",
            "Loss: 7.102393e-02\n",
            "Loss: 7.102321e-02\n",
            "Loss: 7.102216e-02\n",
            "Loss: 7.102142e-02\n",
            "Loss: 7.102072e-02\n",
            "Loss: 7.102030e-02\n",
            "Loss: 7.101986e-02\n",
            "Loss: 7.101886e-02\n",
            "Loss: 7.101735e-02\n",
            "Loss: 7.101533e-02\n",
            "Loss: 7.101165e-02\n",
            "Loss: 7.100934e-02\n",
            "Loss: 7.100777e-02\n",
            "Loss: 7.100736e-02\n",
            "Loss: 7.100642e-02\n",
            "Loss: 7.100587e-02\n",
            "Loss: 7.100549e-02\n",
            "Loss: 7.100455e-02\n",
            "Loss: 7.100240e-02\n",
            "Loss: 7.101958e-02\n",
            "Loss: 7.100189e-02\n",
            "Loss: 7.099999e-02\n",
            "Loss: 7.099948e-02\n",
            "Loss: 7.099851e-02\n",
            "Loss: 7.099757e-02\n",
            "Loss: 7.099718e-02\n",
            "Loss: 7.099579e-02\n",
            "Loss: 7.099541e-02\n",
            "Loss: 7.099454e-02\n",
            "Loss: 7.099336e-02\n",
            "Loss: 7.100031e-02\n",
            "Loss: 7.099241e-02\n",
            "Loss: 7.099070e-02\n",
            "Loss: 7.098927e-02\n",
            "Loss: 7.098784e-02\n",
            "Loss: 7.098667e-02\n",
            "Loss: 7.098871e-02\n",
            "Loss: 7.098622e-02\n",
            "Loss: 7.098529e-02\n",
            "Loss: 7.098398e-02\n",
            "Loss: 7.098246e-02\n",
            "Loss: 7.098076e-02\n",
            "Loss: 7.097880e-02\n",
            "Loss: 7.097874e-02\n",
            "Loss: 7.097772e-02\n",
            "Loss: 7.097619e-02\n",
            "Loss: 7.097505e-02\n",
            "Loss: 7.097404e-02\n",
            "Loss: 7.097272e-02\n",
            "Loss: 7.097019e-02\n",
            "Loss: 7.096815e-02\n",
            "Loss: 7.096797e-02\n",
            "Loss: 7.096710e-02\n",
            "Loss: 7.096560e-02\n",
            "Loss: 7.096451e-02\n",
            "Loss: 7.096297e-02\n",
            "Loss: 7.096183e-02\n",
            "Loss: 7.096069e-02\n",
            "Loss: 7.096005e-02\n",
            "Loss: 7.095839e-02\n",
            "Loss: 7.095735e-02\n",
            "Loss: 7.095875e-02\n",
            "Loss: 7.095646e-02\n",
            "Loss: 7.095537e-02\n",
            "Loss: 7.095505e-02\n",
            "Loss: 7.095429e-02\n",
            "Loss: 7.095265e-02\n",
            "Loss: 7.095063e-02\n",
            "Loss: 7.094884e-02\n",
            "Loss: 7.094752e-02\n",
            "Loss: 7.094579e-02\n",
            "Loss: 7.094540e-02\n",
            "Loss: 7.094458e-02\n",
            "Loss: 7.094397e-02\n",
            "Loss: 7.094300e-02\n",
            "Loss: 7.094263e-02\n",
            "Loss: 7.094119e-02\n",
            "Loss: 7.093992e-02\n",
            "Loss: 7.093862e-02\n",
            "Loss: 7.094234e-02\n",
            "Loss: 7.093783e-02\n",
            "Loss: 7.093615e-02\n",
            "Loss: 7.093476e-02\n",
            "Loss: 7.093439e-02\n",
            "Loss: 7.093304e-02\n",
            "Loss: 7.093289e-02\n",
            "Loss: 7.093199e-02\n",
            "Loss: 7.093090e-02\n",
            "Loss: 7.093088e-02\n",
            "Loss: 7.093021e-02\n",
            "Loss: 7.092925e-02\n",
            "Loss: 7.092874e-02\n",
            "Loss: 7.092775e-02\n",
            "Loss: 7.092732e-02\n",
            "Loss: 7.092623e-02\n",
            "Loss: 7.092611e-02\n",
            "Loss: 7.092439e-02\n",
            "Loss: 7.092334e-02\n",
            "Loss: 7.092218e-02\n",
            "Loss: 7.092070e-02\n",
            "Loss: 7.091943e-02\n",
            "Loss: 7.091832e-02\n",
            "Loss: 7.091771e-02\n",
            "Loss: 7.091689e-02\n",
            "Loss: 7.091650e-02\n",
            "Loss: 7.091527e-02\n",
            "Loss: 7.091301e-02\n",
            "Loss: 7.091756e-02\n",
            "Loss: 7.091220e-02\n",
            "Loss: 7.091089e-02\n",
            "Loss: 7.090919e-02\n",
            "Loss: 7.090718e-02\n",
            "Loss: 7.091494e-02\n",
            "Loss: 7.090712e-02\n",
            "Loss: 7.090665e-02\n",
            "Loss: 7.090589e-02\n",
            "Loss: 7.090498e-02\n",
            "Loss: 7.090397e-02\n",
            "Loss: 7.090840e-02\n",
            "Loss: 7.090309e-02\n",
            "Loss: 7.090209e-02\n",
            "Loss: 7.090166e-02\n",
            "Loss: 7.090085e-02\n",
            "Loss: 7.089897e-02\n",
            "Loss: 7.089783e-02\n",
            "Loss: 7.089645e-02\n",
            "Loss: 7.089549e-02\n",
            "Loss: 7.089404e-02\n",
            "Loss: 7.089394e-02\n",
            "Loss: 7.089244e-02\n",
            "Loss: 7.089123e-02\n",
            "Loss: 7.089090e-02\n",
            "Loss: 7.088977e-02\n",
            "Loss: 7.088893e-02\n",
            "Loss: 7.088639e-02\n",
            "Loss: 7.088622e-02\n",
            "Loss: 7.088491e-02\n",
            "Loss: 7.088438e-02\n",
            "Loss: 7.088286e-02\n",
            "Loss: 7.088232e-02\n",
            "Loss: 7.088161e-02\n",
            "Loss: 7.088077e-02\n",
            "Loss: 7.088005e-02\n",
            "Loss: 7.087944e-02\n",
            "Loss: 7.087883e-02\n",
            "Loss: 7.087893e-02\n",
            "Loss: 7.087796e-02\n",
            "Loss: 7.087678e-02\n",
            "Loss: 7.087570e-02\n",
            "Loss: 7.087466e-02\n",
            "Loss: 7.087700e-02\n",
            "Loss: 7.087404e-02\n",
            "Loss: 7.087351e-02\n",
            "Loss: 7.087198e-02\n",
            "Loss: 7.087103e-02\n",
            "Loss: 7.086992e-02\n",
            "Loss: 7.086890e-02\n",
            "Loss: 7.086633e-02\n",
            "Loss: 7.086512e-02\n",
            "Loss: 7.086642e-02\n",
            "Loss: 7.086432e-02\n",
            "Loss: 7.086320e-02\n",
            "Loss: 7.086253e-02\n",
            "Loss: 7.086089e-02\n",
            "Loss: 7.085984e-02\n",
            "Loss: 7.085931e-02\n",
            "Loss: 7.085729e-02\n",
            "Loss: 7.085581e-02\n",
            "Loss: 7.085519e-02\n",
            "Loss: 7.085391e-02\n",
            "Loss: 7.085367e-02\n",
            "Loss: 7.085298e-02\n",
            "Loss: 7.085091e-02\n",
            "Loss: 7.084838e-02\n",
            "Loss: 7.086603e-02\n",
            "Loss: 7.084759e-02\n",
            "Loss: 7.084641e-02\n",
            "Loss: 7.084534e-02\n",
            "Loss: 7.084450e-02\n",
            "Loss: 7.084286e-02\n",
            "Loss: 7.084068e-02\n",
            "Loss: 7.084180e-02\n",
            "Loss: 7.083945e-02\n",
            "Loss: 7.083849e-02\n",
            "Loss: 7.083768e-02\n",
            "Loss: 7.083666e-02\n",
            "Loss: 7.083491e-02\n",
            "Loss: 7.083852e-02\n",
            "Loss: 7.083418e-02\n",
            "Loss: 7.083265e-02\n",
            "Loss: 7.083165e-02\n",
            "Loss: 7.083043e-02\n",
            "Loss: 7.082850e-02\n",
            "Loss: 7.082649e-02\n",
            "Loss: 7.082564e-02\n",
            "Loss: 7.082422e-02\n",
            "Loss: 7.082319e-02\n",
            "Loss: 7.082254e-02\n",
            "Loss: 7.082146e-02\n",
            "Loss: 7.081933e-02\n",
            "Loss: 7.081872e-02\n",
            "Loss: 7.081722e-02\n",
            "Loss: 7.081567e-02\n",
            "Loss: 7.081574e-02\n",
            "Loss: 7.081561e-02\n",
            "Loss: 7.081455e-02\n",
            "Loss: 7.081232e-02\n",
            "Loss: 7.081126e-02\n",
            "Loss: 7.081059e-02\n",
            "Loss: 7.080957e-02\n",
            "Loss: 7.080843e-02\n",
            "Loss: 7.080752e-02\n",
            "Loss: 7.080619e-02\n",
            "Loss: 7.080411e-02\n",
            "Loss: 7.080180e-02\n",
            "Loss: 7.079989e-02\n",
            "Loss: 7.079822e-02\n",
            "Loss: 7.079958e-02\n",
            "Loss: 7.079777e-02\n",
            "Loss: 7.079645e-02\n",
            "Loss: 7.079524e-02\n",
            "Loss: 7.079498e-02\n",
            "Loss: 7.079445e-02\n",
            "Loss: 7.079329e-02\n",
            "Loss: 7.079218e-02\n",
            "Loss: 7.079054e-02\n",
            "Loss: 7.078937e-02\n",
            "Loss: 7.078803e-02\n",
            "Loss: 7.078736e-02\n",
            "Loss: 7.078668e-02\n",
            "Loss: 7.078594e-02\n",
            "Loss: 7.078506e-02\n",
            "Loss: 7.078899e-02\n",
            "Loss: 7.078470e-02\n",
            "Loss: 7.078316e-02\n",
            "Loss: 7.078225e-02\n",
            "Loss: 7.078047e-02\n",
            "Loss: 7.077827e-02\n",
            "Loss: 7.077701e-02\n",
            "Loss: 7.077620e-02\n",
            "Loss: 7.077452e-02\n",
            "Loss: 7.077387e-02\n",
            "Loss: 7.077288e-02\n",
            "Loss: 7.077142e-02\n",
            "Loss: 7.077869e-02\n",
            "Loss: 7.077071e-02\n",
            "Loss: 7.076935e-02\n",
            "Loss: 7.076781e-02\n",
            "Loss: 7.076670e-02\n",
            "Loss: 7.076472e-02\n",
            "Loss: 7.076263e-02\n",
            "Loss: 7.075928e-02\n",
            "Loss: 7.075702e-02\n",
            "Loss: 7.075436e-02\n",
            "Loss: 7.075334e-02\n",
            "Loss: 7.075261e-02\n",
            "Loss: 7.075101e-02\n",
            "Loss: 7.075006e-02\n",
            "Loss: 7.074890e-02\n",
            "Loss: 7.074702e-02\n",
            "Loss: 7.074855e-02\n",
            "Loss: 7.074653e-02\n",
            "Loss: 7.074549e-02\n",
            "Loss: 7.074524e-02\n",
            "Loss: 7.074460e-02\n",
            "Loss: 7.074406e-02\n",
            "Loss: 7.074283e-02\n",
            "Loss: 7.074410e-02\n",
            "Loss: 7.074252e-02\n",
            "Loss: 7.074163e-02\n",
            "Loss: 7.074038e-02\n",
            "Loss: 7.073927e-02\n",
            "Loss: 7.073837e-02\n",
            "Loss: 7.073646e-02\n",
            "Loss: 7.073515e-02\n",
            "Loss: 7.073364e-02\n",
            "Loss: 7.073227e-02\n",
            "Loss: 7.073194e-02\n",
            "Loss: 7.073112e-02\n",
            "Loss: 7.073040e-02\n",
            "Loss: 7.072924e-02\n",
            "Loss: 7.072815e-02\n",
            "Loss: 7.072616e-02\n",
            "Loss: 7.073501e-02\n",
            "Loss: 7.072531e-02\n",
            "Loss: 7.072452e-02\n",
            "Loss: 7.072242e-02\n",
            "Loss: 7.072221e-02\n",
            "Loss: 7.072128e-02\n",
            "Loss: 7.072075e-02\n",
            "Loss: 7.072021e-02\n",
            "Loss: 7.071932e-02\n",
            "Loss: 7.071788e-02\n",
            "Loss: 7.071846e-02\n",
            "Loss: 7.071733e-02\n",
            "Loss: 7.071611e-02\n",
            "Loss: 7.071605e-02\n",
            "Loss: 7.071522e-02\n",
            "Loss: 7.071347e-02\n",
            "Loss: 7.071839e-02\n",
            "Loss: 7.071270e-02\n",
            "Loss: 7.071028e-02\n",
            "Loss: 7.070889e-02\n",
            "Loss: 7.070840e-02\n",
            "Loss: 7.070717e-02\n",
            "Loss: 7.070656e-02\n",
            "Loss: 7.070530e-02\n",
            "Loss: 7.070364e-02\n",
            "Loss: 7.070148e-02\n",
            "Loss: 7.070333e-02\n",
            "Loss: 7.069981e-02\n",
            "Loss: 7.069801e-02\n",
            "Loss: 7.069653e-02\n",
            "Loss: 7.069562e-02\n",
            "Loss: 7.069375e-02\n",
            "Loss: 7.069322e-02\n",
            "Loss: 7.069167e-02\n",
            "Loss: 7.068954e-02\n",
            "Loss: 7.069138e-02\n",
            "Loss: 7.068919e-02\n",
            "Loss: 7.068781e-02\n",
            "Loss: 7.068744e-02\n",
            "Loss: 7.068683e-02\n",
            "Loss: 7.068633e-02\n",
            "Loss: 7.068549e-02\n",
            "Loss: 7.068514e-02\n",
            "Loss: 7.068478e-02\n",
            "Loss: 7.068378e-02\n",
            "Loss: 7.068311e-02\n",
            "Loss: 7.068200e-02\n",
            "Loss: 7.068107e-02\n",
            "Loss: 7.067961e-02\n",
            "Loss: 7.067832e-02\n",
            "Loss: 7.067659e-02\n",
            "Loss: 7.067554e-02\n",
            "Loss: 7.067432e-02\n",
            "Loss: 7.067382e-02\n",
            "Loss: 7.067316e-02\n",
            "Loss: 7.067236e-02\n",
            "Loss: 7.067142e-02\n",
            "Loss: 7.067150e-02\n",
            "Loss: 7.067029e-02\n",
            "Loss: 7.066942e-02\n",
            "Loss: 7.066865e-02\n",
            "Loss: 7.066786e-02\n",
            "Loss: 7.066716e-02\n",
            "Loss: 7.066662e-02\n",
            "Loss: 7.066614e-02\n",
            "Loss: 7.066572e-02\n",
            "Loss: 7.066441e-02\n",
            "Loss: 7.066446e-02\n",
            "Loss: 7.066428e-02\n",
            "Loss: 7.066324e-02\n",
            "Loss: 7.066271e-02\n",
            "Loss: 7.066096e-02\n",
            "Loss: 7.066076e-02\n",
            "Loss: 7.065918e-02\n",
            "Loss: 7.065849e-02\n",
            "Loss: 7.065742e-02\n",
            "Loss: 7.065752e-02\n",
            "Loss: 7.065684e-02\n",
            "Loss: 7.065611e-02\n",
            "Loss: 7.065558e-02\n",
            "Loss: 7.065460e-02\n",
            "Loss: 7.065322e-02\n",
            "Loss: 7.065145e-02\n",
            "Loss: 7.064950e-02\n",
            "Loss: 7.064903e-02\n",
            "Loss: 7.064816e-02\n",
            "Loss: 7.064725e-02\n",
            "Loss: 7.064624e-02\n",
            "Loss: 7.064569e-02\n",
            "Loss: 7.064436e-02\n",
            "Loss: 7.064302e-02\n",
            "Loss: 7.064138e-02\n",
            "Loss: 7.064077e-02\n",
            "Loss: 7.064050e-02\n",
            "Loss: 7.063958e-02\n",
            "Loss: 7.063884e-02\n",
            "Loss: 7.063892e-02\n",
            "Loss: 7.063858e-02\n",
            "Loss: 7.063787e-02\n",
            "Loss: 7.063749e-02\n",
            "Loss: 7.063654e-02\n",
            "Loss: 7.063655e-02\n",
            "Loss: 7.063662e-02\n",
            "Loss: 7.063699e-02\n",
            "Loss: 7.063641e-02\n",
            "Loss: 7.063648e-02\n",
            "Loss: 7.063641e-02\n",
            "Loss: 7.063641e-02\n",
            "Loss: 7.063670e-02\n",
            "Loss: 7.063641e-02\n",
            "Loss: 7.063641e-02\n",
            "Loss: 7.063684e-02\n",
            "Loss: 7.063641e-02\n",
            "Loss: 7.063641e-02\n",
            "Loss: 7.063672e-02\n",
            "Loss: 7.063641e-02\n",
            "Loss: 7.063638e-02\n",
            "Loss: 7.063570e-02\n",
            "Loss: 7.063475e-02\n",
            "Loss: 7.063417e-02\n",
            "Loss: 7.063388e-02\n",
            "Loss: 7.063316e-02\n",
            "Loss: 7.063299e-02\n",
            "Loss: 7.063206e-02\n",
            "Loss: 7.063151e-02\n",
            "Loss: 7.063077e-02\n",
            "Loss: 7.063049e-02\n",
            "Loss: 7.062976e-02\n",
            "Loss: 7.062928e-02\n",
            "Loss: 7.062855e-02\n",
            "Loss: 7.062789e-02\n",
            "Loss: 7.062748e-02\n",
            "Loss: 7.062697e-02\n",
            "Loss: 7.062645e-02\n",
            "Loss: 7.062650e-02\n",
            "Loss: 7.062630e-02\n",
            "Loss: 7.062653e-02\n",
            "Loss: 7.062630e-02\n",
            "Loss: 7.062591e-02\n",
            "Loss: 7.062573e-02\n",
            "Loss: 7.062491e-02\n",
            "Loss: 7.062510e-02\n",
            "Loss: 7.062429e-02\n",
            "Loss: 7.062346e-02\n",
            "Loss: 7.062295e-02\n",
            "Loss: 7.062222e-02\n",
            "Loss: 7.062124e-02\n",
            "Loss: 7.062192e-02\n",
            "Loss: 7.062078e-02\n",
            "Loss: 7.062022e-02\n",
            "Loss: 7.061976e-02\n",
            "Loss: 7.061911e-02\n",
            "Loss: 7.061806e-02\n",
            "Loss: 7.061744e-02\n",
            "Loss: 7.061671e-02\n",
            "Loss: 7.061615e-02\n",
            "Loss: 7.061466e-02\n",
            "Loss: 7.061275e-02\n",
            "Loss: 7.061970e-02\n",
            "Loss: 7.061248e-02\n",
            "Loss: 7.061008e-02\n",
            "Loss: 7.060917e-02\n",
            "Loss: 7.060856e-02\n",
            "Loss: 7.060793e-02\n",
            "Loss: 7.060622e-02\n",
            "Loss: 7.060470e-02\n",
            "Loss: 7.060318e-02\n",
            "Loss: 7.060192e-02\n",
            "Loss: 7.060149e-02\n",
            "Loss: 7.060032e-02\n",
            "Loss: 7.059895e-02\n",
            "Loss: 7.059924e-02\n",
            "Loss: 7.059806e-02\n",
            "Loss: 7.059713e-02\n",
            "Loss: 7.059595e-02\n",
            "Loss: 7.059482e-02\n",
            "Loss: 7.059319e-02\n",
            "Loss: 7.059163e-02\n",
            "Loss: 7.059444e-02\n",
            "Loss: 7.059108e-02\n",
            "Loss: 7.059005e-02\n",
            "Loss: 7.058978e-02\n",
            "Loss: 7.058930e-02\n",
            "Loss: 7.058886e-02\n",
            "Loss: 7.058787e-02\n",
            "Loss: 7.058699e-02\n",
            "Loss: 7.058615e-02\n",
            "Loss: 7.058546e-02\n",
            "Loss: 7.058402e-02\n",
            "Loss: 7.058419e-02\n",
            "Loss: 7.058325e-02\n",
            "Loss: 7.058239e-02\n",
            "Loss: 7.058184e-02\n",
            "Loss: 7.058147e-02\n",
            "Loss: 7.058078e-02\n",
            "Loss: 7.058004e-02\n",
            "Loss: 7.057926e-02\n",
            "Loss: 7.057782e-02\n",
            "Loss: 7.057657e-02\n",
            "Loss: 7.057520e-02\n",
            "Loss: 7.057381e-02\n",
            "Loss: 7.057316e-02\n",
            "Loss: 7.057167e-02\n",
            "Loss: 7.057123e-02\n",
            "Loss: 7.057059e-02\n",
            "Loss: 7.056966e-02\n",
            "Loss: 7.056802e-02\n",
            "Loss: 7.056749e-02\n",
            "Loss: 7.056639e-02\n",
            "Loss: 7.056463e-02\n",
            "Loss: 7.056420e-02\n",
            "Loss: 7.056157e-02\n",
            "Loss: 7.056080e-02\n",
            "Loss: 7.055926e-02\n",
            "Loss: 7.056218e-02\n",
            "Loss: 7.055914e-02\n",
            "Loss: 7.055828e-02\n",
            "Loss: 7.055705e-02\n",
            "Loss: 7.055464e-02\n",
            "Loss: 7.055219e-02\n",
            "Loss: 7.055463e-02\n",
            "Loss: 7.055093e-02\n",
            "Loss: 7.054980e-02\n",
            "Loss: 7.054867e-02\n",
            "Loss: 7.054806e-02\n",
            "Loss: 7.054642e-02\n",
            "Loss: 7.054419e-02\n",
            "Loss: 7.054328e-02\n",
            "Loss: 7.054231e-02\n",
            "Loss: 7.054116e-02\n",
            "Loss: 7.054035e-02\n",
            "Loss: 7.053930e-02\n",
            "Loss: 7.053781e-02\n",
            "Loss: 7.053541e-02\n",
            "Loss: 7.053816e-02\n",
            "Loss: 7.053488e-02\n",
            "Loss: 7.053304e-02\n",
            "Loss: 7.053230e-02\n",
            "Loss: 7.053145e-02\n",
            "Loss: 7.052988e-02\n",
            "Loss: 7.052891e-02\n",
            "Loss: 7.052784e-02\n",
            "Loss: 7.052742e-02\n",
            "Loss: 7.052689e-02\n",
            "Loss: 7.052644e-02\n",
            "Loss: 7.052545e-02\n",
            "Loss: 7.052477e-02\n",
            "Loss: 7.052274e-02\n",
            "Loss: 7.052228e-02\n",
            "Loss: 7.052065e-02\n",
            "Loss: 7.051999e-02\n",
            "Loss: 7.051945e-02\n",
            "Loss: 7.051794e-02\n",
            "Loss: 7.051703e-02\n",
            "Loss: 7.051515e-02\n",
            "Loss: 7.051392e-02\n",
            "Loss: 7.051184e-02\n",
            "Loss: 7.051031e-02\n",
            "Loss: 7.050918e-02\n",
            "Loss: 7.050902e-02\n",
            "Loss: 7.050881e-02\n",
            "Loss: 7.050782e-02\n",
            "Loss: 7.050693e-02\n",
            "Loss: 7.050637e-02\n",
            "Loss: 7.050481e-02\n",
            "Loss: 7.050303e-02\n",
            "Loss: 7.051021e-02\n",
            "Loss: 7.050192e-02\n",
            "Loss: 7.049972e-02\n",
            "Loss: 7.049840e-02\n",
            "Loss: 7.049794e-02\n",
            "Loss: 7.049678e-02\n",
            "Loss: 7.049622e-02\n",
            "Loss: 7.049573e-02\n",
            "Loss: 7.049431e-02\n",
            "Loss: 7.049240e-02\n",
            "Loss: 7.049432e-02\n",
            "Loss: 7.049151e-02\n",
            "Loss: 7.048994e-02\n",
            "Loss: 7.048886e-02\n",
            "Loss: 7.048773e-02\n",
            "Loss: 7.048672e-02\n",
            "Loss: 7.048428e-02\n",
            "Loss: 7.048597e-02\n",
            "Loss: 7.048368e-02\n",
            "Loss: 7.048222e-02\n",
            "Loss: 7.048117e-02\n",
            "Loss: 7.048015e-02\n",
            "Loss: 7.047752e-02\n",
            "Loss: 7.047426e-02\n",
            "Loss: 7.048900e-02\n",
            "Loss: 7.047413e-02\n",
            "Loss: 7.047296e-02\n",
            "Loss: 7.047161e-02\n",
            "Loss: 7.047047e-02\n",
            "Loss: 7.046866e-02\n",
            "Loss: 7.046639e-02\n",
            "Loss: 7.047210e-02\n",
            "Loss: 7.046555e-02\n",
            "Loss: 7.046363e-02\n",
            "Loss: 7.046224e-02\n",
            "Loss: 7.046150e-02\n",
            "Loss: 7.045986e-02\n",
            "Loss: 7.045810e-02\n",
            "Loss: 7.045817e-02\n",
            "Loss: 7.045645e-02\n",
            "Loss: 7.045578e-02\n",
            "Loss: 7.045449e-02\n",
            "Loss: 7.045406e-02\n",
            "Loss: 7.045282e-02\n",
            "Loss: 7.045151e-02\n",
            "Loss: 7.044959e-02\n",
            "Loss: 7.044798e-02\n",
            "Loss: 7.044607e-02\n",
            "Loss: 7.044421e-02\n",
            "Loss: 7.044233e-02\n",
            "Loss: 7.044087e-02\n",
            "Loss: 7.043953e-02\n",
            "Loss: 7.043922e-02\n",
            "Loss: 7.043830e-02\n",
            "Loss: 7.043741e-02\n",
            "Loss: 7.043586e-02\n",
            "Loss: 7.043394e-02\n",
            "Loss: 7.043155e-02\n",
            "Loss: 7.042925e-02\n",
            "Loss: 7.042883e-02\n",
            "Loss: 7.042740e-02\n",
            "Loss: 7.042578e-02\n",
            "Loss: 7.042376e-02\n",
            "Loss: 7.042208e-02\n",
            "Loss: 7.042112e-02\n",
            "Loss: 7.041889e-02\n",
            "Loss: 7.041730e-02\n",
            "Loss: 7.041634e-02\n",
            "Loss: 7.041539e-02\n",
            "Loss: 7.041294e-02\n",
            "Loss: 7.041161e-02\n",
            "Loss: 7.040956e-02\n",
            "Loss: 7.040776e-02\n",
            "Loss: 7.040572e-02\n",
            "Loss: 7.040524e-02\n",
            "Loss: 7.040384e-02\n",
            "Loss: 7.040300e-02\n",
            "Loss: 7.040233e-02\n",
            "Loss: 7.040143e-02\n",
            "Loss: 7.040066e-02\n",
            "Loss: 7.039946e-02\n",
            "Loss: 7.039877e-02\n",
            "Loss: 7.039770e-02\n",
            "Loss: 7.039695e-02\n",
            "Loss: 7.039762e-02\n",
            "Loss: 7.039632e-02\n",
            "Loss: 7.039488e-02\n",
            "Loss: 7.039445e-02\n",
            "Loss: 7.039309e-02\n",
            "Loss: 7.039198e-02\n",
            "Loss: 7.038902e-02\n",
            "Loss: 7.038619e-02\n",
            "Loss: 7.038306e-02\n",
            "Loss: 7.038099e-02\n",
            "Loss: 7.037964e-02\n",
            "Loss: 7.038021e-02\n",
            "Loss: 7.037884e-02\n",
            "Loss: 7.037779e-02\n",
            "Loss: 7.037591e-02\n",
            "Loss: 7.037561e-02\n",
            "Loss: 7.037372e-02\n",
            "Loss: 7.037175e-02\n",
            "Loss: 7.036991e-02\n",
            "Loss: 7.036868e-02\n",
            "Loss: 7.036544e-02\n",
            "Loss: 7.036661e-02\n",
            "Loss: 7.036384e-02\n",
            "Loss: 7.036293e-02\n",
            "Loss: 7.036235e-02\n",
            "Loss: 7.036174e-02\n",
            "Loss: 7.035883e-02\n",
            "Loss: 7.035662e-02\n",
            "Loss: 7.035445e-02\n",
            "Loss: 7.035644e-02\n",
            "Loss: 7.035348e-02\n",
            "Loss: 7.035257e-02\n",
            "Loss: 7.035217e-02\n",
            "Loss: 7.035045e-02\n",
            "Loss: 7.034844e-02\n",
            "Loss: 7.034636e-02\n",
            "Loss: 7.034492e-02\n",
            "Loss: 7.034351e-02\n",
            "Loss: 7.034262e-02\n",
            "Loss: 7.034067e-02\n",
            "Loss: 7.033972e-02\n",
            "Loss: 7.033955e-02\n",
            "Loss: 7.033821e-02\n",
            "Loss: 7.033602e-02\n",
            "Loss: 7.033536e-02\n",
            "Loss: 7.033373e-02\n",
            "Loss: 7.033305e-02\n",
            "Loss: 7.033221e-02\n",
            "Loss: 7.033601e-02\n",
            "Loss: 7.033166e-02\n",
            "Loss: 7.033046e-02\n",
            "Loss: 7.032836e-02\n",
            "Loss: 7.032827e-02\n",
            "Loss: 7.032740e-02\n",
            "Loss: 7.032655e-02\n",
            "Loss: 7.032526e-02\n",
            "Loss: 7.032494e-02\n",
            "Loss: 7.032350e-02\n",
            "Loss: 7.033245e-02\n",
            "Loss: 7.032360e-02\n",
            "Loss: 7.032361e-02\n",
            "Loss: 7.032367e-02\n",
            "Loss: 7.032355e-02\n",
            "Loss: 7.032347e-02\n",
            "Loss: 7.032349e-02\n",
            "Loss: 7.032347e-02\n",
            "Loss: 7.032347e-02\n",
            "Loss: 7.032349e-02\n",
            "Loss: 7.032347e-02\n",
            "Loss: 7.032347e-02\n",
            "Loss: 7.032349e-02\n",
            "Loss: 7.032347e-02\n",
            "Loss: 7.032347e-02\n",
            "Loss: 7.032347e-02\n",
            "Loss: 7.032347e-02\n",
            "Loss: 7.033257e-02\n",
            "Loss: 7.032344e-02\n",
            "Loss: 7.032230e-02\n",
            "Loss: 7.032125e-02\n",
            "Loss: 7.031961e-02\n",
            "Loss: 7.031801e-02\n",
            "Loss: 7.032927e-02\n",
            "Loss: 7.031788e-02\n",
            "Loss: 7.031567e-02\n",
            "Loss: 7.031395e-02\n",
            "Loss: 7.031188e-02\n",
            "Loss: 7.031097e-02\n",
            "Loss: 7.031230e-02\n",
            "Loss: 7.030966e-02\n",
            "Loss: 7.030905e-02\n",
            "Loss: 7.030806e-02\n",
            "Loss: 7.030705e-02\n",
            "Loss: 7.030647e-02\n",
            "Loss: 7.030448e-02\n",
            "Loss: 7.030283e-02\n",
            "Loss: 7.030067e-02\n",
            "Loss: 7.029901e-02\n",
            "Loss: 7.029834e-02\n",
            "Loss: 7.029639e-02\n",
            "Loss: 7.029476e-02\n",
            "Loss: 7.029315e-02\n",
            "Loss: 7.029283e-02\n",
            "Loss: 7.029127e-02\n",
            "Loss: 7.028987e-02\n",
            "Loss: 7.028847e-02\n",
            "Loss: 7.028661e-02\n",
            "Loss: 7.028481e-02\n",
            "Loss: 7.028472e-02\n",
            "Loss: 7.028362e-02\n",
            "Loss: 7.028264e-02\n",
            "Loss: 7.028148e-02\n",
            "Loss: 7.028186e-02\n",
            "Loss: 7.028110e-02\n",
            "Loss: 7.028086e-02\n",
            "Loss: 7.027984e-02\n",
            "Loss: 7.027828e-02\n",
            "Loss: 7.027687e-02\n",
            "Loss: 7.028046e-02\n",
            "Loss: 7.027653e-02\n",
            "Loss: 7.027495e-02\n",
            "Loss: 7.027364e-02\n",
            "Loss: 7.027248e-02\n",
            "Loss: 7.027058e-02\n",
            "Loss: 7.028275e-02\n",
            "Loss: 7.027045e-02\n",
            "Loss: 7.026909e-02\n",
            "Loss: 7.026860e-02\n",
            "Loss: 7.026771e-02\n",
            "Loss: 7.026691e-02\n",
            "Loss: 7.026440e-02\n",
            "Loss: 7.027134e-02\n",
            "Loss: 7.026328e-02\n",
            "Loss: 7.026254e-02\n",
            "Loss: 7.026178e-02\n",
            "Loss: 7.026150e-02\n",
            "Loss: 7.026040e-02\n",
            "Loss: 7.025983e-02\n",
            "Loss: 7.025876e-02\n",
            "Loss: 7.025812e-02\n",
            "Loss: 7.025763e-02\n",
            "Loss: 7.025683e-02\n",
            "Loss: 7.025547e-02\n",
            "Loss: 7.025501e-02\n",
            "Loss: 7.025459e-02\n",
            "Loss: 7.025301e-02\n",
            "Loss: 7.025351e-02\n",
            "Loss: 7.025185e-02\n",
            "Loss: 7.025075e-02\n",
            "Loss: 7.024928e-02\n",
            "Loss: 7.024699e-02\n",
            "Loss: 7.024483e-02\n",
            "Loss: 7.024361e-02\n",
            "Loss: 7.024202e-02\n",
            "Loss: 7.024115e-02\n",
            "Loss: 7.024058e-02\n",
            "Loss: 7.023990e-02\n",
            "Loss: 7.023893e-02\n",
            "Loss: 7.023750e-02\n",
            "Loss: 7.023478e-02\n",
            "Loss: 7.023732e-02\n",
            "Loss: 7.023381e-02\n",
            "Loss: 7.023215e-02\n",
            "Loss: 7.023040e-02\n",
            "Loss: 7.022987e-02\n",
            "Loss: 7.022849e-02\n",
            "Loss: 7.022730e-02\n",
            "Loss: 7.022598e-02\n",
            "Loss: 7.022470e-02\n",
            "Loss: 7.022391e-02\n",
            "Loss: 7.022422e-02\n",
            "Loss: 7.022338e-02\n",
            "Loss: 7.022210e-02\n",
            "Loss: 7.022016e-02\n",
            "Loss: 7.021882e-02\n",
            "Loss: 7.021781e-02\n",
            "Loss: 7.021602e-02\n",
            "Loss: 7.021748e-02\n",
            "Loss: 7.021526e-02\n",
            "Loss: 7.021431e-02\n",
            "Loss: 7.021368e-02\n",
            "Loss: 7.021245e-02\n",
            "Loss: 7.021217e-02\n",
            "Loss: 7.021157e-02\n",
            "Loss: 7.021090e-02\n",
            "Loss: 7.021040e-02\n",
            "Loss: 7.020958e-02\n",
            "Loss: 7.020828e-02\n",
            "Loss: 7.020816e-02\n",
            "Loss: 7.020639e-02\n",
            "Loss: 7.020613e-02\n",
            "Loss: 7.020485e-02\n",
            "Loss: 7.020444e-02\n",
            "Loss: 7.020312e-02\n",
            "Loss: 7.020221e-02\n",
            "Loss: 7.020119e-02\n",
            "Loss: 7.019981e-02\n",
            "Loss: 7.019902e-02\n",
            "Loss: 7.019845e-02\n",
            "Loss: 7.019767e-02\n",
            "Loss: 7.019765e-02\n",
            "Loss: 7.019595e-02\n",
            "Loss: 7.019497e-02\n",
            "Loss: 7.020086e-02\n",
            "Loss: 7.019491e-02\n",
            "Loss: 7.019392e-02\n",
            "Loss: 7.019351e-02\n",
            "Loss: 7.019316e-02\n",
            "Loss: 7.019247e-02\n",
            "Loss: 7.019187e-02\n",
            "Loss: 7.019199e-02\n",
            "Loss: 7.019110e-02\n",
            "Loss: 7.018954e-02\n",
            "Loss: 7.018848e-02\n",
            "Loss: 7.018773e-02\n",
            "Loss: 7.018648e-02\n",
            "Loss: 7.018486e-02\n",
            "Loss: 7.018337e-02\n",
            "Loss: 7.018244e-02\n",
            "Loss: 7.018165e-02\n",
            "Loss: 7.018119e-02\n",
            "Loss: 7.018004e-02\n",
            "Loss: 7.017943e-02\n",
            "Loss: 7.017907e-02\n",
            "Loss: 7.017838e-02\n",
            "Loss: 7.017731e-02\n",
            "Loss: 7.017633e-02\n",
            "Loss: 7.017503e-02\n",
            "Loss: 7.017424e-02\n",
            "Loss: 7.017335e-02\n",
            "Loss: 7.017180e-02\n",
            "Loss: 7.017897e-02\n",
            "Loss: 7.017147e-02\n",
            "Loss: 7.017070e-02\n",
            "Loss: 7.016986e-02\n",
            "Loss: 7.016975e-02\n",
            "Loss: 7.016886e-02\n",
            "Loss: 7.016823e-02\n",
            "Loss: 7.016763e-02\n",
            "Loss: 7.016662e-02\n",
            "Loss: 7.016549e-02\n",
            "Loss: 7.016507e-02\n",
            "Loss: 7.016441e-02\n",
            "Loss: 7.016423e-02\n",
            "Loss: 7.016372e-02\n",
            "Loss: 7.016321e-02\n",
            "Loss: 7.016273e-02\n",
            "Loss: 7.016241e-02\n",
            "Loss: 7.016215e-02\n",
            "Loss: 7.016191e-02\n",
            "Loss: 7.016110e-02\n",
            "Loss: 7.016057e-02\n",
            "Loss: 7.015902e-02\n",
            "Loss: 7.016036e-02\n",
            "Loss: 7.015880e-02\n",
            "Loss: 7.015743e-02\n",
            "Loss: 7.015678e-02\n",
            "Loss: 7.015627e-02\n",
            "Loss: 7.015517e-02\n",
            "Loss: 7.015374e-02\n",
            "Loss: 7.015239e-02\n",
            "Loss: 7.015133e-02\n",
            "Loss: 7.015894e-02\n",
            "Loss: 7.015128e-02\n",
            "Loss: 7.015088e-02\n",
            "Loss: 7.014979e-02\n",
            "Loss: 7.014842e-02\n",
            "Loss: 7.014829e-02\n",
            "Loss: 7.014728e-02\n",
            "Loss: 7.014655e-02\n",
            "Loss: 7.014589e-02\n",
            "Loss: 7.014509e-02\n",
            "Loss: 7.014398e-02\n",
            "Loss: 7.014311e-02\n",
            "Loss: 7.014265e-02\n",
            "Loss: 7.014152e-02\n",
            "Loss: 7.014037e-02\n",
            "Loss: 7.013906e-02\n",
            "Loss: 7.013841e-02\n",
            "Loss: 7.013741e-02\n",
            "Loss: 7.013674e-02\n",
            "Loss: 7.013632e-02\n",
            "Loss: 7.013530e-02\n",
            "Loss: 7.014073e-02\n",
            "Loss: 7.013486e-02\n",
            "Loss: 7.013395e-02\n",
            "Loss: 7.013348e-02\n",
            "Loss: 7.013304e-02\n",
            "Loss: 7.013153e-02\n",
            "Loss: 7.013244e-02\n",
            "Loss: 7.013141e-02\n",
            "Loss: 7.013026e-02\n",
            "Loss: 7.012956e-02\n",
            "Loss: 7.012995e-02\n",
            "Loss: 7.012861e-02\n",
            "Loss: 7.012723e-02\n",
            "Loss: 7.012664e-02\n",
            "Loss: 7.012567e-02\n",
            "Loss: 7.012443e-02\n",
            "Loss: 7.012384e-02\n",
            "Loss: 7.012185e-02\n",
            "Loss: 7.012127e-02\n",
            "Loss: 7.011992e-02\n",
            "Loss: 7.011934e-02\n",
            "Loss: 7.011779e-02\n",
            "Loss: 7.011727e-02\n",
            "Loss: 7.011682e-02\n",
            "Loss: 7.011625e-02\n",
            "Loss: 7.011587e-02\n",
            "Loss: 7.011440e-02\n",
            "Loss: 7.011548e-02\n",
            "Loss: 7.011411e-02\n",
            "Loss: 7.011305e-02\n",
            "Loss: 7.011234e-02\n",
            "Loss: 7.011193e-02\n",
            "Loss: 7.011130e-02\n",
            "Loss: 7.011043e-02\n",
            "Loss: 7.010881e-02\n",
            "Loss: 7.010777e-02\n",
            "Loss: 7.010604e-02\n",
            "Loss: 7.010494e-02\n",
            "Loss: 7.010372e-02\n",
            "Loss: 7.010335e-02\n",
            "Loss: 7.010149e-02\n",
            "Loss: 7.010131e-02\n",
            "Loss: 7.010055e-02\n",
            "Loss: 7.009972e-02\n",
            "Loss: 7.009917e-02\n",
            "Loss: 7.009771e-02\n",
            "Loss: 7.009681e-02\n",
            "Loss: 7.009622e-02\n",
            "Loss: 7.009514e-02\n",
            "Loss: 7.009412e-02\n",
            "Loss: 7.009304e-02\n",
            "Loss: 7.009199e-02\n",
            "Loss: 7.009180e-02\n",
            "Loss: 7.009079e-02\n",
            "Loss: 7.008993e-02\n",
            "Loss: 7.008755e-02\n",
            "Loss: 7.010491e-02\n",
            "Loss: 7.008708e-02\n",
            "Loss: 7.008636e-02\n",
            "Loss: 7.008580e-02\n",
            "Loss: 7.008523e-02\n",
            "Loss: 7.008386e-02\n",
            "Loss: 7.008573e-02\n",
            "Loss: 7.008320e-02\n",
            "Loss: 7.008230e-02\n",
            "Loss: 7.008117e-02\n",
            "Loss: 7.008047e-02\n",
            "Loss: 7.007990e-02\n",
            "Loss: 7.007897e-02\n",
            "Loss: 7.007827e-02\n",
            "Loss: 7.007802e-02\n",
            "Loss: 7.007703e-02\n",
            "Loss: 7.007528e-02\n",
            "Loss: 7.007451e-02\n",
            "Loss: 7.007422e-02\n",
            "Loss: 7.007402e-02\n",
            "Loss: 7.007219e-02\n",
            "Loss: 7.007363e-02\n",
            "Loss: 7.007148e-02\n",
            "Loss: 7.006955e-02\n",
            "Loss: 7.006826e-02\n",
            "Loss: 7.006703e-02\n",
            "Loss: 7.006630e-02\n",
            "Loss: 7.006398e-02\n",
            "Loss: 7.006286e-02\n",
            "Loss: 7.006171e-02\n",
            "Loss: 7.006026e-02\n",
            "Loss: 7.005857e-02\n",
            "Loss: 7.005762e-02\n",
            "Loss: 7.005598e-02\n",
            "Loss: 7.005466e-02\n",
            "Loss: 7.005478e-02\n",
            "Loss: 7.005387e-02\n",
            "Loss: 7.005267e-02\n",
            "Loss: 7.005101e-02\n",
            "Loss: 7.004976e-02\n",
            "Loss: 7.004777e-02\n",
            "Loss: 7.005514e-02\n",
            "Loss: 7.004680e-02\n",
            "Loss: 7.004573e-02\n",
            "Loss: 7.004443e-02\n",
            "Loss: 7.004170e-02\n",
            "Loss: 7.004379e-02\n",
            "Loss: 7.004069e-02\n",
            "Loss: 7.003945e-02\n",
            "Loss: 7.003840e-02\n",
            "Loss: 7.003694e-02\n",
            "Loss: 7.003631e-02\n",
            "Loss: 7.003517e-02\n",
            "Loss: 7.003444e-02\n",
            "Loss: 7.003400e-02\n",
            "Loss: 7.003293e-02\n",
            "Loss: 7.003225e-02\n",
            "Loss: 7.003140e-02\n",
            "Loss: 7.003206e-02\n",
            "Loss: 7.003085e-02\n",
            "Loss: 7.002966e-02\n",
            "Loss: 7.002879e-02\n",
            "Loss: 7.002828e-02\n",
            "Loss: 7.002693e-02\n",
            "Loss: 7.002766e-02\n",
            "Loss: 7.002637e-02\n",
            "Loss: 7.002533e-02\n",
            "Loss: 7.002392e-02\n",
            "Loss: 7.002202e-02\n",
            "Loss: 7.003037e-02\n",
            "Loss: 7.002185e-02\n",
            "Loss: 7.002088e-02\n",
            "Loss: 7.001953e-02\n",
            "Loss: 7.001778e-02\n",
            "Loss: 7.001604e-02\n",
            "Loss: 7.002147e-02\n",
            "Loss: 7.001596e-02\n",
            "Loss: 7.001481e-02\n",
            "Loss: 7.001365e-02\n",
            "Loss: 7.001235e-02\n",
            "Loss: 7.001050e-02\n",
            "Loss: 7.001620e-02\n",
            "Loss: 7.001038e-02\n",
            "Loss: 7.000910e-02\n",
            "Loss: 7.000868e-02\n",
            "Loss: 7.000728e-02\n",
            "Loss: 7.000557e-02\n",
            "Loss: 7.001149e-02\n",
            "Loss: 7.000495e-02\n",
            "Loss: 7.000268e-02\n",
            "Loss: 7.000187e-02\n",
            "Loss: 7.000056e-02\n",
            "Loss: 6.999882e-02\n",
            "Loss: 7.000219e-02\n",
            "Loss: 6.999850e-02\n",
            "Loss: 6.999756e-02\n",
            "Loss: 6.999653e-02\n",
            "Loss: 6.999548e-02\n",
            "Loss: 6.999565e-02\n",
            "Loss: 6.999461e-02\n",
            "Loss: 6.999315e-02\n",
            "Loss: 6.999159e-02\n",
            "Loss: 6.998946e-02\n",
            "Loss: 6.998862e-02\n",
            "Loss: 6.998820e-02\n",
            "Loss: 6.998761e-02\n",
            "Loss: 6.998674e-02\n",
            "Loss: 6.998607e-02\n",
            "Loss: 6.998427e-02\n",
            "Loss: 6.998348e-02\n",
            "Loss: 6.998269e-02\n",
            "Loss: 6.998180e-02\n",
            "Loss: 6.998165e-02\n",
            "Loss: 6.998082e-02\n",
            "Loss: 6.998037e-02\n",
            "Loss: 6.997933e-02\n",
            "Loss: 6.997876e-02\n",
            "Loss: 6.997830e-02\n",
            "Loss: 6.997798e-02\n",
            "Loss: 6.997712e-02\n",
            "Loss: 6.997698e-02\n",
            "Loss: 6.997682e-02\n",
            "Loss: 6.997611e-02\n",
            "Loss: 6.997614e-02\n",
            "Loss: 6.997512e-02\n",
            "Loss: 6.997464e-02\n",
            "Loss: 6.997362e-02\n",
            "Loss: 6.997246e-02\n",
            "Loss: 6.997258e-02\n",
            "Loss: 6.997214e-02\n",
            "Loss: 6.997122e-02\n",
            "Loss: 6.997060e-02\n",
            "Loss: 6.997006e-02\n",
            "Loss: 6.996898e-02\n",
            "Loss: 6.997617e-02\n",
            "Loss: 6.996883e-02\n",
            "Loss: 6.996807e-02\n",
            "Loss: 6.996763e-02\n",
            "Loss: 6.996670e-02\n",
            "Loss: 6.996633e-02\n",
            "Loss: 6.996615e-02\n",
            "Loss: 6.996566e-02\n",
            "Loss: 6.996511e-02\n",
            "Loss: 6.996442e-02\n",
            "Loss: 6.996447e-02\n",
            "Loss: 6.996416e-02\n",
            "Loss: 6.996401e-02\n",
            "Loss: 6.996404e-02\n",
            "Loss: 6.996436e-02\n",
            "Loss: 6.996407e-02\n",
            "Loss: 6.996413e-02\n",
            "Loss: 6.996401e-02\n",
            "Loss: 6.996401e-02\n",
            "Loss: 6.996392e-02\n",
            "Loss: 6.996392e-02\n",
            "Loss: 6.996392e-02\n",
            "Loss: 6.996392e-02\n",
            "Loss: 6.996392e-02\n",
            "Loss: 6.996392e-02\n",
            "Loss: 6.996394e-02\n",
            "Loss: 6.996392e-02\n",
            "Loss: 6.996392e-02\n",
            "Loss: 6.996409e-02\n",
            "Loss: 6.996392e-02\n",
            "Loss: 6.996385e-02\n",
            "Loss: 6.996306e-02\n",
            "Loss: 6.996461e-02\n",
            "Loss: 6.996214e-02\n",
            "Loss: 6.996126e-02\n",
            "Loss: 6.996060e-02\n",
            "Loss: 6.996018e-02\n",
            "Loss: 6.996023e-02\n",
            "Loss: 6.995965e-02\n",
            "Loss: 6.995904e-02\n",
            "Loss: 6.995830e-02\n",
            "Loss: 6.995776e-02\n",
            "Loss: 6.995660e-02\n",
            "Loss: 6.995599e-02\n",
            "Loss: 6.995503e-02\n",
            "Loss: 6.995614e-02\n",
            "Loss: 6.995436e-02\n",
            "Loss: 6.995361e-02\n",
            "Loss: 6.995311e-02\n",
            "Loss: 6.995154e-02\n",
            "Loss: 6.995049e-02\n",
            "Loss: 6.995086e-02\n",
            "Loss: 6.994977e-02\n",
            "Loss: 6.994944e-02\n",
            "Loss: 6.994880e-02\n",
            "Loss: 6.994783e-02\n",
            "Loss: 6.994750e-02\n",
            "Loss: 6.994666e-02\n",
            "Loss: 6.994598e-02\n",
            "Loss: 6.994544e-02\n",
            "Loss: 6.994524e-02\n",
            "Loss: 6.994395e-02\n",
            "Loss: 6.994324e-02\n",
            "Loss: 6.994285e-02\n",
            "Loss: 6.994270e-02\n",
            "Loss: 6.994171e-02\n",
            "Loss: 6.994134e-02\n",
            "Loss: 6.994012e-02\n",
            "Loss: 6.993975e-02\n",
            "Loss: 6.993915e-02\n",
            "Loss: 6.993835e-02\n",
            "Loss: 6.993793e-02\n",
            "Loss: 6.993693e-02\n",
            "Loss: 6.993623e-02\n",
            "Loss: 6.993528e-02\n",
            "Loss: 6.993584e-02\n",
            "Loss: 6.993476e-02\n",
            "Loss: 6.993371e-02\n",
            "Loss: 6.993321e-02\n",
            "Loss: 6.993237e-02\n",
            "Loss: 6.993106e-02\n",
            "Loss: 6.993012e-02\n",
            "Loss: 6.992949e-02\n",
            "Loss: 6.992932e-02\n",
            "Loss: 6.992859e-02\n",
            "Loss: 6.992789e-02\n",
            "Loss: 6.992786e-02\n",
            "Loss: 6.992616e-02\n",
            "Loss: 6.992547e-02\n",
            "Loss: 6.992507e-02\n",
            "Loss: 6.992403e-02\n",
            "Loss: 6.992364e-02\n",
            "Loss: 6.992310e-02\n",
            "Loss: 6.992175e-02\n",
            "Loss: 6.992146e-02\n",
            "Loss: 6.991987e-02\n",
            "Loss: 6.992137e-02\n",
            "Loss: 6.991967e-02\n",
            "Loss: 6.991792e-02\n",
            "Loss: 6.991760e-02\n",
            "Loss: 6.991745e-02\n",
            "Loss: 6.991661e-02\n",
            "Loss: 6.991634e-02\n",
            "Loss: 6.991523e-02\n",
            "Loss: 6.991474e-02\n",
            "Loss: 6.991345e-02\n",
            "Loss: 6.991441e-02\n",
            "Loss: 6.991334e-02\n",
            "Loss: 6.991260e-02\n",
            "Loss: 6.991171e-02\n",
            "Loss: 6.991054e-02\n",
            "Loss: 6.990979e-02\n",
            "Loss: 6.990854e-02\n",
            "Loss: 6.990826e-02\n",
            "Loss: 6.990691e-02\n",
            "Loss: 6.990691e-02\n",
            "Loss: 6.990702e-02\n",
            "Loss: 6.990717e-02\n",
            "Loss: 6.990679e-02\n",
            "Loss: 6.990679e-02\n",
            "Loss: 6.990711e-02\n",
            "Loss: 6.990693e-02\n",
            "Loss: 6.990679e-02\n",
            "Loss: 6.990679e-02\n",
            "Loss: 6.990682e-02\n",
            "Loss: 6.990679e-02\n",
            "Loss: 7.017275e-02\n",
            "Loss: 6.990680e-02\n",
            "Loss: 6.990694e-02\n",
            "Loss: 6.990739e-02\n",
            "Loss: 6.990698e-02\n",
            "Loss: 6.990679e-02\n",
            "Loss: 6.990679e-02\n",
            "Loss: 6.990679e-02\n",
            "Loss: 6.990679e-02\n",
            "Loss: 6.990679e-02\n",
            "Loss: 6.990679e-02\n",
            "Loss: 6.990679e-02\n",
            "Loss: 6.990679e-02\n",
            "Loss: 6.990679e-02\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.069907\n",
            "  Number of iterations: 6524\n",
            "  Number of functions evaluations: 7130\n",
            "Error u: 7.144873e-03\n",
            "Error u (idn): 7.425233e-03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6erME2d8M1Jx"
      },
      "source": [
        "## Plotting: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4dnerEv8ied"
      },
      "source": [
        "## PLOTTING: \n",
        "import matplotlib as mpl\n",
        "mpl.use('pgf')\n",
        "def figsize(scale, nplots = 1):\n",
        "    fig_width_pt = 390.0                          # Get this from LaTeX using \\the\\textwidth\n",
        "    inches_per_pt = 1.0/72.27                       # Convert pt to inch\n",
        "    golden_mean = (np.sqrt(5.0)-1.0)/2.0            # Aesthetic ratio (you could change this)\n",
        "    fig_width = fig_width_pt*inches_per_pt*scale    # width in inches\n",
        "    fig_height = nplots*fig_width*golden_mean              # height in inches\n",
        "    fig_size = [fig_width,fig_height]\n",
        "    return fig_size\n",
        "\n",
        "pgf_with_latex = {                      # setup matplotlib to use latex for output\n",
        "    \"pgf.texsystem\": \"pdflatex\",        # change this if using xetex or lautex\n",
        "    \"text.usetex\": True,                # use LaTeX to write all text\n",
        "    \"font.family\": \"serif\",\n",
        "    \"font.serif\": [],                   # blank entries should cause plots to inherit fonts from the document\n",
        "    \"font.sans-serif\": [],\n",
        "    \"font.monospace\": [],\n",
        "    \"axes.labelsize\": 10,               # LaTeX default is 10pt font.\n",
        "    \"font.size\": 10,\n",
        "    \"legend.fontsize\": 8,               # Make the legend/label fonts a little smaller\n",
        "    \"xtick.labelsize\": 8,\n",
        "    \"ytick.labelsize\": 8,\n",
        "    \"figure.figsize\": figsize(1.0),     # default fig size of 0.9 textwidth\n",
        "    \"pgf.preamble\": [\n",
        "        r\"\\usepackage[utf8x]{inputenc}\",    # use utf8 fonts becasue your computer can handle it :)\n",
        "        r\"\\usepackage[T1]{fontenc}\",        # plots will be generated using this preamble\n",
        "        ]\n",
        "    }\n",
        "mpl.rcParams.update(pgf_with_latex)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# I make my own newfig and savefig functions\n",
        "def newfig(width, nplots = 1):\n",
        "    fig = plt.figure(figsize=figsize(width, nplots))\n",
        "    ax = fig.add_subplot(111)\n",
        "    return fig, ax\n",
        "\n",
        "def savefig(filename, crop = True):\n",
        "    if crop == True:\n",
        "        plt.savefig('{}.png'.format(filename), bbox_inches='tight', pad_inches=0)\n",
        "        plt.savefig('{}.pdf'.format(filename), bbox_inches='tight', pad_inches=0)\n",
        "     #   plt.savefig('{}.eps'.format(filename), bbox_inches='tight', pad_inches=0)\n",
        "    else:\n",
        "        plt.savefig('{}.png'.format(filename))\n",
        "        plt.savefig('{}.pdf'.format(filename))\n",
        "     #   plt.savefig('{}.eps'.format(filename))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OIA8gDKNMV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11b44699-e0cd-4a51-e608-6e0d29ab23be"
      },
      "source": [
        "from matplotlib import rc\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "rc('text', usetex=True)\n",
        "mpl.rcParams['text.latex.preamble'] = [r'\\usepackage{amsmath}']\n",
        "!apt-get update\n",
        "!apt install texlive-fonts-recommended texlive-fonts-extra cm-super dvipng"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cm-super-minimal fonts-adf-accanthis fonts-adf-berenis fonts-adf-gillius\n",
            "  fonts-adf-universalis fonts-cabin fonts-comfortaa fonts-croscore\n",
            "  fonts-crosextra-caladea fonts-crosextra-carlito fonts-dejavu-core\n",
            "  fonts-dejavu-extra fonts-droid-fallback fonts-ebgaramond\n",
            "  fonts-ebgaramond-extra fonts-font-awesome fonts-freefont-otf\n",
            "  fonts-freefont-ttf fonts-gfs-artemisia fonts-gfs-complutum fonts-gfs-didot\n",
            "  fonts-gfs-neohellenic fonts-gfs-olga fonts-gfs-solomos fonts-go\n",
            "  fonts-junicode fonts-lato fonts-linuxlibertine fonts-lmodern fonts-lobster\n",
            "  fonts-lobstertwo fonts-noto-hinted fonts-noto-mono fonts-oflb-asana-math\n",
            "  fonts-open-sans fonts-roboto-hinted fonts-sil-gentium\n",
            "  fonts-sil-gentium-basic fonts-sil-gentiumplus fonts-sil-gentiumplus-compact\n",
            "  fonts-stix fonts-texgyre ghostscript gsfonts javascript-common\n",
            "  libcupsfilters1 libcupsimage2 libgs9 libgs9-common libijs-0.35 libjbig2dec0\n",
            "  libjs-jquery libkpathsea6 libpotrace0 libptexenc1 libruby2.5 libsynctex1\n",
            "  libtexlua52 libtexluajit2 libzzip-0-13 lmodern pfb2t1c2pfb poppler-data\n",
            "  preview-latex-style rake ruby ruby-did-you-mean ruby-minitest\n",
            "  ruby-net-telnet ruby-power-assert ruby-test-unit ruby2.5\n",
            "  rubygems-integration t1utils tex-common tex-gyre texlive-base\n",
            "  texlive-binaries texlive-fonts-extra-links texlive-latex-base\n",
            "  texlive-latex-extra texlive-latex-recommended texlive-pictures\n",
            "  texlive-plain-generic tipa\n",
            "Suggested packages:\n",
            "  fonts-noto fontforge ghostscript-x apache2 | lighttpd | httpd poppler-utils\n",
            "  fonts-japanese-mincho | fonts-ipafont-mincho fonts-japanese-gothic\n",
            "  | fonts-ipafont-gothic fonts-arphic-ukai fonts-arphic-uming fonts-nanum ri\n",
            "  ruby-dev bundler debhelper perl-tk xpdf-reader | pdf-viewer\n",
            "  texlive-fonts-extra-doc texlive-fonts-recommended-doc texlive-latex-base-doc\n",
            "  python-pygments icc-profiles libfile-which-perl\n",
            "  libspreadsheet-parseexcel-perl texlive-latex-extra-doc\n",
            "  texlive-latex-recommended-doc texlive-pstricks dot2tex prerex ruby-tcltk\n",
            "  | libtcltk-ruby texlive-pictures-doc vprerex\n",
            "The following NEW packages will be installed:\n",
            "  cm-super cm-super-minimal dvipng fonts-adf-accanthis fonts-adf-berenis\n",
            "  fonts-adf-gillius fonts-adf-universalis fonts-cabin fonts-comfortaa\n",
            "  fonts-croscore fonts-crosextra-caladea fonts-crosextra-carlito\n",
            "  fonts-dejavu-core fonts-dejavu-extra fonts-droid-fallback fonts-ebgaramond\n",
            "  fonts-ebgaramond-extra fonts-font-awesome fonts-freefont-otf\n",
            "  fonts-freefont-ttf fonts-gfs-artemisia fonts-gfs-complutum fonts-gfs-didot\n",
            "  fonts-gfs-neohellenic fonts-gfs-olga fonts-gfs-solomos fonts-go\n",
            "  fonts-junicode fonts-lato fonts-linuxlibertine fonts-lmodern fonts-lobster\n",
            "  fonts-lobstertwo fonts-noto-hinted fonts-noto-mono fonts-oflb-asana-math\n",
            "  fonts-open-sans fonts-roboto-hinted fonts-sil-gentium\n",
            "  fonts-sil-gentium-basic fonts-sil-gentiumplus fonts-sil-gentiumplus-compact\n",
            "  fonts-stix fonts-texgyre ghostscript gsfonts javascript-common\n",
            "  libcupsfilters1 libcupsimage2 libgs9 libgs9-common libijs-0.35 libjbig2dec0\n",
            "  libjs-jquery libkpathsea6 libpotrace0 libptexenc1 libruby2.5 libsynctex1\n",
            "  libtexlua52 libtexluajit2 libzzip-0-13 lmodern pfb2t1c2pfb poppler-data\n",
            "  preview-latex-style rake ruby ruby-did-you-mean ruby-minitest\n",
            "  ruby-net-telnet ruby-power-assert ruby-test-unit ruby2.5\n",
            "  rubygems-integration t1utils tex-common tex-gyre texlive-base\n",
            "  texlive-binaries texlive-fonts-extra texlive-fonts-extra-links\n",
            "  texlive-fonts-recommended texlive-latex-base texlive-latex-extra\n",
            "  texlive-latex-recommended texlive-pictures texlive-plain-generic tipa\n",
            "0 upgraded, 89 newly installed, 0 to remove and 30 not upgraded.\n",
            "Need to get 554 MB of archives.\n",
            "After this operation, 1,550 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lato all 2.0-2 [2,698 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 poppler-data all 0.4.8-2 [1,479 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 tex-common all 6.09 [33.0 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkpathsea6 amd64 2017.20170613.44572-8ubuntu0.1 [54.9 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libptexenc1 amd64 2017.20170613.44572-8ubuntu0.1 [34.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsynctex1 amd64 2017.20170613.44572-8ubuntu0.1 [41.4 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexlua52 amd64 2017.20170613.44572-8ubuntu0.1 [91.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexluajit2 amd64 2017.20170613.44572-8ubuntu0.1 [230 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 t1utils amd64 1.41-2 [56.0 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsimage2 amd64 2.2.7-1ubuntu2.8 [18.6 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libijs-0.35 amd64 0.35-13 [15.5 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig2dec0 amd64 0.13-6 [55.9 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9-common all 9.26~dfsg+0-0ubuntu0.18.04.14 [5,092 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9 amd64 9.26~dfsg+0-0ubuntu0.18.04.14 [2,265 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpotrace0 amd64 1.14-2 [17.4 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libzzip-0-13 amd64 0.13.62-3.1ubuntu0.18.04.1 [26.0 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 texlive-binaries amd64 2017.20170613.44572-8ubuntu0.1 [8,179 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-base all 2017.20180305-1 [18.7 MB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lmodern all 2.004.5-3 [4,551 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-base all 2017.20180305-1 [951 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-recommended all 2017.20180305-1 [14.9 MB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cm-super-minimal all 0.3.4-11 [5,810 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/universe amd64 pfb2t1c2pfb amd64 0.3-11 [9,342 B]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cm-super all 0.3.4-11 [18.7 MB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ghostscript amd64 9.26~dfsg+0-0ubuntu0.18.04.14 [51.3 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/universe amd64 dvipng amd64 1.15-1 [78.2 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-adf-accanthis all 0.20110505-1 [202 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-adf-berenis all 0.20110505-1 [281 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-adf-gillius all 0.20110505-1 [190 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-adf-universalis all 0.20110505-1 [111 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-cabin all 1.5-2 [140 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-comfortaa all 3.001-2 [129 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-croscore all 20171026-2 [2,135 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-crosextra-caladea all 20130214-2 [82.4 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-crosextra-carlito all 20130920-1 [742 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-ebgaramond all 0.016-1 [474 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-ebgaramond-extra all 0.016-1 [2,157 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-font-awesome all 4.7.0~dfsg-3 [513 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-freefont-otf all 20120503-7 [3,055 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-freefont-ttf all 20120503-7 [4,202 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-gfs-artemisia all 1.1-5 [260 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-gfs-complutum all 1.1-6 [41.6 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-gfs-didot all 1.1-6 [278 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-gfs-neohellenic all 1.1-6 [215 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-gfs-olga all 1.1-5 [33.4 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-gfs-solomos all 1.1-5 [40.7 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-go all 0~20161116-1 [348 kB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-junicode all 1.001-2 [684 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-linuxlibertine all 5.3.0-4 [1,627 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-lobster all 2.0-2 [38.7 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-lobstertwo all 2.0-2 [92.7 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-noto-hinted all 20171026-2 [6,653 kB]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-noto-mono all 20171026-2 [75.5 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-oflb-asana-math all 000.907-6 [246 kB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-open-sans all 1.11-1 [575 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-roboto-hinted all 2:0~20160106-2 [2,918 kB]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-sil-gentium all 20081126:1.03-2 [245 kB]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-sil-gentium-basic all 1.102-1 [384 kB]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-sil-gentiumplus all 5.000-2 [2,807 kB]\n",
            "Get:63 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-sil-gentiumplus-compact all 5.000-2 [1,514 kB]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-texgyre all 20160520-1 [8,761 kB]\n",
            "Get:65 http://archive.ubuntu.com/ubuntu bionic/main amd64 gsfonts all 1:8.11+urwcyr1.0.7~pre44-4.4 [3,120 kB]\n",
            "Get:66 http://archive.ubuntu.com/ubuntu bionic/main amd64 javascript-common all 11 [6,066 B]\n",
            "Get:67 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsfilters1 amd64 1.20.2-0ubuntu3.1 [108 kB]\n",
            "Get:68 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjs-jquery all 3.2.1-1 [152 kB]\n",
            "Get:69 http://archive.ubuntu.com/ubuntu bionic/main amd64 rubygems-integration all 1.11 [4,994 B]\n",
            "Get:70 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ruby2.5 amd64 2.5.1-1ubuntu1.8 [48.6 kB]\n",
            "Get:71 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby amd64 1:2.5.1 [5,712 B]\n",
            "Get:72 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 rake all 12.3.1-1ubuntu0.1 [44.9 kB]\n",
            "Get:73 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-did-you-mean all 1.2.0-2 [9,700 B]\n",
            "Get:74 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-minitest all 5.10.3-1 [38.6 kB]\n",
            "Get:75 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]\n",
            "Get:76 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-power-assert all 0.3.0-1 [7,952 B]\n",
            "Get:77 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-test-unit all 3.2.5-1 [61.1 kB]\n",
            "Get:78 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libruby2.5 amd64 2.5.1-1ubuntu1.8 [3,069 kB]\n",
            "Get:79 http://archive.ubuntu.com/ubuntu bionic/main amd64 lmodern all 2.004.5-3 [9,631 kB]\n",
            "Get:80 http://archive.ubuntu.com/ubuntu bionic/main amd64 preview-latex-style all 11.91-1ubuntu1 [185 kB]\n",
            "Get:81 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tex-gyre all 20160520-1 [4,998 kB]\n",
            "Get:82 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-fonts-extra all 2017.20180305-2 [354 MB]\n",
            "Get:83 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-stix all 1.1.1-4 [591 kB]\n",
            "Get:84 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-fonts-extra-links all 2017.20180305-2 [20.6 kB]\n",
            "Get:85 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-fonts-recommended all 2017.20180305-1 [5,262 kB]\n",
            "Get:86 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-pictures all 2017.20180305-1 [4,026 kB]\n",
            "Get:87 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-latex-extra all 2017.20180305-2 [10.6 MB]\n",
            "Get:88 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-plain-generic all 2017.20180305-2 [23.6 MB]\n",
            "Get:89 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tipa all 2:1.3-20 [2,978 kB]\n",
            "Fetched 554 MB in 32s (17.3 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 160980 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Selecting previously unselected package fonts-lato.\n",
            "Preparing to unpack .../01-fonts-lato_2.0-2_all.deb ...\n",
            "Unpacking fonts-lato (2.0-2) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../02-poppler-data_0.4.8-2_all.deb ...\n",
            "Unpacking poppler-data (0.4.8-2) ...\n",
            "Selecting previously unselected package tex-common.\n",
            "Preparing to unpack .../03-tex-common_6.09_all.deb ...\n",
            "Unpacking tex-common (6.09) ...\n",
            "Selecting previously unselected package libkpathsea6:amd64.\n",
            "Preparing to unpack .../04-libkpathsea6_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libptexenc1:amd64.\n",
            "Preparing to unpack .../05-libptexenc1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libsynctex1:amd64.\n",
            "Preparing to unpack .../06-libsynctex1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexlua52:amd64.\n",
            "Preparing to unpack .../07-libtexlua52_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexluajit2:amd64.\n",
            "Preparing to unpack .../08-libtexluajit2_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package t1utils.\n",
            "Preparing to unpack .../09-t1utils_1.41-2_amd64.deb ...\n",
            "Unpacking t1utils (1.41-2) ...\n",
            "Selecting previously unselected package libcupsimage2:amd64.\n",
            "Preparing to unpack .../10-libcupsimage2_2.2.7-1ubuntu2.8_amd64.deb ...\n",
            "Unpacking libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../11-libijs-0.35_0.35-13_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-13) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../12-libjbig2dec0_0.13-6_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.13-6) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../13-libgs9-common_9.26~dfsg+0-0ubuntu0.18.04.14_all.deb ...\n",
            "Unpacking libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../14-libgs9_9.26~dfsg+0-0ubuntu0.18.04.14_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Selecting previously unselected package libpotrace0.\n",
            "Preparing to unpack .../15-libpotrace0_1.14-2_amd64.deb ...\n",
            "Unpacking libpotrace0 (1.14-2) ...\n",
            "Selecting previously unselected package libzzip-0-13:amd64.\n",
            "Preparing to unpack .../16-libzzip-0-13_0.13.62-3.1ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package texlive-binaries.\n",
            "Preparing to unpack .../17-texlive-binaries_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package texlive-base.\n",
            "Preparing to unpack .../18-texlive-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package fonts-lmodern.\n",
            "Preparing to unpack .../19-fonts-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking fonts-lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package texlive-latex-base.\n",
            "Preparing to unpack .../20-texlive-latex-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-recommended.\n",
            "Preparing to unpack .../21-texlive-latex-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-recommended (2017.20180305-1) ...\n",
            "Selecting previously unselected package cm-super-minimal.\n",
            "Preparing to unpack .../22-cm-super-minimal_0.3.4-11_all.deb ...\n",
            "Unpacking cm-super-minimal (0.3.4-11) ...\n",
            "Selecting previously unselected package pfb2t1c2pfb.\n",
            "Preparing to unpack .../23-pfb2t1c2pfb_0.3-11_amd64.deb ...\n",
            "Unpacking pfb2t1c2pfb (0.3-11) ...\n",
            "Selecting previously unselected package cm-super.\n",
            "Preparing to unpack .../24-cm-super_0.3.4-11_all.deb ...\n",
            "Unpacking cm-super (0.3.4-11) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../25-ghostscript_9.26~dfsg+0-0ubuntu0.18.04.14_amd64.deb ...\n",
            "Unpacking ghostscript (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Selecting previously unselected package dvipng.\n",
            "Preparing to unpack .../26-dvipng_1.15-1_amd64.deb ...\n",
            "Unpacking dvipng (1.15-1) ...\n",
            "Selecting previously unselected package fonts-adf-accanthis.\n",
            "Preparing to unpack .../27-fonts-adf-accanthis_0.20110505-1_all.deb ...\n",
            "Unpacking fonts-adf-accanthis (0.20110505-1) ...\n",
            "Selecting previously unselected package fonts-adf-berenis.\n",
            "Preparing to unpack .../28-fonts-adf-berenis_0.20110505-1_all.deb ...\n",
            "Unpacking fonts-adf-berenis (0.20110505-1) ...\n",
            "Selecting previously unselected package fonts-adf-gillius.\n",
            "Preparing to unpack .../29-fonts-adf-gillius_0.20110505-1_all.deb ...\n",
            "Unpacking fonts-adf-gillius (0.20110505-1) ...\n",
            "Selecting previously unselected package fonts-adf-universalis.\n",
            "Preparing to unpack .../30-fonts-adf-universalis_0.20110505-1_all.deb ...\n",
            "Unpacking fonts-adf-universalis (0.20110505-1) ...\n",
            "Selecting previously unselected package fonts-cabin.\n",
            "Preparing to unpack .../31-fonts-cabin_1.5-2_all.deb ...\n",
            "Unpacking fonts-cabin (1.5-2) ...\n",
            "Selecting previously unselected package fonts-comfortaa.\n",
            "Preparing to unpack .../32-fonts-comfortaa_3.001-2_all.deb ...\n",
            "Unpacking fonts-comfortaa (3.001-2) ...\n",
            "Selecting previously unselected package fonts-croscore.\n",
            "Preparing to unpack .../33-fonts-croscore_20171026-2_all.deb ...\n",
            "Unpacking fonts-croscore (20171026-2) ...\n",
            "Selecting previously unselected package fonts-crosextra-caladea.\n",
            "Preparing to unpack .../34-fonts-crosextra-caladea_20130214-2_all.deb ...\n",
            "Unpacking fonts-crosextra-caladea (20130214-2) ...\n",
            "Selecting previously unselected package fonts-crosextra-carlito.\n",
            "Preparing to unpack .../35-fonts-crosextra-carlito_20130920-1_all.deb ...\n",
            "Unpacking fonts-crosextra-carlito (20130920-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../36-fonts-dejavu-core_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../37-fonts-dejavu-extra_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-1) ...\n",
            "Selecting previously unselected package fonts-ebgaramond.\n",
            "Preparing to unpack .../38-fonts-ebgaramond_0.016-1_all.deb ...\n",
            "Unpacking fonts-ebgaramond (0.016-1) ...\n",
            "Selecting previously unselected package fonts-ebgaramond-extra.\n",
            "Preparing to unpack .../39-fonts-ebgaramond-extra_0.016-1_all.deb ...\n",
            "Unpacking fonts-ebgaramond-extra (0.016-1) ...\n",
            "Selecting previously unselected package fonts-font-awesome.\n",
            "Preparing to unpack .../40-fonts-font-awesome_4.7.0~dfsg-3_all.deb ...\n",
            "Unpacking fonts-font-awesome (4.7.0~dfsg-3) ...\n",
            "Selecting previously unselected package fonts-freefont-otf.\n",
            "Preparing to unpack .../41-fonts-freefont-otf_20120503-7_all.deb ...\n",
            "Unpacking fonts-freefont-otf (20120503-7) ...\n",
            "Selecting previously unselected package fonts-freefont-ttf.\n",
            "Preparing to unpack .../42-fonts-freefont-ttf_20120503-7_all.deb ...\n",
            "Unpacking fonts-freefont-ttf (20120503-7) ...\n",
            "Selecting previously unselected package fonts-gfs-artemisia.\n",
            "Preparing to unpack .../43-fonts-gfs-artemisia_1.1-5_all.deb ...\n",
            "Unpacking fonts-gfs-artemisia (1.1-5) ...\n",
            "Selecting previously unselected package fonts-gfs-complutum.\n",
            "Preparing to unpack .../44-fonts-gfs-complutum_1.1-6_all.deb ...\n",
            "Unpacking fonts-gfs-complutum (1.1-6) ...\n",
            "Selecting previously unselected package fonts-gfs-didot.\n",
            "Preparing to unpack .../45-fonts-gfs-didot_1.1-6_all.deb ...\n",
            "Unpacking fonts-gfs-didot (1.1-6) ...\n",
            "Selecting previously unselected package fonts-gfs-neohellenic.\n",
            "Preparing to unpack .../46-fonts-gfs-neohellenic_1.1-6_all.deb ...\n",
            "Unpacking fonts-gfs-neohellenic (1.1-6) ...\n",
            "Selecting previously unselected package fonts-gfs-olga.\n",
            "Preparing to unpack .../47-fonts-gfs-olga_1.1-5_all.deb ...\n",
            "Unpacking fonts-gfs-olga (1.1-5) ...\n",
            "Selecting previously unselected package fonts-gfs-solomos.\n",
            "Preparing to unpack .../48-fonts-gfs-solomos_1.1-5_all.deb ...\n",
            "Unpacking fonts-gfs-solomos (1.1-5) ...\n",
            "Selecting previously unselected package fonts-go.\n",
            "Preparing to unpack .../49-fonts-go_0~20161116-1_all.deb ...\n",
            "Unpacking fonts-go (0~20161116-1) ...\n",
            "Selecting previously unselected package fonts-junicode.\n",
            "Preparing to unpack .../50-fonts-junicode_1.001-2_all.deb ...\n",
            "Unpacking fonts-junicode (1.001-2) ...\n",
            "Selecting previously unselected package fonts-linuxlibertine.\n",
            "Preparing to unpack .../51-fonts-linuxlibertine_5.3.0-4_all.deb ...\n",
            "Unpacking fonts-linuxlibertine (5.3.0-4) ...\n",
            "Selecting previously unselected package fonts-lobster.\n",
            "Preparing to unpack .../52-fonts-lobster_2.0-2_all.deb ...\n",
            "Unpacking fonts-lobster (2.0-2) ...\n",
            "Selecting previously unselected package fonts-lobstertwo.\n",
            "Preparing to unpack .../53-fonts-lobstertwo_2.0-2_all.deb ...\n",
            "Unpacking fonts-lobstertwo (2.0-2) ...\n",
            "Selecting previously unselected package fonts-noto-hinted.\n",
            "Preparing to unpack .../54-fonts-noto-hinted_20171026-2_all.deb ...\n",
            "Unpacking fonts-noto-hinted (20171026-2) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../55-fonts-noto-mono_20171026-2_all.deb ...\n",
            "Unpacking fonts-noto-mono (20171026-2) ...\n",
            "Selecting previously unselected package fonts-oflb-asana-math.\n",
            "Preparing to unpack .../56-fonts-oflb-asana-math_000.907-6_all.deb ...\n",
            "Unpacking fonts-oflb-asana-math (000.907-6) ...\n",
            "Selecting previously unselected package fonts-open-sans.\n",
            "Preparing to unpack .../57-fonts-open-sans_1.11-1_all.deb ...\n",
            "Unpacking fonts-open-sans (1.11-1) ...\n",
            "Selecting previously unselected package fonts-roboto-hinted.\n",
            "Preparing to unpack .../58-fonts-roboto-hinted_2%3a0~20160106-2_all.deb ...\n",
            "Unpacking fonts-roboto-hinted (2:0~20160106-2) ...\n",
            "Selecting previously unselected package fonts-sil-gentium.\n",
            "Preparing to unpack .../59-fonts-sil-gentium_20081126%3a1.03-2_all.deb ...\n",
            "Unpacking fonts-sil-gentium (20081126:1.03-2) ...\n",
            "Selecting previously unselected package fonts-sil-gentium-basic.\n",
            "Preparing to unpack .../60-fonts-sil-gentium-basic_1.102-1_all.deb ...\n",
            "Unpacking fonts-sil-gentium-basic (1.102-1) ...\n",
            "Selecting previously unselected package fonts-sil-gentiumplus.\n",
            "Preparing to unpack .../61-fonts-sil-gentiumplus_5.000-2_all.deb ...\n",
            "Unpacking fonts-sil-gentiumplus (5.000-2) ...\n",
            "Selecting previously unselected package fonts-sil-gentiumplus-compact.\n",
            "Preparing to unpack .../62-fonts-sil-gentiumplus-compact_5.000-2_all.deb ...\n",
            "Unpacking fonts-sil-gentiumplus-compact (5.000-2) ...\n",
            "Selecting previously unselected package fonts-texgyre.\n",
            "Preparing to unpack .../63-fonts-texgyre_20160520-1_all.deb ...\n",
            "Unpacking fonts-texgyre (20160520-1) ...\n",
            "Selecting previously unselected package gsfonts.\n",
            "Preparing to unpack .../64-gsfonts_1%3a8.11+urwcyr1.0.7~pre44-4.4_all.deb ...\n",
            "Unpacking gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n",
            "Selecting previously unselected package javascript-common.\n",
            "Preparing to unpack .../65-javascript-common_11_all.deb ...\n",
            "Unpacking javascript-common (11) ...\n",
            "Selecting previously unselected package libcupsfilters1:amd64.\n",
            "Preparing to unpack .../66-libcupsfilters1_1.20.2-0ubuntu3.1_amd64.deb ...\n",
            "Unpacking libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Selecting previously unselected package libjs-jquery.\n",
            "Preparing to unpack .../67-libjs-jquery_3.2.1-1_all.deb ...\n",
            "Unpacking libjs-jquery (3.2.1-1) ...\n",
            "Selecting previously unselected package rubygems-integration.\n",
            "Preparing to unpack .../68-rubygems-integration_1.11_all.deb ...\n",
            "Unpacking rubygems-integration (1.11) ...\n",
            "Selecting previously unselected package ruby2.5.\n",
            "Preparing to unpack .../69-ruby2.5_2.5.1-1ubuntu1.8_amd64.deb ...\n",
            "Unpacking ruby2.5 (2.5.1-1ubuntu1.8) ...\n",
            "Selecting previously unselected package ruby.\n",
            "Preparing to unpack .../70-ruby_1%3a2.5.1_amd64.deb ...\n",
            "Unpacking ruby (1:2.5.1) ...\n",
            "Selecting previously unselected package rake.\n",
            "Preparing to unpack .../71-rake_12.3.1-1ubuntu0.1_all.deb ...\n",
            "Unpacking rake (12.3.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package ruby-did-you-mean.\n",
            "Preparing to unpack .../72-ruby-did-you-mean_1.2.0-2_all.deb ...\n",
            "Unpacking ruby-did-you-mean (1.2.0-2) ...\n",
            "Selecting previously unselected package ruby-minitest.\n",
            "Preparing to unpack .../73-ruby-minitest_5.10.3-1_all.deb ...\n",
            "Unpacking ruby-minitest (5.10.3-1) ...\n",
            "Selecting previously unselected package ruby-net-telnet.\n",
            "Preparing to unpack .../74-ruby-net-telnet_0.1.1-2_all.deb ...\n",
            "Unpacking ruby-net-telnet (0.1.1-2) ...\n",
            "Selecting previously unselected package ruby-power-assert.\n",
            "Preparing to unpack .../75-ruby-power-assert_0.3.0-1_all.deb ...\n",
            "Unpacking ruby-power-assert (0.3.0-1) ...\n",
            "Selecting previously unselected package ruby-test-unit.\n",
            "Preparing to unpack .../76-ruby-test-unit_3.2.5-1_all.deb ...\n",
            "Unpacking ruby-test-unit (3.2.5-1) ...\n",
            "Selecting previously unselected package libruby2.5:amd64.\n",
            "Preparing to unpack .../77-libruby2.5_2.5.1-1ubuntu1.8_amd64.deb ...\n",
            "Unpacking libruby2.5:amd64 (2.5.1-1ubuntu1.8) ...\n",
            "Selecting previously unselected package lmodern.\n",
            "Preparing to unpack .../78-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package preview-latex-style.\n",
            "Preparing to unpack .../79-preview-latex-style_11.91-1ubuntu1_all.deb ...\n",
            "Unpacking preview-latex-style (11.91-1ubuntu1) ...\n",
            "Selecting previously unselected package tex-gyre.\n",
            "Preparing to unpack .../80-tex-gyre_20160520-1_all.deb ...\n",
            "Unpacking tex-gyre (20160520-1) ...\n",
            "Selecting previously unselected package texlive-fonts-extra.\n",
            "Preparing to unpack .../81-texlive-fonts-extra_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-fonts-extra (2017.20180305-2) ...\n",
            "Selecting previously unselected package fonts-stix.\n",
            "Preparing to unpack .../82-fonts-stix_1.1.1-4_all.deb ...\n",
            "Unpacking fonts-stix (1.1.1-4) ...\n",
            "Selecting previously unselected package texlive-fonts-extra-links.\n",
            "Preparing to unpack .../83-texlive-fonts-extra-links_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-fonts-extra-links (2017.20180305-2) ...\n",
            "Selecting previously unselected package texlive-fonts-recommended.\n",
            "Preparing to unpack .../84-texlive-fonts-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-pictures.\n",
            "Preparing to unpack .../85-texlive-pictures_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-pictures (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-extra.\n",
            "Preparing to unpack .../86-texlive-latex-extra_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-latex-extra (2017.20180305-2) ...\n",
            "Selecting previously unselected package texlive-plain-generic.\n",
            "Preparing to unpack .../87-texlive-plain-generic_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-plain-generic (2017.20180305-2) ...\n",
            "Selecting previously unselected package tipa.\n",
            "Preparing to unpack .../88-tipa_2%3a1.3-20_all.deb ...\n",
            "Unpacking tipa (2:1.3-20) ...\n",
            "Setting up libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Setting up libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libjs-jquery (3.2.1-1) ...\n",
            "Setting up libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Setting up libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-gfs-neohellenic (1.1-6) ...\n",
            "Setting up tex-common (6.09) ...\n",
            "update-language: texlive-base not installed and configured, doing nothing!\n",
            "Setting up fonts-stix (1.1.1-4) ...\n",
            "Setting up fonts-comfortaa (3.001-2) ...\n",
            "Setting up gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n",
            "Setting up fonts-dejavu-core (2.37-1) ...\n",
            "Setting up fonts-linuxlibertine (5.3.0-4) ...\n",
            "Setting up poppler-data (0.4.8-2) ...\n",
            "Setting up fonts-oflb-asana-math (000.907-6) ...\n",
            "Setting up tex-gyre (20160520-1) ...\n",
            "Setting up fonts-lobster (2.0-2) ...\n",
            "Setting up fonts-gfs-solomos (1.1-5) ...\n",
            "Setting up fonts-adf-accanthis (0.20110505-1) ...\n",
            "Setting up fonts-freefont-otf (20120503-7) ...\n",
            "Setting up preview-latex-style (11.91-1ubuntu1) ...\n",
            "Setting up fonts-open-sans (1.11-1) ...\n",
            "Setting up fonts-texgyre (20160520-1) ...\n",
            "Setting up fonts-crosextra-carlito (20130920-1) ...\n",
            "Setting up pfb2t1c2pfb (0.3-11) ...\n",
            "Setting up fonts-ebgaramond-extra (0.016-1) ...\n",
            "Setting up fonts-font-awesome (4.7.0~dfsg-3) ...\n",
            "Setting up fonts-junicode (1.001-2) ...\n",
            "Setting up fonts-noto-mono (20171026-2) ...\n",
            "Setting up fonts-lato (2.0-2) ...\n",
            "Setting up libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Setting up fonts-gfs-complutum (1.1-6) ...\n",
            "Setting up fonts-cabin (1.5-2) ...\n",
            "Setting up libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n",
            "Setting up fonts-sil-gentiumplus-compact (5.000-2) ...\n",
            "Setting up libjbig2dec0:amd64 (0.13-6) ...\n",
            "Setting up ruby-did-you-mean (1.2.0-2) ...\n",
            "Setting up fonts-adf-gillius (0.20110505-1) ...\n",
            "Setting up fonts-crosextra-caladea (20130214-2) ...\n",
            "Setting up fonts-noto-hinted (20171026-2) ...\n",
            "Setting up t1utils (1.41-2) ...\n",
            "Setting up fonts-ebgaramond (0.016-1) ...\n",
            "Setting up ruby-net-telnet (0.1.1-2) ...\n",
            "Setting up fonts-croscore (20171026-2) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-13) ...\n",
            "Setting up rubygems-integration (1.11) ...\n",
            "Setting up libpotrace0 (1.14-2) ...\n",
            "Setting up fonts-adf-berenis (0.20110505-1) ...\n",
            "Setting up fonts-adf-universalis (0.20110505-1) ...\n",
            "Setting up fonts-sil-gentiumplus (5.000-2) ...\n",
            "Setting up fonts-gfs-didot (1.1-6) ...\n",
            "Setting up javascript-common (11) ...\n",
            "Setting up fonts-gfs-artemisia (1.1-5) ...\n",
            "Setting up fonts-dejavu-extra (2.37-1) ...\n",
            "Setting up fonts-freefont-ttf (20120503-7) ...\n",
            "Setting up ruby-minitest (5.10.3-1) ...\n",
            "Setting up fonts-go (0~20161116-1) ...\n",
            "Setting up libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Setting up fonts-sil-gentium (20081126:1.03-2) ...\n",
            "Setting up libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Setting up fonts-sil-gentium-basic (1.102-1) ...\n",
            "Setting up libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-gfs-olga (1.1-5) ...\n",
            "Setting up fonts-lmodern (2.004.5-3) ...\n",
            "Setting up ruby-power-assert (0.3.0-1) ...\n",
            "Setting up fonts-roboto-hinted (2:0~20160106-2) ...\n",
            "Setting up fonts-lobstertwo (2.0-2) ...\n",
            "Setting up ghostscript (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Setting up texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "update-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\n",
            "update-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\n",
            "Setting up texlive-base (2017.20180305-1) ...\n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R... \n",
            "mktexlsr: Done.\n",
            "tl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\n",
            "tl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\n",
            "tl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\n",
            "tl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/config/pdftexconfig.tex\n",
            "Setting up texlive-fonts-extra-links (2017.20180305-2) ...\n",
            "Setting up texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Setting up texlive-plain-generic (2017.20180305-2) ...\n",
            "Setting up texlive-latex-base (2017.20180305-1) ...\n",
            "Setting up lmodern (2.004.5-3) ...\n",
            "Setting up texlive-latex-recommended (2017.20180305-1) ...\n",
            "Setting up texlive-fonts-extra (2017.20180305-2) ...\n",
            "Setting up texlive-pictures (2017.20180305-1) ...\n",
            "Setting up dvipng (1.15-1) ...\n",
            "Setting up tipa (2:1.3-20) ...\n",
            "Regenerating '/var/lib/texmf/fmtutil.cnf-DEBIAN'... done.\n",
            "Regenerating '/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST'... done.\n",
            "update-fmtutil has updated the following file(s):\n",
            "\t/var/lib/texmf/fmtutil.cnf-DEBIAN\n",
            "\t/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST\n",
            "If you want to activate the changes in the above file(s),\n",
            "you should run fmtutil-sys or fmtutil.\n",
            "Setting up cm-super-minimal (0.3.4-11) ...\n",
            "Setting up texlive-latex-extra (2017.20180305-2) ...\n",
            "Setting up cm-super (0.3.4-11) ...\n",
            "Creating fonts. This may take some time... done.\n",
            "Setting up rake (12.3.1-1ubuntu0.1) ...\n",
            "Setting up ruby2.5 (2.5.1-1ubuntu1.8) ...\n",
            "Setting up ruby (1:2.5.1) ...\n",
            "Setting up ruby-test-unit (3.2.5-1) ...\n",
            "Setting up libruby2.5:amd64 (2.5.1-1ubuntu1.8) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for tex-common (6.09) ...\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Building format(s) --all.\n",
            "\tThis may take some time... done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89lKvjja8ieu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "faddda18-fcf2-47be-ae9b-712365dbda25"
      },
      "source": [
        "  ######################################################################\n",
        "    ############################# Plotting ###############################\n",
        "    ######################################################################    \n",
        "    \n",
        "fig, ax = newfig(1.5, 1)\n",
        "ax.axis('off')\n",
        "    \n",
        "    ######## Row 2: Pressure #######################\n",
        "    ########      Predicted p(t,x,y)     ########### \n",
        "gs = gridspec.GridSpec(1, 2)\n",
        "gs.update(top=0.8, bottom=0.2, left=0.1, right=0.9, wspace=0.5)\n",
        "ax = plt.subplot(gs[:, 0])\n",
        "h = ax.imshow(Exact_sol, interpolation='nearest', cmap='jet', \n",
        "                  extent=[lb_sol[0], ub_sol[0], lb_sol[1], ub_sol[1]],\n",
        "                  origin='lower', aspect='auto')\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "fig.colorbar(h, cax=cax)\n",
        "ax.set_xlabel('$t$')\n",
        "ax.set_ylabel('$x$')\n",
        "ax.set_title('Exact Dynamics', fontsize = 10)\n",
        "line = np.linspace(lb_sol[1], ub_sol[1], 2)[:,None]\n",
        "ax.plot(t_idn[index]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "    \n",
        "    ########     Exact p(t,x,y)     ########### \n",
        "ax = plt.subplot(gs[:, 1])\n",
        "h = ax.imshow(U_pred, interpolation='nearest', cmap='jet', \n",
        "                 extent=[lb_sol[0], ub_sol[0], lb_sol[1], ub_sol[1]],origin='lower', aspect='auto')\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "\n",
        "fig.colorbar(h, cax=cax)\n",
        "ax.set_xlabel('$t$')\n",
        "ax.set_ylabel('$x$')\n",
        "ax.set_title('Learned Dynamics', fontsize = 10)\n",
        "line = np.linspace(lb_sol[1], ub_sol[1], 2)[:,None]\n",
        "ax.plot(t_idn[index]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "savefig('/content/figures/Burgers_Sine')\n",
        "# savefig('/content/figures/Burgers_Exp')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 582.814x360.199 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
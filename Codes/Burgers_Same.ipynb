{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.3 64-bit (conda)",
      "metadata": {
        "interpreter": {
          "hash": "51c008122401afe5535fd6c3a84bd5dd8b8bd079df3baf2c4d203d1ed6e4d4a5"
        }
      }
    },
    "colab": {
      "name": "Burgers_Same.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6hx4sG_8ieS"
      },
      "source": [
        "# Burgers Equation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub5oHbXH8pkf",
        "outputId": "a98a2303-4ac2-46b7-cd0b-8471c5ec11c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pyDOE"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyDOE in /usr/local/lib/python3.7/dist-packages (0.3.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyDOE) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyDOE) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeH35EQU8ieb",
        "outputId": "97c3f6f1-97a6-4a28-cc1a-5c8eeca06c5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%tensorflow_version 1.x ### to run on Google Colab: \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "from scipy.interpolate import griddata\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from pyDOE import lhs\n",
        "import time\n",
        "import matplotlib.gridspec as gridspec\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.x ### to run on Google Colab:`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioO_XM0H8iec",
        "outputId": "cbca553b-c4f8-417d-df08-269084d703d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5bGi5OH8iee"
      },
      "source": [
        "###############################################################################\n",
        "############################## Helper Functions ###############################\n",
        "###############################################################################\n",
        "\n",
        "def initialize_NN(layers):\n",
        "    weights = []\n",
        "    biases = []\n",
        "    num_layers = len(layers) \n",
        "    for l in range(0,num_layers-1):\n",
        "        W = xavier_init(size=[layers[l], layers[l+1]])\n",
        "        b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
        "        weights.append(W)\n",
        "        biases.append(b)\n",
        "    return weights, biases\n",
        "    \n",
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    out_dim = size[1]\n",
        "    xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
        "    return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev, dtype=tf.float32), dtype=tf.float32)\n",
        "\n",
        "def neural_net(X, weights, biases):\n",
        "    num_layers = len(weights) + 1\n",
        "    H = X\n",
        "    for l in range(0,num_layers-2):\n",
        "        W = weights[l]\n",
        "        b = biases[l]\n",
        "        H = tf.sin(tf.add(tf.matmul(H, W), b))\n",
        "    W = weights[-1]\n",
        "    b = biases[-1]\n",
        "    Y = tf.add(tf.matmul(H, W), b)\n",
        "    return Y\n",
        "\n",
        "###############################################################################\n",
        "################################ DeepHPM Class ################################\n",
        "###############################################################################\n",
        "\n",
        "class DeepHPM:\n",
        "    def __init__(self, t, x, u,\n",
        "                       x0, u0, tb, X_f,\n",
        "                       u_layers, pde_layers,\n",
        "                       layers,\n",
        "                       lb_idn, ub_idn,\n",
        "                       lb_sol, ub_sol):\n",
        "        \n",
        "        # Domain Boundary\n",
        "        self.lb_idn = lb_idn\n",
        "        self.ub_idn = ub_idn\n",
        "        \n",
        "        self.lb_sol = lb_sol\n",
        "        self.ub_sol = ub_sol\n",
        "        \n",
        "        # Init for Identification\n",
        "        self.idn_init(t, x, u, u_layers, pde_layers)\n",
        "        \n",
        "        # Init for Solution\n",
        "        self.sol_init(x0, u0, tb, X_f, layers)\n",
        "        \n",
        "        # tf session\n",
        "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
        "                                                     log_device_placement=True))\n",
        "        \n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess.run(init)\n",
        "    \n",
        "    ###########################################################################\n",
        "    ############################# Identifier ##################################\n",
        "    ###########################################################################\n",
        "        \n",
        "    def idn_init(self, t, x, u, u_layers, pde_layers):\n",
        "        # Training Data for Identification\n",
        "        self.t = t\n",
        "        self.x = x\n",
        "        self.u = u\n",
        "        \n",
        "        # Layers for Identification\n",
        "        self.u_layers = u_layers\n",
        "        self.pde_layers = pde_layers\n",
        "        \n",
        "        # Initialize NNs for Identification\n",
        "        self.u_weights, self.u_biases = initialize_NN(u_layers)\n",
        "        self.pde_weights, self.pde_biases = initialize_NN(pde_layers)\n",
        "        \n",
        "        # tf placeholders for Identification\n",
        "        self.t_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.x_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.u_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.terms_tf = tf.placeholder(tf.float32, shape=[None, pde_layers[0]])\n",
        "        \n",
        "        # tf graphs for Identification\n",
        "        self.idn_u_pred = self.idn_net_u(self.t_tf, self.x_tf)\n",
        "        self.pde_pred = self.net_pde(self.terms_tf)\n",
        "        self.idn_f_pred = self.idn_net_f(self.t_tf, self.x_tf)\n",
        "        \n",
        "        # loss for Identification\n",
        "        self.idn_u_loss = tf.reduce_sum(tf.square(self.idn_u_pred - self.u_tf))\n",
        "        self.idn_f_loss = tf.reduce_sum(tf.square(self.idn_f_pred))\n",
        "        \n",
        "        # Optimizer for Identification\n",
        "        self.idn_u_optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.idn_u_loss,\n",
        "                               var_list = self.u_weights + self.u_biases,\n",
        "                               method = 'L-BFGS-B',\n",
        "                               options = {'maxiter': 50000,\n",
        "                                          'maxfun': 50000,\n",
        "                                          'maxcor': 50,\n",
        "                                          'maxls': 50,\n",
        "                                          'ftol': 1.0*np.finfo(float).eps})\n",
        "    \n",
        "        self.idn_f_optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.idn_f_loss,\n",
        "                               var_list = self.pde_weights + self.pde_biases,\n",
        "                               method = 'L-BFGS-B',\n",
        "                               options = {'maxiter': 50000,\n",
        "                                          'maxfun': 50000,\n",
        "                                          'maxcor': 50,\n",
        "                                          'maxls': 50,\n",
        "                                          'ftol': 1.0*np.finfo(float).eps})\n",
        "    \n",
        "        self.idn_u_optimizer_Adam = tf.train.AdamOptimizer()\n",
        "        self.idn_u_train_op_Adam = self.idn_u_optimizer_Adam.minimize(self.idn_u_loss, \n",
        "                                   var_list = self.u_weights + self.u_biases)\n",
        "        \n",
        "        self.idn_f_optimizer_Adam = tf.train.AdamOptimizer()\n",
        "        self.idn_f_train_op_Adam = self.idn_f_optimizer_Adam.minimize(self.idn_f_loss, \n",
        "                                   var_list = self.pde_weights + self.pde_biases)  \n",
        "    \n",
        "    def idn_net_u(self, t, x):\n",
        "        X = tf.concat([t,x],1)\n",
        "        H = 2.0*(X - self.lb_idn)/(self.ub_idn - self.lb_idn) - 1.0\n",
        "        u = neural_net(H, self.u_weights, self.u_biases)\n",
        "        return u\n",
        "    \n",
        "    def net_pde(self, terms):\n",
        "        pde = neural_net(terms, self.pde_weights, self.pde_biases)\n",
        "        return pde\n",
        "    \n",
        "    def idn_net_f(self, t, x):\n",
        "        u = self.idn_net_u(t, x)\n",
        "        \n",
        "        u_t = tf.gradients(u, t)[0]\n",
        "        \n",
        "        u_x = tf.gradients(u, x)[0]\n",
        "        u_xx = tf.gradients(u_x, x)[0]\n",
        "        \n",
        "        terms = tf.concat([u,u_x,u_xx],1)\n",
        "\n",
        "        \n",
        "        f = u_t - self.net_pde(terms)\n",
        "        \n",
        "        return f\n",
        "\n",
        "    def idn_u_train(self, N_iter):\n",
        "        tf_dict = {self.t_tf: self.t, self.x_tf: self.x, self.u_tf: self.u}\n",
        "        \n",
        "        start_time = time.time()\n",
        "        for it in range(N_iter):\n",
        "            \n",
        "            self.sess.run(self.idn_u_train_op_Adam, tf_dict)\n",
        "            \n",
        "            # Print\n",
        "            if it % 10 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                loss_value = self.sess.run(self.idn_u_loss, tf_dict)\n",
        "                print('It: %d, Loss: %.3e, Time: %.2f' % \n",
        "                      (it, loss_value, elapsed))\n",
        "                start_time = time.time()\n",
        "        \n",
        "        self.idn_u_optimizer.minimize(self.sess,\n",
        "                                      feed_dict = tf_dict,\n",
        "                                      fetches = [self.idn_u_loss],\n",
        "                                      loss_callback = self.callback)\n",
        "\n",
        "    def idn_f_train(self, N_iter):\n",
        "        tf_dict = {self.t_tf: self.t, self.x_tf: self.x}\n",
        "        \n",
        "        start_time = time.time()\n",
        "        for it in range(N_iter):\n",
        "            \n",
        "            self.sess.run(self.idn_f_train_op_Adam, tf_dict)\n",
        "            \n",
        "            # Print\n",
        "            if it % 10 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                loss_value = self.sess.run(self.idn_f_loss, tf_dict)\n",
        "                print('It: %d, Loss: %.3e, Time: %.2f' % \n",
        "                      (it, loss_value, elapsed))\n",
        "                start_time = time.time()\n",
        "        \n",
        "        self.idn_f_optimizer.minimize(self.sess,\n",
        "                                      feed_dict = tf_dict,\n",
        "                                      fetches = [self.idn_f_loss],\n",
        "                                      loss_callback = self.callback)\n",
        "\n",
        "    def idn_predict(self, t_star, x_star):\n",
        "        \n",
        "        tf_dict = {self.t_tf: t_star, self.x_tf: x_star}\n",
        "        \n",
        "        u_star = self.sess.run(self.idn_u_pred, tf_dict)\n",
        "        f_star = self.sess.run(self.idn_f_pred, tf_dict)\n",
        "        \n",
        "        return u_star, f_star\n",
        "    \n",
        "    def predict_pde(self, terms_star):\n",
        "        \n",
        "        tf_dict = {self.terms_tf: terms_star}\n",
        "        \n",
        "        pde_star = self.sess.run(self.pde_pred, tf_dict)\n",
        "        \n",
        "        return pde_star\n",
        "    \n",
        "    ###########################################################################\n",
        "    ############################### Solver ####################################\n",
        "    ###########################################################################\n",
        "    \n",
        "    def sol_init(self, x0, u0, tb, X_f, layers):\n",
        "        # Training Data for Solution\n",
        "        X0 = np.concatenate((0*x0, x0), 1) # (0, x0)\n",
        "        X_lb = np.concatenate((tb, 0*tb + self.lb_sol[1]), 1) # (tb, lb[1])\n",
        "        X_ub = np.concatenate((tb, 0*tb + self.ub_sol[1]), 1) # (tb, ub[1])\n",
        "                \n",
        "        self.X_f = X_f # Collocation Points\n",
        "        self.t0 = X0[:,0:1] # Initial Data (time)\n",
        "        self.x0 = X0[:,1:2] # Initial Data (space)\n",
        "        self.t_lb = X_lb[:,0:1] # Boundary Data (time) -- lower boundary\n",
        "        self.x_lb = X_lb[:,1:2] # Boundary Data (space) -- lower boundary\n",
        "        self.t_ub = X_ub[:,0:1] # Boundary Data (time) -- upper boundary\n",
        "        self.x_ub = X_ub[:,1:2] # Boundary Data (space) -- upper boundary\n",
        "        self.t_f = X_f[:,0:1] # Collocation Points (time)\n",
        "        self.x_f = X_f[:,1:2] # Collocation Points (space)\n",
        "        self.u0 = u0 # Boundary Data\n",
        "        \n",
        "        # Layers for Solution\n",
        "        self.layers = layers\n",
        "        \n",
        "        # Initialize NNs for Solution\n",
        "        self.weights, self.biases = initialize_NN(layers)\n",
        "        \n",
        "        # tf placeholders for Solution\n",
        "        self.t0_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.x0_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.u0_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.t_lb_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.x_lb_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.t_ub_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.x_ub_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.t_f_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.x_f_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        \n",
        "        # tf graphs for Solution\n",
        "        self.u0_pred, _  = self.sol_net_u(self.t0_tf, self.x0_tf)\n",
        "        self.u_lb_pred, self.u_x_lb_pred = self.sol_net_u(self.t_lb_tf, self.x_lb_tf)\n",
        "        self.u_ub_pred, self.u_x_ub_pred = self.sol_net_u(self.t_ub_tf, self.x_ub_tf)\n",
        "        self.sol_f_pred = self.sol_net_f(self.t_f_tf, self.x_f_tf)\n",
        "        \n",
        "        # loss for Solution\n",
        "        self.sol_loss = tf.reduce_sum(tf.square(self.u0_tf - self.u0_pred)) + \\\n",
        "                        tf.reduce_sum(tf.square(self.u_lb_pred - self.u_ub_pred)) + \\\n",
        "                        tf.reduce_sum(tf.square(self.u_x_lb_pred - self.u_x_ub_pred)) + \\\n",
        "                        tf.reduce_sum(tf.square(self.sol_f_pred))\n",
        "        \n",
        "        # Optimizer for Solution\n",
        "        self.sol_optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.sol_loss,\n",
        "                             var_list = self.weights + self.biases,\n",
        "                             method = 'L-BFGS-B',\n",
        "                             options = {'maxiter': 50000,\n",
        "                                        'maxfun': 50000,\n",
        "                                        'maxcor': 50,\n",
        "                                        'maxls': 50,\n",
        "                                        'ftol': 1.0*np.finfo(float).eps})\n",
        "    \n",
        "        self.sol_optimizer_Adam = tf.train.AdamOptimizer()\n",
        "        self.sol_train_op_Adam = self.sol_optimizer_Adam.minimize(self.sol_loss,\n",
        "                                 var_list = self.weights + self.biases)\n",
        "    \n",
        "    def sol_net_u(self, t, x):\n",
        "        X = tf.concat([t,x],1)\n",
        "        H = 2.0*(X - self.lb_sol)/(self.ub_sol - self.lb_sol) - 1.0\n",
        "        u = neural_net(H, self.weights, self.biases)\n",
        "        u_x = tf.gradients(u, x)[0]\n",
        "        return u, u_x\n",
        "    \n",
        "    def sol_net_f(self, t, x):\n",
        "        u, _ = self.sol_net_u(t,x)\n",
        "        \n",
        "        u_t = tf.gradients(u, t)[0]\n",
        "        \n",
        "        u_x = tf.gradients(u, x)[0]\n",
        "        u_xx = tf.gradients(u_x, x)[0]\n",
        "        \n",
        "        terms = tf.concat([u,u_x,u_xx],1)\n",
        "        \n",
        "        f = u_t - self.net_pde(terms)\n",
        "        \n",
        "        return f\n",
        "    \n",
        "    def callback(self, loss):\n",
        "        print('Loss: %e' % (loss))\n",
        "        \n",
        "    def sol_train(self, N_iter):\n",
        "        tf_dict = {self.t0_tf: self.t0, self.x0_tf: self.x0,\n",
        "                   self.u0_tf: self.u0,\n",
        "                   self.t_lb_tf: self.t_lb, self.x_lb_tf: self.x_lb,\n",
        "                   self.t_ub_tf: self.t_ub, self.x_ub_tf: self.x_ub,\n",
        "                   self.t_f_tf: self.t_f, self.x_f_tf: self.x_f}\n",
        "        \n",
        "        start_time = time.time()\n",
        "        for it in range(N_iter):\n",
        "            \n",
        "            self.sess.run(self.sol_train_op_Adam, tf_dict)\n",
        "            \n",
        "            # Print\n",
        "            if it % 10 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                loss_value = self.sess.run(self.sol_loss, tf_dict)\n",
        "                print('It: %d, Loss: %.3e, Time: %.2f' % \n",
        "                      (it, loss_value, elapsed))\n",
        "                start_time = time.time()\n",
        "                \n",
        "        self.sol_optimizer.minimize(self.sess,\n",
        "                                    feed_dict = tf_dict,\n",
        "                                    fetches = [self.sol_loss],\n",
        "                                    loss_callback = self.callback)\n",
        "    \n",
        "    def sol_predict(self, t_star, x_star):\n",
        "        \n",
        "        u_star = self.sess.run(self.u0_pred, {self.t0_tf: t_star, self.x0_tf: x_star})  \n",
        "        f_star = self.sess.run(self.sol_f_pred, {self.t_f_tf: t_star, self.x_f_tf: x_star})\n",
        "               \n",
        "        return u_star, f_star    "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dJn1YsD8iem"
      },
      "source": [
        "## Problem Set-Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FFu1pR682CG",
        "outputId": "e855ec74-9583-4b0f-b155-1119982bffce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\r\n",
        "cwd = os.getcwd()\r\n",
        "print(cwd)\r\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLTVx4zY8iet"
      },
      "source": [
        "   # Doman bounds\n",
        "lb_idn = np.array([0.0, -8.0])\n",
        "ub_idn = np.array([10.0, 8.0])\n",
        "    \n",
        "lb_sol = np.array([0.0, -8.0])\n",
        "ub_sol = np.array([10.0, 8.0])\n",
        "    \n",
        "    ### Load Data ###    \n",
        "data_idn = scipy.io.loadmat('/content/Data/burgers_sine.mat')\n",
        "t_idn = data_idn['t'].flatten()[:,None]\n",
        "x_idn = data_idn['x'].flatten()[:,None]\n",
        "Exact_idn = np.real(data_idn['usol'])    \n",
        "T_idn, X_idn = np.meshgrid(t_idn,x_idn)\n",
        "keep = 2/3\n",
        "index = int(keep*t_idn.shape[0])\n",
        "T_idn = T_idn[:,0:index]\n",
        "X_idn = X_idn[:,0:index]\n",
        "Exact_idn = Exact_idn[:,0:index]\n",
        "    \n",
        "t_idn_star = T_idn.flatten()[:,None]\n",
        "x_idn_star = X_idn.flatten()[:,None]\n",
        "X_idn_star = np.hstack((t_idn_star, x_idn_star))\n",
        "u_idn_star = Exact_idn.flatten()[:,None]\n",
        "    \n",
        "    # Data Solution: \n",
        "data_sol = scipy.io.loadmat('/content/Data/burgers_sine.mat')\n",
        "t_sol = data_sol['t'].flatten()[:,None]\n",
        "x_sol = data_sol['x'].flatten()[:,None]\n",
        "Exact_sol = np.real(data_sol['usol'])\n",
        "T_sol, X_sol = np.meshgrid(t_sol,x_sol)\n",
        "t_sol_star = T_sol.flatten()[:,None]\n",
        "x_sol_star = X_sol.flatten()[:,None]\n",
        "X_sol_star = np.hstack((t_sol_star, x_sol_star))\n",
        "u_sol_star = Exact_sol.flatten()[:,None]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2NDTJCt8iet"
      },
      "source": [
        "## Training Process: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eEyOSPy8iet",
        "outputId": "57a2ba16-c17c-4382-9d54-3659d8ef92cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "    ### Training Data ###\n",
        "    \n",
        "    # For identification\n",
        "N_train = 1000 # 10,000\n",
        "idx = np.random.choice(t_idn_star.shape[0], N_train, replace=False)    \n",
        "t_train = t_idn_star[idx,:]\n",
        "x_train = x_idn_star[idx,:]\n",
        "u_train = u_idn_star[idx,:]\n",
        "noise = 0.00\n",
        "u_train = u_train + noise*np.std(u_train)*np.random.randn(u_train.shape[0], u_train.shape[1])\n",
        "    \n",
        "# For solution\n",
        "N0 = Exact_sol.shape[0]\n",
        "N_b = Exact_sol.shape[1]\n",
        "N_f = 2000  # 20,000\n",
        "idx_x = np.random.choice(x_sol.shape[0], N0, replace=False)\n",
        "x0_train = x_sol[idx_x,:]\n",
        "u0_train = Exact_sol[idx_x,0:1]   \n",
        "idx_t = np.random.choice(t_sol.shape[0], N_b, replace=False)\n",
        "tb_train = t_sol[idx_t,:] \n",
        "X_f_train = lb_sol + (ub_sol-lb_sol)*lhs(2, N_f)\n",
        "        \n",
        "    # Layers\n",
        "u_layers = [2, 50, 50, 50, 50, 1]\n",
        "pde_layers = [3, 100, 100, 1]    \n",
        "layers = [2, 50, 50, 50, 50, 1]\n",
        "    # Model\n",
        "model = DeepHPM(t_train, x_train, u_train,x0_train, u0_train, tb_train, X_f_train,u_layers, pde_layers,\n",
        "                    layers,lb_idn, ub_idn,\n",
        "                    lb_sol,ub_sol)\n",
        "    # Train the identifier\n",
        "model.idn_u_train(N_iter=0)\n",
        "model.idn_f_train(N_iter=0)   \n",
        "u_pred_identifier, f_pred_identifier = model.idn_predict(t_idn_star, x_idn_star)  \n",
        "error_u_identifier = np.linalg.norm(u_idn_star-u_pred_identifier,2)/np.linalg.norm(u_idn_star,2)\n",
        "print('Error u: %e' % (error_u_identifier))\n",
        "\n",
        "    ### Solution ###\n",
        "    \n",
        "    # Train the solver\n",
        "model.sol_train(N_iter=0)\n",
        "u_pred, f_pred = model.sol_predict(t_sol_star, x_sol_star)   \n",
        "u_pred_idn, f_pred_idn = model.sol_predict(t_idn_star, x_idn_star)\n",
        "error_u = np.linalg.norm(u_sol_star-u_pred,2)/np.linalg.norm(u_sol_star,2)\n",
        "error_u_idn = np.linalg.norm(u_idn_star-u_pred_idn,2)/np.linalg.norm(u_idn_star,2)\n",
        "print('Error u: %e' % (error_u))\n",
        "print('Error u (idn): %e' % (error_u_idn))\n",
        "U_pred = griddata(X_sol_star, u_pred.flatten(), (T_sol, X_sol), method='cubic')\n",
        "    "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Loss: 2.908564e-02\n",
            "Loss: 2.907572e-02\n",
            "Loss: 2.907164e-02\n",
            "Loss: 2.906364e-02\n",
            "Loss: 2.905804e-02\n",
            "Loss: 2.905324e-02\n",
            "Loss: 2.904608e-02\n",
            "Loss: 2.903867e-02\n",
            "Loss: 2.903381e-02\n",
            "Loss: 2.902008e-02\n",
            "Loss: 2.901239e-02\n",
            "Loss: 2.900400e-02\n",
            "Loss: 2.899504e-02\n",
            "Loss: 2.898499e-02\n",
            "Loss: 2.897741e-02\n",
            "Loss: 2.896794e-02\n",
            "Loss: 2.896082e-02\n",
            "Loss: 2.895865e-02\n",
            "Loss: 2.895298e-02\n",
            "Loss: 2.894990e-02\n",
            "Loss: 2.894398e-02\n",
            "Loss: 2.893451e-02\n",
            "Loss: 2.892715e-02\n",
            "Loss: 2.891684e-02\n",
            "Loss: 2.890627e-02\n",
            "Loss: 2.889774e-02\n",
            "Loss: 2.889693e-02\n",
            "Loss: 2.889396e-02\n",
            "Loss: 2.888869e-02\n",
            "Loss: 2.888540e-02\n",
            "Loss: 2.887904e-02\n",
            "Loss: 2.886839e-02\n",
            "Loss: 2.888608e-02\n",
            "Loss: 2.886550e-02\n",
            "Loss: 2.886115e-02\n",
            "Loss: 2.885356e-02\n",
            "Loss: 2.884582e-02\n",
            "Loss: 2.883628e-02\n",
            "Loss: 2.883327e-02\n",
            "Loss: 2.882468e-02\n",
            "Loss: 2.881641e-02\n",
            "Loss: 2.881285e-02\n",
            "Loss: 2.880684e-02\n",
            "Loss: 2.879922e-02\n",
            "Loss: 2.897862e-02\n",
            "Loss: 2.879650e-02\n",
            "Loss: 2.878905e-02\n",
            "Loss: 2.878246e-02\n",
            "Loss: 2.877340e-02\n",
            "Loss: 2.879272e-02\n",
            "Loss: 2.877054e-02\n",
            "Loss: 2.876609e-02\n",
            "Loss: 2.876128e-02\n",
            "Loss: 2.875869e-02\n",
            "Loss: 2.875497e-02\n",
            "Loss: 2.874499e-02\n",
            "Loss: 2.875741e-02\n",
            "Loss: 2.874146e-02\n",
            "Loss: 2.873738e-02\n",
            "Loss: 2.873257e-02\n",
            "Loss: 2.872700e-02\n",
            "Loss: 2.871799e-02\n",
            "Loss: 2.871390e-02\n",
            "Loss: 2.870680e-02\n",
            "Loss: 2.870347e-02\n",
            "Loss: 2.870059e-02\n",
            "Loss: 2.869373e-02\n",
            "Loss: 2.867953e-02\n",
            "Loss: 2.866705e-02\n",
            "Loss: 2.865469e-02\n",
            "Loss: 2.864436e-02\n",
            "Loss: 2.863794e-02\n",
            "Loss: 2.863058e-02\n",
            "Loss: 2.861998e-02\n",
            "Loss: 2.861416e-02\n",
            "Loss: 2.861189e-02\n",
            "Loss: 2.859995e-02\n",
            "Loss: 2.859586e-02\n",
            "Loss: 2.858628e-02\n",
            "Loss: 2.861431e-02\n",
            "Loss: 2.858217e-02\n",
            "Loss: 2.857669e-02\n",
            "Loss: 2.856849e-02\n",
            "Loss: 2.856849e-02\n",
            "Loss: 2.856309e-02\n",
            "Loss: 2.855389e-02\n",
            "Loss: 2.855027e-02\n",
            "Loss: 2.854192e-02\n",
            "Loss: 2.853284e-02\n",
            "Loss: 2.852574e-02\n",
            "Loss: 2.851682e-02\n",
            "Loss: 2.851187e-02\n",
            "Loss: 2.850057e-02\n",
            "Loss: 2.849205e-02\n",
            "Loss: 2.848320e-02\n",
            "Loss: 2.852571e-02\n",
            "Loss: 2.848026e-02\n",
            "Loss: 2.847536e-02\n",
            "Loss: 2.846896e-02\n",
            "Loss: 2.846065e-02\n",
            "Loss: 2.845314e-02\n",
            "Loss: 2.844541e-02\n",
            "Loss: 2.844143e-02\n",
            "Loss: 2.843469e-02\n",
            "Loss: 2.842809e-02\n",
            "Loss: 2.841984e-02\n",
            "Loss: 2.841358e-02\n",
            "Loss: 2.840498e-02\n",
            "Loss: 2.839947e-02\n",
            "Loss: 2.839603e-02\n",
            "Loss: 2.839267e-02\n",
            "Loss: 2.838556e-02\n",
            "Loss: 2.838623e-02\n",
            "Loss: 2.838200e-02\n",
            "Loss: 2.837795e-02\n",
            "Loss: 2.837411e-02\n",
            "Loss: 2.836590e-02\n",
            "Loss: 2.835775e-02\n",
            "Loss: 2.838501e-02\n",
            "Loss: 2.835543e-02\n",
            "Loss: 2.834831e-02\n",
            "Loss: 2.834424e-02\n",
            "Loss: 2.833840e-02\n",
            "Loss: 2.833116e-02\n",
            "Loss: 2.832014e-02\n",
            "Loss: 2.831112e-02\n",
            "Loss: 2.830455e-02\n",
            "Loss: 2.829826e-02\n",
            "Loss: 2.829300e-02\n",
            "Loss: 2.828737e-02\n",
            "Loss: 2.828106e-02\n",
            "Loss: 2.827146e-02\n",
            "Loss: 2.826530e-02\n",
            "Loss: 2.825429e-02\n",
            "Loss: 2.824988e-02\n",
            "Loss: 2.824211e-02\n",
            "Loss: 2.826720e-02\n",
            "Loss: 2.823855e-02\n",
            "Loss: 2.823311e-02\n",
            "Loss: 2.822432e-02\n",
            "Loss: 2.825214e-02\n",
            "Loss: 2.822277e-02\n",
            "Loss: 2.821824e-02\n",
            "Loss: 2.821536e-02\n",
            "Loss: 2.820992e-02\n",
            "Loss: 2.820203e-02\n",
            "Loss: 2.819048e-02\n",
            "Loss: 2.823893e-02\n",
            "Loss: 2.818748e-02\n",
            "Loss: 2.818262e-02\n",
            "Loss: 2.818047e-02\n",
            "Loss: 2.817704e-02\n",
            "Loss: 2.817000e-02\n",
            "Loss: 2.816877e-02\n",
            "Loss: 2.815817e-02\n",
            "Loss: 2.815480e-02\n",
            "Loss: 2.814869e-02\n",
            "Loss: 2.819577e-02\n",
            "Loss: 2.814616e-02\n",
            "Loss: 2.814041e-02\n",
            "Loss: 2.813265e-02\n",
            "Loss: 2.812204e-02\n",
            "Loss: 2.811674e-02\n",
            "Loss: 2.811207e-02\n",
            "Loss: 2.810717e-02\n",
            "Loss: 2.810301e-02\n",
            "Loss: 2.809645e-02\n",
            "Loss: 2.808957e-02\n",
            "Loss: 2.808299e-02\n",
            "Loss: 2.807398e-02\n",
            "Loss: 2.806910e-02\n",
            "Loss: 2.806222e-02\n",
            "Loss: 2.805591e-02\n",
            "Loss: 2.804994e-02\n",
            "Loss: 2.804190e-02\n",
            "Loss: 2.806062e-02\n",
            "Loss: 2.803987e-02\n",
            "Loss: 2.803635e-02\n",
            "Loss: 2.803358e-02\n",
            "Loss: 2.803099e-02\n",
            "Loss: 2.802767e-02\n",
            "Loss: 2.801967e-02\n",
            "Loss: 2.801487e-02\n",
            "Loss: 2.800267e-02\n",
            "Loss: 2.799857e-02\n",
            "Loss: 2.799393e-02\n",
            "Loss: 2.799057e-02\n",
            "Loss: 2.798656e-02\n",
            "Loss: 2.797597e-02\n",
            "Loss: 2.812335e-02\n",
            "Loss: 2.797438e-02\n",
            "Loss: 2.797134e-02\n",
            "Loss: 2.796718e-02\n",
            "Loss: 2.796345e-02\n",
            "Loss: 2.795951e-02\n",
            "Loss: 2.795483e-02\n",
            "Loss: 2.794929e-02\n",
            "Loss: 2.794549e-02\n",
            "Loss: 2.794054e-02\n",
            "Loss: 2.793625e-02\n",
            "Loss: 2.792813e-02\n",
            "Loss: 2.792039e-02\n",
            "Loss: 2.791366e-02\n",
            "Loss: 2.790941e-02\n",
            "Loss: 2.790504e-02\n",
            "Loss: 2.789994e-02\n",
            "Loss: 2.789282e-02\n",
            "Loss: 2.787931e-02\n",
            "Loss: 2.789176e-02\n",
            "Loss: 2.787543e-02\n",
            "Loss: 2.786807e-02\n",
            "Loss: 2.786445e-02\n",
            "Loss: 2.786071e-02\n",
            "Loss: 2.785181e-02\n",
            "Loss: 2.787909e-02\n",
            "Loss: 2.784834e-02\n",
            "Loss: 2.784022e-02\n",
            "Loss: 2.783134e-02\n",
            "Loss: 2.781913e-02\n",
            "Loss: 2.781693e-02\n",
            "Loss: 2.780634e-02\n",
            "Loss: 2.780103e-02\n",
            "Loss: 2.779637e-02\n",
            "Loss: 2.779141e-02\n",
            "Loss: 2.778218e-02\n",
            "Loss: 2.777292e-02\n",
            "Loss: 2.776820e-02\n",
            "Loss: 2.776273e-02\n",
            "Loss: 2.775581e-02\n",
            "Loss: 2.774832e-02\n",
            "Loss: 2.774136e-02\n",
            "Loss: 2.773407e-02\n",
            "Loss: 2.773158e-02\n",
            "Loss: 2.772705e-02\n",
            "Loss: 2.772275e-02\n",
            "Loss: 2.771818e-02\n",
            "Loss: 2.771245e-02\n",
            "Loss: 2.770728e-02\n",
            "Loss: 2.769932e-02\n",
            "Loss: 2.770649e-02\n",
            "Loss: 2.769545e-02\n",
            "Loss: 2.768870e-02\n",
            "Loss: 2.768410e-02\n",
            "Loss: 2.767986e-02\n",
            "Loss: 2.767570e-02\n",
            "Loss: 2.766933e-02\n",
            "Loss: 2.766440e-02\n",
            "Loss: 2.765506e-02\n",
            "Loss: 2.765043e-02\n",
            "Loss: 2.764770e-02\n",
            "Loss: 2.764387e-02\n",
            "Loss: 2.764075e-02\n",
            "Loss: 2.763828e-02\n",
            "Loss: 2.763357e-02\n",
            "Loss: 2.763167e-02\n",
            "Loss: 2.762295e-02\n",
            "Loss: 2.762707e-02\n",
            "Loss: 2.761870e-02\n",
            "Loss: 2.761361e-02\n",
            "Loss: 2.760929e-02\n",
            "Loss: 2.760466e-02\n",
            "Loss: 2.760349e-02\n",
            "Loss: 2.759273e-02\n",
            "Loss: 2.758688e-02\n",
            "Loss: 2.757597e-02\n",
            "Loss: 2.758258e-02\n",
            "Loss: 2.757131e-02\n",
            "Loss: 2.756864e-02\n",
            "Loss: 2.756129e-02\n",
            "Loss: 2.755529e-02\n",
            "Loss: 2.754803e-02\n",
            "Loss: 2.754723e-02\n",
            "Loss: 2.754353e-02\n",
            "Loss: 2.753830e-02\n",
            "Loss: 2.753212e-02\n",
            "Loss: 2.752630e-02\n",
            "Loss: 2.751490e-02\n",
            "Loss: 2.767859e-02\n",
            "Loss: 2.751244e-02\n",
            "Loss: 2.750569e-02\n",
            "Loss: 2.749964e-02\n",
            "Loss: 2.749509e-02\n",
            "Loss: 2.749184e-02\n",
            "Loss: 2.748608e-02\n",
            "Loss: 2.748084e-02\n",
            "Loss: 2.747756e-02\n",
            "Loss: 2.746747e-02\n",
            "Loss: 2.754978e-02\n",
            "Loss: 2.746450e-02\n",
            "Loss: 2.746003e-02\n",
            "Loss: 2.745425e-02\n",
            "Loss: 2.744425e-02\n",
            "Loss: 2.744929e-02\n",
            "Loss: 2.743918e-02\n",
            "Loss: 2.743169e-02\n",
            "Loss: 2.742143e-02\n",
            "Loss: 2.741478e-02\n",
            "Loss: 2.741013e-02\n",
            "Loss: 2.740429e-02\n",
            "Loss: 2.739672e-02\n",
            "Loss: 2.738804e-02\n",
            "Loss: 2.738350e-02\n",
            "Loss: 2.737721e-02\n",
            "Loss: 2.737210e-02\n",
            "Loss: 2.736657e-02\n",
            "Loss: 2.735769e-02\n",
            "Loss: 2.742508e-02\n",
            "Loss: 2.735514e-02\n",
            "Loss: 2.734726e-02\n",
            "Loss: 2.734366e-02\n",
            "Loss: 2.733920e-02\n",
            "Loss: 2.733748e-02\n",
            "Loss: 2.733527e-02\n",
            "Loss: 2.733316e-02\n",
            "Loss: 2.732932e-02\n",
            "Loss: 2.732477e-02\n",
            "Loss: 2.732096e-02\n",
            "Loss: 2.731638e-02\n",
            "Loss: 2.731080e-02\n",
            "Loss: 2.730512e-02\n",
            "Loss: 2.729720e-02\n",
            "Loss: 2.729648e-02\n",
            "Loss: 2.729027e-02\n",
            "Loss: 2.728609e-02\n",
            "Loss: 2.728327e-02\n",
            "Loss: 2.727938e-02\n",
            "Loss: 2.727418e-02\n",
            "Loss: 2.726606e-02\n",
            "Loss: 2.725953e-02\n",
            "Loss: 2.725598e-02\n",
            "Loss: 2.725018e-02\n",
            "Loss: 2.724536e-02\n",
            "Loss: 2.723869e-02\n",
            "Loss: 2.723159e-02\n",
            "Loss: 2.725331e-02\n",
            "Loss: 2.722844e-02\n",
            "Loss: 2.722217e-02\n",
            "Loss: 2.721530e-02\n",
            "Loss: 2.720685e-02\n",
            "Loss: 2.719912e-02\n",
            "Loss: 2.721220e-02\n",
            "Loss: 2.719604e-02\n",
            "Loss: 2.718983e-02\n",
            "Loss: 2.718371e-02\n",
            "Loss: 2.717760e-02\n",
            "Loss: 2.717888e-02\n",
            "Loss: 2.717540e-02\n",
            "Loss: 2.716941e-02\n",
            "Loss: 2.716440e-02\n",
            "Loss: 2.715916e-02\n",
            "Loss: 2.715424e-02\n",
            "Loss: 2.714357e-02\n",
            "Loss: 2.715759e-02\n",
            "Loss: 2.713936e-02\n",
            "Loss: 2.713114e-02\n",
            "Loss: 2.712719e-02\n",
            "Loss: 2.712157e-02\n",
            "Loss: 2.711675e-02\n",
            "Loss: 2.711139e-02\n",
            "Loss: 2.710342e-02\n",
            "Loss: 2.711885e-02\n",
            "Loss: 2.709955e-02\n",
            "Loss: 2.709398e-02\n",
            "Loss: 2.708967e-02\n",
            "Loss: 2.708328e-02\n",
            "Loss: 2.707530e-02\n",
            "Loss: 2.710808e-02\n",
            "Loss: 2.707214e-02\n",
            "Loss: 2.706802e-02\n",
            "Loss: 2.706488e-02\n",
            "Loss: 2.706306e-02\n",
            "Loss: 2.706025e-02\n",
            "Loss: 2.705749e-02\n",
            "Loss: 2.705337e-02\n",
            "Loss: 2.704708e-02\n",
            "Loss: 2.703952e-02\n",
            "Loss: 2.703376e-02\n",
            "Loss: 2.702786e-02\n",
            "Loss: 2.703026e-02\n",
            "Loss: 2.702346e-02\n",
            "Loss: 2.701810e-02\n",
            "Loss: 2.700929e-02\n",
            "Loss: 2.700486e-02\n",
            "Loss: 2.699620e-02\n",
            "Loss: 2.698920e-02\n",
            "Loss: 2.698561e-02\n",
            "Loss: 2.697852e-02\n",
            "Loss: 2.697351e-02\n",
            "Loss: 2.696826e-02\n",
            "Loss: 2.695877e-02\n",
            "Loss: 2.695367e-02\n",
            "Loss: 2.694737e-02\n",
            "Loss: 2.694278e-02\n",
            "Loss: 2.693933e-02\n",
            "Loss: 2.693684e-02\n",
            "Loss: 2.693427e-02\n",
            "Loss: 2.693029e-02\n",
            "Loss: 2.692463e-02\n",
            "Loss: 2.692194e-02\n",
            "Loss: 2.691815e-02\n",
            "Loss: 2.691503e-02\n",
            "Loss: 2.691202e-02\n",
            "Loss: 2.690709e-02\n",
            "Loss: 2.690299e-02\n",
            "Loss: 2.689911e-02\n",
            "Loss: 2.689533e-02\n",
            "Loss: 2.688978e-02\n",
            "Loss: 2.688111e-02\n",
            "Loss: 2.687718e-02\n",
            "Loss: 2.686733e-02\n",
            "Loss: 2.686170e-02\n",
            "Loss: 2.685763e-02\n",
            "Loss: 2.685159e-02\n",
            "Loss: 2.684278e-02\n",
            "Loss: 2.684117e-02\n",
            "Loss: 2.683281e-02\n",
            "Loss: 2.682974e-02\n",
            "Loss: 2.682357e-02\n",
            "Loss: 2.681511e-02\n",
            "Loss: 2.683819e-02\n",
            "Loss: 2.681183e-02\n",
            "Loss: 2.680351e-02\n",
            "Loss: 2.679907e-02\n",
            "Loss: 2.680036e-02\n",
            "Loss: 2.679671e-02\n",
            "Loss: 2.679394e-02\n",
            "Loss: 2.679117e-02\n",
            "Loss: 2.678371e-02\n",
            "Loss: 2.677872e-02\n",
            "Loss: 2.676897e-02\n",
            "Loss: 2.677376e-02\n",
            "Loss: 2.676115e-02\n",
            "Loss: 2.674912e-02\n",
            "Loss: 2.673723e-02\n",
            "Loss: 2.672964e-02\n",
            "Loss: 2.672091e-02\n",
            "Loss: 2.671431e-02\n",
            "Loss: 2.670119e-02\n",
            "Loss: 2.670371e-02\n",
            "Loss: 2.669725e-02\n",
            "Loss: 2.668996e-02\n",
            "Loss: 2.668166e-02\n",
            "Loss: 2.667511e-02\n",
            "Loss: 2.666942e-02\n",
            "Loss: 2.666136e-02\n",
            "Loss: 2.664602e-02\n",
            "Loss: 2.664808e-02\n",
            "Loss: 2.663905e-02\n",
            "Loss: 2.662954e-02\n",
            "Loss: 2.662176e-02\n",
            "Loss: 2.661619e-02\n",
            "Loss: 2.660617e-02\n",
            "Loss: 2.660679e-02\n",
            "Loss: 2.659905e-02\n",
            "Loss: 2.659150e-02\n",
            "Loss: 2.658501e-02\n",
            "Loss: 2.657700e-02\n",
            "Loss: 2.657844e-02\n",
            "Loss: 2.657378e-02\n",
            "Loss: 2.656846e-02\n",
            "Loss: 2.656191e-02\n",
            "Loss: 2.655429e-02\n",
            "Loss: 2.657280e-02\n",
            "Loss: 2.655089e-02\n",
            "Loss: 2.654194e-02\n",
            "Loss: 2.653481e-02\n",
            "Loss: 2.652257e-02\n",
            "Loss: 2.650870e-02\n",
            "Loss: 2.648724e-02\n",
            "Loss: 2.653562e-02\n",
            "Loss: 2.648072e-02\n",
            "Loss: 2.646817e-02\n",
            "Loss: 2.646099e-02\n",
            "Loss: 2.645246e-02\n",
            "Loss: 2.644412e-02\n",
            "Loss: 2.643340e-02\n",
            "Loss: 2.642623e-02\n",
            "Loss: 2.641699e-02\n",
            "Loss: 2.641030e-02\n",
            "Loss: 2.639907e-02\n",
            "Loss: 2.639336e-02\n",
            "Loss: 2.641006e-02\n",
            "Loss: 2.638800e-02\n",
            "Loss: 2.638236e-02\n",
            "Loss: 2.637812e-02\n",
            "Loss: 2.637533e-02\n",
            "Loss: 2.637082e-02\n",
            "Loss: 2.636037e-02\n",
            "Loss: 2.635091e-02\n",
            "Loss: 2.634631e-02\n",
            "Loss: 2.634061e-02\n",
            "Loss: 2.633365e-02\n",
            "Loss: 2.631572e-02\n",
            "Loss: 2.632390e-02\n",
            "Loss: 2.630880e-02\n",
            "Loss: 2.629958e-02\n",
            "Loss: 2.629426e-02\n",
            "Loss: 2.628767e-02\n",
            "Loss: 2.629029e-02\n",
            "Loss: 2.628217e-02\n",
            "Loss: 2.627341e-02\n",
            "Loss: 2.626813e-02\n",
            "Loss: 2.626448e-02\n",
            "Loss: 2.625959e-02\n",
            "Loss: 2.625335e-02\n",
            "Loss: 2.624289e-02\n",
            "Loss: 2.623860e-02\n",
            "Loss: 2.623487e-02\n",
            "Loss: 2.623031e-02\n",
            "Loss: 2.622463e-02\n",
            "Loss: 2.621879e-02\n",
            "Loss: 2.621143e-02\n",
            "Loss: 2.620442e-02\n",
            "Loss: 2.620030e-02\n",
            "Loss: 2.619148e-02\n",
            "Loss: 2.618614e-02\n",
            "Loss: 2.617820e-02\n",
            "Loss: 2.617282e-02\n",
            "Loss: 2.616968e-02\n",
            "Loss: 2.616226e-02\n",
            "Loss: 2.617814e-02\n",
            "Loss: 2.615844e-02\n",
            "Loss: 2.615196e-02\n",
            "Loss: 2.614610e-02\n",
            "Loss: 2.613959e-02\n",
            "Loss: 2.612921e-02\n",
            "Loss: 2.614591e-02\n",
            "Loss: 2.612419e-02\n",
            "Loss: 2.611900e-02\n",
            "Loss: 2.611308e-02\n",
            "Loss: 2.610291e-02\n",
            "Loss: 2.609599e-02\n",
            "Loss: 2.608941e-02\n",
            "Loss: 2.608421e-02\n",
            "Loss: 2.607867e-02\n",
            "Loss: 2.607710e-02\n",
            "Loss: 2.606583e-02\n",
            "Loss: 2.606328e-02\n",
            "Loss: 2.605930e-02\n",
            "Loss: 2.605495e-02\n",
            "Loss: 2.609684e-02\n",
            "Loss: 2.605330e-02\n",
            "Loss: 2.604802e-02\n",
            "Loss: 2.604495e-02\n",
            "Loss: 2.604086e-02\n",
            "Loss: 2.603612e-02\n",
            "Loss: 2.603162e-02\n",
            "Loss: 2.602144e-02\n",
            "Loss: 2.601799e-02\n",
            "Loss: 2.601455e-02\n",
            "Loss: 2.601020e-02\n",
            "Loss: 2.600376e-02\n",
            "Loss: 2.599514e-02\n",
            "Loss: 2.599107e-02\n",
            "Loss: 2.598633e-02\n",
            "Loss: 2.598219e-02\n",
            "Loss: 2.599526e-02\n",
            "Loss: 2.597864e-02\n",
            "Loss: 2.597241e-02\n",
            "Loss: 2.596734e-02\n",
            "Loss: 2.596357e-02\n",
            "Loss: 2.595716e-02\n",
            "Loss: 2.594730e-02\n",
            "Loss: 2.596184e-02\n",
            "Loss: 2.594285e-02\n",
            "Loss: 2.593719e-02\n",
            "Loss: 2.593339e-02\n",
            "Loss: 2.592878e-02\n",
            "Loss: 2.592147e-02\n",
            "Loss: 2.590916e-02\n",
            "Loss: 2.589820e-02\n",
            "Loss: 2.588979e-02\n",
            "Loss: 2.587972e-02\n",
            "Loss: 2.591091e-02\n",
            "Loss: 2.587699e-02\n",
            "Loss: 2.587356e-02\n",
            "Loss: 2.586848e-02\n",
            "Loss: 2.586535e-02\n",
            "Loss: 2.585774e-02\n",
            "Loss: 2.586857e-02\n",
            "Loss: 2.585522e-02\n",
            "Loss: 2.584924e-02\n",
            "Loss: 2.584507e-02\n",
            "Loss: 2.584027e-02\n",
            "Loss: 2.583299e-02\n",
            "Loss: 2.585895e-02\n",
            "Loss: 2.583111e-02\n",
            "Loss: 2.582515e-02\n",
            "Loss: 2.581948e-02\n",
            "Loss: 2.581090e-02\n",
            "Loss: 2.580379e-02\n",
            "Loss: 2.579755e-02\n",
            "Loss: 2.579292e-02\n",
            "Loss: 2.578517e-02\n",
            "Loss: 2.578163e-02\n",
            "Loss: 2.577513e-02\n",
            "Loss: 2.576698e-02\n",
            "Loss: 2.576342e-02\n",
            "Loss: 2.575858e-02\n",
            "Loss: 2.575185e-02\n",
            "Loss: 2.574676e-02\n",
            "Loss: 2.574154e-02\n",
            "Loss: 2.573686e-02\n",
            "Loss: 2.572153e-02\n",
            "Loss: 2.574164e-02\n",
            "Loss: 2.571718e-02\n",
            "Loss: 2.570806e-02\n",
            "Loss: 2.570307e-02\n",
            "Loss: 2.569560e-02\n",
            "Loss: 2.568635e-02\n",
            "Loss: 2.568291e-02\n",
            "Loss: 2.567370e-02\n",
            "Loss: 2.566942e-02\n",
            "Loss: 2.566413e-02\n",
            "Loss: 2.565369e-02\n",
            "Loss: 2.571214e-02\n",
            "Loss: 2.564947e-02\n",
            "Loss: 2.563899e-02\n",
            "Loss: 2.563110e-02\n",
            "Loss: 2.562321e-02\n",
            "Loss: 2.561472e-02\n",
            "Loss: 2.562134e-02\n",
            "Loss: 2.560920e-02\n",
            "Loss: 2.559817e-02\n",
            "Loss: 2.558900e-02\n",
            "Loss: 2.557815e-02\n",
            "Loss: 2.556850e-02\n",
            "Loss: 2.555509e-02\n",
            "Loss: 2.553980e-02\n",
            "Loss: 2.552681e-02\n",
            "Loss: 2.550944e-02\n",
            "Loss: 2.550218e-02\n",
            "Loss: 2.549638e-02\n",
            "Loss: 2.548889e-02\n",
            "Loss: 2.548002e-02\n",
            "Loss: 2.546378e-02\n",
            "Loss: 2.547815e-02\n",
            "Loss: 2.545646e-02\n",
            "Loss: 2.544814e-02\n",
            "Loss: 2.544149e-02\n",
            "Loss: 2.542884e-02\n",
            "Loss: 2.541416e-02\n",
            "Loss: 2.541564e-02\n",
            "Loss: 2.540466e-02\n",
            "Loss: 2.539378e-02\n",
            "Loss: 2.538345e-02\n",
            "Loss: 2.537365e-02\n",
            "Loss: 2.535609e-02\n",
            "Loss: 2.534353e-02\n",
            "Loss: 2.532929e-02\n",
            "Loss: 2.532098e-02\n",
            "Loss: 2.531358e-02\n",
            "Loss: 2.530927e-02\n",
            "Loss: 2.530384e-02\n",
            "Loss: 2.529676e-02\n",
            "Loss: 2.529138e-02\n",
            "Loss: 2.528851e-02\n",
            "Loss: 2.528156e-02\n",
            "Loss: 2.527835e-02\n",
            "Loss: 2.527580e-02\n",
            "Loss: 2.526840e-02\n",
            "Loss: 2.527191e-02\n",
            "Loss: 2.526374e-02\n",
            "Loss: 2.525398e-02\n",
            "Loss: 2.524900e-02\n",
            "Loss: 2.524185e-02\n",
            "Loss: 2.523199e-02\n",
            "Loss: 2.521722e-02\n",
            "Loss: 2.523455e-02\n",
            "Loss: 2.521153e-02\n",
            "Loss: 2.520510e-02\n",
            "Loss: 2.520088e-02\n",
            "Loss: 2.519600e-02\n",
            "Loss: 2.518590e-02\n",
            "Loss: 2.517616e-02\n",
            "Loss: 2.516702e-02\n",
            "Loss: 2.515663e-02\n",
            "Loss: 2.514539e-02\n",
            "Loss: 2.514624e-02\n",
            "Loss: 2.513687e-02\n",
            "Loss: 2.512725e-02\n",
            "Loss: 2.512087e-02\n",
            "Loss: 2.511114e-02\n",
            "Loss: 2.510954e-02\n",
            "Loss: 2.509542e-02\n",
            "Loss: 2.509089e-02\n",
            "Loss: 2.508580e-02\n",
            "Loss: 2.507979e-02\n",
            "Loss: 2.506880e-02\n",
            "Loss: 2.506493e-02\n",
            "Loss: 2.505361e-02\n",
            "Loss: 2.504790e-02\n",
            "Loss: 2.504165e-02\n",
            "Loss: 2.505555e-02\n",
            "Loss: 2.503726e-02\n",
            "Loss: 2.502632e-02\n",
            "Loss: 2.501906e-02\n",
            "Loss: 2.500774e-02\n",
            "Loss: 2.499796e-02\n",
            "Loss: 2.502102e-02\n",
            "Loss: 2.499357e-02\n",
            "Loss: 2.498489e-02\n",
            "Loss: 2.497916e-02\n",
            "Loss: 2.496980e-02\n",
            "Loss: 2.495849e-02\n",
            "Loss: 2.494373e-02\n",
            "Loss: 2.494064e-02\n",
            "Loss: 2.492547e-02\n",
            "Loss: 2.492329e-02\n",
            "Loss: 2.492137e-02\n",
            "Loss: 2.491815e-02\n",
            "Loss: 2.491491e-02\n",
            "Loss: 2.490773e-02\n",
            "Loss: 2.489811e-02\n",
            "Loss: 2.489274e-02\n",
            "Loss: 2.488548e-02\n",
            "Loss: 2.488325e-02\n",
            "Loss: 2.487585e-02\n",
            "Loss: 2.487526e-02\n",
            "Loss: 2.487199e-02\n",
            "Loss: 2.486879e-02\n",
            "Loss: 2.486405e-02\n",
            "Loss: 2.485752e-02\n",
            "Loss: 2.485840e-02\n",
            "Loss: 2.485339e-02\n",
            "Loss: 2.484767e-02\n",
            "Loss: 2.484087e-02\n",
            "Loss: 2.483953e-02\n",
            "Loss: 2.483453e-02\n",
            "Loss: 2.483118e-02\n",
            "Loss: 2.482790e-02\n",
            "Loss: 2.482457e-02\n",
            "Loss: 2.482525e-02\n",
            "Loss: 2.482151e-02\n",
            "Loss: 2.481425e-02\n",
            "Loss: 2.480978e-02\n",
            "Loss: 2.480138e-02\n",
            "Loss: 2.479723e-02\n",
            "Loss: 2.479255e-02\n",
            "Loss: 2.478721e-02\n",
            "Loss: 2.478179e-02\n",
            "Loss: 2.477193e-02\n",
            "Loss: 2.478896e-02\n",
            "Loss: 2.476856e-02\n",
            "Loss: 2.476115e-02\n",
            "Loss: 2.475391e-02\n",
            "Loss: 2.474484e-02\n",
            "Loss: 2.474285e-02\n",
            "Loss: 2.473381e-02\n",
            "Loss: 2.472973e-02\n",
            "Loss: 2.472217e-02\n",
            "Loss: 2.471838e-02\n",
            "Loss: 2.470506e-02\n",
            "Loss: 2.469813e-02\n",
            "Loss: 2.469072e-02\n",
            "Loss: 2.467973e-02\n",
            "Loss: 2.466901e-02\n",
            "Loss: 2.466148e-02\n",
            "Loss: 2.465489e-02\n",
            "Loss: 2.464938e-02\n",
            "Loss: 2.464343e-02\n",
            "Loss: 2.463161e-02\n",
            "Loss: 2.462609e-02\n",
            "Loss: 2.461170e-02\n",
            "Loss: 2.460543e-02\n",
            "Loss: 2.460076e-02\n",
            "Loss: 2.459610e-02\n",
            "Loss: 2.459036e-02\n",
            "Loss: 2.457922e-02\n",
            "Loss: 2.457107e-02\n",
            "Loss: 2.457668e-02\n",
            "Loss: 2.456982e-02\n",
            "Loss: 2.456563e-02\n",
            "Loss: 2.456214e-02\n",
            "Loss: 2.455823e-02\n",
            "Loss: 2.455259e-02\n",
            "Loss: 2.455301e-02\n",
            "Loss: 2.454997e-02\n",
            "Loss: 2.454457e-02\n",
            "Loss: 2.454001e-02\n",
            "Loss: 2.453381e-02\n",
            "Loss: 2.452782e-02\n",
            "Loss: 2.451805e-02\n",
            "Loss: 2.453301e-02\n",
            "Loss: 2.451381e-02\n",
            "Loss: 2.450794e-02\n",
            "Loss: 2.450600e-02\n",
            "Loss: 2.450310e-02\n",
            "Loss: 2.449719e-02\n",
            "Loss: 2.448790e-02\n",
            "Loss: 2.447920e-02\n",
            "Loss: 2.447398e-02\n",
            "Loss: 2.446891e-02\n",
            "Loss: 2.446302e-02\n",
            "Loss: 2.445374e-02\n",
            "Loss: 2.444614e-02\n",
            "Loss: 2.442704e-02\n",
            "Loss: 2.442267e-02\n",
            "Loss: 2.441237e-02\n",
            "Loss: 2.440826e-02\n",
            "Loss: 2.440282e-02\n",
            "Loss: 2.439727e-02\n",
            "Loss: 2.439104e-02\n",
            "Loss: 2.438504e-02\n",
            "Loss: 2.438052e-02\n",
            "Loss: 2.437585e-02\n",
            "Loss: 2.436884e-02\n",
            "Loss: 2.435949e-02\n",
            "Loss: 2.436054e-02\n",
            "Loss: 2.435308e-02\n",
            "Loss: 2.434695e-02\n",
            "Loss: 2.434087e-02\n",
            "Loss: 2.433134e-02\n",
            "Loss: 2.433609e-02\n",
            "Loss: 2.432688e-02\n",
            "Loss: 2.431949e-02\n",
            "Loss: 2.431573e-02\n",
            "Loss: 2.430944e-02\n",
            "Loss: 2.430067e-02\n",
            "Loss: 2.428396e-02\n",
            "Loss: 2.428141e-02\n",
            "Loss: 2.426143e-02\n",
            "Loss: 2.426177e-02\n",
            "Loss: 2.425805e-02\n",
            "Loss: 2.425393e-02\n",
            "Loss: 2.425042e-02\n",
            "Loss: 2.424475e-02\n",
            "Loss: 2.423526e-02\n",
            "Loss: 2.450147e-02\n",
            "Loss: 2.423422e-02\n",
            "Loss: 2.422737e-02\n",
            "Loss: 2.422328e-02\n",
            "Loss: 2.421807e-02\n",
            "Loss: 2.421192e-02\n",
            "Loss: 2.421115e-02\n",
            "Loss: 2.420048e-02\n",
            "Loss: 2.419664e-02\n",
            "Loss: 2.419172e-02\n",
            "Loss: 2.418348e-02\n",
            "Loss: 2.418724e-02\n",
            "Loss: 2.417775e-02\n",
            "Loss: 2.417693e-02\n",
            "Loss: 2.416871e-02\n",
            "Loss: 2.416623e-02\n",
            "Loss: 2.416256e-02\n",
            "Loss: 2.415657e-02\n",
            "Loss: 2.416114e-02\n",
            "Loss: 2.415169e-02\n",
            "Loss: 2.414382e-02\n",
            "Loss: 2.413843e-02\n",
            "Loss: 2.413307e-02\n",
            "Loss: 2.412782e-02\n",
            "Loss: 2.412219e-02\n",
            "Loss: 2.411646e-02\n",
            "Loss: 2.411105e-02\n",
            "Loss: 2.410460e-02\n",
            "Loss: 2.409331e-02\n",
            "Loss: 2.411041e-02\n",
            "Loss: 2.408915e-02\n",
            "Loss: 2.408154e-02\n",
            "Loss: 2.407665e-02\n",
            "Loss: 2.407275e-02\n",
            "Loss: 2.406646e-02\n",
            "Loss: 2.406101e-02\n",
            "Loss: 2.405225e-02\n",
            "Loss: 2.404485e-02\n",
            "Loss: 2.403732e-02\n",
            "Loss: 2.402987e-02\n",
            "Loss: 2.402664e-02\n",
            "Loss: 2.401770e-02\n",
            "Loss: 2.401176e-02\n",
            "Loss: 2.400535e-02\n",
            "Loss: 2.400066e-02\n",
            "Loss: 2.399454e-02\n",
            "Loss: 2.398867e-02\n",
            "Loss: 2.397828e-02\n",
            "Loss: 2.396772e-02\n",
            "Loss: 2.395470e-02\n",
            "Loss: 2.394379e-02\n",
            "Loss: 2.396827e-02\n",
            "Loss: 2.393945e-02\n",
            "Loss: 2.393326e-02\n",
            "Loss: 2.392877e-02\n",
            "Loss: 2.392171e-02\n",
            "Loss: 2.391480e-02\n",
            "Loss: 2.391248e-02\n",
            "Loss: 2.390511e-02\n",
            "Loss: 2.390311e-02\n",
            "Loss: 2.389834e-02\n",
            "Loss: 2.388871e-02\n",
            "Loss: 2.391072e-02\n",
            "Loss: 2.388537e-02\n",
            "Loss: 2.388126e-02\n",
            "Loss: 2.387767e-02\n",
            "Loss: 2.387435e-02\n",
            "Loss: 2.386559e-02\n",
            "Loss: 2.386286e-02\n",
            "Loss: 2.385190e-02\n",
            "Loss: 2.384680e-02\n",
            "Loss: 2.384318e-02\n",
            "Loss: 2.383769e-02\n",
            "Loss: 2.382674e-02\n",
            "Loss: 2.383158e-02\n",
            "Loss: 2.382114e-02\n",
            "Loss: 2.381568e-02\n",
            "Loss: 2.381274e-02\n",
            "Loss: 2.380739e-02\n",
            "Loss: 2.380376e-02\n",
            "Loss: 2.379813e-02\n",
            "Loss: 2.379458e-02\n",
            "Loss: 2.379009e-02\n",
            "Loss: 2.378124e-02\n",
            "Loss: 2.377236e-02\n",
            "Loss: 2.376323e-02\n",
            "Loss: 2.375913e-02\n",
            "Loss: 2.375328e-02\n",
            "Loss: 2.375145e-02\n",
            "Loss: 2.374320e-02\n",
            "Loss: 2.373734e-02\n",
            "Loss: 2.373088e-02\n",
            "Loss: 2.372414e-02\n",
            "Loss: 2.379906e-02\n",
            "Loss: 2.372104e-02\n",
            "Loss: 2.371449e-02\n",
            "Loss: 2.371333e-02\n",
            "Loss: 2.370855e-02\n",
            "Loss: 2.370484e-02\n",
            "Loss: 2.370099e-02\n",
            "Loss: 2.369419e-02\n",
            "Loss: 2.368949e-02\n",
            "Loss: 2.368239e-02\n",
            "Loss: 2.367834e-02\n",
            "Loss: 2.367451e-02\n",
            "Loss: 2.366726e-02\n",
            "Loss: 2.365718e-02\n",
            "Loss: 2.365964e-02\n",
            "Loss: 2.365120e-02\n",
            "Loss: 2.364380e-02\n",
            "Loss: 2.363738e-02\n",
            "Loss: 2.363367e-02\n",
            "Loss: 2.362060e-02\n",
            "Loss: 2.362135e-02\n",
            "Loss: 2.361615e-02\n",
            "Loss: 2.360835e-02\n",
            "Loss: 2.360440e-02\n",
            "Loss: 2.360311e-02\n",
            "Loss: 2.359530e-02\n",
            "Loss: 2.359399e-02\n",
            "Loss: 2.359082e-02\n",
            "Loss: 2.358563e-02\n",
            "Loss: 2.357302e-02\n",
            "Loss: 2.366531e-02\n",
            "Loss: 2.357131e-02\n",
            "Loss: 2.356303e-02\n",
            "Loss: 2.356853e-02\n",
            "Loss: 2.356009e-02\n",
            "Loss: 2.355520e-02\n",
            "Loss: 2.355009e-02\n",
            "Loss: 2.354567e-02\n",
            "Loss: 2.354149e-02\n",
            "Loss: 2.353638e-02\n",
            "Loss: 2.353697e-02\n",
            "Loss: 2.353451e-02\n",
            "Loss: 2.353242e-02\n",
            "Loss: 2.352189e-02\n",
            "Loss: 2.351421e-02\n",
            "Loss: 2.351155e-02\n",
            "Loss: 2.350100e-02\n",
            "Loss: 2.349900e-02\n",
            "Loss: 2.349642e-02\n",
            "Loss: 2.349243e-02\n",
            "Loss: 2.348700e-02\n",
            "Loss: 2.347849e-02\n",
            "Loss: 2.347407e-02\n",
            "Loss: 2.346687e-02\n",
            "Loss: 2.346643e-02\n",
            "Loss: 2.346087e-02\n",
            "Loss: 2.345663e-02\n",
            "Loss: 2.345255e-02\n",
            "Loss: 2.344779e-02\n",
            "Loss: 2.344284e-02\n",
            "Loss: 2.343611e-02\n",
            "Loss: 2.343130e-02\n",
            "Loss: 2.342504e-02\n",
            "Loss: 2.342224e-02\n",
            "Loss: 2.341465e-02\n",
            "Loss: 2.340903e-02\n",
            "Loss: 2.340589e-02\n",
            "Loss: 2.340166e-02\n",
            "Loss: 2.341001e-02\n",
            "Loss: 2.339731e-02\n",
            "Loss: 2.338961e-02\n",
            "Loss: 2.338238e-02\n",
            "Loss: 2.337863e-02\n",
            "Loss: 2.337367e-02\n",
            "Loss: 2.337064e-02\n",
            "Loss: 2.336009e-02\n",
            "Loss: 2.334958e-02\n",
            "Loss: 2.341046e-02\n",
            "Loss: 2.334757e-02\n",
            "Loss: 2.333937e-02\n",
            "Loss: 2.333353e-02\n",
            "Loss: 2.332863e-02\n",
            "Loss: 2.332506e-02\n",
            "Loss: 2.331671e-02\n",
            "Loss: 2.330850e-02\n",
            "Loss: 2.330121e-02\n",
            "Loss: 2.329851e-02\n",
            "Loss: 2.329242e-02\n",
            "Loss: 2.328214e-02\n",
            "Loss: 2.331914e-02\n",
            "Loss: 2.327866e-02\n",
            "Loss: 2.326880e-02\n",
            "Loss: 2.326158e-02\n",
            "Loss: 2.325615e-02\n",
            "Loss: 2.325163e-02\n",
            "Loss: 2.324878e-02\n",
            "Loss: 2.324369e-02\n",
            "Loss: 2.324518e-02\n",
            "Loss: 2.324014e-02\n",
            "Loss: 2.323695e-02\n",
            "Loss: 2.322822e-02\n",
            "Loss: 2.322392e-02\n",
            "Loss: 2.323945e-02\n",
            "Loss: 2.321990e-02\n",
            "Loss: 2.321354e-02\n",
            "Loss: 2.320644e-02\n",
            "Loss: 2.319917e-02\n",
            "Loss: 2.319329e-02\n",
            "Loss: 2.318354e-02\n",
            "Loss: 2.321150e-02\n",
            "Loss: 2.318034e-02\n",
            "Loss: 2.317251e-02\n",
            "Loss: 2.316865e-02\n",
            "Loss: 2.316724e-02\n",
            "Loss: 2.316185e-02\n",
            "Loss: 2.315853e-02\n",
            "Loss: 2.315288e-02\n",
            "Loss: 2.314780e-02\n",
            "Loss: 2.314070e-02\n",
            "Loss: 2.313403e-02\n",
            "Loss: 2.312938e-02\n",
            "Loss: 2.312358e-02\n",
            "Loss: 2.312008e-02\n",
            "Loss: 2.311913e-02\n",
            "Loss: 2.311475e-02\n",
            "Loss: 2.310428e-02\n",
            "Loss: 2.309872e-02\n",
            "Loss: 2.309097e-02\n",
            "Loss: 2.308705e-02\n",
            "Loss: 2.308276e-02\n",
            "Loss: 2.307723e-02\n",
            "Loss: 2.307349e-02\n",
            "Loss: 2.306654e-02\n",
            "Loss: 2.305957e-02\n",
            "Loss: 2.305347e-02\n",
            "Loss: 2.305056e-02\n",
            "Loss: 2.304692e-02\n",
            "Loss: 2.304385e-02\n",
            "Loss: 2.304011e-02\n",
            "Loss: 2.303384e-02\n",
            "Loss: 2.302597e-02\n",
            "Loss: 2.301812e-02\n",
            "Loss: 2.301552e-02\n",
            "Loss: 2.301306e-02\n",
            "Loss: 2.300798e-02\n",
            "Loss: 2.299774e-02\n",
            "Loss: 2.302382e-02\n",
            "Loss: 2.299373e-02\n",
            "Loss: 2.298479e-02\n",
            "Loss: 2.297340e-02\n",
            "Loss: 2.296406e-02\n",
            "Loss: 2.297053e-02\n",
            "Loss: 2.295753e-02\n",
            "Loss: 2.294892e-02\n",
            "Loss: 2.293964e-02\n",
            "Loss: 2.293371e-02\n",
            "Loss: 2.292947e-02\n",
            "Loss: 2.292519e-02\n",
            "Loss: 2.291823e-02\n",
            "Loss: 2.291218e-02\n",
            "Loss: 2.290662e-02\n",
            "Loss: 2.289543e-02\n",
            "Loss: 2.288277e-02\n",
            "Loss: 2.286905e-02\n",
            "Loss: 2.285803e-02\n",
            "Loss: 2.284861e-02\n",
            "Loss: 2.283832e-02\n",
            "Loss: 2.283017e-02\n",
            "Loss: 2.281377e-02\n",
            "Loss: 2.282554e-02\n",
            "Loss: 2.280881e-02\n",
            "Loss: 2.280049e-02\n",
            "Loss: 2.279161e-02\n",
            "Loss: 2.278632e-02\n",
            "Loss: 2.278072e-02\n",
            "Loss: 2.277139e-02\n",
            "Loss: 2.276199e-02\n",
            "Loss: 2.275497e-02\n",
            "Loss: 2.274419e-02\n",
            "Loss: 2.273646e-02\n",
            "Loss: 2.272567e-02\n",
            "Loss: 2.271468e-02\n",
            "Loss: 2.270329e-02\n",
            "Loss: 2.269100e-02\n",
            "Loss: 2.268310e-02\n",
            "Loss: 2.267403e-02\n",
            "Loss: 2.266679e-02\n",
            "Loss: 2.265671e-02\n",
            "Loss: 2.266253e-02\n",
            "Loss: 2.264889e-02\n",
            "Loss: 2.264024e-02\n",
            "Loss: 2.263270e-02\n",
            "Loss: 2.262745e-02\n",
            "Loss: 2.261939e-02\n",
            "Loss: 2.259774e-02\n",
            "Loss: 2.277871e-02\n",
            "Loss: 2.259349e-02\n",
            "Loss: 2.258277e-02\n",
            "Loss: 2.257721e-02\n",
            "Loss: 2.256836e-02\n",
            "Loss: 2.255490e-02\n",
            "Loss: 2.252845e-02\n",
            "Loss: 2.249948e-02\n",
            "Loss: 2.247869e-02\n",
            "Loss: 2.245968e-02\n",
            "Loss: 2.244639e-02\n",
            "Loss: 2.243585e-02\n",
            "Loss: 2.242591e-02\n",
            "Loss: 2.241482e-02\n",
            "Loss: 2.240774e-02\n",
            "Loss: 2.239825e-02\n",
            "Loss: 2.238863e-02\n",
            "Loss: 2.237249e-02\n",
            "Loss: 2.236278e-02\n",
            "Loss: 2.235855e-02\n",
            "Loss: 2.234826e-02\n",
            "Loss: 2.240936e-02\n",
            "Loss: 2.234255e-02\n",
            "Loss: 2.232495e-02\n",
            "Loss: 2.230974e-02\n",
            "Loss: 2.228302e-02\n",
            "Loss: 2.226670e-02\n",
            "Loss: 2.225115e-02\n",
            "Loss: 2.223908e-02\n",
            "Loss: 2.222770e-02\n",
            "Loss: 2.223086e-02\n",
            "Loss: 2.222240e-02\n",
            "Loss: 2.221221e-02\n",
            "Loss: 2.220196e-02\n",
            "Loss: 2.219384e-02\n",
            "Loss: 2.218101e-02\n",
            "Loss: 2.217447e-02\n",
            "Loss: 2.215528e-02\n",
            "Loss: 2.214965e-02\n",
            "Loss: 2.214087e-02\n",
            "Loss: 2.212804e-02\n",
            "Loss: 2.214353e-02\n",
            "Loss: 2.212025e-02\n",
            "Loss: 2.210585e-02\n",
            "Loss: 2.209830e-02\n",
            "Loss: 2.208975e-02\n",
            "Loss: 2.208014e-02\n",
            "Loss: 2.206923e-02\n",
            "Loss: 2.205994e-02\n",
            "Loss: 2.205082e-02\n",
            "Loss: 2.204619e-02\n",
            "Loss: 2.202717e-02\n",
            "Loss: 2.215432e-02\n",
            "Loss: 2.202437e-02\n",
            "Loss: 2.201058e-02\n",
            "Loss: 2.199225e-02\n",
            "Loss: 2.197667e-02\n",
            "Loss: 2.196520e-02\n",
            "Loss: 2.195462e-02\n",
            "Loss: 2.194615e-02\n",
            "Loss: 2.192935e-02\n",
            "Loss: 2.191620e-02\n",
            "Loss: 2.190126e-02\n",
            "Loss: 2.188104e-02\n",
            "Loss: 2.186256e-02\n",
            "Loss: 2.184136e-02\n",
            "Loss: 2.182214e-02\n",
            "Loss: 2.180808e-02\n",
            "Loss: 2.179871e-02\n",
            "Loss: 2.178950e-02\n",
            "Loss: 2.177846e-02\n",
            "Loss: 2.176878e-02\n",
            "Loss: 2.175268e-02\n",
            "Loss: 2.174837e-02\n",
            "Loss: 2.173379e-02\n",
            "Loss: 2.172947e-02\n",
            "Loss: 2.172347e-02\n",
            "Loss: 2.171014e-02\n",
            "Loss: 2.172302e-02\n",
            "Loss: 2.170594e-02\n",
            "Loss: 2.169581e-02\n",
            "Loss: 2.168997e-02\n",
            "Loss: 2.168121e-02\n",
            "Loss: 2.167108e-02\n",
            "Loss: 2.165140e-02\n",
            "Loss: 2.176971e-02\n",
            "Loss: 2.164703e-02\n",
            "Loss: 2.163634e-02\n",
            "Loss: 2.163088e-02\n",
            "Loss: 2.162690e-02\n",
            "Loss: 2.161786e-02\n",
            "Loss: 2.160191e-02\n",
            "Loss: 2.158783e-02\n",
            "Loss: 2.157894e-02\n",
            "Loss: 2.157003e-02\n",
            "Loss: 2.156240e-02\n",
            "Loss: 2.154763e-02\n",
            "Loss: 2.155663e-02\n",
            "Loss: 2.154230e-02\n",
            "Loss: 2.153316e-02\n",
            "Loss: 2.152133e-02\n",
            "Loss: 2.150436e-02\n",
            "Loss: 2.149293e-02\n",
            "Loss: 2.148178e-02\n",
            "Loss: 2.147616e-02\n",
            "Loss: 2.146916e-02\n",
            "Loss: 2.145887e-02\n",
            "Loss: 2.145509e-02\n",
            "Loss: 2.143704e-02\n",
            "Loss: 2.143298e-02\n",
            "Loss: 2.142464e-02\n",
            "Loss: 2.141242e-02\n",
            "Loss: 2.143266e-02\n",
            "Loss: 2.140749e-02\n",
            "Loss: 2.140038e-02\n",
            "Loss: 2.139238e-02\n",
            "Loss: 2.137905e-02\n",
            "Loss: 2.136737e-02\n",
            "Loss: 2.135482e-02\n",
            "Loss: 2.134358e-02\n",
            "Loss: 2.133362e-02\n",
            "Loss: 2.132229e-02\n",
            "Loss: 2.131187e-02\n",
            "Loss: 2.130147e-02\n",
            "Loss: 2.129402e-02\n",
            "Loss: 2.128148e-02\n",
            "Loss: 2.127000e-02\n",
            "Loss: 2.125965e-02\n",
            "Loss: 2.125202e-02\n",
            "Loss: 2.124412e-02\n",
            "Loss: 2.131465e-02\n",
            "Loss: 2.123875e-02\n",
            "Loss: 2.122751e-02\n",
            "Loss: 2.121709e-02\n",
            "Loss: 2.120601e-02\n",
            "Loss: 2.119525e-02\n",
            "Loss: 2.118288e-02\n",
            "Loss: 2.117024e-02\n",
            "Loss: 2.116015e-02\n",
            "Loss: 2.114912e-02\n",
            "Loss: 2.114183e-02\n",
            "Loss: 2.113157e-02\n",
            "Loss: 2.122968e-02\n",
            "Loss: 2.112794e-02\n",
            "Loss: 2.111421e-02\n",
            "Loss: 2.110666e-02\n",
            "Loss: 2.109443e-02\n",
            "Loss: 2.108152e-02\n",
            "Loss: 2.106062e-02\n",
            "Loss: 2.119821e-02\n",
            "Loss: 2.105665e-02\n",
            "Loss: 2.104339e-02\n",
            "Loss: 2.103396e-02\n",
            "Loss: 2.102139e-02\n",
            "Loss: 2.101462e-02\n",
            "Loss: 2.100286e-02\n",
            "Loss: 2.099327e-02\n",
            "Loss: 2.097845e-02\n",
            "Loss: 2.097238e-02\n",
            "Loss: 2.096216e-02\n",
            "Loss: 2.095605e-02\n",
            "Loss: 2.095076e-02\n",
            "Loss: 2.094052e-02\n",
            "Loss: 2.092364e-02\n",
            "Loss: 2.092742e-02\n",
            "Loss: 2.091589e-02\n",
            "Loss: 2.090911e-02\n",
            "Loss: 2.090093e-02\n",
            "Loss: 2.089131e-02\n",
            "Loss: 2.089204e-02\n",
            "Loss: 2.088493e-02\n",
            "Loss: 2.087805e-02\n",
            "Loss: 2.087007e-02\n",
            "Loss: 2.085621e-02\n",
            "Loss: 2.084001e-02\n",
            "Loss: 2.087229e-02\n",
            "Loss: 2.083396e-02\n",
            "Loss: 2.082568e-02\n",
            "Loss: 2.081798e-02\n",
            "Loss: 2.081093e-02\n",
            "Loss: 2.080283e-02\n",
            "Loss: 2.079471e-02\n",
            "Loss: 2.078152e-02\n",
            "Loss: 2.077194e-02\n",
            "Loss: 2.076159e-02\n",
            "Loss: 2.075176e-02\n",
            "Loss: 2.074546e-02\n",
            "Loss: 2.074097e-02\n",
            "Loss: 2.073631e-02\n",
            "Loss: 2.072701e-02\n",
            "Loss: 2.072558e-02\n",
            "Loss: 2.071461e-02\n",
            "Loss: 2.069646e-02\n",
            "Loss: 2.067993e-02\n",
            "Loss: 2.076156e-02\n",
            "Loss: 2.067504e-02\n",
            "Loss: 2.066437e-02\n",
            "Loss: 2.065646e-02\n",
            "Loss: 2.064661e-02\n",
            "Loss: 2.064153e-02\n",
            "Loss: 2.063634e-02\n",
            "Loss: 2.063088e-02\n",
            "Loss: 2.062715e-02\n",
            "Loss: 2.062239e-02\n",
            "Loss: 2.061579e-02\n",
            "Loss: 2.060150e-02\n",
            "Loss: 2.071316e-02\n",
            "Loss: 2.059928e-02\n",
            "Loss: 2.058915e-02\n",
            "Loss: 2.058274e-02\n",
            "Loss: 2.057240e-02\n",
            "Loss: 2.056471e-02\n",
            "Loss: 2.058701e-02\n",
            "Loss: 2.056075e-02\n",
            "Loss: 2.054910e-02\n",
            "Loss: 2.054249e-02\n",
            "Loss: 2.053583e-02\n",
            "Loss: 2.058460e-02\n",
            "Loss: 2.053425e-02\n",
            "Loss: 2.053005e-02\n",
            "Loss: 2.052320e-02\n",
            "Loss: 2.051755e-02\n",
            "Loss: 2.051236e-02\n",
            "Loss: 2.050365e-02\n",
            "Loss: 2.050325e-02\n",
            "Loss: 2.049592e-02\n",
            "Loss: 2.049134e-02\n",
            "Loss: 2.048352e-02\n",
            "Loss: 2.048058e-02\n",
            "Loss: 2.047052e-02\n",
            "Loss: 2.046625e-02\n",
            "Loss: 2.045922e-02\n",
            "Loss: 2.045045e-02\n",
            "Loss: 2.044431e-02\n",
            "Loss: 2.043656e-02\n",
            "Loss: 2.043060e-02\n",
            "Loss: 2.042423e-02\n",
            "Loss: 2.042880e-02\n",
            "Loss: 2.041833e-02\n",
            "Loss: 2.041024e-02\n",
            "Loss: 2.040444e-02\n",
            "Loss: 2.039511e-02\n",
            "Loss: 2.038692e-02\n",
            "Loss: 2.038000e-02\n",
            "Loss: 2.037029e-02\n",
            "Loss: 2.036148e-02\n",
            "Loss: 2.035437e-02\n",
            "Loss: 2.034340e-02\n",
            "Loss: 2.033354e-02\n",
            "Loss: 2.033143e-02\n",
            "Loss: 2.032320e-02\n",
            "Loss: 2.031394e-02\n",
            "Loss: 2.031722e-02\n",
            "Loss: 2.030848e-02\n",
            "Loss: 2.029845e-02\n",
            "Loss: 2.029079e-02\n",
            "Loss: 2.027905e-02\n",
            "Loss: 2.026776e-02\n",
            "Loss: 2.031776e-02\n",
            "Loss: 2.026299e-02\n",
            "Loss: 2.025357e-02\n",
            "Loss: 2.024750e-02\n",
            "Loss: 2.024039e-02\n",
            "Loss: 2.023191e-02\n",
            "Loss: 2.022551e-02\n",
            "Loss: 2.021743e-02\n",
            "Loss: 2.021265e-02\n",
            "Loss: 2.020621e-02\n",
            "Loss: 2.020007e-02\n",
            "Loss: 2.018973e-02\n",
            "Loss: 2.021175e-02\n",
            "Loss: 2.018515e-02\n",
            "Loss: 2.017635e-02\n",
            "Loss: 2.016856e-02\n",
            "Loss: 2.016113e-02\n",
            "Loss: 2.017363e-02\n",
            "Loss: 2.015932e-02\n",
            "Loss: 2.015390e-02\n",
            "Loss: 2.014847e-02\n",
            "Loss: 2.014277e-02\n",
            "Loss: 2.013556e-02\n",
            "Loss: 2.014680e-02\n",
            "Loss: 2.013241e-02\n",
            "Loss: 2.012496e-02\n",
            "Loss: 2.011823e-02\n",
            "Loss: 2.011007e-02\n",
            "Loss: 2.010843e-02\n",
            "Loss: 2.010232e-02\n",
            "Loss: 2.009953e-02\n",
            "Loss: 2.009517e-02\n",
            "Loss: 2.008872e-02\n",
            "Loss: 2.007699e-02\n",
            "Loss: 2.008039e-02\n",
            "Loss: 2.007097e-02\n",
            "Loss: 2.006374e-02\n",
            "Loss: 2.005723e-02\n",
            "Loss: 2.005088e-02\n",
            "Loss: 2.004406e-02\n",
            "Loss: 2.003516e-02\n",
            "Loss: 2.002786e-02\n",
            "Loss: 2.002133e-02\n",
            "Loss: 2.001113e-02\n",
            "Loss: 2.000124e-02\n",
            "Loss: 1.999611e-02\n",
            "Loss: 1.999049e-02\n",
            "Loss: 1.998799e-02\n",
            "Loss: 1.998489e-02\n",
            "Loss: 1.998100e-02\n",
            "Loss: 1.997701e-02\n",
            "Loss: 1.997445e-02\n",
            "Loss: 1.996822e-02\n",
            "Loss: 1.995901e-02\n",
            "Loss: 1.999151e-02\n",
            "Loss: 1.995702e-02\n",
            "Loss: 1.994891e-02\n",
            "Loss: 1.994526e-02\n",
            "Loss: 1.994212e-02\n",
            "Loss: 1.994635e-02\n",
            "Loss: 1.994058e-02\n",
            "Loss: 1.993623e-02\n",
            "Loss: 1.993026e-02\n",
            "Loss: 1.992586e-02\n",
            "Loss: 1.992217e-02\n",
            "Loss: 1.991576e-02\n",
            "Loss: 1.991156e-02\n",
            "Loss: 1.990344e-02\n",
            "Loss: 1.989738e-02\n",
            "Loss: 1.989095e-02\n",
            "Loss: 1.987940e-02\n",
            "Loss: 1.988061e-02\n",
            "Loss: 1.987132e-02\n",
            "Loss: 1.986367e-02\n",
            "Loss: 1.985792e-02\n",
            "Loss: 1.985445e-02\n",
            "Loss: 1.985036e-02\n",
            "Loss: 1.984488e-02\n",
            "Loss: 1.983715e-02\n",
            "Loss: 1.983447e-02\n",
            "Loss: 1.983895e-02\n",
            "Loss: 1.983124e-02\n",
            "Loss: 1.982693e-02\n",
            "Loss: 1.982092e-02\n",
            "Loss: 1.981003e-02\n",
            "Loss: 1.980215e-02\n",
            "Loss: 1.979388e-02\n",
            "Loss: 1.978830e-02\n",
            "Loss: 1.978411e-02\n",
            "Loss: 1.978006e-02\n",
            "Loss: 1.977272e-02\n",
            "Loss: 1.976234e-02\n",
            "Loss: 1.975054e-02\n",
            "Loss: 1.973737e-02\n",
            "Loss: 1.973042e-02\n",
            "Loss: 1.972341e-02\n",
            "Loss: 1.971569e-02\n",
            "Loss: 1.971776e-02\n",
            "Loss: 1.970953e-02\n",
            "Loss: 1.970087e-02\n",
            "Loss: 1.969583e-02\n",
            "Loss: 1.969112e-02\n",
            "Loss: 1.968319e-02\n",
            "Loss: 1.967268e-02\n",
            "Loss: 1.966339e-02\n",
            "Loss: 1.966768e-02\n",
            "Loss: 1.965810e-02\n",
            "Loss: 1.965241e-02\n",
            "Loss: 1.964766e-02\n",
            "Loss: 1.963812e-02\n",
            "Loss: 1.963264e-02\n",
            "Loss: 1.962803e-02\n",
            "Loss: 1.962802e-02\n",
            "Loss: 1.962351e-02\n",
            "Loss: 1.961731e-02\n",
            "Loss: 1.961150e-02\n",
            "Loss: 1.960500e-02\n",
            "Loss: 1.960248e-02\n",
            "Loss: 1.959850e-02\n",
            "Loss: 1.959655e-02\n",
            "Loss: 1.959296e-02\n",
            "Loss: 1.958859e-02\n",
            "Loss: 1.958277e-02\n",
            "Loss: 1.957431e-02\n",
            "Loss: 1.961480e-02\n",
            "Loss: 1.957065e-02\n",
            "Loss: 1.956442e-02\n",
            "Loss: 1.955996e-02\n",
            "Loss: 1.955597e-02\n",
            "Loss: 1.955031e-02\n",
            "Loss: 1.954100e-02\n",
            "Loss: 1.953541e-02\n",
            "Loss: 1.952839e-02\n",
            "Loss: 1.952361e-02\n",
            "Loss: 1.951837e-02\n",
            "Loss: 1.951095e-02\n",
            "Loss: 1.950333e-02\n",
            "Loss: 1.954818e-02\n",
            "Loss: 1.950100e-02\n",
            "Loss: 1.949593e-02\n",
            "Loss: 1.949071e-02\n",
            "Loss: 1.948125e-02\n",
            "Loss: 1.947211e-02\n",
            "Loss: 1.947946e-02\n",
            "Loss: 1.946866e-02\n",
            "Loss: 1.946052e-02\n",
            "Loss: 1.945602e-02\n",
            "Loss: 1.944979e-02\n",
            "Loss: 1.944374e-02\n",
            "Loss: 1.943823e-02\n",
            "Loss: 1.942516e-02\n",
            "Loss: 1.941926e-02\n",
            "Loss: 1.941123e-02\n",
            "Loss: 1.940195e-02\n",
            "Loss: 1.939160e-02\n",
            "Loss: 1.938497e-02\n",
            "Loss: 1.937485e-02\n",
            "Loss: 1.936872e-02\n",
            "Loss: 1.936027e-02\n",
            "Loss: 1.935213e-02\n",
            "Loss: 1.934497e-02\n",
            "Loss: 1.933842e-02\n",
            "Loss: 1.933517e-02\n",
            "Loss: 1.933307e-02\n",
            "Loss: 1.932739e-02\n",
            "Loss: 1.932122e-02\n",
            "Loss: 1.931703e-02\n",
            "Loss: 1.931223e-02\n",
            "Loss: 1.930901e-02\n",
            "Loss: 1.930383e-02\n",
            "Loss: 1.929926e-02\n",
            "Loss: 1.929479e-02\n",
            "Loss: 1.928624e-02\n",
            "Loss: 1.937714e-02\n",
            "Loss: 1.928509e-02\n",
            "Loss: 1.928013e-02\n",
            "Loss: 1.927445e-02\n",
            "Loss: 1.926824e-02\n",
            "Loss: 1.926359e-02\n",
            "Loss: 1.925910e-02\n",
            "Loss: 1.925225e-02\n",
            "Loss: 1.925009e-02\n",
            "Loss: 1.924610e-02\n",
            "Loss: 1.924299e-02\n",
            "Loss: 1.923969e-02\n",
            "Loss: 1.923460e-02\n",
            "Loss: 1.922865e-02\n",
            "Loss: 1.922354e-02\n",
            "Loss: 1.922091e-02\n",
            "Loss: 1.921740e-02\n",
            "Loss: 1.921396e-02\n",
            "Loss: 1.920834e-02\n",
            "Loss: 1.925861e-02\n",
            "Loss: 1.920610e-02\n",
            "Loss: 1.920140e-02\n",
            "Loss: 1.919605e-02\n",
            "Loss: 1.919137e-02\n",
            "Loss: 1.918492e-02\n",
            "Loss: 1.918634e-02\n",
            "Loss: 1.918104e-02\n",
            "Loss: 1.917664e-02\n",
            "Loss: 1.917292e-02\n",
            "Loss: 1.917089e-02\n",
            "Loss: 1.916409e-02\n",
            "Loss: 1.916444e-02\n",
            "Loss: 1.915984e-02\n",
            "Loss: 1.915443e-02\n",
            "Loss: 1.914828e-02\n",
            "Loss: 1.913777e-02\n",
            "Loss: 1.913396e-02\n",
            "Loss: 1.912341e-02\n",
            "Loss: 1.911814e-02\n",
            "Loss: 1.911205e-02\n",
            "Loss: 1.910227e-02\n",
            "Loss: 1.910265e-02\n",
            "Loss: 1.909549e-02\n",
            "Loss: 1.908693e-02\n",
            "Loss: 1.908060e-02\n",
            "Loss: 1.908447e-02\n",
            "Loss: 1.907771e-02\n",
            "Loss: 1.907255e-02\n",
            "Loss: 1.906737e-02\n",
            "Loss: 1.906145e-02\n",
            "Loss: 1.905737e-02\n",
            "Loss: 1.905196e-02\n",
            "Loss: 1.904849e-02\n",
            "Loss: 1.903765e-02\n",
            "Loss: 1.905160e-02\n",
            "Loss: 1.903371e-02\n",
            "Loss: 1.902530e-02\n",
            "Loss: 1.901521e-02\n",
            "Loss: 1.900359e-02\n",
            "Loss: 1.923642e-02\n",
            "Loss: 1.900293e-02\n",
            "Loss: 1.899847e-02\n",
            "Loss: 1.899276e-02\n",
            "Loss: 1.898338e-02\n",
            "Loss: 1.898096e-02\n",
            "Loss: 1.897365e-02\n",
            "Loss: 1.896908e-02\n",
            "Loss: 1.896418e-02\n",
            "Loss: 1.895876e-02\n",
            "Loss: 1.895423e-02\n",
            "Loss: 1.895008e-02\n",
            "Loss: 1.894432e-02\n",
            "Loss: 1.893973e-02\n",
            "Loss: 1.892954e-02\n",
            "Loss: 1.907729e-02\n",
            "Loss: 1.892729e-02\n",
            "Loss: 1.892088e-02\n",
            "Loss: 1.891671e-02\n",
            "Loss: 1.890810e-02\n",
            "Loss: 1.890719e-02\n",
            "Loss: 1.889937e-02\n",
            "Loss: 1.889659e-02\n",
            "Loss: 1.889342e-02\n",
            "Loss: 1.888769e-02\n",
            "Loss: 1.887624e-02\n",
            "Loss: 1.896457e-02\n",
            "Loss: 1.887348e-02\n",
            "Loss: 1.886683e-02\n",
            "Loss: 1.886063e-02\n",
            "Loss: 1.885413e-02\n",
            "Loss: 1.884606e-02\n",
            "Loss: 1.883266e-02\n",
            "Loss: 1.884733e-02\n",
            "Loss: 1.882690e-02\n",
            "Loss: 1.881921e-02\n",
            "Loss: 1.881528e-02\n",
            "Loss: 1.881206e-02\n",
            "Loss: 1.880671e-02\n",
            "Loss: 1.879843e-02\n",
            "Loss: 1.879026e-02\n",
            "Loss: 1.878365e-02\n",
            "Loss: 1.877931e-02\n",
            "Loss: 1.877466e-02\n",
            "Loss: 1.877686e-02\n",
            "Loss: 1.877240e-02\n",
            "Loss: 1.876901e-02\n",
            "Loss: 1.876516e-02\n",
            "Loss: 1.876093e-02\n",
            "Loss: 1.875495e-02\n",
            "Loss: 1.875045e-02\n",
            "Loss: 1.874570e-02\n",
            "Loss: 1.874300e-02\n",
            "Loss: 1.873898e-02\n",
            "Loss: 1.873445e-02\n",
            "Loss: 1.872392e-02\n",
            "Loss: 1.871760e-02\n",
            "Loss: 1.871228e-02\n",
            "Loss: 1.871414e-02\n",
            "Loss: 1.871030e-02\n",
            "Loss: 1.870814e-02\n",
            "Loss: 1.870379e-02\n",
            "Loss: 1.869776e-02\n",
            "Loss: 1.868846e-02\n",
            "Loss: 1.868570e-02\n",
            "Loss: 1.867664e-02\n",
            "Loss: 1.867310e-02\n",
            "Loss: 1.866787e-02\n",
            "Loss: 1.865528e-02\n",
            "Loss: 1.867874e-02\n",
            "Loss: 1.865027e-02\n",
            "Loss: 1.863972e-02\n",
            "Loss: 1.863187e-02\n",
            "Loss: 1.863051e-02\n",
            "Loss: 1.862239e-02\n",
            "Loss: 1.861948e-02\n",
            "Loss: 1.861385e-02\n",
            "Loss: 1.861020e-02\n",
            "Loss: 1.862187e-02\n",
            "Loss: 1.860657e-02\n",
            "Loss: 1.859826e-02\n",
            "Loss: 1.859313e-02\n",
            "Loss: 1.858583e-02\n",
            "Loss: 1.857852e-02\n",
            "Loss: 1.859760e-02\n",
            "Loss: 1.857438e-02\n",
            "Loss: 1.856828e-02\n",
            "Loss: 1.856400e-02\n",
            "Loss: 1.855564e-02\n",
            "Loss: 1.854880e-02\n",
            "Loss: 1.854326e-02\n",
            "Loss: 1.853603e-02\n",
            "Loss: 1.853503e-02\n",
            "Loss: 1.852926e-02\n",
            "Loss: 1.852590e-02\n",
            "Loss: 1.852249e-02\n",
            "Loss: 1.851890e-02\n",
            "Loss: 1.851290e-02\n",
            "Loss: 1.851263e-02\n",
            "Loss: 1.850940e-02\n",
            "Loss: 1.850622e-02\n",
            "Loss: 1.850292e-02\n",
            "Loss: 1.849842e-02\n",
            "Loss: 1.849207e-02\n",
            "Loss: 1.848636e-02\n",
            "Loss: 1.848049e-02\n",
            "Loss: 1.847586e-02\n",
            "Loss: 1.847374e-02\n",
            "Loss: 1.846765e-02\n",
            "Loss: 1.846465e-02\n",
            "Loss: 1.846123e-02\n",
            "Loss: 1.845647e-02\n",
            "Loss: 1.844889e-02\n",
            "Loss: 1.847962e-02\n",
            "Loss: 1.844632e-02\n",
            "Loss: 1.844311e-02\n",
            "Loss: 1.844093e-02\n",
            "Loss: 1.843780e-02\n",
            "Loss: 1.843481e-02\n",
            "Loss: 1.843185e-02\n",
            "Loss: 1.842783e-02\n",
            "Loss: 1.841948e-02\n",
            "Loss: 1.843278e-02\n",
            "Loss: 1.841417e-02\n",
            "Loss: 1.840958e-02\n",
            "Loss: 1.840500e-02\n",
            "Loss: 1.840176e-02\n",
            "Loss: 1.839399e-02\n",
            "Loss: 1.838542e-02\n",
            "Loss: 1.838095e-02\n",
            "Loss: 1.837341e-02\n",
            "Loss: 1.837065e-02\n",
            "Loss: 1.836848e-02\n",
            "Loss: 1.836524e-02\n",
            "Loss: 1.835992e-02\n",
            "Loss: 1.835579e-02\n",
            "Loss: 1.835067e-02\n",
            "Loss: 1.834699e-02\n",
            "Loss: 1.834455e-02\n",
            "Loss: 1.833991e-02\n",
            "Loss: 1.832761e-02\n",
            "Loss: 1.843513e-02\n",
            "Loss: 1.832546e-02\n",
            "Loss: 1.831831e-02\n",
            "Loss: 1.831379e-02\n",
            "Loss: 1.830744e-02\n",
            "Loss: 1.830004e-02\n",
            "Loss: 1.828448e-02\n",
            "Loss: 1.828242e-02\n",
            "Loss: 1.826616e-02\n",
            "Loss: 1.826327e-02\n",
            "Loss: 1.826026e-02\n",
            "Loss: 1.825671e-02\n",
            "Loss: 1.825172e-02\n",
            "Loss: 1.824715e-02\n",
            "Loss: 1.824101e-02\n",
            "Loss: 1.823231e-02\n",
            "Loss: 1.822618e-02\n",
            "Loss: 1.822134e-02\n",
            "Loss: 1.821618e-02\n",
            "Loss: 1.821260e-02\n",
            "Loss: 1.820749e-02\n",
            "Loss: 1.820425e-02\n",
            "Loss: 1.821632e-02\n",
            "Loss: 1.820154e-02\n",
            "Loss: 1.819608e-02\n",
            "Loss: 1.819197e-02\n",
            "Loss: 1.818649e-02\n",
            "Loss: 1.818288e-02\n",
            "Loss: 1.818249e-02\n",
            "Loss: 1.817980e-02\n",
            "Loss: 1.817613e-02\n",
            "Loss: 1.817356e-02\n",
            "Loss: 1.817097e-02\n",
            "Loss: 1.816630e-02\n",
            "Loss: 1.815967e-02\n",
            "Loss: 1.815656e-02\n",
            "Loss: 1.815288e-02\n",
            "Loss: 1.814767e-02\n",
            "Loss: 1.815058e-02\n",
            "Loss: 1.814449e-02\n",
            "Loss: 1.814025e-02\n",
            "Loss: 1.813560e-02\n",
            "Loss: 1.812973e-02\n",
            "Loss: 1.812177e-02\n",
            "Loss: 1.813329e-02\n",
            "Loss: 1.811914e-02\n",
            "Loss: 1.811362e-02\n",
            "Loss: 1.810979e-02\n",
            "Loss: 1.810551e-02\n",
            "Loss: 1.809985e-02\n",
            "Loss: 1.809422e-02\n",
            "Loss: 1.808767e-02\n",
            "Loss: 1.808281e-02\n",
            "Loss: 1.807901e-02\n",
            "Loss: 1.807592e-02\n",
            "Loss: 1.806623e-02\n",
            "Loss: 1.806302e-02\n",
            "Loss: 1.805841e-02\n",
            "Loss: 1.805145e-02\n",
            "Loss: 1.805141e-02\n",
            "Loss: 1.804671e-02\n",
            "Loss: 1.803857e-02\n",
            "Loss: 1.803122e-02\n",
            "Loss: 1.801618e-02\n",
            "Loss: 1.800506e-02\n",
            "Loss: 1.799166e-02\n",
            "Loss: 1.798424e-02\n",
            "Loss: 1.797804e-02\n",
            "Loss: 1.797388e-02\n",
            "Loss: 1.796931e-02\n",
            "Loss: 1.796088e-02\n",
            "Loss: 1.795319e-02\n",
            "Loss: 1.794678e-02\n",
            "Loss: 1.794170e-02\n",
            "Loss: 1.793701e-02\n",
            "Loss: 1.793137e-02\n",
            "Loss: 1.792599e-02\n",
            "Loss: 1.792001e-02\n",
            "Loss: 1.791152e-02\n",
            "Loss: 1.790880e-02\n",
            "Loss: 1.789914e-02\n",
            "Loss: 1.789591e-02\n",
            "Loss: 1.789063e-02\n",
            "Loss: 1.788911e-02\n",
            "Loss: 1.788272e-02\n",
            "Loss: 1.788029e-02\n",
            "Loss: 1.787608e-02\n",
            "Loss: 1.787025e-02\n",
            "Loss: 1.786410e-02\n",
            "Loss: 1.785958e-02\n",
            "Loss: 1.785658e-02\n",
            "Loss: 1.785343e-02\n",
            "Loss: 1.785040e-02\n",
            "Loss: 1.784345e-02\n",
            "Loss: 1.783635e-02\n",
            "Loss: 1.782806e-02\n",
            "Loss: 1.782532e-02\n",
            "Loss: 1.781798e-02\n",
            "Loss: 1.781547e-02\n",
            "Loss: 1.780788e-02\n",
            "Loss: 1.780289e-02\n",
            "Loss: 1.779278e-02\n",
            "Loss: 1.778756e-02\n",
            "Loss: 1.778128e-02\n",
            "Loss: 1.777974e-02\n",
            "Loss: 1.777420e-02\n",
            "Loss: 1.777044e-02\n",
            "Loss: 1.776597e-02\n",
            "Loss: 1.776101e-02\n",
            "Loss: 1.775809e-02\n",
            "Loss: 1.775029e-02\n",
            "Loss: 1.774808e-02\n",
            "Loss: 1.774324e-02\n",
            "Loss: 1.774091e-02\n",
            "Loss: 1.772956e-02\n",
            "Loss: 1.772408e-02\n",
            "Loss: 1.771491e-02\n",
            "Loss: 1.770149e-02\n",
            "Loss: 1.769776e-02\n",
            "Loss: 1.768722e-02\n",
            "Loss: 1.768563e-02\n",
            "Loss: 1.768224e-02\n",
            "Loss: 1.767794e-02\n",
            "Loss: 1.767336e-02\n",
            "Loss: 1.766645e-02\n",
            "Loss: 1.766269e-02\n",
            "Loss: 1.765476e-02\n",
            "Loss: 1.766066e-02\n",
            "Loss: 1.765204e-02\n",
            "Loss: 1.764873e-02\n",
            "Loss: 1.764423e-02\n",
            "Loss: 1.763830e-02\n",
            "Loss: 1.763526e-02\n",
            "Loss: 1.763024e-02\n",
            "Loss: 1.762735e-02\n",
            "Loss: 1.762139e-02\n",
            "Loss: 1.761903e-02\n",
            "Loss: 1.761525e-02\n",
            "Loss: 1.760976e-02\n",
            "Loss: 1.760552e-02\n",
            "Loss: 1.759882e-02\n",
            "Loss: 1.758920e-02\n",
            "Loss: 1.758302e-02\n",
            "Loss: 1.757755e-02\n",
            "Loss: 1.757514e-02\n",
            "Loss: 1.757255e-02\n",
            "Loss: 1.756413e-02\n",
            "Loss: 1.756270e-02\n",
            "Loss: 1.755341e-02\n",
            "Loss: 1.755074e-02\n",
            "Loss: 1.754490e-02\n",
            "Loss: 1.753753e-02\n",
            "Loss: 1.753073e-02\n",
            "Loss: 1.752517e-02\n",
            "Loss: 1.752412e-02\n",
            "Loss: 1.751784e-02\n",
            "Loss: 1.751543e-02\n",
            "Loss: 1.751066e-02\n",
            "Loss: 1.750687e-02\n",
            "Loss: 1.754208e-02\n",
            "Loss: 1.750511e-02\n",
            "Loss: 1.749941e-02\n",
            "Loss: 1.749436e-02\n",
            "Loss: 1.748879e-02\n",
            "Loss: 1.748701e-02\n",
            "Loss: 1.748067e-02\n",
            "Loss: 1.747722e-02\n",
            "Loss: 1.747520e-02\n",
            "Loss: 1.747202e-02\n",
            "Loss: 1.746260e-02\n",
            "Loss: 1.745675e-02\n",
            "Loss: 1.745099e-02\n",
            "Loss: 1.744851e-02\n",
            "Loss: 1.744469e-02\n",
            "Loss: 1.744054e-02\n",
            "Loss: 1.743465e-02\n",
            "Loss: 1.742854e-02\n",
            "Loss: 1.742515e-02\n",
            "Loss: 1.741733e-02\n",
            "Loss: 1.742927e-02\n",
            "Loss: 1.741367e-02\n",
            "Loss: 1.741037e-02\n",
            "Loss: 1.740815e-02\n",
            "Loss: 1.740589e-02\n",
            "Loss: 1.740307e-02\n",
            "Loss: 1.739852e-02\n",
            "Loss: 1.739658e-02\n",
            "Loss: 1.739142e-02\n",
            "Loss: 1.739976e-02\n",
            "Loss: 1.738865e-02\n",
            "Loss: 1.738666e-02\n",
            "Loss: 1.738308e-02\n",
            "Loss: 1.738145e-02\n",
            "Loss: 1.737915e-02\n",
            "Loss: 1.737360e-02\n",
            "Loss: 1.737113e-02\n",
            "Loss: 1.736791e-02\n",
            "Loss: 1.736407e-02\n",
            "Loss: 1.735922e-02\n",
            "Loss: 1.735478e-02\n",
            "Loss: 1.735210e-02\n",
            "Loss: 1.734986e-02\n",
            "Loss: 1.734595e-02\n",
            "Loss: 1.733965e-02\n",
            "Loss: 1.733325e-02\n",
            "Loss: 1.732637e-02\n",
            "Loss: 1.732017e-02\n",
            "Loss: 1.731727e-02\n",
            "Loss: 1.731260e-02\n",
            "Loss: 1.730794e-02\n",
            "Loss: 1.731168e-02\n",
            "Loss: 1.730366e-02\n",
            "Loss: 1.730038e-02\n",
            "Loss: 1.729434e-02\n",
            "Loss: 1.729066e-02\n",
            "Loss: 1.728658e-02\n",
            "Loss: 1.728912e-02\n",
            "Loss: 1.728440e-02\n",
            "Loss: 1.728120e-02\n",
            "Loss: 1.727701e-02\n",
            "Loss: 1.727253e-02\n",
            "Loss: 1.726798e-02\n",
            "Loss: 1.728553e-02\n",
            "Loss: 1.726599e-02\n",
            "Loss: 1.726313e-02\n",
            "Loss: 1.726020e-02\n",
            "Loss: 1.725882e-02\n",
            "Loss: 1.725504e-02\n",
            "Loss: 1.724885e-02\n",
            "Loss: 1.728223e-02\n",
            "Loss: 1.724633e-02\n",
            "Loss: 1.724023e-02\n",
            "Loss: 1.723589e-02\n",
            "Loss: 1.723105e-02\n",
            "Loss: 1.722509e-02\n",
            "Loss: 1.721939e-02\n",
            "Loss: 1.721301e-02\n",
            "Loss: 1.720696e-02\n",
            "Loss: 1.720303e-02\n",
            "Loss: 1.719787e-02\n",
            "Loss: 1.719445e-02\n",
            "Loss: 1.719176e-02\n",
            "Loss: 1.718750e-02\n",
            "Loss: 1.718046e-02\n",
            "Loss: 1.716979e-02\n",
            "Loss: 1.718942e-02\n",
            "Loss: 1.716711e-02\n",
            "Loss: 1.715969e-02\n",
            "Loss: 1.715580e-02\n",
            "Loss: 1.715069e-02\n",
            "Loss: 1.714580e-02\n",
            "Loss: 1.717853e-02\n",
            "Loss: 1.714347e-02\n",
            "Loss: 1.713768e-02\n",
            "Loss: 1.713409e-02\n",
            "Loss: 1.713068e-02\n",
            "Loss: 1.712737e-02\n",
            "Loss: 1.712679e-02\n",
            "Loss: 1.712252e-02\n",
            "Loss: 1.712089e-02\n",
            "Loss: 1.711880e-02\n",
            "Loss: 1.711443e-02\n",
            "Loss: 1.710668e-02\n",
            "Loss: 1.710984e-02\n",
            "Loss: 1.710189e-02\n",
            "Loss: 1.709507e-02\n",
            "Loss: 1.709119e-02\n",
            "Loss: 1.708698e-02\n",
            "Loss: 1.708230e-02\n",
            "Loss: 1.708210e-02\n",
            "Loss: 1.707938e-02\n",
            "Loss: 1.707539e-02\n",
            "Loss: 1.707204e-02\n",
            "Loss: 1.706738e-02\n",
            "Loss: 1.706397e-02\n",
            "Loss: 1.706017e-02\n",
            "Loss: 1.705811e-02\n",
            "Loss: 1.705554e-02\n",
            "Loss: 1.705308e-02\n",
            "Loss: 1.705098e-02\n",
            "Loss: 1.705885e-02\n",
            "Loss: 1.704951e-02\n",
            "Loss: 1.704573e-02\n",
            "Loss: 1.704160e-02\n",
            "Loss: 1.703750e-02\n",
            "Loss: 1.703398e-02\n",
            "Loss: 1.702676e-02\n",
            "Loss: 1.701798e-02\n",
            "Loss: 1.702797e-02\n",
            "Loss: 1.701384e-02\n",
            "Loss: 1.700910e-02\n",
            "Loss: 1.700418e-02\n",
            "Loss: 1.699846e-02\n",
            "Loss: 1.698976e-02\n",
            "Loss: 1.698750e-02\n",
            "Loss: 1.697871e-02\n",
            "Loss: 1.697417e-02\n",
            "Loss: 1.696793e-02\n",
            "Loss: 1.697526e-02\n",
            "Loss: 1.696510e-02\n",
            "Loss: 1.696066e-02\n",
            "Loss: 1.695721e-02\n",
            "Loss: 1.695476e-02\n",
            "Loss: 1.695067e-02\n",
            "Loss: 1.695119e-02\n",
            "Loss: 1.694789e-02\n",
            "Loss: 1.694304e-02\n",
            "Loss: 1.693866e-02\n",
            "Loss: 1.693310e-02\n",
            "Loss: 1.693139e-02\n",
            "Loss: 1.692446e-02\n",
            "Loss: 1.692122e-02\n",
            "Loss: 1.691782e-02\n",
            "Loss: 1.691335e-02\n",
            "Loss: 1.690903e-02\n",
            "Loss: 1.690339e-02\n",
            "Loss: 1.690449e-02\n",
            "Loss: 1.690175e-02\n",
            "Loss: 1.690006e-02\n",
            "Loss: 1.689537e-02\n",
            "Loss: 1.689140e-02\n",
            "Loss: 1.688380e-02\n",
            "Loss: 1.687889e-02\n",
            "Loss: 1.687290e-02\n",
            "Loss: 1.686830e-02\n",
            "Loss: 1.686439e-02\n",
            "Loss: 1.686007e-02\n",
            "Loss: 1.685623e-02\n",
            "Loss: 1.685178e-02\n",
            "Loss: 1.684920e-02\n",
            "Loss: 1.684567e-02\n",
            "Loss: 1.683854e-02\n",
            "Loss: 1.683121e-02\n",
            "Loss: 1.683444e-02\n",
            "Loss: 1.682638e-02\n",
            "Loss: 1.682253e-02\n",
            "Loss: 1.681950e-02\n",
            "Loss: 1.681693e-02\n",
            "Loss: 1.681511e-02\n",
            "Loss: 1.681194e-02\n",
            "Loss: 1.681044e-02\n",
            "Loss: 1.680800e-02\n",
            "Loss: 1.680033e-02\n",
            "Loss: 1.680025e-02\n",
            "Loss: 1.679656e-02\n",
            "Loss: 1.679010e-02\n",
            "Loss: 1.678435e-02\n",
            "Loss: 1.677986e-02\n",
            "Loss: 1.677339e-02\n",
            "Loss: 1.676575e-02\n",
            "Loss: 1.675726e-02\n",
            "Loss: 1.675252e-02\n",
            "Loss: 1.674777e-02\n",
            "Loss: 1.674544e-02\n",
            "Loss: 1.673819e-02\n",
            "Loss: 1.673519e-02\n",
            "Loss: 1.673869e-02\n",
            "Loss: 1.673267e-02\n",
            "Loss: 1.673046e-02\n",
            "Loss: 1.672752e-02\n",
            "Loss: 1.672419e-02\n",
            "Loss: 1.672089e-02\n",
            "Loss: 1.671732e-02\n",
            "Loss: 1.671285e-02\n",
            "Loss: 1.670759e-02\n",
            "Loss: 1.670394e-02\n",
            "Loss: 1.669651e-02\n",
            "Loss: 1.669300e-02\n",
            "Loss: 1.668836e-02\n",
            "Loss: 1.668651e-02\n",
            "Loss: 1.668482e-02\n",
            "Loss: 1.668254e-02\n",
            "Loss: 1.668016e-02\n",
            "Loss: 1.667881e-02\n",
            "Loss: 1.667498e-02\n",
            "Loss: 1.667287e-02\n",
            "Loss: 1.667106e-02\n",
            "Loss: 1.666923e-02\n",
            "Loss: 1.666505e-02\n",
            "Loss: 1.666032e-02\n",
            "Loss: 1.665671e-02\n",
            "Loss: 1.665379e-02\n",
            "Loss: 1.665094e-02\n",
            "Loss: 1.664708e-02\n",
            "Loss: 1.664499e-02\n",
            "Loss: 1.664315e-02\n",
            "Loss: 1.663936e-02\n",
            "Loss: 1.663408e-02\n",
            "Loss: 1.663112e-02\n",
            "Loss: 1.662748e-02\n",
            "Loss: 1.662469e-02\n",
            "Loss: 1.662176e-02\n",
            "Loss: 1.661901e-02\n",
            "Loss: 1.661732e-02\n",
            "Loss: 1.661338e-02\n",
            "Loss: 1.661081e-02\n",
            "Loss: 1.660550e-02\n",
            "Loss: 1.660125e-02\n",
            "Loss: 1.659770e-02\n",
            "Loss: 1.659393e-02\n",
            "Loss: 1.659147e-02\n",
            "Loss: 1.658561e-02\n",
            "Loss: 1.658270e-02\n",
            "Loss: 1.657749e-02\n",
            "Loss: 1.657470e-02\n",
            "Loss: 1.657133e-02\n",
            "Loss: 1.656678e-02\n",
            "Loss: 1.656999e-02\n",
            "Loss: 1.656333e-02\n",
            "Loss: 1.655948e-02\n",
            "Loss: 1.655516e-02\n",
            "Loss: 1.655033e-02\n",
            "Loss: 1.655293e-02\n",
            "Loss: 1.654808e-02\n",
            "Loss: 1.654405e-02\n",
            "Loss: 1.654246e-02\n",
            "Loss: 1.653948e-02\n",
            "Loss: 1.654115e-02\n",
            "Loss: 1.653759e-02\n",
            "Loss: 1.653519e-02\n",
            "Loss: 1.652715e-02\n",
            "Loss: 1.652198e-02\n",
            "Loss: 1.652174e-02\n",
            "Loss: 1.651870e-02\n",
            "Loss: 1.651387e-02\n",
            "Loss: 1.651145e-02\n",
            "Loss: 1.650761e-02\n",
            "Loss: 1.650176e-02\n",
            "Loss: 1.649942e-02\n",
            "Loss: 1.649688e-02\n",
            "Loss: 1.650133e-02\n",
            "Loss: 1.649585e-02\n",
            "Loss: 1.649426e-02\n",
            "Loss: 1.648799e-02\n",
            "Loss: 1.648206e-02\n",
            "Loss: 1.647351e-02\n",
            "Loss: 1.646526e-02\n",
            "Loss: 1.646925e-02\n",
            "Loss: 1.646098e-02\n",
            "Loss: 1.645576e-02\n",
            "Loss: 1.645117e-02\n",
            "Loss: 1.644874e-02\n",
            "Loss: 1.644599e-02\n",
            "Loss: 1.644368e-02\n",
            "Loss: 1.644066e-02\n",
            "Loss: 1.643789e-02\n",
            "Loss: 1.643380e-02\n",
            "Loss: 1.642655e-02\n",
            "Loss: 1.642709e-02\n",
            "Loss: 1.642108e-02\n",
            "Loss: 1.641398e-02\n",
            "Loss: 1.641559e-02\n",
            "Loss: 1.641206e-02\n",
            "Loss: 1.640902e-02\n",
            "Loss: 1.640691e-02\n",
            "Loss: 1.640365e-02\n",
            "Loss: 1.639947e-02\n",
            "Loss: 1.639422e-02\n",
            "Loss: 1.639058e-02\n",
            "Loss: 1.638541e-02\n",
            "Loss: 1.637953e-02\n",
            "Loss: 1.637511e-02\n",
            "Loss: 1.636867e-02\n",
            "Loss: 1.636360e-02\n",
            "Loss: 1.635696e-02\n",
            "Loss: 1.635105e-02\n",
            "Loss: 1.634237e-02\n",
            "Loss: 1.633817e-02\n",
            "Loss: 1.633280e-02\n",
            "Loss: 1.632818e-02\n",
            "Loss: 1.632169e-02\n",
            "Loss: 1.631804e-02\n",
            "Loss: 1.631516e-02\n",
            "Loss: 1.631166e-02\n",
            "Loss: 1.630801e-02\n",
            "Loss: 1.630299e-02\n",
            "Loss: 1.629872e-02\n",
            "Loss: 1.629842e-02\n",
            "Loss: 1.629464e-02\n",
            "Loss: 1.628887e-02\n",
            "Loss: 1.628636e-02\n",
            "Loss: 1.628300e-02\n",
            "Loss: 1.627934e-02\n",
            "Loss: 1.627174e-02\n",
            "Loss: 1.626120e-02\n",
            "Loss: 1.625355e-02\n",
            "Loss: 1.624676e-02\n",
            "Loss: 1.624309e-02\n",
            "Loss: 1.623783e-02\n",
            "Loss: 1.623359e-02\n",
            "Loss: 1.622759e-02\n",
            "Loss: 1.622409e-02\n",
            "Loss: 1.621763e-02\n",
            "Loss: 1.621228e-02\n",
            "Loss: 1.620754e-02\n",
            "Loss: 1.620265e-02\n",
            "Loss: 1.621754e-02\n",
            "Loss: 1.619975e-02\n",
            "Loss: 1.619267e-02\n",
            "Loss: 1.618836e-02\n",
            "Loss: 1.618055e-02\n",
            "Loss: 1.617252e-02\n",
            "Loss: 1.616643e-02\n",
            "Loss: 1.615351e-02\n",
            "Loss: 1.614875e-02\n",
            "Loss: 1.614412e-02\n",
            "Loss: 1.616399e-02\n",
            "Loss: 1.614312e-02\n",
            "Loss: 1.613965e-02\n",
            "Loss: 1.613354e-02\n",
            "Loss: 1.612720e-02\n",
            "Loss: 1.612037e-02\n",
            "Loss: 1.611913e-02\n",
            "Loss: 1.611223e-02\n",
            "Loss: 1.611014e-02\n",
            "Loss: 1.610465e-02\n",
            "Loss: 1.609597e-02\n",
            "Loss: 1.609178e-02\n",
            "Loss: 1.607747e-02\n",
            "Loss: 1.607159e-02\n",
            "Loss: 1.606586e-02\n",
            "Loss: 1.606235e-02\n",
            "Loss: 1.605611e-02\n",
            "Loss: 1.605130e-02\n",
            "Loss: 1.604724e-02\n",
            "Loss: 1.604091e-02\n",
            "Loss: 1.603053e-02\n",
            "Loss: 1.602878e-02\n",
            "Loss: 1.601974e-02\n",
            "Loss: 1.601759e-02\n",
            "Loss: 1.601216e-02\n",
            "Loss: 1.600424e-02\n",
            "Loss: 1.599791e-02\n",
            "Loss: 1.599198e-02\n",
            "Loss: 1.598971e-02\n",
            "Loss: 1.598674e-02\n",
            "Loss: 1.597941e-02\n",
            "Loss: 1.596954e-02\n",
            "Loss: 1.596162e-02\n",
            "Loss: 1.595082e-02\n",
            "Loss: 1.594671e-02\n",
            "Loss: 1.594515e-02\n",
            "Loss: 1.594344e-02\n",
            "Loss: 1.594099e-02\n",
            "Loss: 1.593816e-02\n",
            "Loss: 1.593514e-02\n",
            "Loss: 1.593173e-02\n",
            "Loss: 1.592756e-02\n",
            "Loss: 1.592463e-02\n",
            "Loss: 1.592035e-02\n",
            "Loss: 1.591617e-02\n",
            "Loss: 1.591172e-02\n",
            "Loss: 1.590890e-02\n",
            "Loss: 1.590628e-02\n",
            "Loss: 1.590344e-02\n",
            "Loss: 1.589421e-02\n",
            "Loss: 1.588378e-02\n",
            "Loss: 1.587506e-02\n",
            "Loss: 1.588522e-02\n",
            "Loss: 1.587286e-02\n",
            "Loss: 1.586801e-02\n",
            "Loss: 1.586426e-02\n",
            "Loss: 1.585979e-02\n",
            "Loss: 1.585422e-02\n",
            "Loss: 1.584537e-02\n",
            "Loss: 1.583843e-02\n",
            "Loss: 1.583337e-02\n",
            "Loss: 1.582975e-02\n",
            "Loss: 1.582483e-02\n",
            "Loss: 1.581445e-02\n",
            "Loss: 1.580820e-02\n",
            "Loss: 1.580121e-02\n",
            "Loss: 1.579771e-02\n",
            "Loss: 1.579302e-02\n",
            "Loss: 1.578618e-02\n",
            "Loss: 1.578365e-02\n",
            "Loss: 1.577652e-02\n",
            "Loss: 1.577409e-02\n",
            "Loss: 1.577080e-02\n",
            "Loss: 1.576672e-02\n",
            "Loss: 1.576260e-02\n",
            "Loss: 1.575868e-02\n",
            "Loss: 1.575575e-02\n",
            "Loss: 1.574819e-02\n",
            "Loss: 1.574480e-02\n",
            "Loss: 1.574235e-02\n",
            "Loss: 1.574096e-02\n",
            "Loss: 1.573836e-02\n",
            "Loss: 1.573234e-02\n",
            "Loss: 1.572497e-02\n",
            "Loss: 1.572002e-02\n",
            "Loss: 1.571596e-02\n",
            "Loss: 1.571295e-02\n",
            "Loss: 1.570560e-02\n",
            "Loss: 1.570287e-02\n",
            "Loss: 1.570030e-02\n",
            "Loss: 1.569885e-02\n",
            "Loss: 1.569478e-02\n",
            "Loss: 1.569031e-02\n",
            "Loss: 1.568571e-02\n",
            "Loss: 1.568227e-02\n",
            "Loss: 1.567913e-02\n",
            "Loss: 1.567309e-02\n",
            "Loss: 1.567300e-02\n",
            "Loss: 1.567100e-02\n",
            "Loss: 1.566770e-02\n",
            "Loss: 1.566515e-02\n",
            "Loss: 1.566294e-02\n",
            "Loss: 1.565653e-02\n",
            "Loss: 1.565254e-02\n",
            "Loss: 1.564639e-02\n",
            "Loss: 1.564207e-02\n",
            "Loss: 1.564036e-02\n",
            "Loss: 1.563588e-02\n",
            "Loss: 1.563346e-02\n",
            "Loss: 1.563133e-02\n",
            "Loss: 1.562707e-02\n",
            "Loss: 1.562040e-02\n",
            "Loss: 1.562383e-02\n",
            "Loss: 1.561494e-02\n",
            "Loss: 1.560939e-02\n",
            "Loss: 1.560056e-02\n",
            "Loss: 1.559880e-02\n",
            "Loss: 1.559296e-02\n",
            "Loss: 1.558879e-02\n",
            "Loss: 1.558570e-02\n",
            "Loss: 1.557843e-02\n",
            "Loss: 1.558001e-02\n",
            "Loss: 1.557357e-02\n",
            "Loss: 1.556506e-02\n",
            "Loss: 1.556058e-02\n",
            "Loss: 1.555705e-02\n",
            "Loss: 1.555346e-02\n",
            "Loss: 1.554893e-02\n",
            "Loss: 1.554581e-02\n",
            "Loss: 1.554337e-02\n",
            "Loss: 1.553923e-02\n",
            "Loss: 1.553719e-02\n",
            "Loss: 1.553414e-02\n",
            "Loss: 1.553357e-02\n",
            "Loss: 1.553022e-02\n",
            "Loss: 1.552822e-02\n",
            "Loss: 1.552555e-02\n",
            "Loss: 1.552230e-02\n",
            "Loss: 1.552292e-02\n",
            "Loss: 1.551955e-02\n",
            "Loss: 1.551308e-02\n",
            "Loss: 1.550933e-02\n",
            "Loss: 1.550486e-02\n",
            "Loss: 1.550072e-02\n",
            "Loss: 1.549560e-02\n",
            "Loss: 1.549425e-02\n",
            "Loss: 1.548602e-02\n",
            "Loss: 1.548483e-02\n",
            "Loss: 1.548295e-02\n",
            "Loss: 1.548005e-02\n",
            "Loss: 1.547486e-02\n",
            "Loss: 1.547678e-02\n",
            "Loss: 1.547041e-02\n",
            "Loss: 1.546630e-02\n",
            "Loss: 1.546276e-02\n",
            "Loss: 1.545998e-02\n",
            "Loss: 1.545602e-02\n",
            "Loss: 1.545258e-02\n",
            "Loss: 1.545070e-02\n",
            "Loss: 1.544620e-02\n",
            "Loss: 1.543867e-02\n",
            "Loss: 1.543284e-02\n",
            "Loss: 1.542765e-02\n",
            "Loss: 1.542506e-02\n",
            "Loss: 1.542207e-02\n",
            "Loss: 1.541532e-02\n",
            "Loss: 1.540989e-02\n",
            "Loss: 1.540564e-02\n",
            "Loss: 1.540071e-02\n",
            "Loss: 1.539723e-02\n",
            "Loss: 1.539240e-02\n",
            "Loss: 1.538852e-02\n",
            "Loss: 1.538191e-02\n",
            "Loss: 1.537769e-02\n",
            "Loss: 1.537255e-02\n",
            "Loss: 1.536617e-02\n",
            "Loss: 1.536106e-02\n",
            "Loss: 1.535714e-02\n",
            "Loss: 1.535430e-02\n",
            "Loss: 1.534853e-02\n",
            "Loss: 1.534669e-02\n",
            "Loss: 1.533849e-02\n",
            "Loss: 1.533574e-02\n",
            "Loss: 1.532927e-02\n",
            "Loss: 1.532879e-02\n",
            "Loss: 1.532623e-02\n",
            "Loss: 1.532248e-02\n",
            "Loss: 1.531941e-02\n",
            "Loss: 1.531462e-02\n",
            "Loss: 1.532673e-02\n",
            "Loss: 1.531202e-02\n",
            "Loss: 1.530803e-02\n",
            "Loss: 1.530603e-02\n",
            "Loss: 1.530217e-02\n",
            "Loss: 1.529711e-02\n",
            "Loss: 1.529433e-02\n",
            "Loss: 1.528531e-02\n",
            "Loss: 1.528147e-02\n",
            "Loss: 1.527831e-02\n",
            "Loss: 1.527524e-02\n",
            "Loss: 1.527019e-02\n",
            "Loss: 1.527105e-02\n",
            "Loss: 1.526722e-02\n",
            "Loss: 1.526485e-02\n",
            "Loss: 1.526226e-02\n",
            "Loss: 1.526025e-02\n",
            "Loss: 1.525247e-02\n",
            "Loss: 1.525327e-02\n",
            "Loss: 1.524887e-02\n",
            "Loss: 1.524211e-02\n",
            "Loss: 1.523699e-02\n",
            "Loss: 1.523267e-02\n",
            "Loss: 1.522650e-02\n",
            "Loss: 1.522369e-02\n",
            "Loss: 1.522043e-02\n",
            "Loss: 1.521711e-02\n",
            "Loss: 1.520834e-02\n",
            "Loss: 1.537188e-02\n",
            "Loss: 1.520742e-02\n",
            "Loss: 1.520312e-02\n",
            "Loss: 1.519967e-02\n",
            "Loss: 1.519581e-02\n",
            "Loss: 1.519165e-02\n",
            "Loss: 1.518759e-02\n",
            "Loss: 1.518477e-02\n",
            "Loss: 1.518233e-02\n",
            "Loss: 1.517760e-02\n",
            "Loss: 1.517088e-02\n",
            "Loss: 1.516853e-02\n",
            "Loss: 1.516290e-02\n",
            "Loss: 1.516063e-02\n",
            "Loss: 1.515605e-02\n",
            "Loss: 1.515107e-02\n",
            "Loss: 1.514760e-02\n",
            "Loss: 1.514387e-02\n",
            "Loss: 1.514152e-02\n",
            "Loss: 1.513924e-02\n",
            "Loss: 1.513394e-02\n",
            "Loss: 1.513203e-02\n",
            "Loss: 1.512558e-02\n",
            "Loss: 1.512370e-02\n",
            "Loss: 1.512109e-02\n",
            "Loss: 1.511837e-02\n",
            "Loss: 1.511644e-02\n",
            "Loss: 1.511342e-02\n",
            "Loss: 1.511170e-02\n",
            "Loss: 1.510931e-02\n",
            "Loss: 1.510727e-02\n",
            "Loss: 1.510460e-02\n",
            "Loss: 1.509952e-02\n",
            "Loss: 1.509468e-02\n",
            "Loss: 1.509131e-02\n",
            "Loss: 1.508772e-02\n",
            "Loss: 1.508619e-02\n",
            "Loss: 1.508355e-02\n",
            "Loss: 1.507911e-02\n",
            "Loss: 1.509581e-02\n",
            "Loss: 1.507796e-02\n",
            "Loss: 1.507435e-02\n",
            "Loss: 1.507104e-02\n",
            "Loss: 1.506647e-02\n",
            "Loss: 1.506247e-02\n",
            "Loss: 1.509664e-02\n",
            "Loss: 1.506137e-02\n",
            "Loss: 1.505636e-02\n",
            "Loss: 1.505008e-02\n",
            "Loss: 1.504099e-02\n",
            "Loss: 1.504768e-02\n",
            "Loss: 1.503882e-02\n",
            "Loss: 1.503536e-02\n",
            "Loss: 1.503160e-02\n",
            "Loss: 1.502520e-02\n",
            "Loss: 1.501833e-02\n",
            "Loss: 1.503687e-02\n",
            "Loss: 1.501622e-02\n",
            "Loss: 1.501151e-02\n",
            "Loss: 1.500717e-02\n",
            "Loss: 1.500119e-02\n",
            "Loss: 1.499778e-02\n",
            "Loss: 1.499144e-02\n",
            "Loss: 1.498918e-02\n",
            "Loss: 1.498603e-02\n",
            "Loss: 1.498204e-02\n",
            "Loss: 1.497504e-02\n",
            "Loss: 1.496934e-02\n",
            "Loss: 1.496450e-02\n",
            "Loss: 1.496057e-02\n",
            "Loss: 1.495717e-02\n",
            "Loss: 1.495259e-02\n",
            "Loss: 1.494881e-02\n",
            "Loss: 1.494447e-02\n",
            "Loss: 1.494192e-02\n",
            "Loss: 1.493676e-02\n",
            "Loss: 1.493243e-02\n",
            "Loss: 1.492763e-02\n",
            "Loss: 1.492285e-02\n",
            "Loss: 1.491763e-02\n",
            "Loss: 1.491582e-02\n",
            "Loss: 1.491366e-02\n",
            "Loss: 1.491143e-02\n",
            "Loss: 1.490914e-02\n",
            "Loss: 1.490619e-02\n",
            "Loss: 1.490642e-02\n",
            "Loss: 1.490427e-02\n",
            "Loss: 1.490251e-02\n",
            "Loss: 1.489873e-02\n",
            "Loss: 1.489601e-02\n",
            "Loss: 1.489178e-02\n",
            "Loss: 1.488595e-02\n",
            "Loss: 1.488741e-02\n",
            "Loss: 1.488335e-02\n",
            "Loss: 1.487890e-02\n",
            "Loss: 1.487785e-02\n",
            "Loss: 1.487223e-02\n",
            "Loss: 1.490134e-02\n",
            "Loss: 1.487076e-02\n",
            "Loss: 1.486699e-02\n",
            "Loss: 1.486385e-02\n",
            "Loss: 1.486024e-02\n",
            "Loss: 1.485910e-02\n",
            "Loss: 1.485513e-02\n",
            "Loss: 1.485331e-02\n",
            "Loss: 1.485169e-02\n",
            "Loss: 1.484961e-02\n",
            "Loss: 1.484723e-02\n",
            "Loss: 1.484324e-02\n",
            "Loss: 1.484132e-02\n",
            "Loss: 1.483870e-02\n",
            "Loss: 1.483583e-02\n",
            "Loss: 1.483321e-02\n",
            "Loss: 1.482925e-02\n",
            "Loss: 1.482802e-02\n",
            "Loss: 1.482437e-02\n",
            "Loss: 1.483520e-02\n",
            "Loss: 1.482361e-02\n",
            "Loss: 1.482194e-02\n",
            "Loss: 1.481944e-02\n",
            "Loss: 1.481543e-02\n",
            "Loss: 1.481245e-02\n",
            "Loss: 1.480479e-02\n",
            "Loss: 1.480315e-02\n",
            "Loss: 1.479401e-02\n",
            "Loss: 1.479146e-02\n",
            "Loss: 1.478959e-02\n",
            "Loss: 1.478687e-02\n",
            "Loss: 1.478387e-02\n",
            "Loss: 1.478397e-02\n",
            "Loss: 1.478125e-02\n",
            "Loss: 1.477823e-02\n",
            "Loss: 1.477450e-02\n",
            "Loss: 1.477048e-02\n",
            "Loss: 1.476571e-02\n",
            "Loss: 1.476705e-02\n",
            "Loss: 1.476327e-02\n",
            "Loss: 1.475927e-02\n",
            "Loss: 1.475629e-02\n",
            "Loss: 1.475271e-02\n",
            "Loss: 1.474875e-02\n",
            "Loss: 1.474516e-02\n",
            "Loss: 1.474172e-02\n",
            "Loss: 1.474021e-02\n",
            "Loss: 1.473829e-02\n",
            "Loss: 1.473614e-02\n",
            "Loss: 1.473445e-02\n",
            "Loss: 1.472887e-02\n",
            "Loss: 1.472349e-02\n",
            "Loss: 1.474027e-02\n",
            "Loss: 1.472203e-02\n",
            "Loss: 1.471987e-02\n",
            "Loss: 1.471759e-02\n",
            "Loss: 1.471435e-02\n",
            "Loss: 1.471989e-02\n",
            "Loss: 1.471316e-02\n",
            "Loss: 1.471032e-02\n",
            "Loss: 1.470824e-02\n",
            "Loss: 1.470503e-02\n",
            "Loss: 1.470145e-02\n",
            "Loss: 1.469652e-02\n",
            "Loss: 1.469284e-02\n",
            "Loss: 1.468999e-02\n",
            "Loss: 1.468773e-02\n",
            "Loss: 1.468490e-02\n",
            "Loss: 1.468105e-02\n",
            "Loss: 1.467727e-02\n",
            "Loss: 1.467374e-02\n",
            "Loss: 1.467063e-02\n",
            "Loss: 1.466541e-02\n",
            "Loss: 1.465793e-02\n",
            "Loss: 1.465443e-02\n",
            "Loss: 1.464856e-02\n",
            "Loss: 1.464710e-02\n",
            "Loss: 1.464155e-02\n",
            "Loss: 1.463820e-02\n",
            "Loss: 1.463557e-02\n",
            "Loss: 1.463061e-02\n",
            "Loss: 1.462290e-02\n",
            "Loss: 1.461664e-02\n",
            "Loss: 1.461001e-02\n",
            "Loss: 1.460503e-02\n",
            "Loss: 1.460459e-02\n",
            "Loss: 1.459968e-02\n",
            "Loss: 1.459755e-02\n",
            "Loss: 1.459515e-02\n",
            "Loss: 1.459242e-02\n",
            "Loss: 1.459533e-02\n",
            "Loss: 1.459050e-02\n",
            "Loss: 1.458810e-02\n",
            "Loss: 1.458514e-02\n",
            "Loss: 1.458211e-02\n",
            "Loss: 1.457982e-02\n",
            "Loss: 1.457875e-02\n",
            "Loss: 1.457755e-02\n",
            "Loss: 1.457550e-02\n",
            "Loss: 1.457232e-02\n",
            "Loss: 1.457756e-02\n",
            "Loss: 1.457066e-02\n",
            "Loss: 1.456741e-02\n",
            "Loss: 1.456842e-02\n",
            "Loss: 1.456588e-02\n",
            "Loss: 1.456402e-02\n",
            "Loss: 1.456170e-02\n",
            "Loss: 1.455695e-02\n",
            "Loss: 1.455185e-02\n",
            "Loss: 1.454788e-02\n",
            "Loss: 1.454525e-02\n",
            "Loss: 1.454257e-02\n",
            "Loss: 1.454010e-02\n",
            "Loss: 1.453810e-02\n",
            "Loss: 1.453492e-02\n",
            "Loss: 1.453514e-02\n",
            "Loss: 1.453283e-02\n",
            "Loss: 1.452933e-02\n",
            "Loss: 1.452614e-02\n",
            "Loss: 1.452137e-02\n",
            "Loss: 1.451885e-02\n",
            "Loss: 1.451522e-02\n",
            "Loss: 1.451326e-02\n",
            "Loss: 1.451046e-02\n",
            "Loss: 1.450802e-02\n",
            "Loss: 1.450496e-02\n",
            "Loss: 1.450216e-02\n",
            "Loss: 1.449964e-02\n",
            "Loss: 1.449969e-02\n",
            "Loss: 1.449839e-02\n",
            "Loss: 1.449564e-02\n",
            "Loss: 1.449368e-02\n",
            "Loss: 1.449024e-02\n",
            "Loss: 1.448733e-02\n",
            "Loss: 1.448376e-02\n",
            "Loss: 1.448117e-02\n",
            "Loss: 1.447803e-02\n",
            "Loss: 1.447510e-02\n",
            "Loss: 1.447150e-02\n",
            "Loss: 1.446829e-02\n",
            "Loss: 1.446537e-02\n",
            "Loss: 1.446147e-02\n",
            "Loss: 1.445647e-02\n",
            "Loss: 1.446588e-02\n",
            "Loss: 1.445477e-02\n",
            "Loss: 1.445121e-02\n",
            "Loss: 1.444864e-02\n",
            "Loss: 1.444539e-02\n",
            "Loss: 1.444229e-02\n",
            "Loss: 1.443836e-02\n",
            "Loss: 1.443539e-02\n",
            "Loss: 1.443297e-02\n",
            "Loss: 1.442884e-02\n",
            "Loss: 1.442767e-02\n",
            "Loss: 1.442632e-02\n",
            "Loss: 1.442311e-02\n",
            "Loss: 1.441676e-02\n",
            "Loss: 1.442423e-02\n",
            "Loss: 1.441317e-02\n",
            "Loss: 1.441029e-02\n",
            "Loss: 1.440744e-02\n",
            "Loss: 1.440581e-02\n",
            "Loss: 1.440295e-02\n",
            "Loss: 1.439918e-02\n",
            "Loss: 1.439411e-02\n",
            "Loss: 1.439323e-02\n",
            "Loss: 1.438537e-02\n",
            "Loss: 1.438385e-02\n",
            "Loss: 1.438180e-02\n",
            "Loss: 1.437950e-02\n",
            "Loss: 1.437837e-02\n",
            "Loss: 1.437425e-02\n",
            "Loss: 1.437312e-02\n",
            "Loss: 1.437091e-02\n",
            "Loss: 1.436787e-02\n",
            "Loss: 1.436434e-02\n",
            "Loss: 1.436342e-02\n",
            "Loss: 1.435730e-02\n",
            "Loss: 1.435481e-02\n",
            "Loss: 1.435192e-02\n",
            "Loss: 1.434909e-02\n",
            "Loss: 1.434521e-02\n",
            "Loss: 1.434239e-02\n",
            "Loss: 1.433939e-02\n",
            "Loss: 1.433889e-02\n",
            "Loss: 1.433660e-02\n",
            "Loss: 1.433529e-02\n",
            "Loss: 1.433361e-02\n",
            "Loss: 1.433073e-02\n",
            "Loss: 1.434014e-02\n",
            "Loss: 1.432918e-02\n",
            "Loss: 1.432695e-02\n",
            "Loss: 1.432505e-02\n",
            "Loss: 1.432077e-02\n",
            "Loss: 1.431984e-02\n",
            "Loss: 1.431489e-02\n",
            "Loss: 1.431281e-02\n",
            "Loss: 1.431018e-02\n",
            "Loss: 1.430720e-02\n",
            "Loss: 1.430058e-02\n",
            "Loss: 1.431853e-02\n",
            "Loss: 1.429875e-02\n",
            "Loss: 1.429299e-02\n",
            "Loss: 1.428985e-02\n",
            "Loss: 1.428484e-02\n",
            "Loss: 1.428098e-02\n",
            "Loss: 1.427777e-02\n",
            "Loss: 1.427370e-02\n",
            "Loss: 1.427117e-02\n",
            "Loss: 1.426640e-02\n",
            "Loss: 1.426372e-02\n",
            "Loss: 1.426016e-02\n",
            "Loss: 1.425800e-02\n",
            "Loss: 1.425303e-02\n",
            "Loss: 1.425099e-02\n",
            "Loss: 1.424876e-02\n",
            "Loss: 1.424632e-02\n",
            "Loss: 1.424343e-02\n",
            "Loss: 1.423785e-02\n",
            "Loss: 1.423360e-02\n",
            "Loss: 1.423320e-02\n",
            "Loss: 1.422995e-02\n",
            "Loss: 1.422877e-02\n",
            "Loss: 1.422617e-02\n",
            "Loss: 1.422349e-02\n",
            "Loss: 1.422067e-02\n",
            "Loss: 1.421813e-02\n",
            "Loss: 1.421327e-02\n",
            "Loss: 1.420902e-02\n",
            "Loss: 1.420452e-02\n",
            "Loss: 1.419997e-02\n",
            "Loss: 1.419673e-02\n",
            "Loss: 1.419418e-02\n",
            "Loss: 1.418937e-02\n",
            "Loss: 1.419193e-02\n",
            "Loss: 1.418747e-02\n",
            "Loss: 1.418428e-02\n",
            "Loss: 1.418212e-02\n",
            "Loss: 1.417909e-02\n",
            "Loss: 1.417859e-02\n",
            "Loss: 1.417365e-02\n",
            "Loss: 1.417208e-02\n",
            "Loss: 1.417022e-02\n",
            "Loss: 1.416790e-02\n",
            "Loss: 1.416388e-02\n",
            "Loss: 1.416205e-02\n",
            "Loss: 1.415966e-02\n",
            "Loss: 1.415768e-02\n",
            "Loss: 1.415527e-02\n",
            "Loss: 1.415091e-02\n",
            "Loss: 1.414922e-02\n",
            "Loss: 1.414410e-02\n",
            "Loss: 1.414160e-02\n",
            "Loss: 1.413890e-02\n",
            "Loss: 1.413952e-02\n",
            "Loss: 1.413721e-02\n",
            "Loss: 1.413462e-02\n",
            "Loss: 1.413121e-02\n",
            "Loss: 1.412810e-02\n",
            "Loss: 1.412450e-02\n",
            "Loss: 1.412069e-02\n",
            "Loss: 1.411826e-02\n",
            "Loss: 1.411491e-02\n",
            "Loss: 1.411243e-02\n",
            "Loss: 1.411090e-02\n",
            "Loss: 1.410790e-02\n",
            "Loss: 1.410535e-02\n",
            "Loss: 1.410308e-02\n",
            "Loss: 1.410110e-02\n",
            "Loss: 1.409809e-02\n",
            "Loss: 1.409443e-02\n",
            "Loss: 1.408998e-02\n",
            "Loss: 1.408461e-02\n",
            "Loss: 1.408080e-02\n",
            "Loss: 1.407830e-02\n",
            "Loss: 1.407281e-02\n",
            "Loss: 1.407910e-02\n",
            "Loss: 1.406984e-02\n",
            "Loss: 1.406411e-02\n",
            "Loss: 1.406159e-02\n",
            "Loss: 1.405798e-02\n",
            "Loss: 1.405326e-02\n",
            "Loss: 1.404822e-02\n",
            "Loss: 1.404249e-02\n",
            "Loss: 1.403696e-02\n",
            "Loss: 1.403438e-02\n",
            "Loss: 1.403096e-02\n",
            "Loss: 1.402719e-02\n",
            "Loss: 1.402326e-02\n",
            "Loss: 1.402077e-02\n",
            "Loss: 1.401933e-02\n",
            "Loss: 1.401582e-02\n",
            "Loss: 1.401100e-02\n",
            "Loss: 1.401034e-02\n",
            "Loss: 1.400527e-02\n",
            "Loss: 1.400385e-02\n",
            "Loss: 1.400086e-02\n",
            "Loss: 1.399709e-02\n",
            "Loss: 1.399428e-02\n",
            "Loss: 1.399011e-02\n",
            "Loss: 1.398845e-02\n",
            "Loss: 1.398428e-02\n",
            "Loss: 1.398091e-02\n",
            "Loss: 1.397954e-02\n",
            "Loss: 1.397480e-02\n",
            "Loss: 1.396984e-02\n",
            "Loss: 1.396573e-02\n",
            "Loss: 1.396379e-02\n",
            "Loss: 1.396174e-02\n",
            "Loss: 1.396011e-02\n",
            "Loss: 1.395782e-02\n",
            "Loss: 1.395529e-02\n",
            "Loss: 1.395379e-02\n",
            "Loss: 1.394932e-02\n",
            "Loss: 1.396003e-02\n",
            "Loss: 1.394760e-02\n",
            "Loss: 1.394295e-02\n",
            "Loss: 1.393982e-02\n",
            "Loss: 1.393563e-02\n",
            "Loss: 1.393345e-02\n",
            "Loss: 1.393077e-02\n",
            "Loss: 1.392637e-02\n",
            "Loss: 1.392276e-02\n",
            "Loss: 1.391936e-02\n",
            "Loss: 1.391425e-02\n",
            "Loss: 1.391385e-02\n",
            "Loss: 1.391267e-02\n",
            "Loss: 1.391051e-02\n",
            "Loss: 1.390825e-02\n",
            "Loss: 1.390571e-02\n",
            "Loss: 1.390102e-02\n",
            "Loss: 1.391210e-02\n",
            "Loss: 1.389902e-02\n",
            "Loss: 1.389622e-02\n",
            "Loss: 1.389325e-02\n",
            "Loss: 1.388974e-02\n",
            "Loss: 1.388596e-02\n",
            "Loss: 1.388217e-02\n",
            "Loss: 1.387904e-02\n",
            "Loss: 1.387537e-02\n",
            "Loss: 1.387194e-02\n",
            "Loss: 1.386895e-02\n",
            "Loss: 1.386411e-02\n",
            "Loss: 1.386136e-02\n",
            "Loss: 1.386065e-02\n",
            "Loss: 1.385674e-02\n",
            "Loss: 1.385601e-02\n",
            "Loss: 1.385267e-02\n",
            "Loss: 1.384753e-02\n",
            "Loss: 1.384774e-02\n",
            "Loss: 1.384479e-02\n",
            "Loss: 1.384307e-02\n",
            "Loss: 1.384052e-02\n",
            "Loss: 1.383737e-02\n",
            "Loss: 1.383716e-02\n",
            "Loss: 1.383486e-02\n",
            "Loss: 1.383254e-02\n",
            "Loss: 1.383152e-02\n",
            "Loss: 1.382974e-02\n",
            "Loss: 1.382792e-02\n",
            "Loss: 1.382334e-02\n",
            "Loss: 1.381977e-02\n",
            "Loss: 1.381733e-02\n",
            "Loss: 1.381640e-02\n",
            "Loss: 1.381397e-02\n",
            "Loss: 1.381050e-02\n",
            "Loss: 1.381423e-02\n",
            "Loss: 1.380956e-02\n",
            "Loss: 1.380729e-02\n",
            "Loss: 1.380582e-02\n",
            "Loss: 1.380388e-02\n",
            "Loss: 1.380118e-02\n",
            "Loss: 1.379857e-02\n",
            "Loss: 1.379605e-02\n",
            "Loss: 1.379460e-02\n",
            "Loss: 1.379262e-02\n",
            "Loss: 1.379033e-02\n",
            "Loss: 1.378672e-02\n",
            "Loss: 1.378402e-02\n",
            "Loss: 1.378140e-02\n",
            "Loss: 1.377689e-02\n",
            "Loss: 1.377546e-02\n",
            "Loss: 1.377121e-02\n",
            "Loss: 1.376967e-02\n",
            "Loss: 1.376871e-02\n",
            "Loss: 1.376601e-02\n",
            "Loss: 1.376417e-02\n",
            "Loss: 1.376181e-02\n",
            "Loss: 1.376000e-02\n",
            "Loss: 1.375902e-02\n",
            "Loss: 1.375713e-02\n",
            "Loss: 1.375462e-02\n",
            "Loss: 1.375237e-02\n",
            "Loss: 1.374875e-02\n",
            "Loss: 1.374463e-02\n",
            "Loss: 1.374333e-02\n",
            "Loss: 1.374121e-02\n",
            "Loss: 1.373982e-02\n",
            "Loss: 1.373680e-02\n",
            "Loss: 1.375115e-02\n",
            "Loss: 1.373576e-02\n",
            "Loss: 1.373221e-02\n",
            "Loss: 1.372968e-02\n",
            "Loss: 1.372793e-02\n",
            "Loss: 1.372584e-02\n",
            "Loss: 1.374660e-02\n",
            "Loss: 1.372491e-02\n",
            "Loss: 1.372171e-02\n",
            "Loss: 1.371819e-02\n",
            "Loss: 1.371556e-02\n",
            "Loss: 1.371381e-02\n",
            "Loss: 1.370961e-02\n",
            "Loss: 1.370610e-02\n",
            "Loss: 1.370288e-02\n",
            "Loss: 1.369964e-02\n",
            "Loss: 1.369438e-02\n",
            "Loss: 1.369076e-02\n",
            "Loss: 1.368752e-02\n",
            "Loss: 1.368525e-02\n",
            "Loss: 1.368276e-02\n",
            "Loss: 1.367539e-02\n",
            "Loss: 1.370929e-02\n",
            "Loss: 1.367401e-02\n",
            "Loss: 1.366953e-02\n",
            "Loss: 1.366410e-02\n",
            "Loss: 1.365562e-02\n",
            "Loss: 1.365247e-02\n",
            "Loss: 1.364852e-02\n",
            "Loss: 1.364609e-02\n",
            "Loss: 1.364500e-02\n",
            "Loss: 1.364219e-02\n",
            "Loss: 1.363989e-02\n",
            "Loss: 1.363732e-02\n",
            "Loss: 1.363424e-02\n",
            "Loss: 1.363634e-02\n",
            "Loss: 1.363187e-02\n",
            "Loss: 1.362920e-02\n",
            "Loss: 1.362678e-02\n",
            "Loss: 1.362441e-02\n",
            "Loss: 1.362460e-02\n",
            "Loss: 1.362248e-02\n",
            "Loss: 1.361991e-02\n",
            "Loss: 1.361774e-02\n",
            "Loss: 1.361611e-02\n",
            "Loss: 1.361324e-02\n",
            "Loss: 1.361091e-02\n",
            "Loss: 1.360836e-02\n",
            "Loss: 1.360696e-02\n",
            "Loss: 1.360349e-02\n",
            "Loss: 1.359789e-02\n",
            "Loss: 1.359489e-02\n",
            "Loss: 1.359336e-02\n",
            "Loss: 1.359095e-02\n",
            "Loss: 1.358799e-02\n",
            "Loss: 1.358532e-02\n",
            "Loss: 1.358164e-02\n",
            "Loss: 1.357956e-02\n",
            "Loss: 1.357696e-02\n",
            "Loss: 1.358926e-02\n",
            "Loss: 1.357502e-02\n",
            "Loss: 1.357199e-02\n",
            "Loss: 1.356872e-02\n",
            "Loss: 1.356507e-02\n",
            "Loss: 1.356321e-02\n",
            "Loss: 1.356235e-02\n",
            "Loss: 1.356010e-02\n",
            "Loss: 1.355758e-02\n",
            "Loss: 1.355372e-02\n",
            "Loss: 1.354964e-02\n",
            "Loss: 1.354656e-02\n",
            "Loss: 1.354358e-02\n",
            "Loss: 1.354204e-02\n",
            "Loss: 1.353914e-02\n",
            "Loss: 1.353412e-02\n",
            "Loss: 1.354352e-02\n",
            "Loss: 1.353202e-02\n",
            "Loss: 1.352876e-02\n",
            "Loss: 1.352487e-02\n",
            "Loss: 1.352112e-02\n",
            "Loss: 1.352311e-02\n",
            "Loss: 1.351843e-02\n",
            "Loss: 1.351382e-02\n",
            "Loss: 1.350919e-02\n",
            "Loss: 1.350516e-02\n",
            "Loss: 1.349784e-02\n",
            "Loss: 1.349573e-02\n",
            "Loss: 1.348736e-02\n",
            "Loss: 1.348480e-02\n",
            "Loss: 1.348300e-02\n",
            "Loss: 1.347838e-02\n",
            "Loss: 1.347486e-02\n",
            "Loss: 1.346770e-02\n",
            "Loss: 1.346443e-02\n",
            "Loss: 1.346183e-02\n",
            "Loss: 1.345998e-02\n",
            "Loss: 1.345622e-02\n",
            "Loss: 1.345400e-02\n",
            "Loss: 1.345127e-02\n",
            "Loss: 1.344774e-02\n",
            "Loss: 1.344069e-02\n",
            "Loss: 1.343909e-02\n",
            "Loss: 1.343297e-02\n",
            "Loss: 1.343101e-02\n",
            "Loss: 1.342797e-02\n",
            "Loss: 1.342564e-02\n",
            "Loss: 1.342119e-02\n",
            "Loss: 1.344524e-02\n",
            "Loss: 1.341857e-02\n",
            "Loss: 1.341349e-02\n",
            "Loss: 1.340520e-02\n",
            "Loss: 1.339990e-02\n",
            "Loss: 1.339618e-02\n",
            "Loss: 1.339177e-02\n",
            "Loss: 1.338846e-02\n",
            "Loss: 1.338379e-02\n",
            "Loss: 1.338026e-02\n",
            "Loss: 1.337407e-02\n",
            "Loss: 1.337750e-02\n",
            "Loss: 1.337315e-02\n",
            "Loss: 1.337124e-02\n",
            "Loss: 1.336979e-02\n",
            "Loss: 1.336824e-02\n",
            "Loss: 1.336510e-02\n",
            "Loss: 1.336007e-02\n",
            "Loss: 1.336498e-02\n",
            "Loss: 1.335788e-02\n",
            "Loss: 1.335306e-02\n",
            "Loss: 1.334940e-02\n",
            "Loss: 1.334433e-02\n",
            "Loss: 1.334122e-02\n",
            "Loss: 1.333605e-02\n",
            "Loss: 1.333209e-02\n",
            "Loss: 1.332869e-02\n",
            "Loss: 1.332460e-02\n",
            "Loss: 1.332052e-02\n",
            "Loss: 1.331704e-02\n",
            "Loss: 1.331382e-02\n",
            "Loss: 1.330843e-02\n",
            "Loss: 1.330492e-02\n",
            "Loss: 1.330106e-02\n",
            "Loss: 1.329588e-02\n",
            "Loss: 1.329430e-02\n",
            "Loss: 1.328724e-02\n",
            "Loss: 1.328564e-02\n",
            "Loss: 1.328220e-02\n",
            "Loss: 1.327619e-02\n",
            "Loss: 1.326866e-02\n",
            "Loss: 1.326650e-02\n",
            "Loss: 1.326183e-02\n",
            "Loss: 1.326020e-02\n",
            "Loss: 1.325784e-02\n",
            "Loss: 1.326581e-02\n",
            "Loss: 1.325707e-02\n",
            "Loss: 1.325476e-02\n",
            "Loss: 1.324954e-02\n",
            "Loss: 1.324318e-02\n",
            "Loss: 1.323996e-02\n",
            "Loss: 1.323780e-02\n",
            "Loss: 1.323590e-02\n",
            "Loss: 1.323337e-02\n",
            "Loss: 1.323035e-02\n",
            "Loss: 1.322473e-02\n",
            "Loss: 1.322082e-02\n",
            "Loss: 1.321378e-02\n",
            "Loss: 1.320977e-02\n",
            "Loss: 1.320643e-02\n",
            "Loss: 1.320369e-02\n",
            "Loss: 1.320102e-02\n",
            "Loss: 1.319808e-02\n",
            "Loss: 1.319278e-02\n",
            "Loss: 1.319534e-02\n",
            "Loss: 1.318937e-02\n",
            "Loss: 1.318632e-02\n",
            "Loss: 1.318408e-02\n",
            "Loss: 1.318241e-02\n",
            "Loss: 1.318035e-02\n",
            "Loss: 1.317768e-02\n",
            "Loss: 1.317418e-02\n",
            "Loss: 1.316989e-02\n",
            "Loss: 1.318907e-02\n",
            "Loss: 1.316709e-02\n",
            "Loss: 1.316477e-02\n",
            "Loss: 1.316112e-02\n",
            "Loss: 1.315788e-02\n",
            "Loss: 1.315481e-02\n",
            "Loss: 1.315244e-02\n",
            "Loss: 1.315033e-02\n",
            "Loss: 1.314787e-02\n",
            "Loss: 1.314322e-02\n",
            "Loss: 1.313998e-02\n",
            "Loss: 1.313635e-02\n",
            "Loss: 1.313405e-02\n",
            "Loss: 1.313077e-02\n",
            "Loss: 1.312762e-02\n",
            "Loss: 1.312470e-02\n",
            "Loss: 1.311882e-02\n",
            "Loss: 1.311686e-02\n",
            "Loss: 1.311341e-02\n",
            "Loss: 1.311065e-02\n",
            "Loss: 1.310968e-02\n",
            "Loss: 1.310781e-02\n",
            "Loss: 1.310529e-02\n",
            "Loss: 1.309955e-02\n",
            "Loss: 1.311450e-02\n",
            "Loss: 1.309777e-02\n",
            "Loss: 1.309450e-02\n",
            "Loss: 1.309129e-02\n",
            "Loss: 1.309043e-02\n",
            "Loss: 1.308662e-02\n",
            "Loss: 1.308431e-02\n",
            "Loss: 1.308142e-02\n",
            "Loss: 1.307849e-02\n",
            "Loss: 1.307782e-02\n",
            "Loss: 1.307525e-02\n",
            "Loss: 1.307098e-02\n",
            "Loss: 1.306847e-02\n",
            "Loss: 1.306396e-02\n",
            "Loss: 1.305960e-02\n",
            "Loss: 1.305366e-02\n",
            "Loss: 1.304863e-02\n",
            "Loss: 1.304443e-02\n",
            "Loss: 1.304204e-02\n",
            "Loss: 1.303977e-02\n",
            "Loss: 1.303735e-02\n",
            "Loss: 1.303444e-02\n",
            "Loss: 1.303021e-02\n",
            "Loss: 1.303531e-02\n",
            "Loss: 1.302861e-02\n",
            "Loss: 1.302713e-02\n",
            "Loss: 1.302582e-02\n",
            "Loss: 1.303159e-02\n",
            "Loss: 1.302510e-02\n",
            "Loss: 1.302399e-02\n",
            "Loss: 1.301967e-02\n",
            "Loss: 1.301568e-02\n",
            "Loss: 1.301284e-02\n",
            "Loss: 1.301009e-02\n",
            "Loss: 1.300745e-02\n",
            "Loss: 1.300190e-02\n",
            "Loss: 1.299889e-02\n",
            "Loss: 1.299675e-02\n",
            "Loss: 1.299309e-02\n",
            "Loss: 1.298969e-02\n",
            "Loss: 1.298424e-02\n",
            "Loss: 1.298133e-02\n",
            "Loss: 1.297873e-02\n",
            "Loss: 1.297557e-02\n",
            "Loss: 1.297266e-02\n",
            "Loss: 1.297463e-02\n",
            "Loss: 1.297030e-02\n",
            "Loss: 1.296647e-02\n",
            "Loss: 1.296285e-02\n",
            "Loss: 1.295800e-02\n",
            "Loss: 1.295228e-02\n",
            "Loss: 1.295529e-02\n",
            "Loss: 1.295005e-02\n",
            "Loss: 1.294494e-02\n",
            "Loss: 1.294210e-02\n",
            "Loss: 1.293820e-02\n",
            "Loss: 1.293390e-02\n",
            "Loss: 1.293119e-02\n",
            "Loss: 1.292533e-02\n",
            "Loss: 1.292312e-02\n",
            "Loss: 1.292033e-02\n",
            "Loss: 1.291694e-02\n",
            "Loss: 1.291751e-02\n",
            "Loss: 1.291458e-02\n",
            "Loss: 1.291154e-02\n",
            "Loss: 1.290815e-02\n",
            "Loss: 1.290519e-02\n",
            "Loss: 1.290419e-02\n",
            "Loss: 1.289924e-02\n",
            "Loss: 1.289800e-02\n",
            "Loss: 1.289550e-02\n",
            "Loss: 1.289204e-02\n",
            "Loss: 1.288872e-02\n",
            "Loss: 1.288506e-02\n",
            "Loss: 1.288232e-02\n",
            "Loss: 1.287827e-02\n",
            "Loss: 1.287464e-02\n",
            "Loss: 1.287223e-02\n",
            "Loss: 1.286864e-02\n",
            "Loss: 1.286522e-02\n",
            "Loss: 1.285878e-02\n",
            "Loss: 1.287489e-02\n",
            "Loss: 1.285678e-02\n",
            "Loss: 1.285392e-02\n",
            "Loss: 1.285229e-02\n",
            "Loss: 1.285063e-02\n",
            "Loss: 1.284681e-02\n",
            "Loss: 1.284299e-02\n",
            "Loss: 1.284025e-02\n",
            "Loss: 1.283713e-02\n",
            "Loss: 1.283533e-02\n",
            "Loss: 1.283266e-02\n",
            "Loss: 1.282883e-02\n",
            "Loss: 1.282499e-02\n",
            "Loss: 1.282179e-02\n",
            "Loss: 1.281860e-02\n",
            "Loss: 1.281408e-02\n",
            "Loss: 1.281117e-02\n",
            "Loss: 1.280357e-02\n",
            "Loss: 1.280077e-02\n",
            "Loss: 1.279610e-02\n",
            "Loss: 1.279772e-02\n",
            "Loss: 1.279409e-02\n",
            "Loss: 1.279103e-02\n",
            "Loss: 1.278680e-02\n",
            "Loss: 1.278427e-02\n",
            "Loss: 1.278142e-02\n",
            "Loss: 1.277962e-02\n",
            "Loss: 1.277795e-02\n",
            "Loss: 1.277650e-02\n",
            "Loss: 1.277355e-02\n",
            "Loss: 1.276983e-02\n",
            "Loss: 1.276481e-02\n",
            "Loss: 1.276596e-02\n",
            "Loss: 1.276294e-02\n",
            "Loss: 1.276000e-02\n",
            "Loss: 1.275708e-02\n",
            "Loss: 1.275513e-02\n",
            "Loss: 1.275457e-02\n",
            "Loss: 1.275061e-02\n",
            "Loss: 1.274942e-02\n",
            "Loss: 1.274670e-02\n",
            "Loss: 1.274569e-02\n",
            "Loss: 1.274112e-02\n",
            "Loss: 1.273850e-02\n",
            "Loss: 1.273716e-02\n",
            "Loss: 1.273437e-02\n",
            "Loss: 1.272875e-02\n",
            "Loss: 1.272853e-02\n",
            "Loss: 1.272254e-02\n",
            "Loss: 1.272025e-02\n",
            "Loss: 1.271923e-02\n",
            "Loss: 1.271761e-02\n",
            "Loss: 1.271664e-02\n",
            "Loss: 1.271558e-02\n",
            "Loss: 1.271273e-02\n",
            "Loss: 1.273504e-02\n",
            "Loss: 1.271100e-02\n",
            "Loss: 1.270851e-02\n",
            "Loss: 1.270729e-02\n",
            "Loss: 1.270561e-02\n",
            "Loss: 1.270387e-02\n",
            "Loss: 1.270154e-02\n",
            "Loss: 1.269955e-02\n",
            "Loss: 1.269748e-02\n",
            "Loss: 1.269487e-02\n",
            "Loss: 1.269277e-02\n",
            "Loss: 1.268925e-02\n",
            "Loss: 1.268608e-02\n",
            "Loss: 1.268756e-02\n",
            "Loss: 1.268408e-02\n",
            "Loss: 1.267907e-02\n",
            "Loss: 1.267592e-02\n",
            "Loss: 1.267190e-02\n",
            "Loss: 1.266745e-02\n",
            "Loss: 1.266844e-02\n",
            "Loss: 1.266422e-02\n",
            "Loss: 1.266076e-02\n",
            "Loss: 1.265847e-02\n",
            "Loss: 1.265613e-02\n",
            "Loss: 1.265137e-02\n",
            "Loss: 1.264650e-02\n",
            "Loss: 1.264322e-02\n",
            "Loss: 1.264022e-02\n",
            "Loss: 1.263842e-02\n",
            "Loss: 1.263473e-02\n",
            "Loss: 1.263265e-02\n",
            "Loss: 1.262810e-02\n",
            "Loss: 1.262393e-02\n",
            "Loss: 1.262118e-02\n",
            "Loss: 1.261770e-02\n",
            "Loss: 1.261559e-02\n",
            "Loss: 1.261381e-02\n",
            "Loss: 1.260923e-02\n",
            "Loss: 1.267306e-02\n",
            "Loss: 1.260833e-02\n",
            "Loss: 1.260545e-02\n",
            "Loss: 1.260114e-02\n",
            "Loss: 1.259615e-02\n",
            "Loss: 1.260287e-02\n",
            "Loss: 1.259455e-02\n",
            "Loss: 1.259227e-02\n",
            "Loss: 1.258918e-02\n",
            "Loss: 1.258683e-02\n",
            "Loss: 1.258397e-02\n",
            "Loss: 1.257807e-02\n",
            "Loss: 1.257261e-02\n",
            "Loss: 1.256632e-02\n",
            "Loss: 1.256157e-02\n",
            "Loss: 1.255659e-02\n",
            "Loss: 1.256692e-02\n",
            "Loss: 1.255520e-02\n",
            "Loss: 1.255287e-02\n",
            "Loss: 1.254798e-02\n",
            "Loss: 1.254635e-02\n",
            "Loss: 1.254360e-02\n",
            "Loss: 1.254225e-02\n",
            "Loss: 1.253833e-02\n",
            "Loss: 1.255769e-02\n",
            "Loss: 1.253679e-02\n",
            "Loss: 1.253393e-02\n",
            "Loss: 1.253029e-02\n",
            "Loss: 1.252685e-02\n",
            "Loss: 1.252329e-02\n",
            "Loss: 1.252092e-02\n",
            "Loss: 1.251478e-02\n",
            "Loss: 1.250923e-02\n",
            "Loss: 1.251859e-02\n",
            "Loss: 1.250666e-02\n",
            "Loss: 1.250216e-02\n",
            "Loss: 1.249901e-02\n",
            "Loss: 1.249354e-02\n",
            "Loss: 1.248910e-02\n",
            "Loss: 1.248669e-02\n",
            "Loss: 1.248397e-02\n",
            "Loss: 1.248247e-02\n",
            "Loss: 1.247910e-02\n",
            "Loss: 1.247443e-02\n",
            "Loss: 1.247076e-02\n",
            "Loss: 1.246819e-02\n",
            "Loss: 1.246616e-02\n",
            "Loss: 1.246343e-02\n",
            "Loss: 1.246114e-02\n",
            "Loss: 1.245757e-02\n",
            "Loss: 1.245253e-02\n",
            "Loss: 1.244616e-02\n",
            "Loss: 1.245117e-02\n",
            "Loss: 1.244370e-02\n",
            "Loss: 1.244172e-02\n",
            "Loss: 1.244017e-02\n",
            "Loss: 1.243818e-02\n",
            "Loss: 1.243307e-02\n",
            "Loss: 1.246810e-02\n",
            "Loss: 1.243227e-02\n",
            "Loss: 1.242832e-02\n",
            "Loss: 1.242614e-02\n",
            "Loss: 1.242385e-02\n",
            "Loss: 1.242068e-02\n",
            "Loss: 1.242416e-02\n",
            "Loss: 1.241910e-02\n",
            "Loss: 1.241591e-02\n",
            "Loss: 1.241258e-02\n",
            "Loss: 1.241086e-02\n",
            "Loss: 1.240575e-02\n",
            "Loss: 1.239857e-02\n",
            "Loss: 1.240069e-02\n",
            "Loss: 1.239494e-02\n",
            "Loss: 1.238894e-02\n",
            "Loss: 1.238581e-02\n",
            "Loss: 1.238273e-02\n",
            "Loss: 1.237961e-02\n",
            "Loss: 1.237684e-02\n",
            "Loss: 1.237337e-02\n",
            "Loss: 1.238151e-02\n",
            "Loss: 1.237221e-02\n",
            "Loss: 1.236990e-02\n",
            "Loss: 1.236554e-02\n",
            "Loss: 1.236088e-02\n",
            "Loss: 1.235750e-02\n",
            "Loss: 1.235377e-02\n",
            "Loss: 1.235188e-02\n",
            "Loss: 1.234935e-02\n",
            "Loss: 1.234716e-02\n",
            "Loss: 1.234367e-02\n",
            "Loss: 1.233822e-02\n",
            "Loss: 1.234370e-02\n",
            "Loss: 1.233525e-02\n",
            "Loss: 1.232935e-02\n",
            "Loss: 1.232570e-02\n",
            "Loss: 1.232189e-02\n",
            "Loss: 1.231891e-02\n",
            "Loss: 1.231625e-02\n",
            "Loss: 1.231337e-02\n",
            "Loss: 1.231182e-02\n",
            "Loss: 1.230678e-02\n",
            "Loss: 1.230332e-02\n",
            "Loss: 1.230030e-02\n",
            "Loss: 1.229801e-02\n",
            "Loss: 1.229606e-02\n",
            "Loss: 1.229389e-02\n",
            "Loss: 1.229137e-02\n",
            "Loss: 1.228717e-02\n",
            "Loss: 1.228242e-02\n",
            "Loss: 1.227696e-02\n",
            "Loss: 1.227768e-02\n",
            "Loss: 1.227464e-02\n",
            "Loss: 1.227133e-02\n",
            "Loss: 1.226670e-02\n",
            "Loss: 1.225972e-02\n",
            "Loss: 1.225252e-02\n",
            "Loss: 1.225985e-02\n",
            "Loss: 1.225044e-02\n",
            "Loss: 1.224731e-02\n",
            "Loss: 1.224427e-02\n",
            "Loss: 1.224142e-02\n",
            "Loss: 1.223604e-02\n",
            "Loss: 1.222935e-02\n",
            "Loss: 1.222502e-02\n",
            "Loss: 1.221861e-02\n",
            "Loss: 1.221347e-02\n",
            "Loss: 1.220884e-02\n",
            "Loss: 1.220439e-02\n",
            "Loss: 1.219877e-02\n",
            "Loss: 1.219570e-02\n",
            "Loss: 1.219243e-02\n",
            "Loss: 1.218905e-02\n",
            "Loss: 1.218805e-02\n",
            "Loss: 1.218588e-02\n",
            "Loss: 1.218229e-02\n",
            "Loss: 1.217977e-02\n",
            "Loss: 1.217643e-02\n",
            "Loss: 1.217158e-02\n",
            "Loss: 1.216935e-02\n",
            "Loss: 1.216575e-02\n",
            "Loss: 1.216264e-02\n",
            "Loss: 1.215885e-02\n",
            "Loss: 1.215585e-02\n",
            "Loss: 1.215361e-02\n",
            "Loss: 1.215141e-02\n",
            "Loss: 1.214801e-02\n",
            "Loss: 1.214359e-02\n",
            "Loss: 1.215072e-02\n",
            "Loss: 1.214162e-02\n",
            "Loss: 1.213825e-02\n",
            "Loss: 1.213579e-02\n",
            "Loss: 1.213386e-02\n",
            "Loss: 1.213169e-02\n",
            "Loss: 1.212656e-02\n",
            "Loss: 1.213414e-02\n",
            "Loss: 1.212446e-02\n",
            "Loss: 1.212007e-02\n",
            "Loss: 1.211690e-02\n",
            "Loss: 1.211233e-02\n",
            "Loss: 1.211091e-02\n",
            "Loss: 1.210583e-02\n",
            "Loss: 1.210348e-02\n",
            "Loss: 1.210174e-02\n",
            "Loss: 1.209899e-02\n",
            "Loss: 1.209396e-02\n",
            "Loss: 1.209036e-02\n",
            "Loss: 1.208748e-02\n",
            "Loss: 1.208574e-02\n",
            "Loss: 1.208285e-02\n",
            "Loss: 1.207703e-02\n",
            "Loss: 1.207435e-02\n",
            "Loss: 1.207361e-02\n",
            "Loss: 1.206965e-02\n",
            "Loss: 1.206870e-02\n",
            "Loss: 1.206713e-02\n",
            "Loss: 1.206506e-02\n",
            "Loss: 1.206082e-02\n",
            "Loss: 1.212970e-02\n",
            "Loss: 1.205942e-02\n",
            "Loss: 1.205550e-02\n",
            "Loss: 1.205278e-02\n",
            "Loss: 1.205066e-02\n",
            "Loss: 1.204790e-02\n",
            "Loss: 1.204194e-02\n",
            "Loss: 1.205130e-02\n",
            "Loss: 1.204028e-02\n",
            "Loss: 1.203595e-02\n",
            "Loss: 1.203244e-02\n",
            "Loss: 1.202893e-02\n",
            "Loss: 1.202856e-02\n",
            "Loss: 1.202700e-02\n",
            "Loss: 1.202214e-02\n",
            "Loss: 1.201656e-02\n",
            "Loss: 1.201460e-02\n",
            "Loss: 1.201169e-02\n",
            "Loss: 1.201063e-02\n",
            "Loss: 1.200796e-02\n",
            "Loss: 1.200577e-02\n",
            "Loss: 1.200105e-02\n",
            "Loss: 1.199974e-02\n",
            "Loss: 1.199550e-02\n",
            "Loss: 1.199359e-02\n",
            "Loss: 1.199056e-02\n",
            "Loss: 1.198518e-02\n",
            "Loss: 1.198129e-02\n",
            "Loss: 1.197773e-02\n",
            "Loss: 1.197411e-02\n",
            "Loss: 1.196828e-02\n",
            "Loss: 1.196164e-02\n",
            "Loss: 1.196169e-02\n",
            "Loss: 1.195867e-02\n",
            "Loss: 1.195317e-02\n",
            "Loss: 1.194761e-02\n",
            "Loss: 1.194160e-02\n",
            "Loss: 1.193626e-02\n",
            "Loss: 1.193441e-02\n",
            "Loss: 1.193131e-02\n",
            "Loss: 1.192975e-02\n",
            "Loss: 1.192835e-02\n",
            "Loss: 1.192455e-02\n",
            "Loss: 1.192524e-02\n",
            "Loss: 1.192158e-02\n",
            "Loss: 1.191936e-02\n",
            "Loss: 1.191526e-02\n",
            "Loss: 1.191307e-02\n",
            "Loss: 1.191118e-02\n",
            "Loss: 1.190637e-02\n",
            "Loss: 1.190807e-02\n",
            "Loss: 1.190339e-02\n",
            "Loss: 1.190014e-02\n",
            "Loss: 1.189732e-02\n",
            "Loss: 1.189614e-02\n",
            "Loss: 1.189333e-02\n",
            "Loss: 1.189178e-02\n",
            "Loss: 1.188936e-02\n",
            "Loss: 1.188629e-02\n",
            "Loss: 1.189150e-02\n",
            "Loss: 1.188437e-02\n",
            "Loss: 1.188062e-02\n",
            "Loss: 1.187826e-02\n",
            "Loss: 1.187611e-02\n",
            "Loss: 1.187296e-02\n",
            "Loss: 1.186775e-02\n",
            "Loss: 1.188050e-02\n",
            "Loss: 1.186574e-02\n",
            "Loss: 1.186215e-02\n",
            "Loss: 1.185906e-02\n",
            "Loss: 1.185524e-02\n",
            "Loss: 1.185605e-02\n",
            "Loss: 1.185284e-02\n",
            "Loss: 1.184954e-02\n",
            "Loss: 1.185024e-02\n",
            "Loss: 1.184827e-02\n",
            "Loss: 1.184689e-02\n",
            "Loss: 1.184427e-02\n",
            "Loss: 1.184079e-02\n",
            "Loss: 1.183885e-02\n",
            "Loss: 1.183397e-02\n",
            "Loss: 1.183132e-02\n",
            "Loss: 1.182941e-02\n",
            "Loss: 1.182585e-02\n",
            "Loss: 1.182125e-02\n",
            "Loss: 1.181649e-02\n",
            "Loss: 1.181421e-02\n",
            "Loss: 1.181187e-02\n",
            "Loss: 1.180950e-02\n",
            "Loss: 1.180632e-02\n",
            "Loss: 1.180365e-02\n",
            "Loss: 1.179996e-02\n",
            "Loss: 1.179674e-02\n",
            "Loss: 1.179339e-02\n",
            "Loss: 1.178910e-02\n",
            "Loss: 1.178681e-02\n",
            "Loss: 1.178466e-02\n",
            "Loss: 1.178243e-02\n",
            "Loss: 1.178028e-02\n",
            "Loss: 1.177737e-02\n",
            "Loss: 1.177464e-02\n",
            "Loss: 1.177065e-02\n",
            "Loss: 1.177893e-02\n",
            "Loss: 1.176869e-02\n",
            "Loss: 1.176718e-02\n",
            "Loss: 1.176561e-02\n",
            "Loss: 1.176168e-02\n",
            "Loss: 1.175752e-02\n",
            "Loss: 1.175316e-02\n",
            "Loss: 1.175020e-02\n",
            "Loss: 1.174814e-02\n",
            "Loss: 1.174675e-02\n",
            "Loss: 1.174462e-02\n",
            "Loss: 1.174172e-02\n",
            "Loss: 1.173982e-02\n",
            "Loss: 1.173728e-02\n",
            "Loss: 1.174047e-02\n",
            "Loss: 1.173631e-02\n",
            "Loss: 1.173396e-02\n",
            "Loss: 1.173190e-02\n",
            "Loss: 1.172695e-02\n",
            "Loss: 1.172380e-02\n",
            "Loss: 1.171966e-02\n",
            "Loss: 1.171539e-02\n",
            "Loss: 1.171257e-02\n",
            "Loss: 1.170932e-02\n",
            "Loss: 1.170486e-02\n",
            "Loss: 1.169853e-02\n",
            "Loss: 1.170537e-02\n",
            "Loss: 1.169709e-02\n",
            "Loss: 1.169532e-02\n",
            "Loss: 1.169447e-02\n",
            "Loss: 1.169258e-02\n",
            "Loss: 1.168862e-02\n",
            "Loss: 1.168494e-02\n",
            "Loss: 1.168286e-02\n",
            "Loss: 1.168112e-02\n",
            "Loss: 1.167768e-02\n",
            "Loss: 1.167472e-02\n",
            "Loss: 1.167197e-02\n",
            "Loss: 1.166942e-02\n",
            "Loss: 1.166766e-02\n",
            "Loss: 1.166304e-02\n",
            "Loss: 1.166173e-02\n",
            "Loss: 1.165877e-02\n",
            "Loss: 1.165717e-02\n",
            "Loss: 1.165574e-02\n",
            "Loss: 1.165281e-02\n",
            "Loss: 1.165112e-02\n",
            "Loss: 1.164682e-02\n",
            "Loss: 1.164556e-02\n",
            "Loss: 1.164317e-02\n",
            "Loss: 1.164193e-02\n",
            "Loss: 1.164115e-02\n",
            "Loss: 1.163911e-02\n",
            "Loss: 1.163786e-02\n",
            "Loss: 1.163441e-02\n",
            "Loss: 1.164357e-02\n",
            "Loss: 1.163307e-02\n",
            "Loss: 1.162973e-02\n",
            "Loss: 1.162791e-02\n",
            "Loss: 1.162608e-02\n",
            "Loss: 1.162369e-02\n",
            "Loss: 1.161858e-02\n",
            "Loss: 1.162223e-02\n",
            "Loss: 1.161669e-02\n",
            "Loss: 1.161328e-02\n",
            "Loss: 1.161114e-02\n",
            "Loss: 1.160931e-02\n",
            "Loss: 1.160652e-02\n",
            "Loss: 1.160428e-02\n",
            "Loss: 1.160239e-02\n",
            "Loss: 1.162929e-02\n",
            "Loss: 1.160173e-02\n",
            "Loss: 1.160013e-02\n",
            "Loss: 1.159783e-02\n",
            "Loss: 1.159509e-02\n",
            "Loss: 1.159326e-02\n",
            "Loss: 1.158975e-02\n",
            "Loss: 1.158565e-02\n",
            "Loss: 1.158208e-02\n",
            "Loss: 1.157872e-02\n",
            "Loss: 1.157545e-02\n",
            "Loss: 1.157307e-02\n",
            "Loss: 1.157049e-02\n",
            "Loss: 1.156795e-02\n",
            "Loss: 1.156725e-02\n",
            "Loss: 1.156645e-02\n",
            "Loss: 1.156504e-02\n",
            "Loss: 1.156282e-02\n",
            "Loss: 1.156040e-02\n",
            "Loss: 1.155787e-02\n",
            "Loss: 1.155576e-02\n",
            "Loss: 1.155361e-02\n",
            "Loss: 1.155153e-02\n",
            "Loss: 1.154969e-02\n",
            "Loss: 1.154788e-02\n",
            "Loss: 1.154647e-02\n",
            "Loss: 1.154418e-02\n",
            "Loss: 1.154297e-02\n",
            "Loss: 1.153939e-02\n",
            "Loss: 1.153803e-02\n",
            "Loss: 1.153601e-02\n",
            "Loss: 1.153451e-02\n",
            "Loss: 1.153085e-02\n",
            "Loss: 1.152881e-02\n",
            "Loss: 1.152516e-02\n",
            "Loss: 1.152455e-02\n",
            "Loss: 1.152257e-02\n",
            "Loss: 1.152060e-02\n",
            "Loss: 1.151862e-02\n",
            "Loss: 1.151627e-02\n",
            "Loss: 1.152348e-02\n",
            "Loss: 1.151425e-02\n",
            "Loss: 1.150941e-02\n",
            "Loss: 1.150553e-02\n",
            "Loss: 1.150120e-02\n",
            "Loss: 1.149751e-02\n",
            "Loss: 1.149425e-02\n",
            "Loss: 1.149276e-02\n",
            "Loss: 1.148877e-02\n",
            "Loss: 1.148774e-02\n",
            "Loss: 1.148536e-02\n",
            "Loss: 1.148404e-02\n",
            "Loss: 1.148192e-02\n",
            "Loss: 1.148022e-02\n",
            "Loss: 1.147886e-02\n",
            "Loss: 1.147937e-02\n",
            "Loss: 1.147727e-02\n",
            "Loss: 1.147489e-02\n",
            "Loss: 1.147252e-02\n",
            "Loss: 1.147093e-02\n",
            "Loss: 1.146679e-02\n",
            "Loss: 1.146085e-02\n",
            "Loss: 1.145786e-02\n",
            "Loss: 1.145365e-02\n",
            "Loss: 1.145100e-02\n",
            "Loss: 1.144837e-02\n",
            "Loss: 1.144431e-02\n",
            "Loss: 1.143939e-02\n",
            "Loss: 1.143887e-02\n",
            "Loss: 1.143361e-02\n",
            "Loss: 1.143244e-02\n",
            "Loss: 1.143002e-02\n",
            "Loss: 1.142792e-02\n",
            "Loss: 1.142434e-02\n",
            "Loss: 1.142341e-02\n",
            "Loss: 1.141976e-02\n",
            "Loss: 1.141826e-02\n",
            "Loss: 1.141461e-02\n",
            "Loss: 1.141020e-02\n",
            "Loss: 1.140879e-02\n",
            "Loss: 1.140382e-02\n",
            "Loss: 1.140170e-02\n",
            "Loss: 1.139815e-02\n",
            "Loss: 1.139956e-02\n",
            "Loss: 1.139665e-02\n",
            "Loss: 1.139267e-02\n",
            "Loss: 1.138941e-02\n",
            "Loss: 1.138562e-02\n",
            "Loss: 1.138307e-02\n",
            "Loss: 1.138085e-02\n",
            "Loss: 1.137960e-02\n",
            "Loss: 1.137728e-02\n",
            "Loss: 1.137683e-02\n",
            "Loss: 1.137453e-02\n",
            "Loss: 1.137264e-02\n",
            "Loss: 1.136980e-02\n",
            "Loss: 1.137707e-02\n",
            "Loss: 1.136889e-02\n",
            "Loss: 1.136702e-02\n",
            "Loss: 1.136501e-02\n",
            "Loss: 1.136438e-02\n",
            "Loss: 1.136206e-02\n",
            "Loss: 1.135823e-02\n",
            "Loss: 1.137207e-02\n",
            "Loss: 1.135671e-02\n",
            "Loss: 1.135476e-02\n",
            "Loss: 1.135367e-02\n",
            "Loss: 1.135142e-02\n",
            "Loss: 1.135031e-02\n",
            "Loss: 1.134776e-02\n",
            "Loss: 1.134628e-02\n",
            "Loss: 1.134536e-02\n",
            "Loss: 1.134459e-02\n",
            "Loss: 1.134297e-02\n",
            "Loss: 1.134129e-02\n",
            "Loss: 1.133833e-02\n",
            "Loss: 1.133522e-02\n",
            "Loss: 1.133263e-02\n",
            "Loss: 1.133014e-02\n",
            "Loss: 1.132677e-02\n",
            "Loss: 1.132562e-02\n",
            "Loss: 1.132237e-02\n",
            "Loss: 1.132048e-02\n",
            "Loss: 1.131783e-02\n",
            "Loss: 1.131563e-02\n",
            "Loss: 1.132286e-02\n",
            "Loss: 1.131533e-02\n",
            "Loss: 1.131389e-02\n",
            "Loss: 1.131115e-02\n",
            "Loss: 1.130809e-02\n",
            "Loss: 1.130571e-02\n",
            "Loss: 1.130288e-02\n",
            "Loss: 1.130080e-02\n",
            "Loss: 1.129835e-02\n",
            "Loss: 1.129633e-02\n",
            "Loss: 1.129196e-02\n",
            "Loss: 1.129109e-02\n",
            "Loss: 1.128609e-02\n",
            "Loss: 1.128407e-02\n",
            "Loss: 1.128106e-02\n",
            "Loss: 1.127654e-02\n",
            "Loss: 1.128520e-02\n",
            "Loss: 1.127489e-02\n",
            "Loss: 1.127133e-02\n",
            "Loss: 1.126939e-02\n",
            "Loss: 1.126684e-02\n",
            "Loss: 1.126883e-02\n",
            "Loss: 1.126584e-02\n",
            "Loss: 1.126422e-02\n",
            "Loss: 1.126209e-02\n",
            "Loss: 1.126059e-02\n",
            "Loss: 1.125718e-02\n",
            "Loss: 1.125515e-02\n",
            "Loss: 1.125413e-02\n",
            "Loss: 1.125169e-02\n",
            "Loss: 1.125068e-02\n",
            "Loss: 1.124983e-02\n",
            "Loss: 1.124721e-02\n",
            "Loss: 1.124375e-02\n",
            "Loss: 1.124556e-02\n",
            "Loss: 1.124180e-02\n",
            "Loss: 1.123857e-02\n",
            "Loss: 1.123709e-02\n",
            "Loss: 1.123403e-02\n",
            "Loss: 1.123248e-02\n",
            "Loss: 1.123223e-02\n",
            "Loss: 1.123056e-02\n",
            "Loss: 1.122824e-02\n",
            "Loss: 1.122696e-02\n",
            "Loss: 1.122517e-02\n",
            "Loss: 1.122323e-02\n",
            "Loss: 1.121983e-02\n",
            "Loss: 1.121808e-02\n",
            "Loss: 1.121580e-02\n",
            "Loss: 1.121535e-02\n",
            "Loss: 1.121321e-02\n",
            "Loss: 1.121044e-02\n",
            "Loss: 1.120786e-02\n",
            "Loss: 1.120527e-02\n",
            "Loss: 1.120244e-02\n",
            "Loss: 1.120043e-02\n",
            "Loss: 1.119764e-02\n",
            "Loss: 1.119519e-02\n",
            "Loss: 1.119356e-02\n",
            "Loss: 1.119118e-02\n",
            "Loss: 1.118953e-02\n",
            "Loss: 1.118820e-02\n",
            "Loss: 1.118530e-02\n",
            "Loss: 1.118111e-02\n",
            "Loss: 1.117905e-02\n",
            "Loss: 1.117617e-02\n",
            "Loss: 1.117427e-02\n",
            "Loss: 1.117073e-02\n",
            "Loss: 1.116750e-02\n",
            "Loss: 1.116440e-02\n",
            "Loss: 1.116221e-02\n",
            "Loss: 1.115878e-02\n",
            "Loss: 1.115548e-02\n",
            "Loss: 1.116001e-02\n",
            "Loss: 1.115334e-02\n",
            "Loss: 1.115033e-02\n",
            "Loss: 1.114790e-02\n",
            "Loss: 1.114324e-02\n",
            "Loss: 1.115318e-02\n",
            "Loss: 1.114202e-02\n",
            "Loss: 1.113970e-02\n",
            "Loss: 1.113722e-02\n",
            "Loss: 1.113461e-02\n",
            "Loss: 1.113005e-02\n",
            "Loss: 1.112554e-02\n",
            "Loss: 1.112187e-02\n",
            "Loss: 1.112054e-02\n",
            "Loss: 1.111888e-02\n",
            "Loss: 1.111803e-02\n",
            "Loss: 1.111629e-02\n",
            "Loss: 1.111357e-02\n",
            "Loss: 1.111093e-02\n",
            "Loss: 1.110735e-02\n",
            "Loss: 1.110587e-02\n",
            "Loss: 1.110376e-02\n",
            "Loss: 1.110122e-02\n",
            "Loss: 1.110338e-02\n",
            "Loss: 1.109894e-02\n",
            "Loss: 1.109687e-02\n",
            "Loss: 1.109524e-02\n",
            "Loss: 1.109390e-02\n",
            "Loss: 1.109169e-02\n",
            "Loss: 1.109048e-02\n",
            "Loss: 1.108845e-02\n",
            "Loss: 1.108573e-02\n",
            "Loss: 1.108302e-02\n",
            "Loss: 1.107945e-02\n",
            "Loss: 1.107762e-02\n",
            "Loss: 1.107428e-02\n",
            "Loss: 1.107060e-02\n",
            "Loss: 1.106826e-02\n",
            "Loss: 1.106447e-02\n",
            "Loss: 1.106169e-02\n",
            "Loss: 1.105964e-02\n",
            "Loss: 1.106443e-02\n",
            "Loss: 1.105831e-02\n",
            "Loss: 1.105631e-02\n",
            "Loss: 1.105351e-02\n",
            "Loss: 1.105069e-02\n",
            "Loss: 1.104814e-02\n",
            "Loss: 1.104273e-02\n",
            "Loss: 1.106453e-02\n",
            "Loss: 1.104127e-02\n",
            "Loss: 1.103775e-02\n",
            "Loss: 1.103578e-02\n",
            "Loss: 1.103254e-02\n",
            "Loss: 1.103154e-02\n",
            "Loss: 1.102889e-02\n",
            "Loss: 1.102772e-02\n",
            "Loss: 1.102575e-02\n",
            "Loss: 1.102362e-02\n",
            "Loss: 1.102116e-02\n",
            "Loss: 1.101975e-02\n",
            "Loss: 1.101890e-02\n",
            "Loss: 1.101663e-02\n",
            "Loss: 1.101531e-02\n",
            "Loss: 1.101344e-02\n",
            "Loss: 1.101246e-02\n",
            "Loss: 1.101120e-02\n",
            "Loss: 1.100704e-02\n",
            "Loss: 1.100822e-02\n",
            "Loss: 1.100557e-02\n",
            "Loss: 1.100251e-02\n",
            "Loss: 1.100111e-02\n",
            "Loss: 1.099870e-02\n",
            "Loss: 1.099717e-02\n",
            "Loss: 1.099570e-02\n",
            "Loss: 1.099334e-02\n",
            "Loss: 1.099254e-02\n",
            "Loss: 1.099043e-02\n",
            "Loss: 1.098856e-02\n",
            "Loss: 1.098675e-02\n",
            "Loss: 1.098423e-02\n",
            "Loss: 1.098487e-02\n",
            "Loss: 1.098190e-02\n",
            "Loss: 1.097980e-02\n",
            "Loss: 1.097853e-02\n",
            "Loss: 1.097696e-02\n",
            "Loss: 1.097542e-02\n",
            "Loss: 1.097237e-02\n",
            "Loss: 1.096932e-02\n",
            "Loss: 1.096728e-02\n",
            "Loss: 1.096503e-02\n",
            "Loss: 1.096406e-02\n",
            "Loss: 1.096261e-02\n",
            "Loss: 1.095853e-02\n",
            "Loss: 1.095713e-02\n",
            "Loss: 1.095290e-02\n",
            "Loss: 1.095197e-02\n",
            "Loss: 1.095017e-02\n",
            "Loss: 1.095142e-02\n",
            "Loss: 1.094895e-02\n",
            "Loss: 1.094818e-02\n",
            "Loss: 1.094681e-02\n",
            "Loss: 1.094544e-02\n",
            "Loss: 1.094112e-02\n",
            "Loss: 1.093733e-02\n",
            "Loss: 1.093541e-02\n",
            "Loss: 1.093336e-02\n",
            "Loss: 1.093225e-02\n",
            "Loss: 1.093008e-02\n",
            "Loss: 1.092766e-02\n",
            "Loss: 1.092526e-02\n",
            "Loss: 1.092330e-02\n",
            "Loss: 1.092115e-02\n",
            "Loss: 1.091914e-02\n",
            "Loss: 1.091741e-02\n",
            "Loss: 1.091606e-02\n",
            "Loss: 1.091469e-02\n",
            "Loss: 1.091287e-02\n",
            "Loss: 1.091103e-02\n",
            "Loss: 1.090826e-02\n",
            "Loss: 1.090732e-02\n",
            "Loss: 1.090621e-02\n",
            "Loss: 1.090371e-02\n",
            "Loss: 1.090105e-02\n",
            "Loss: 1.091588e-02\n",
            "Loss: 1.090043e-02\n",
            "Loss: 1.089782e-02\n",
            "Loss: 1.089699e-02\n",
            "Loss: 1.089503e-02\n",
            "Loss: 1.089331e-02\n",
            "Loss: 1.089184e-02\n",
            "Loss: 1.089028e-02\n",
            "Loss: 1.088972e-02\n",
            "Loss: 1.088904e-02\n",
            "Loss: 1.088734e-02\n",
            "Loss: 1.088816e-02\n",
            "Loss: 1.088645e-02\n",
            "Loss: 1.088394e-02\n",
            "Loss: 1.088176e-02\n",
            "Loss: 1.088061e-02\n",
            "Loss: 1.087989e-02\n",
            "Loss: 1.087863e-02\n",
            "Loss: 1.087680e-02\n",
            "Loss: 1.087346e-02\n",
            "Loss: 1.087097e-02\n",
            "Loss: 1.086828e-02\n",
            "Loss: 1.086650e-02\n",
            "Loss: 1.086494e-02\n",
            "Loss: 1.086365e-02\n",
            "Loss: 1.086097e-02\n",
            "Loss: 1.086531e-02\n",
            "Loss: 1.086028e-02\n",
            "Loss: 1.085901e-02\n",
            "Loss: 1.085659e-02\n",
            "Loss: 1.086152e-02\n",
            "Loss: 1.085582e-02\n",
            "Loss: 1.085472e-02\n",
            "Loss: 1.085248e-02\n",
            "Loss: 1.084902e-02\n",
            "Loss: 1.084551e-02\n",
            "Loss: 1.084213e-02\n",
            "Loss: 1.084027e-02\n",
            "Loss: 1.083860e-02\n",
            "Loss: 1.083671e-02\n",
            "Loss: 1.083485e-02\n",
            "Loss: 1.083372e-02\n",
            "Loss: 1.083071e-02\n",
            "Loss: 1.082987e-02\n",
            "Loss: 1.082829e-02\n",
            "Loss: 1.082656e-02\n",
            "Loss: 1.082458e-02\n",
            "Loss: 1.082333e-02\n",
            "Loss: 1.082199e-02\n",
            "Loss: 1.082080e-02\n",
            "Loss: 1.081945e-02\n",
            "Loss: 1.081781e-02\n",
            "Loss: 1.081658e-02\n",
            "Loss: 1.081561e-02\n",
            "Loss: 1.081440e-02\n",
            "Loss: 1.081130e-02\n",
            "Loss: 1.081754e-02\n",
            "Loss: 1.081060e-02\n",
            "Loss: 1.080950e-02\n",
            "Loss: 1.080836e-02\n",
            "Loss: 1.080668e-02\n",
            "Loss: 1.080426e-02\n",
            "Loss: 1.080392e-02\n",
            "Loss: 1.080170e-02\n",
            "Loss: 1.080065e-02\n",
            "Loss: 1.079800e-02\n",
            "Loss: 1.079799e-02\n",
            "Loss: 1.079443e-02\n",
            "Loss: 1.079386e-02\n",
            "Loss: 1.079206e-02\n",
            "Loss: 1.079085e-02\n",
            "Loss: 1.078962e-02\n",
            "Loss: 1.078899e-02\n",
            "Loss: 1.078746e-02\n",
            "Loss: 1.078434e-02\n",
            "Loss: 1.078346e-02\n",
            "Loss: 1.078015e-02\n",
            "Loss: 1.077936e-02\n",
            "Loss: 1.077759e-02\n",
            "Loss: 1.077554e-02\n",
            "Loss: 1.077353e-02\n",
            "Loss: 1.077163e-02\n",
            "Loss: 1.077026e-02\n",
            "Loss: 1.076925e-02\n",
            "Loss: 1.076570e-02\n",
            "Loss: 1.077307e-02\n",
            "Loss: 1.076511e-02\n",
            "Loss: 1.076428e-02\n",
            "Loss: 1.076224e-02\n",
            "Loss: 1.076034e-02\n",
            "Loss: 1.075745e-02\n",
            "Loss: 1.075664e-02\n",
            "Loss: 1.075301e-02\n",
            "Loss: 1.075194e-02\n",
            "Loss: 1.075037e-02\n",
            "Loss: 1.074817e-02\n",
            "Loss: 1.074614e-02\n",
            "Loss: 1.074350e-02\n",
            "Loss: 1.074185e-02\n",
            "Loss: 1.073963e-02\n",
            "Loss: 1.073746e-02\n",
            "Loss: 1.073617e-02\n",
            "Loss: 1.073354e-02\n",
            "Loss: 1.073212e-02\n",
            "Loss: 1.073125e-02\n",
            "Loss: 1.072983e-02\n",
            "Loss: 1.072857e-02\n",
            "Loss: 1.072669e-02\n",
            "Loss: 1.072511e-02\n",
            "Loss: 1.072164e-02\n",
            "Loss: 1.074237e-02\n",
            "Loss: 1.072136e-02\n",
            "Loss: 1.071952e-02\n",
            "Loss: 1.071687e-02\n",
            "Loss: 1.071389e-02\n",
            "Loss: 1.071085e-02\n",
            "Loss: 1.071425e-02\n",
            "Loss: 1.070897e-02\n",
            "Loss: 1.070665e-02\n",
            "Loss: 1.070536e-02\n",
            "Loss: 1.070352e-02\n",
            "Loss: 1.070099e-02\n",
            "Loss: 1.069834e-02\n",
            "Loss: 1.069609e-02\n",
            "Loss: 1.069509e-02\n",
            "Loss: 1.069292e-02\n",
            "Loss: 1.069108e-02\n",
            "Loss: 1.068926e-02\n",
            "Loss: 1.068729e-02\n",
            "Loss: 1.068589e-02\n",
            "Loss: 1.068393e-02\n",
            "Loss: 1.069943e-02\n",
            "Loss: 1.068332e-02\n",
            "Loss: 1.068028e-02\n",
            "Loss: 1.067738e-02\n",
            "Loss: 1.067361e-02\n",
            "Loss: 1.067268e-02\n",
            "Loss: 1.066990e-02\n",
            "Loss: 1.066792e-02\n",
            "Loss: 1.066679e-02\n",
            "Loss: 1.066592e-02\n",
            "Loss: 1.066401e-02\n",
            "Loss: 1.066311e-02\n",
            "Loss: 1.066160e-02\n",
            "Loss: 1.066011e-02\n",
            "Loss: 1.065651e-02\n",
            "Loss: 1.065593e-02\n",
            "Loss: 1.065247e-02\n",
            "Loss: 1.065124e-02\n",
            "Loss: 1.064949e-02\n",
            "Loss: 1.064787e-02\n",
            "Loss: 1.064522e-02\n",
            "Loss: 1.064273e-02\n",
            "Loss: 1.064210e-02\n",
            "Loss: 1.064080e-02\n",
            "Loss: 1.063786e-02\n",
            "Loss: 1.063505e-02\n",
            "Loss: 1.063862e-02\n",
            "Loss: 1.063378e-02\n",
            "Loss: 1.063188e-02\n",
            "Loss: 1.063048e-02\n",
            "Loss: 1.062877e-02\n",
            "Loss: 1.062878e-02\n",
            "Loss: 1.062832e-02\n",
            "Loss: 1.062686e-02\n",
            "Loss: 1.062528e-02\n",
            "Loss: 1.062330e-02\n",
            "Loss: 1.062365e-02\n",
            "Loss: 1.062164e-02\n",
            "Loss: 1.062083e-02\n",
            "Loss: 1.061909e-02\n",
            "Loss: 1.061798e-02\n",
            "Loss: 1.061573e-02\n",
            "Loss: 1.061581e-02\n",
            "Loss: 1.061475e-02\n",
            "Loss: 1.061206e-02\n",
            "Loss: 1.061051e-02\n",
            "Loss: 1.060663e-02\n",
            "Loss: 1.060483e-02\n",
            "Loss: 1.060249e-02\n",
            "Loss: 1.060136e-02\n",
            "Loss: 1.060034e-02\n",
            "Loss: 1.059937e-02\n",
            "Loss: 1.059632e-02\n",
            "Loss: 1.059523e-02\n",
            "Loss: 1.059330e-02\n",
            "Loss: 1.059108e-02\n",
            "Loss: 1.058977e-02\n",
            "Loss: 1.058766e-02\n",
            "Loss: 1.058825e-02\n",
            "Loss: 1.058638e-02\n",
            "Loss: 1.058405e-02\n",
            "Loss: 1.058193e-02\n",
            "Loss: 1.057844e-02\n",
            "Loss: 1.057696e-02\n",
            "Loss: 1.057478e-02\n",
            "Loss: 1.057315e-02\n",
            "Loss: 1.057131e-02\n",
            "Loss: 1.056799e-02\n",
            "Loss: 1.056629e-02\n",
            "Loss: 1.056398e-02\n",
            "Loss: 1.056365e-02\n",
            "Loss: 1.056245e-02\n",
            "Loss: 1.055966e-02\n",
            "Loss: 1.055709e-02\n",
            "Loss: 1.055541e-02\n",
            "Loss: 1.055448e-02\n",
            "Loss: 1.055329e-02\n",
            "Loss: 1.055110e-02\n",
            "Loss: 1.055088e-02\n",
            "Loss: 1.054948e-02\n",
            "Loss: 1.054670e-02\n",
            "Loss: 1.054517e-02\n",
            "Loss: 1.054338e-02\n",
            "Loss: 1.054122e-02\n",
            "Loss: 1.053944e-02\n",
            "Loss: 1.053783e-02\n",
            "Loss: 1.053667e-02\n",
            "Loss: 1.053579e-02\n",
            "Loss: 1.053404e-02\n",
            "Loss: 1.053263e-02\n",
            "Loss: 1.053079e-02\n",
            "Loss: 1.053024e-02\n",
            "Loss: 1.052855e-02\n",
            "Loss: 1.052796e-02\n",
            "Loss: 1.052674e-02\n",
            "Loss: 1.052488e-02\n",
            "Loss: 1.052515e-02\n",
            "Loss: 1.052357e-02\n",
            "Loss: 1.052194e-02\n",
            "Loss: 1.052054e-02\n",
            "Loss: 1.051883e-02\n",
            "Loss: 1.051715e-02\n",
            "Loss: 1.051529e-02\n",
            "Loss: 1.051298e-02\n",
            "Loss: 1.051131e-02\n",
            "Loss: 1.050961e-02\n",
            "Loss: 1.050860e-02\n",
            "Loss: 1.050716e-02\n",
            "Loss: 1.050597e-02\n",
            "Loss: 1.050517e-02\n",
            "Loss: 1.050411e-02\n",
            "Loss: 1.050265e-02\n",
            "Loss: 1.050007e-02\n",
            "Loss: 1.050026e-02\n",
            "Loss: 1.049927e-02\n",
            "Loss: 1.049790e-02\n",
            "Loss: 1.049554e-02\n",
            "Loss: 1.049277e-02\n",
            "Loss: 1.048958e-02\n",
            "Loss: 1.048746e-02\n",
            "Loss: 1.048555e-02\n",
            "Loss: 1.048390e-02\n",
            "Loss: 1.048282e-02\n",
            "Loss: 1.048062e-02\n",
            "Loss: 1.048202e-02\n",
            "Loss: 1.048004e-02\n",
            "Loss: 1.047858e-02\n",
            "Loss: 1.047720e-02\n",
            "Loss: 1.047415e-02\n",
            "Loss: 1.047604e-02\n",
            "Loss: 1.047296e-02\n",
            "Loss: 1.046986e-02\n",
            "Loss: 1.046738e-02\n",
            "Loss: 1.046440e-02\n",
            "Loss: 1.046133e-02\n",
            "Loss: 1.046051e-02\n",
            "Loss: 1.045635e-02\n",
            "Loss: 1.045481e-02\n",
            "Loss: 1.045266e-02\n",
            "Loss: 1.044992e-02\n",
            "Loss: 1.045030e-02\n",
            "Loss: 1.044827e-02\n",
            "Loss: 1.044421e-02\n",
            "Loss: 1.044130e-02\n",
            "Loss: 1.043851e-02\n",
            "Loss: 1.044126e-02\n",
            "Loss: 1.043762e-02\n",
            "Loss: 1.043604e-02\n",
            "Loss: 1.043419e-02\n",
            "Loss: 1.043295e-02\n",
            "Loss: 1.043591e-02\n",
            "Loss: 1.043194e-02\n",
            "Loss: 1.043076e-02\n",
            "Loss: 1.042882e-02\n",
            "Loss: 1.042728e-02\n",
            "Loss: 1.042463e-02\n",
            "Loss: 1.042131e-02\n",
            "Loss: 1.041967e-02\n",
            "Loss: 1.041794e-02\n",
            "Loss: 1.041714e-02\n",
            "Loss: 1.041575e-02\n",
            "Loss: 1.041285e-02\n",
            "Loss: 1.041663e-02\n",
            "Loss: 1.041193e-02\n",
            "Loss: 1.040980e-02\n",
            "Loss: 1.040835e-02\n",
            "Loss: 1.040655e-02\n",
            "Loss: 1.040557e-02\n",
            "Loss: 1.040234e-02\n",
            "Loss: 1.040103e-02\n",
            "Loss: 1.039777e-02\n",
            "Loss: 1.039969e-02\n",
            "Loss: 1.039607e-02\n",
            "Loss: 1.039334e-02\n",
            "Loss: 1.039142e-02\n",
            "Loss: 1.038967e-02\n",
            "Loss: 1.038652e-02\n",
            "Loss: 1.038311e-02\n",
            "Loss: 1.037873e-02\n",
            "Loss: 1.037602e-02\n",
            "Loss: 1.037305e-02\n",
            "Loss: 1.037648e-02\n",
            "Loss: 1.037204e-02\n",
            "Loss: 1.037036e-02\n",
            "Loss: 1.036870e-02\n",
            "Loss: 1.036597e-02\n",
            "Loss: 1.036339e-02\n",
            "Loss: 1.036088e-02\n",
            "Loss: 1.035900e-02\n",
            "Loss: 1.035745e-02\n",
            "Loss: 1.035671e-02\n",
            "Loss: 1.035525e-02\n",
            "Loss: 1.035274e-02\n",
            "Loss: 1.035470e-02\n",
            "Loss: 1.035152e-02\n",
            "Loss: 1.034980e-02\n",
            "Loss: 1.034751e-02\n",
            "Loss: 1.034680e-02\n",
            "Loss: 1.034464e-02\n",
            "Loss: 1.034449e-02\n",
            "Loss: 1.034345e-02\n",
            "Loss: 1.034108e-02\n",
            "Loss: 1.033975e-02\n",
            "Loss: 1.033911e-02\n",
            "Loss: 1.033794e-02\n",
            "Loss: 1.033628e-02\n",
            "Loss: 1.033474e-02\n",
            "Loss: 1.033240e-02\n",
            "Loss: 1.033206e-02\n",
            "Loss: 1.033015e-02\n",
            "Loss: 1.032887e-02\n",
            "Loss: 1.032779e-02\n",
            "Loss: 1.032534e-02\n",
            "Loss: 1.032148e-02\n",
            "Loss: 1.033131e-02\n",
            "Loss: 1.031995e-02\n",
            "Loss: 1.031800e-02\n",
            "Loss: 1.031682e-02\n",
            "Loss: 1.031565e-02\n",
            "Loss: 1.031320e-02\n",
            "Loss: 1.031085e-02\n",
            "Loss: 1.030829e-02\n",
            "Loss: 1.030647e-02\n",
            "Loss: 1.030428e-02\n",
            "Loss: 1.030277e-02\n",
            "Loss: 1.030158e-02\n",
            "Loss: 1.029781e-02\n",
            "Loss: 1.029685e-02\n",
            "Loss: 1.029498e-02\n",
            "Loss: 1.029533e-02\n",
            "Loss: 1.029407e-02\n",
            "Loss: 1.029252e-02\n",
            "Loss: 1.028863e-02\n",
            "Loss: 1.028709e-02\n",
            "Loss: 1.028505e-02\n",
            "Loss: 1.028174e-02\n",
            "Loss: 1.028328e-02\n",
            "Loss: 1.028036e-02\n",
            "Loss: 1.027761e-02\n",
            "Loss: 1.027616e-02\n",
            "Loss: 1.027500e-02\n",
            "Loss: 1.027406e-02\n",
            "Loss: 1.027215e-02\n",
            "Loss: 1.027044e-02\n",
            "Loss: 1.026777e-02\n",
            "Loss: 1.026511e-02\n",
            "Loss: 1.026355e-02\n",
            "Loss: 1.026196e-02\n",
            "Loss: 1.025986e-02\n",
            "Loss: 1.025656e-02\n",
            "Loss: 1.025558e-02\n",
            "Loss: 1.025285e-02\n",
            "Loss: 1.025176e-02\n",
            "Loss: 1.024988e-02\n",
            "Loss: 1.024679e-02\n",
            "Loss: 1.024417e-02\n",
            "Loss: 1.024370e-02\n",
            "Loss: 1.024194e-02\n",
            "Loss: 1.024163e-02\n",
            "Loss: 1.024062e-02\n",
            "Loss: 1.023845e-02\n",
            "Loss: 1.023685e-02\n",
            "Loss: 1.023486e-02\n",
            "Loss: 1.023247e-02\n",
            "Loss: 1.023558e-02\n",
            "Loss: 1.023119e-02\n",
            "Loss: 1.022764e-02\n",
            "Loss: 1.022652e-02\n",
            "Loss: 1.022526e-02\n",
            "Loss: 1.022368e-02\n",
            "Loss: 1.022142e-02\n",
            "Loss: 1.022110e-02\n",
            "Loss: 1.021840e-02\n",
            "Loss: 1.021746e-02\n",
            "Loss: 1.021674e-02\n",
            "Loss: 1.021530e-02\n",
            "Loss: 1.021307e-02\n",
            "Loss: 1.021246e-02\n",
            "Loss: 1.020919e-02\n",
            "Loss: 1.020855e-02\n",
            "Loss: 1.020752e-02\n",
            "Loss: 1.020566e-02\n",
            "Loss: 1.020866e-02\n",
            "Loss: 1.020377e-02\n",
            "Loss: 1.020095e-02\n",
            "Loss: 1.020002e-02\n",
            "Loss: 1.019883e-02\n",
            "Loss: 1.019756e-02\n",
            "Loss: 1.019653e-02\n",
            "Loss: 1.019557e-02\n",
            "Loss: 1.019336e-02\n",
            "Loss: 1.019272e-02\n",
            "Loss: 1.018879e-02\n",
            "Loss: 1.018775e-02\n",
            "Loss: 1.018599e-02\n",
            "Loss: 1.018528e-02\n",
            "Loss: 1.018292e-02\n",
            "Loss: 1.018101e-02\n",
            "Loss: 1.017995e-02\n",
            "Loss: 1.017842e-02\n",
            "Loss: 1.017881e-02\n",
            "Loss: 1.017744e-02\n",
            "Loss: 1.017502e-02\n",
            "Loss: 1.017277e-02\n",
            "Loss: 1.016973e-02\n",
            "Loss: 1.016782e-02\n",
            "Loss: 1.016534e-02\n",
            "Loss: 1.016402e-02\n",
            "Loss: 1.016189e-02\n",
            "Loss: 1.016097e-02\n",
            "Loss: 1.015995e-02\n",
            "Loss: 1.016021e-02\n",
            "Loss: 1.015890e-02\n",
            "Loss: 1.015719e-02\n",
            "Loss: 1.015577e-02\n",
            "Loss: 1.015403e-02\n",
            "Loss: 1.015424e-02\n",
            "Loss: 1.015327e-02\n",
            "Loss: 1.015255e-02\n",
            "Loss: 1.015171e-02\n",
            "Loss: 1.014941e-02\n",
            "Loss: 1.016303e-02\n",
            "Loss: 1.014915e-02\n",
            "Loss: 1.014764e-02\n",
            "Loss: 1.014650e-02\n",
            "Loss: 1.014540e-02\n",
            "Loss: 1.014371e-02\n",
            "Loss: 1.014305e-02\n",
            "Loss: 1.014080e-02\n",
            "Loss: 1.013947e-02\n",
            "Loss: 1.013797e-02\n",
            "Loss: 1.013657e-02\n",
            "Loss: 1.013500e-02\n",
            "Loss: 1.013303e-02\n",
            "Loss: 1.013153e-02\n",
            "Loss: 1.013209e-02\n",
            "Loss: 1.013039e-02\n",
            "Loss: 1.012892e-02\n",
            "Loss: 1.012698e-02\n",
            "Loss: 1.012542e-02\n",
            "Loss: 1.012341e-02\n",
            "Loss: 1.012253e-02\n",
            "Loss: 1.011983e-02\n",
            "Loss: 1.011813e-02\n",
            "Loss: 1.011638e-02\n",
            "Loss: 1.011373e-02\n",
            "Loss: 1.011109e-02\n",
            "Loss: 1.011016e-02\n",
            "Loss: 1.010760e-02\n",
            "Loss: 1.010538e-02\n",
            "Loss: 1.010144e-02\n",
            "Loss: 1.009969e-02\n",
            "Loss: 1.009754e-02\n",
            "Loss: 1.009616e-02\n",
            "Loss: 1.009532e-02\n",
            "Loss: 1.009426e-02\n",
            "Loss: 1.009226e-02\n",
            "Loss: 1.009154e-02\n",
            "Loss: 1.009020e-02\n",
            "Loss: 1.008757e-02\n",
            "Loss: 1.008664e-02\n",
            "Loss: 1.008431e-02\n",
            "Loss: 1.008171e-02\n",
            "Loss: 1.007978e-02\n",
            "Loss: 1.007742e-02\n",
            "Loss: 1.007659e-02\n",
            "Loss: 1.007544e-02\n",
            "Loss: 1.007504e-02\n",
            "Loss: 1.007303e-02\n",
            "Loss: 1.007220e-02\n",
            "Loss: 1.006997e-02\n",
            "Loss: 1.006731e-02\n",
            "Loss: 1.008285e-02\n",
            "Loss: 1.006651e-02\n",
            "Loss: 1.006464e-02\n",
            "Loss: 1.006379e-02\n",
            "Loss: 1.006224e-02\n",
            "Loss: 1.006369e-02\n",
            "Loss: 1.006166e-02\n",
            "Loss: 1.006076e-02\n",
            "Loss: 1.005955e-02\n",
            "Loss: 1.005928e-02\n",
            "Loss: 1.005678e-02\n",
            "Loss: 1.005410e-02\n",
            "Loss: 1.005676e-02\n",
            "Loss: 1.005258e-02\n",
            "Loss: 1.005055e-02\n",
            "Loss: 1.004940e-02\n",
            "Loss: 1.004748e-02\n",
            "Loss: 1.004453e-02\n",
            "Loss: 1.004105e-02\n",
            "Loss: 1.003850e-02\n",
            "Loss: 1.003899e-02\n",
            "Loss: 1.003769e-02\n",
            "Loss: 1.003672e-02\n",
            "Loss: 1.003297e-02\n",
            "Loss: 1.002882e-02\n",
            "Loss: 1.002823e-02\n",
            "Loss: 1.002385e-02\n",
            "Loss: 1.002266e-02\n",
            "Loss: 1.002129e-02\n",
            "Loss: 1.001894e-02\n",
            "Loss: 1.002316e-02\n",
            "Loss: 1.001796e-02\n",
            "Loss: 1.001646e-02\n",
            "Loss: 1.001404e-02\n",
            "Loss: 1.001226e-02\n",
            "Loss: 1.000760e-02\n",
            "Loss: 1.000966e-02\n",
            "Loss: 1.000521e-02\n",
            "Loss: 1.000169e-02\n",
            "Loss: 9.998755e-03\n",
            "Loss: 1.001283e-02\n",
            "Loss: 9.998087e-03\n",
            "Loss: 9.996221e-03\n",
            "Loss: 9.995369e-03\n",
            "Loss: 9.993194e-03\n",
            "Loss: 9.991465e-03\n",
            "Loss: 9.989141e-03\n",
            "Loss: 9.987392e-03\n",
            "Loss: 9.984458e-03\n",
            "Loss: 9.982244e-03\n",
            "Loss: 9.979578e-03\n",
            "Loss: 9.976747e-03\n",
            "Loss: 9.975599e-03\n",
            "Loss: 9.974573e-03\n",
            "Loss: 9.973658e-03\n",
            "Loss: 9.972055e-03\n",
            "Loss: 9.970401e-03\n",
            "Loss: 9.967708e-03\n",
            "Loss: 9.965464e-03\n",
            "Loss: 9.962889e-03\n",
            "Loss: 9.962020e-03\n",
            "Loss: 9.960109e-03\n",
            "Loss: 9.958460e-03\n",
            "Loss: 9.957142e-03\n",
            "Loss: 9.955745e-03\n",
            "Loss: 9.954815e-03\n",
            "Loss: 9.953897e-03\n",
            "Loss: 9.951619e-03\n",
            "Loss: 9.949841e-03\n",
            "Loss: 9.948818e-03\n",
            "Loss: 9.948105e-03\n",
            "Loss: 9.946127e-03\n",
            "Loss: 9.943212e-03\n",
            "Loss: 9.941368e-03\n",
            "Loss: 9.939852e-03\n",
            "Loss: 9.938451e-03\n",
            "Loss: 9.936488e-03\n",
            "Loss: 9.934663e-03\n",
            "Loss: 9.933048e-03\n",
            "Loss: 9.932238e-03\n",
            "Loss: 9.930881e-03\n",
            "Loss: 9.929173e-03\n",
            "Loss: 9.927000e-03\n",
            "Loss: 9.925637e-03\n",
            "Loss: 9.923678e-03\n",
            "Loss: 9.922437e-03\n",
            "Loss: 9.921807e-03\n",
            "Loss: 9.920985e-03\n",
            "Loss: 9.919157e-03\n",
            "Loss: 9.917866e-03\n",
            "Loss: 9.916117e-03\n",
            "Loss: 9.914177e-03\n",
            "Loss: 9.910839e-03\n",
            "Loss: 9.927333e-03\n",
            "Loss: 9.910353e-03\n",
            "Loss: 9.908049e-03\n",
            "Loss: 9.906955e-03\n",
            "Loss: 9.905639e-03\n",
            "Loss: 9.903187e-03\n",
            "Loss: 9.902794e-03\n",
            "Loss: 9.899730e-03\n",
            "Loss: 9.899152e-03\n",
            "Loss: 9.897417e-03\n",
            "Loss: 9.895083e-03\n",
            "Loss: 9.892765e-03\n",
            "Loss: 9.889602e-03\n",
            "Loss: 9.887711e-03\n",
            "Loss: 9.885715e-03\n",
            "Loss: 9.884091e-03\n",
            "Loss: 9.881569e-03\n",
            "Loss: 9.878444e-03\n",
            "Loss: 9.876491e-03\n",
            "Loss: 9.881645e-03\n",
            "Loss: 9.875653e-03\n",
            "Loss: 9.873215e-03\n",
            "Loss: 9.871230e-03\n",
            "Loss: 9.869824e-03\n",
            "Loss: 9.869916e-03\n",
            "Loss: 9.868903e-03\n",
            "Loss: 9.868120e-03\n",
            "Loss: 9.866706e-03\n",
            "Loss: 9.865565e-03\n",
            "Loss: 9.862758e-03\n",
            "Loss: 9.860505e-03\n",
            "Loss: 9.858669e-03\n",
            "Loss: 9.857461e-03\n",
            "Loss: 9.855099e-03\n",
            "Loss: 9.853376e-03\n",
            "Loss: 9.851726e-03\n",
            "Loss: 9.850771e-03\n",
            "Loss: 9.849277e-03\n",
            "Loss: 9.846471e-03\n",
            "Loss: 9.845043e-03\n",
            "Loss: 9.842669e-03\n",
            "Loss: 9.841393e-03\n",
            "Loss: 9.839827e-03\n",
            "Loss: 9.837908e-03\n",
            "Loss: 9.835986e-03\n",
            "Loss: 9.834738e-03\n",
            "Loss: 9.832682e-03\n",
            "Loss: 9.830605e-03\n",
            "Loss: 9.828241e-03\n",
            "Loss: 9.825520e-03\n",
            "Loss: 9.826774e-03\n",
            "Loss: 9.824516e-03\n",
            "Loss: 9.823727e-03\n",
            "Loss: 9.821307e-03\n",
            "Loss: 9.820060e-03\n",
            "Loss: 9.817055e-03\n",
            "Loss: 9.820169e-03\n",
            "Loss: 9.816055e-03\n",
            "Loss: 9.813664e-03\n",
            "Loss: 9.812761e-03\n",
            "Loss: 9.810747e-03\n",
            "Loss: 9.809460e-03\n",
            "Loss: 9.807713e-03\n",
            "Loss: 9.807203e-03\n",
            "Loss: 9.806318e-03\n",
            "Loss: 9.804053e-03\n",
            "Loss: 9.817764e-03\n",
            "Loss: 9.803841e-03\n",
            "Loss: 9.801176e-03\n",
            "Loss: 9.798244e-03\n",
            "Loss: 9.796271e-03\n",
            "Loss: 9.795144e-03\n",
            "Loss: 9.792766e-03\n",
            "Loss: 9.790679e-03\n",
            "Loss: 9.787454e-03\n",
            "Loss: 9.785750e-03\n",
            "Loss: 9.781814e-03\n",
            "Loss: 9.781002e-03\n",
            "Loss: 9.780058e-03\n",
            "Loss: 9.778546e-03\n",
            "Loss: 9.778574e-03\n",
            "Loss: 9.777839e-03\n",
            "Loss: 9.776969e-03\n",
            "Loss: 9.774539e-03\n",
            "Loss: 9.773371e-03\n",
            "Loss: 9.770649e-03\n",
            "Loss: 9.768794e-03\n",
            "Loss: 9.765897e-03\n",
            "Loss: 9.764178e-03\n",
            "Loss: 9.760917e-03\n",
            "Loss: 9.763816e-03\n",
            "Loss: 9.759755e-03\n",
            "Loss: 9.757251e-03\n",
            "Loss: 9.754262e-03\n",
            "Loss: 9.751176e-03\n",
            "Loss: 9.748557e-03\n",
            "Loss: 9.745015e-03\n",
            "Loss: 9.745091e-03\n",
            "Loss: 9.744365e-03\n",
            "Loss: 9.742616e-03\n",
            "Loss: 9.741366e-03\n",
            "Loss: 9.740014e-03\n",
            "Loss: 9.737214e-03\n",
            "Loss: 9.737677e-03\n",
            "Loss: 9.735114e-03\n",
            "Loss: 9.733564e-03\n",
            "Loss: 9.732060e-03\n",
            "Loss: 9.730836e-03\n",
            "Loss: 9.729646e-03\n",
            "Loss: 9.727669e-03\n",
            "Loss: 9.736132e-03\n",
            "Loss: 9.727769e-03\n",
            "Loss: 9.728008e-03\n",
            "Loss: 9.727638e-03\n",
            "Loss: 9.727779e-03\n",
            "Loss: 9.727638e-03\n",
            "Loss: 9.728855e-03\n",
            "Loss: 9.727458e-03\n",
            "Loss: 9.726522e-03\n",
            "Loss: 9.725021e-03\n",
            "Loss: 9.726040e-03\n",
            "Loss: 9.723664e-03\n",
            "Loss: 9.721830e-03\n",
            "Loss: 9.720615e-03\n",
            "Loss: 9.719033e-03\n",
            "Loss: 9.718182e-03\n",
            "Loss: 9.724826e-03\n",
            "Loss: 9.716985e-03\n",
            "Loss: 9.715403e-03\n",
            "Loss: 9.713999e-03\n",
            "Loss: 9.713124e-03\n",
            "Loss: 9.712419e-03\n",
            "Loss: 9.711022e-03\n",
            "Loss: 9.708668e-03\n",
            "Loss: 9.709517e-03\n",
            "Loss: 9.707085e-03\n",
            "Loss: 9.705084e-03\n",
            "Loss: 9.703171e-03\n",
            "Loss: 9.702086e-03\n",
            "Loss: 9.700643e-03\n",
            "Loss: 9.698501e-03\n",
            "Loss: 9.697516e-03\n",
            "Loss: 9.696265e-03\n",
            "Loss: 9.695023e-03\n",
            "Loss: 9.693707e-03\n",
            "Loss: 9.692472e-03\n",
            "Loss: 9.690595e-03\n",
            "Loss: 9.700559e-03\n",
            "Loss: 9.689370e-03\n",
            "Loss: 9.687723e-03\n",
            "Loss: 9.684862e-03\n",
            "Loss: 9.683128e-03\n",
            "Loss: 9.681260e-03\n",
            "Loss: 9.682966e-03\n",
            "Loss: 9.679934e-03\n",
            "Loss: 9.678694e-03\n",
            "Loss: 9.677762e-03\n",
            "Loss: 9.676119e-03\n",
            "Loss: 9.673809e-03\n",
            "Loss: 9.671073e-03\n",
            "Loss: 9.669767e-03\n",
            "Loss: 9.667548e-03\n",
            "Loss: 9.666501e-03\n",
            "Loss: 9.664933e-03\n",
            "Loss: 9.663798e-03\n",
            "Loss: 9.662707e-03\n",
            "Loss: 9.661607e-03\n",
            "Loss: 9.659433e-03\n",
            "Loss: 9.657914e-03\n",
            "Loss: 9.656920e-03\n",
            "Loss: 9.656154e-03\n",
            "Loss: 9.654427e-03\n",
            "Loss: 9.652679e-03\n",
            "Loss: 9.651505e-03\n",
            "Loss: 9.650239e-03\n",
            "Loss: 9.649514e-03\n",
            "Loss: 9.648897e-03\n",
            "Loss: 9.646792e-03\n",
            "Loss: 9.646227e-03\n",
            "Loss: 9.644373e-03\n",
            "Loss: 9.643884e-03\n",
            "Loss: 9.641943e-03\n",
            "Loss: 9.641938e-03\n",
            "Loss: 9.640380e-03\n",
            "Loss: 9.640027e-03\n",
            "Loss: 9.639470e-03\n",
            "Loss: 9.638006e-03\n",
            "Loss: 9.637826e-03\n",
            "Loss: 9.636235e-03\n",
            "Loss: 9.633248e-03\n",
            "Loss: 9.631401e-03\n",
            "Loss: 9.630056e-03\n",
            "Loss: 9.628202e-03\n",
            "Loss: 9.628924e-03\n",
            "Loss: 9.627211e-03\n",
            "Loss: 9.624731e-03\n",
            "Loss: 9.623411e-03\n",
            "Loss: 9.621581e-03\n",
            "Loss: 9.623594e-03\n",
            "Loss: 9.620298e-03\n",
            "Loss: 9.618930e-03\n",
            "Loss: 9.616077e-03\n",
            "Loss: 9.614778e-03\n",
            "Loss: 9.613233e-03\n",
            "Loss: 9.613598e-03\n",
            "Loss: 9.612260e-03\n",
            "Loss: 9.610049e-03\n",
            "Loss: 9.608418e-03\n",
            "Loss: 9.607723e-03\n",
            "Loss: 9.606337e-03\n",
            "Loss: 9.604598e-03\n",
            "Loss: 9.602504e-03\n",
            "Loss: 9.600461e-03\n",
            "Loss: 9.598585e-03\n",
            "Loss: 9.596816e-03\n",
            "Loss: 9.595053e-03\n",
            "Loss: 9.592587e-03\n",
            "Loss: 9.591248e-03\n",
            "Loss: 9.589464e-03\n",
            "Loss: 9.586629e-03\n",
            "Loss: 9.600040e-03\n",
            "Loss: 9.585641e-03\n",
            "Loss: 9.582874e-03\n",
            "Loss: 9.580983e-03\n",
            "Loss: 9.579322e-03\n",
            "Loss: 9.577283e-03\n",
            "Loss: 9.577002e-03\n",
            "Loss: 9.575287e-03\n",
            "Loss: 9.572559e-03\n",
            "Loss: 9.570903e-03\n",
            "Loss: 9.568242e-03\n",
            "Loss: 9.566576e-03\n",
            "Loss: 9.564403e-03\n",
            "Loss: 9.561790e-03\n",
            "Loss: 9.560615e-03\n",
            "Loss: 9.559542e-03\n",
            "Loss: 9.558314e-03\n",
            "Loss: 9.556826e-03\n",
            "Loss: 9.555249e-03\n",
            "Loss: 9.552699e-03\n",
            "Loss: 9.551178e-03\n",
            "Loss: 9.553787e-03\n",
            "Loss: 9.550727e-03\n",
            "Loss: 9.549452e-03\n",
            "Loss: 9.547670e-03\n",
            "Loss: 9.544845e-03\n",
            "Loss: 9.542694e-03\n",
            "Loss: 9.539314e-03\n",
            "Loss: 9.537659e-03\n",
            "Loss: 9.534414e-03\n",
            "Loss: 9.533406e-03\n",
            "Loss: 9.531052e-03\n",
            "Loss: 9.531908e-03\n",
            "Loss: 9.529702e-03\n",
            "Loss: 9.527227e-03\n",
            "Loss: 9.526202e-03\n",
            "Loss: 9.524275e-03\n",
            "Loss: 9.526320e-03\n",
            "Loss: 9.522775e-03\n",
            "Loss: 9.521781e-03\n",
            "Loss: 9.519635e-03\n",
            "Loss: 9.519413e-03\n",
            "Loss: 9.517495e-03\n",
            "Loss: 9.516385e-03\n",
            "Loss: 9.515914e-03\n",
            "Loss: 9.514949e-03\n",
            "Loss: 9.514351e-03\n",
            "Loss: 9.511285e-03\n",
            "Loss: 9.509594e-03\n",
            "Loss: 9.507221e-03\n",
            "Loss: 9.505531e-03\n",
            "Loss: 9.502850e-03\n",
            "Loss: 9.500482e-03\n",
            "Loss: 9.498823e-03\n",
            "Loss: 9.497351e-03\n",
            "Loss: 9.496008e-03\n",
            "Loss: 9.493212e-03\n",
            "Loss: 9.492718e-03\n",
            "Loss: 9.489561e-03\n",
            "Loss: 9.488534e-03\n",
            "Loss: 9.486908e-03\n",
            "Loss: 9.484304e-03\n",
            "Loss: 9.480109e-03\n",
            "Loss: 9.479844e-03\n",
            "Loss: 9.477800e-03\n",
            "Loss: 9.475694e-03\n",
            "Loss: 9.474315e-03\n",
            "Loss: 9.472648e-03\n",
            "Loss: 9.470958e-03\n",
            "Loss: 9.467516e-03\n",
            "Loss: 9.466120e-03\n",
            "Loss: 9.464695e-03\n",
            "Loss: 9.463976e-03\n",
            "Loss: 9.463027e-03\n",
            "Loss: 9.460517e-03\n",
            "Loss: 9.459597e-03\n",
            "Loss: 9.458814e-03\n",
            "Loss: 9.457760e-03\n",
            "Loss: 9.456798e-03\n",
            "Loss: 9.456423e-03\n",
            "Loss: 9.454662e-03\n",
            "Loss: 9.451607e-03\n",
            "Loss: 9.492883e-03\n",
            "Loss: 9.451098e-03\n",
            "Loss: 9.448089e-03\n",
            "Loss: 9.446872e-03\n",
            "Loss: 9.445711e-03\n",
            "Loss: 9.443205e-03\n",
            "Loss: 9.446317e-03\n",
            "Loss: 9.441495e-03\n",
            "Loss: 9.438986e-03\n",
            "Loss: 9.437827e-03\n",
            "Loss: 9.436089e-03\n",
            "Loss: 9.437371e-03\n",
            "Loss: 9.435342e-03\n",
            "Loss: 9.433283e-03\n",
            "Loss: 9.431430e-03\n",
            "Loss: 9.429554e-03\n",
            "Loss: 9.433059e-03\n",
            "Loss: 9.429348e-03\n",
            "Loss: 9.427981e-03\n",
            "Loss: 9.425635e-03\n",
            "Loss: 9.424157e-03\n",
            "Loss: 9.421898e-03\n",
            "Loss: 9.421987e-03\n",
            "Loss: 9.421105e-03\n",
            "Loss: 9.418856e-03\n",
            "Loss: 9.417268e-03\n",
            "Loss: 9.414402e-03\n",
            "Loss: 9.412523e-03\n",
            "Loss: 9.410445e-03\n",
            "Loss: 9.408771e-03\n",
            "Loss: 9.407131e-03\n",
            "Loss: 9.404650e-03\n",
            "Loss: 9.401826e-03\n",
            "Loss: 9.400075e-03\n",
            "Loss: 9.397770e-03\n",
            "Loss: 9.397339e-03\n",
            "Loss: 9.395286e-03\n",
            "Loss: 9.394468e-03\n",
            "Loss: 9.393820e-03\n",
            "Loss: 9.392509e-03\n",
            "Loss: 9.390549e-03\n",
            "Loss: 9.388646e-03\n",
            "Loss: 9.386864e-03\n",
            "Loss: 9.386615e-03\n",
            "Loss: 9.385563e-03\n",
            "Loss: 9.384671e-03\n",
            "Loss: 9.398587e-03\n",
            "Loss: 9.384156e-03\n",
            "Loss: 9.383684e-03\n",
            "Loss: 9.382229e-03\n",
            "Loss: 9.380989e-03\n",
            "Loss: 9.380260e-03\n",
            "Loss: 9.389201e-03\n",
            "Loss: 9.380171e-03\n",
            "Loss: 9.379669e-03\n",
            "Loss: 9.378619e-03\n",
            "Loss: 9.378291e-03\n",
            "Loss: 9.377369e-03\n",
            "Loss: 9.375654e-03\n",
            "Loss: 9.374630e-03\n",
            "Loss: 9.374609e-03\n",
            "Loss: 9.372443e-03\n",
            "Loss: 9.372517e-03\n",
            "Loss: 9.373066e-03\n",
            "Loss: 9.372651e-03\n",
            "Loss: 9.372406e-03\n",
            "Loss: 9.372405e-03\n",
            "Loss: 9.372676e-03\n",
            "Loss: 9.372427e-03\n",
            "Loss: 9.372405e-03\n",
            "Loss: 9.372571e-03\n",
            "Loss: 9.372942e-03\n",
            "Loss: 9.372586e-03\n",
            "Loss: 9.372424e-03\n",
            "Loss: 9.372405e-03\n",
            "Loss: 9.372405e-03\n",
            "Loss: 9.372405e-03\n",
            "Loss: 9.372405e-03\n",
            "Loss: 9.372405e-03\n",
            "Loss: 9.372405e-03\n",
            "Loss: 9.372405e-03\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.009372\n",
            "  Number of iterations: 15001\n",
            "  Number of functions evaluations: 16183\n",
            "Error u: 1.584191e-01\n",
            "Error u (idn): 1.690445e-01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6erME2d8M1Jx"
      },
      "source": [
        "## Plotting: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OIA8gDKNMV4",
        "outputId": "b757da60-51dd-45c9-d91a-604e3e5ba155",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from matplotlib import rc\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "rc('text', usetex=True)\r\n",
        "mpl.rcParams['text.latex.preamble'] = [r'\\usepackage{amsmath}']\r\n",
        "!apt install texlive-fonts-recommended texlive-fonts-extra cm-super dvipng"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cm-super-minimal fonts-adf-accanthis fonts-adf-berenis fonts-adf-gillius\n",
            "  fonts-adf-universalis fonts-cabin fonts-comfortaa fonts-croscore\n",
            "  fonts-crosextra-caladea fonts-crosextra-carlito fonts-dejavu-core\n",
            "  fonts-dejavu-extra fonts-droid-fallback fonts-ebgaramond\n",
            "  fonts-ebgaramond-extra fonts-font-awesome fonts-freefont-otf\n",
            "  fonts-freefont-ttf fonts-gfs-artemisia fonts-gfs-complutum fonts-gfs-didot\n",
            "  fonts-gfs-neohellenic fonts-gfs-olga fonts-gfs-solomos fonts-go\n",
            "  fonts-junicode fonts-lato fonts-linuxlibertine fonts-lmodern fonts-lobster\n",
            "  fonts-lobstertwo fonts-noto-hinted fonts-noto-mono fonts-oflb-asana-math\n",
            "  fonts-open-sans fonts-roboto-hinted fonts-sil-gentium\n",
            "  fonts-sil-gentium-basic fonts-sil-gentiumplus fonts-sil-gentiumplus-compact\n",
            "  fonts-stix fonts-texgyre ghostscript gsfonts javascript-common\n",
            "  libcupsfilters1 libcupsimage2 libgs9 libgs9-common libijs-0.35 libjbig2dec0\n",
            "  libjs-jquery libkpathsea6 libpotrace0 libptexenc1 libruby2.5 libsynctex1\n",
            "  libtexlua52 libtexluajit2 libzzip-0-13 lmodern pfb2t1c2pfb poppler-data\n",
            "  preview-latex-style rake ruby ruby-did-you-mean ruby-minitest\n",
            "  ruby-net-telnet ruby-power-assert ruby-test-unit ruby2.5\n",
            "  rubygems-integration t1utils tex-common tex-gyre texlive-base\n",
            "  texlive-binaries texlive-fonts-extra-links texlive-latex-base\n",
            "  texlive-latex-extra texlive-latex-recommended texlive-pictures\n",
            "  texlive-plain-generic tipa\n",
            "Suggested packages:\n",
            "  fonts-noto fontforge ghostscript-x apache2 | lighttpd | httpd poppler-utils\n",
            "  fonts-japanese-mincho | fonts-ipafont-mincho fonts-japanese-gothic\n",
            "  | fonts-ipafont-gothic fonts-arphic-ukai fonts-arphic-uming fonts-nanum ri\n",
            "  ruby-dev bundler debhelper perl-tk xpdf-reader | pdf-viewer\n",
            "  texlive-fonts-extra-doc texlive-fonts-recommended-doc texlive-latex-base-doc\n",
            "  python-pygments icc-profiles libfile-which-perl\n",
            "  libspreadsheet-parseexcel-perl texlive-latex-extra-doc\n",
            "  texlive-latex-recommended-doc texlive-pstricks dot2tex prerex ruby-tcltk\n",
            "  | libtcltk-ruby texlive-pictures-doc vprerex\n",
            "The following NEW packages will be installed:\n",
            "  cm-super cm-super-minimal dvipng fonts-adf-accanthis fonts-adf-berenis\n",
            "  fonts-adf-gillius fonts-adf-universalis fonts-cabin fonts-comfortaa\n",
            "  fonts-croscore fonts-crosextra-caladea fonts-crosextra-carlito\n",
            "  fonts-dejavu-core fonts-dejavu-extra fonts-droid-fallback fonts-ebgaramond\n",
            "  fonts-ebgaramond-extra fonts-font-awesome fonts-freefont-otf\n",
            "  fonts-freefont-ttf fonts-gfs-artemisia fonts-gfs-complutum fonts-gfs-didot\n",
            "  fonts-gfs-neohellenic fonts-gfs-olga fonts-gfs-solomos fonts-go\n",
            "  fonts-junicode fonts-lato fonts-linuxlibertine fonts-lmodern fonts-lobster\n",
            "  fonts-lobstertwo fonts-noto-hinted fonts-noto-mono fonts-oflb-asana-math\n",
            "  fonts-open-sans fonts-roboto-hinted fonts-sil-gentium\n",
            "  fonts-sil-gentium-basic fonts-sil-gentiumplus fonts-sil-gentiumplus-compact\n",
            "  fonts-stix fonts-texgyre ghostscript gsfonts javascript-common\n",
            "  libcupsfilters1 libcupsimage2 libgs9 libgs9-common libijs-0.35 libjbig2dec0\n",
            "  libjs-jquery libkpathsea6 libpotrace0 libptexenc1 libruby2.5 libsynctex1\n",
            "  libtexlua52 libtexluajit2 libzzip-0-13 lmodern pfb2t1c2pfb poppler-data\n",
            "  preview-latex-style rake ruby ruby-did-you-mean ruby-minitest\n",
            "  ruby-net-telnet ruby-power-assert ruby-test-unit ruby2.5\n",
            "  rubygems-integration t1utils tex-common tex-gyre texlive-base\n",
            "  texlive-binaries texlive-fonts-extra texlive-fonts-extra-links\n",
            "  texlive-fonts-recommended texlive-latex-base texlive-latex-extra\n",
            "  texlive-latex-recommended texlive-pictures texlive-plain-generic tipa\n",
            "0 upgraded, 89 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 554 MB of archives.\n",
            "After this operation, 1,550 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lato all 2.0-2 [2,698 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 poppler-data all 0.4.8-2 [1,479 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 tex-common all 6.09 [33.0 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkpathsea6 amd64 2017.20170613.44572-8ubuntu0.1 [54.9 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libptexenc1 amd64 2017.20170613.44572-8ubuntu0.1 [34.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsynctex1 amd64 2017.20170613.44572-8ubuntu0.1 [41.4 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexlua52 amd64 2017.20170613.44572-8ubuntu0.1 [91.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexluajit2 amd64 2017.20170613.44572-8ubuntu0.1 [230 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 t1utils amd64 1.41-2 [56.0 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsimage2 amd64 2.2.7-1ubuntu2.8 [18.6 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libijs-0.35 amd64 0.35-13 [15.5 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig2dec0 amd64 0.13-6 [55.9 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9-common all 9.26~dfsg+0-0ubuntu0.18.04.14 [5,092 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9 amd64 9.26~dfsg+0-0ubuntu0.18.04.14 [2,265 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpotrace0 amd64 1.14-2 [17.4 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libzzip-0-13 amd64 0.13.62-3.1ubuntu0.18.04.1 [26.0 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 texlive-binaries amd64 2017.20170613.44572-8ubuntu0.1 [8,179 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-base all 2017.20180305-1 [18.7 MB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lmodern all 2.004.5-3 [4,551 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-base all 2017.20180305-1 [951 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-recommended all 2017.20180305-1 [14.9 MB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cm-super-minimal all 0.3.4-11 [5,810 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/universe amd64 pfb2t1c2pfb amd64 0.3-11 [9,342 B]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cm-super all 0.3.4-11 [18.7 MB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ghostscript amd64 9.26~dfsg+0-0ubuntu0.18.04.14 [51.3 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/universe amd64 dvipng amd64 1.15-1 [78.2 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-adf-accanthis all 0.20110505-1 [202 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-adf-berenis all 0.20110505-1 [281 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-adf-gillius all 0.20110505-1 [190 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-adf-universalis all 0.20110505-1 [111 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-cabin all 1.5-2 [140 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-comfortaa all 3.001-2 [129 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-croscore all 20171026-2 [2,135 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-crosextra-caladea all 20130214-2 [82.4 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-crosextra-carlito all 20130920-1 [742 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-ebgaramond all 0.016-1 [474 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-ebgaramond-extra all 0.016-1 [2,157 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-font-awesome all 4.7.0~dfsg-3 [513 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-freefont-otf all 20120503-7 [3,055 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-freefont-ttf all 20120503-7 [4,202 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-gfs-artemisia all 1.1-5 [260 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-gfs-complutum all 1.1-6 [41.6 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-gfs-didot all 1.1-6 [278 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-gfs-neohellenic all 1.1-6 [215 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-gfs-olga all 1.1-5 [33.4 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-gfs-solomos all 1.1-5 [40.7 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-go all 0~20161116-1 [348 kB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-junicode all 1.001-2 [684 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-linuxlibertine all 5.3.0-4 [1,627 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-lobster all 2.0-2 [38.7 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-lobstertwo all 2.0-2 [92.7 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-noto-hinted all 20171026-2 [6,653 kB]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-noto-mono all 20171026-2 [75.5 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-oflb-asana-math all 000.907-6 [246 kB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-open-sans all 1.11-1 [575 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-roboto-hinted all 2:0~20160106-2 [2,918 kB]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-sil-gentium all 20081126:1.03-2 [245 kB]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-sil-gentium-basic all 1.102-1 [384 kB]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-sil-gentiumplus all 5.000-2 [2,807 kB]\n",
            "Get:63 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-sil-gentiumplus-compact all 5.000-2 [1,514 kB]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-texgyre all 20160520-1 [8,761 kB]\n",
            "Get:65 http://archive.ubuntu.com/ubuntu bionic/main amd64 gsfonts all 1:8.11+urwcyr1.0.7~pre44-4.4 [3,120 kB]\n",
            "Get:66 http://archive.ubuntu.com/ubuntu bionic/main amd64 javascript-common all 11 [6,066 B]\n",
            "Get:67 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsfilters1 amd64 1.20.2-0ubuntu3.1 [108 kB]\n",
            "Get:68 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjs-jquery all 3.2.1-1 [152 kB]\n",
            "Get:69 http://archive.ubuntu.com/ubuntu bionic/main amd64 rubygems-integration all 1.11 [4,994 B]\n",
            "Get:70 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ruby2.5 amd64 2.5.1-1ubuntu1.7 [48.6 kB]\n",
            "Get:71 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby amd64 1:2.5.1 [5,712 B]\n",
            "Get:72 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 rake all 12.3.1-1ubuntu0.1 [44.9 kB]\n",
            "Get:73 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-did-you-mean all 1.2.0-2 [9,700 B]\n",
            "Get:74 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-minitest all 5.10.3-1 [38.6 kB]\n",
            "Get:75 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]\n",
            "Get:76 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-power-assert all 0.3.0-1 [7,952 B]\n",
            "Get:77 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-test-unit all 3.2.5-1 [61.1 kB]\n",
            "Get:78 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libruby2.5 amd64 2.5.1-1ubuntu1.7 [3,068 kB]\n",
            "Get:79 http://archive.ubuntu.com/ubuntu bionic/main amd64 lmodern all 2.004.5-3 [9,631 kB]\n",
            "Get:80 http://archive.ubuntu.com/ubuntu bionic/main amd64 preview-latex-style all 11.91-1ubuntu1 [185 kB]\n",
            "Get:81 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tex-gyre all 20160520-1 [4,998 kB]\n",
            "Get:82 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-fonts-extra all 2017.20180305-2 [354 MB]\n",
            "Get:83 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-stix all 1.1.1-4 [591 kB]\n",
            "Get:84 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-fonts-extra-links all 2017.20180305-2 [20.6 kB]\n",
            "Get:85 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-fonts-recommended all 2017.20180305-1 [5,262 kB]\n",
            "Get:86 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-pictures all 2017.20180305-1 [4,026 kB]\n",
            "Get:87 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-latex-extra all 2017.20180305-2 [10.6 MB]\n",
            "Get:88 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-plain-generic all 2017.20180305-2 [23.6 MB]\n",
            "Get:89 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tipa all 2:1.3-20 [2,978 kB]\n",
            "Fetched 554 MB in 18s (30.8 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 160975 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Selecting previously unselected package fonts-lato.\n",
            "Preparing to unpack .../01-fonts-lato_2.0-2_all.deb ...\n",
            "Unpacking fonts-lato (2.0-2) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../02-poppler-data_0.4.8-2_all.deb ...\n",
            "Unpacking poppler-data (0.4.8-2) ...\n",
            "Selecting previously unselected package tex-common.\n",
            "Preparing to unpack .../03-tex-common_6.09_all.deb ...\n",
            "Unpacking tex-common (6.09) ...\n",
            "Selecting previously unselected package libkpathsea6:amd64.\n",
            "Preparing to unpack .../04-libkpathsea6_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libptexenc1:amd64.\n",
            "Preparing to unpack .../05-libptexenc1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libsynctex1:amd64.\n",
            "Preparing to unpack .../06-libsynctex1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexlua52:amd64.\n",
            "Preparing to unpack .../07-libtexlua52_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexluajit2:amd64.\n",
            "Preparing to unpack .../08-libtexluajit2_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package t1utils.\n",
            "Preparing to unpack .../09-t1utils_1.41-2_amd64.deb ...\n",
            "Unpacking t1utils (1.41-2) ...\n",
            "Selecting previously unselected package libcupsimage2:amd64.\n",
            "Preparing to unpack .../10-libcupsimage2_2.2.7-1ubuntu2.8_amd64.deb ...\n",
            "Unpacking libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../11-libijs-0.35_0.35-13_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-13) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../12-libjbig2dec0_0.13-6_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.13-6) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../13-libgs9-common_9.26~dfsg+0-0ubuntu0.18.04.14_all.deb ...\n",
            "Unpacking libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../14-libgs9_9.26~dfsg+0-0ubuntu0.18.04.14_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Selecting previously unselected package libpotrace0.\n",
            "Preparing to unpack .../15-libpotrace0_1.14-2_amd64.deb ...\n",
            "Unpacking libpotrace0 (1.14-2) ...\n",
            "Selecting previously unselected package libzzip-0-13:amd64.\n",
            "Preparing to unpack .../16-libzzip-0-13_0.13.62-3.1ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package texlive-binaries.\n",
            "Preparing to unpack .../17-texlive-binaries_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package texlive-base.\n",
            "Preparing to unpack .../18-texlive-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package fonts-lmodern.\n",
            "Preparing to unpack .../19-fonts-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking fonts-lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package texlive-latex-base.\n",
            "Preparing to unpack .../20-texlive-latex-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-recommended.\n",
            "Preparing to unpack .../21-texlive-latex-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-recommended (2017.20180305-1) ...\n",
            "Selecting previously unselected package cm-super-minimal.\n",
            "Preparing to unpack .../22-cm-super-minimal_0.3.4-11_all.deb ...\n",
            "Unpacking cm-super-minimal (0.3.4-11) ...\n",
            "Selecting previously unselected package pfb2t1c2pfb.\n",
            "Preparing to unpack .../23-pfb2t1c2pfb_0.3-11_amd64.deb ...\n",
            "Unpacking pfb2t1c2pfb (0.3-11) ...\n",
            "Selecting previously unselected package cm-super.\n",
            "Preparing to unpack .../24-cm-super_0.3.4-11_all.deb ...\n",
            "Unpacking cm-super (0.3.4-11) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../25-ghostscript_9.26~dfsg+0-0ubuntu0.18.04.14_amd64.deb ...\n",
            "Unpacking ghostscript (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Selecting previously unselected package dvipng.\n",
            "Preparing to unpack .../26-dvipng_1.15-1_amd64.deb ...\n",
            "Unpacking dvipng (1.15-1) ...\n",
            "Selecting previously unselected package fonts-adf-accanthis.\n",
            "Preparing to unpack .../27-fonts-adf-accanthis_0.20110505-1_all.deb ...\n",
            "Unpacking fonts-adf-accanthis (0.20110505-1) ...\n",
            "Selecting previously unselected package fonts-adf-berenis.\n",
            "Preparing to unpack .../28-fonts-adf-berenis_0.20110505-1_all.deb ...\n",
            "Unpacking fonts-adf-berenis (0.20110505-1) ...\n",
            "Selecting previously unselected package fonts-adf-gillius.\n",
            "Preparing to unpack .../29-fonts-adf-gillius_0.20110505-1_all.deb ...\n",
            "Unpacking fonts-adf-gillius (0.20110505-1) ...\n",
            "Selecting previously unselected package fonts-adf-universalis.\n",
            "Preparing to unpack .../30-fonts-adf-universalis_0.20110505-1_all.deb ...\n",
            "Unpacking fonts-adf-universalis (0.20110505-1) ...\n",
            "Selecting previously unselected package fonts-cabin.\n",
            "Preparing to unpack .../31-fonts-cabin_1.5-2_all.deb ...\n",
            "Unpacking fonts-cabin (1.5-2) ...\n",
            "Selecting previously unselected package fonts-comfortaa.\n",
            "Preparing to unpack .../32-fonts-comfortaa_3.001-2_all.deb ...\n",
            "Unpacking fonts-comfortaa (3.001-2) ...\n",
            "Selecting previously unselected package fonts-croscore.\n",
            "Preparing to unpack .../33-fonts-croscore_20171026-2_all.deb ...\n",
            "Unpacking fonts-croscore (20171026-2) ...\n",
            "Selecting previously unselected package fonts-crosextra-caladea.\n",
            "Preparing to unpack .../34-fonts-crosextra-caladea_20130214-2_all.deb ...\n",
            "Unpacking fonts-crosextra-caladea (20130214-2) ...\n",
            "Selecting previously unselected package fonts-crosextra-carlito.\n",
            "Preparing to unpack .../35-fonts-crosextra-carlito_20130920-1_all.deb ...\n",
            "Unpacking fonts-crosextra-carlito (20130920-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../36-fonts-dejavu-core_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../37-fonts-dejavu-extra_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-1) ...\n",
            "Selecting previously unselected package fonts-ebgaramond.\n",
            "Preparing to unpack .../38-fonts-ebgaramond_0.016-1_all.deb ...\n",
            "Unpacking fonts-ebgaramond (0.016-1) ...\n",
            "Selecting previously unselected package fonts-ebgaramond-extra.\n",
            "Preparing to unpack .../39-fonts-ebgaramond-extra_0.016-1_all.deb ...\n",
            "Unpacking fonts-ebgaramond-extra (0.016-1) ...\n",
            "Selecting previously unselected package fonts-font-awesome.\n",
            "Preparing to unpack .../40-fonts-font-awesome_4.7.0~dfsg-3_all.deb ...\n",
            "Unpacking fonts-font-awesome (4.7.0~dfsg-3) ...\n",
            "Selecting previously unselected package fonts-freefont-otf.\n",
            "Preparing to unpack .../41-fonts-freefont-otf_20120503-7_all.deb ...\n",
            "Unpacking fonts-freefont-otf (20120503-7) ...\n",
            "Selecting previously unselected package fonts-freefont-ttf.\n",
            "Preparing to unpack .../42-fonts-freefont-ttf_20120503-7_all.deb ...\n",
            "Unpacking fonts-freefont-ttf (20120503-7) ...\n",
            "Selecting previously unselected package fonts-gfs-artemisia.\n",
            "Preparing to unpack .../43-fonts-gfs-artemisia_1.1-5_all.deb ...\n",
            "Unpacking fonts-gfs-artemisia (1.1-5) ...\n",
            "Selecting previously unselected package fonts-gfs-complutum.\n",
            "Preparing to unpack .../44-fonts-gfs-complutum_1.1-6_all.deb ...\n",
            "Unpacking fonts-gfs-complutum (1.1-6) ...\n",
            "Selecting previously unselected package fonts-gfs-didot.\n",
            "Preparing to unpack .../45-fonts-gfs-didot_1.1-6_all.deb ...\n",
            "Unpacking fonts-gfs-didot (1.1-6) ...\n",
            "Selecting previously unselected package fonts-gfs-neohellenic.\n",
            "Preparing to unpack .../46-fonts-gfs-neohellenic_1.1-6_all.deb ...\n",
            "Unpacking fonts-gfs-neohellenic (1.1-6) ...\n",
            "Selecting previously unselected package fonts-gfs-olga.\n",
            "Preparing to unpack .../47-fonts-gfs-olga_1.1-5_all.deb ...\n",
            "Unpacking fonts-gfs-olga (1.1-5) ...\n",
            "Selecting previously unselected package fonts-gfs-solomos.\n",
            "Preparing to unpack .../48-fonts-gfs-solomos_1.1-5_all.deb ...\n",
            "Unpacking fonts-gfs-solomos (1.1-5) ...\n",
            "Selecting previously unselected package fonts-go.\n",
            "Preparing to unpack .../49-fonts-go_0~20161116-1_all.deb ...\n",
            "Unpacking fonts-go (0~20161116-1) ...\n",
            "Selecting previously unselected package fonts-junicode.\n",
            "Preparing to unpack .../50-fonts-junicode_1.001-2_all.deb ...\n",
            "Unpacking fonts-junicode (1.001-2) ...\n",
            "Selecting previously unselected package fonts-linuxlibertine.\n",
            "Preparing to unpack .../51-fonts-linuxlibertine_5.3.0-4_all.deb ...\n",
            "Unpacking fonts-linuxlibertine (5.3.0-4) ...\n",
            "Selecting previously unselected package fonts-lobster.\n",
            "Preparing to unpack .../52-fonts-lobster_2.0-2_all.deb ...\n",
            "Unpacking fonts-lobster (2.0-2) ...\n",
            "Selecting previously unselected package fonts-lobstertwo.\n",
            "Preparing to unpack .../53-fonts-lobstertwo_2.0-2_all.deb ...\n",
            "Unpacking fonts-lobstertwo (2.0-2) ...\n",
            "Selecting previously unselected package fonts-noto-hinted.\n",
            "Preparing to unpack .../54-fonts-noto-hinted_20171026-2_all.deb ...\n",
            "Unpacking fonts-noto-hinted (20171026-2) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../55-fonts-noto-mono_20171026-2_all.deb ...\n",
            "Unpacking fonts-noto-mono (20171026-2) ...\n",
            "Selecting previously unselected package fonts-oflb-asana-math.\n",
            "Preparing to unpack .../56-fonts-oflb-asana-math_000.907-6_all.deb ...\n",
            "Unpacking fonts-oflb-asana-math (000.907-6) ...\n",
            "Selecting previously unselected package fonts-open-sans.\n",
            "Preparing to unpack .../57-fonts-open-sans_1.11-1_all.deb ...\n",
            "Unpacking fonts-open-sans (1.11-1) ...\n",
            "Selecting previously unselected package fonts-roboto-hinted.\n",
            "Preparing to unpack .../58-fonts-roboto-hinted_2%3a0~20160106-2_all.deb ...\n",
            "Unpacking fonts-roboto-hinted (2:0~20160106-2) ...\n",
            "Selecting previously unselected package fonts-sil-gentium.\n",
            "Preparing to unpack .../59-fonts-sil-gentium_20081126%3a1.03-2_all.deb ...\n",
            "Unpacking fonts-sil-gentium (20081126:1.03-2) ...\n",
            "Selecting previously unselected package fonts-sil-gentium-basic.\n",
            "Preparing to unpack .../60-fonts-sil-gentium-basic_1.102-1_all.deb ...\n",
            "Unpacking fonts-sil-gentium-basic (1.102-1) ...\n",
            "Selecting previously unselected package fonts-sil-gentiumplus.\n",
            "Preparing to unpack .../61-fonts-sil-gentiumplus_5.000-2_all.deb ...\n",
            "Unpacking fonts-sil-gentiumplus (5.000-2) ...\n",
            "Selecting previously unselected package fonts-sil-gentiumplus-compact.\n",
            "Preparing to unpack .../62-fonts-sil-gentiumplus-compact_5.000-2_all.deb ...\n",
            "Unpacking fonts-sil-gentiumplus-compact (5.000-2) ...\n",
            "Selecting previously unselected package fonts-texgyre.\n",
            "Preparing to unpack .../63-fonts-texgyre_20160520-1_all.deb ...\n",
            "Unpacking fonts-texgyre (20160520-1) ...\n",
            "Selecting previously unselected package gsfonts.\n",
            "Preparing to unpack .../64-gsfonts_1%3a8.11+urwcyr1.0.7~pre44-4.4_all.deb ...\n",
            "Unpacking gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n",
            "Selecting previously unselected package javascript-common.\n",
            "Preparing to unpack .../65-javascript-common_11_all.deb ...\n",
            "Unpacking javascript-common (11) ...\n",
            "Selecting previously unselected package libcupsfilters1:amd64.\n",
            "Preparing to unpack .../66-libcupsfilters1_1.20.2-0ubuntu3.1_amd64.deb ...\n",
            "Unpacking libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Selecting previously unselected package libjs-jquery.\n",
            "Preparing to unpack .../67-libjs-jquery_3.2.1-1_all.deb ...\n",
            "Unpacking libjs-jquery (3.2.1-1) ...\n",
            "Selecting previously unselected package rubygems-integration.\n",
            "Preparing to unpack .../68-rubygems-integration_1.11_all.deb ...\n",
            "Unpacking rubygems-integration (1.11) ...\n",
            "Selecting previously unselected package ruby2.5.\n",
            "Preparing to unpack .../69-ruby2.5_2.5.1-1ubuntu1.7_amd64.deb ...\n",
            "Unpacking ruby2.5 (2.5.1-1ubuntu1.7) ...\n",
            "Selecting previously unselected package ruby.\n",
            "Preparing to unpack .../70-ruby_1%3a2.5.1_amd64.deb ...\n",
            "Unpacking ruby (1:2.5.1) ...\n",
            "Selecting previously unselected package rake.\n",
            "Preparing to unpack .../71-rake_12.3.1-1ubuntu0.1_all.deb ...\n",
            "Unpacking rake (12.3.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package ruby-did-you-mean.\n",
            "Preparing to unpack .../72-ruby-did-you-mean_1.2.0-2_all.deb ...\n",
            "Unpacking ruby-did-you-mean (1.2.0-2) ...\n",
            "Selecting previously unselected package ruby-minitest.\n",
            "Preparing to unpack .../73-ruby-minitest_5.10.3-1_all.deb ...\n",
            "Unpacking ruby-minitest (5.10.3-1) ...\n",
            "Selecting previously unselected package ruby-net-telnet.\n",
            "Preparing to unpack .../74-ruby-net-telnet_0.1.1-2_all.deb ...\n",
            "Unpacking ruby-net-telnet (0.1.1-2) ...\n",
            "Selecting previously unselected package ruby-power-assert.\n",
            "Preparing to unpack .../75-ruby-power-assert_0.3.0-1_all.deb ...\n",
            "Unpacking ruby-power-assert (0.3.0-1) ...\n",
            "Selecting previously unselected package ruby-test-unit.\n",
            "Preparing to unpack .../76-ruby-test-unit_3.2.5-1_all.deb ...\n",
            "Unpacking ruby-test-unit (3.2.5-1) ...\n",
            "Selecting previously unselected package libruby2.5:amd64.\n",
            "Preparing to unpack .../77-libruby2.5_2.5.1-1ubuntu1.7_amd64.deb ...\n",
            "Unpacking libruby2.5:amd64 (2.5.1-1ubuntu1.7) ...\n",
            "Selecting previously unselected package lmodern.\n",
            "Preparing to unpack .../78-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package preview-latex-style.\n",
            "Preparing to unpack .../79-preview-latex-style_11.91-1ubuntu1_all.deb ...\n",
            "Unpacking preview-latex-style (11.91-1ubuntu1) ...\n",
            "Selecting previously unselected package tex-gyre.\n",
            "Preparing to unpack .../80-tex-gyre_20160520-1_all.deb ...\n",
            "Unpacking tex-gyre (20160520-1) ...\n",
            "Selecting previously unselected package texlive-fonts-extra.\n",
            "Preparing to unpack .../81-texlive-fonts-extra_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-fonts-extra (2017.20180305-2) ...\n",
            "Selecting previously unselected package fonts-stix.\n",
            "Preparing to unpack .../82-fonts-stix_1.1.1-4_all.deb ...\n",
            "Unpacking fonts-stix (1.1.1-4) ...\n",
            "Selecting previously unselected package texlive-fonts-extra-links.\n",
            "Preparing to unpack .../83-texlive-fonts-extra-links_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-fonts-extra-links (2017.20180305-2) ...\n",
            "Selecting previously unselected package texlive-fonts-recommended.\n",
            "Preparing to unpack .../84-texlive-fonts-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-pictures.\n",
            "Preparing to unpack .../85-texlive-pictures_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-pictures (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-extra.\n",
            "Preparing to unpack .../86-texlive-latex-extra_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-latex-extra (2017.20180305-2) ...\n",
            "Selecting previously unselected package texlive-plain-generic.\n",
            "Preparing to unpack .../87-texlive-plain-generic_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-plain-generic (2017.20180305-2) ...\n",
            "Selecting previously unselected package tipa.\n",
            "Preparing to unpack .../88-tipa_2%3a1.3-20_all.deb ...\n",
            "Unpacking tipa (2:1.3-20) ...\n",
            "Setting up libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Setting up libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libjs-jquery (3.2.1-1) ...\n",
            "Setting up libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Setting up libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-gfs-neohellenic (1.1-6) ...\n",
            "Setting up tex-common (6.09) ...\n",
            "update-language: texlive-base not installed and configured, doing nothing!\n",
            "Setting up fonts-stix (1.1.1-4) ...\n",
            "Setting up fonts-comfortaa (3.001-2) ...\n",
            "Setting up gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n",
            "Setting up fonts-dejavu-core (2.37-1) ...\n",
            "Setting up fonts-linuxlibertine (5.3.0-4) ...\n",
            "Setting up poppler-data (0.4.8-2) ...\n",
            "Setting up fonts-oflb-asana-math (000.907-6) ...\n",
            "Setting up tex-gyre (20160520-1) ...\n",
            "Setting up fonts-lobster (2.0-2) ...\n",
            "Setting up fonts-gfs-solomos (1.1-5) ...\n",
            "Setting up fonts-adf-accanthis (0.20110505-1) ...\n",
            "Setting up fonts-freefont-otf (20120503-7) ...\n",
            "Setting up preview-latex-style (11.91-1ubuntu1) ...\n",
            "Setting up fonts-open-sans (1.11-1) ...\n",
            "Setting up fonts-texgyre (20160520-1) ...\n",
            "Setting up fonts-crosextra-carlito (20130920-1) ...\n",
            "Setting up pfb2t1c2pfb (0.3-11) ...\n",
            "Setting up fonts-ebgaramond-extra (0.016-1) ...\n",
            "Setting up fonts-font-awesome (4.7.0~dfsg-3) ...\n",
            "Setting up fonts-junicode (1.001-2) ...\n",
            "Setting up fonts-noto-mono (20171026-2) ...\n",
            "Setting up fonts-lato (2.0-2) ...\n",
            "Setting up libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Setting up fonts-gfs-complutum (1.1-6) ...\n",
            "Setting up fonts-cabin (1.5-2) ...\n",
            "Setting up libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n",
            "Setting up fonts-sil-gentiumplus-compact (5.000-2) ...\n",
            "Setting up libjbig2dec0:amd64 (0.13-6) ...\n",
            "Setting up ruby-did-you-mean (1.2.0-2) ...\n",
            "Setting up fonts-adf-gillius (0.20110505-1) ...\n",
            "Setting up fonts-crosextra-caladea (20130214-2) ...\n",
            "Setting up fonts-noto-hinted (20171026-2) ...\n",
            "Setting up t1utils (1.41-2) ...\n",
            "Setting up fonts-ebgaramond (0.016-1) ...\n",
            "Setting up ruby-net-telnet (0.1.1-2) ...\n",
            "Setting up fonts-croscore (20171026-2) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-13) ...\n",
            "Setting up rubygems-integration (1.11) ...\n",
            "Setting up libpotrace0 (1.14-2) ...\n",
            "Setting up fonts-adf-berenis (0.20110505-1) ...\n",
            "Setting up fonts-adf-universalis (0.20110505-1) ...\n",
            "Setting up fonts-sil-gentiumplus (5.000-2) ...\n",
            "Setting up fonts-gfs-didot (1.1-6) ...\n",
            "Setting up javascript-common (11) ...\n",
            "Setting up fonts-gfs-artemisia (1.1-5) ...\n",
            "Setting up fonts-dejavu-extra (2.37-1) ...\n",
            "Setting up fonts-freefont-ttf (20120503-7) ...\n",
            "Setting up ruby-minitest (5.10.3-1) ...\n",
            "Setting up fonts-go (0~20161116-1) ...\n",
            "Setting up libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Setting up fonts-sil-gentium (20081126:1.03-2) ...\n",
            "Setting up libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Setting up fonts-sil-gentium-basic (1.102-1) ...\n",
            "Setting up libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-gfs-olga (1.1-5) ...\n",
            "Setting up fonts-lmodern (2.004.5-3) ...\n",
            "Setting up ruby-power-assert (0.3.0-1) ...\n",
            "Setting up fonts-roboto-hinted (2:0~20160106-2) ...\n",
            "Setting up fonts-lobstertwo (2.0-2) ...\n",
            "Setting up ghostscript (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Setting up texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "update-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\n",
            "update-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\n",
            "Setting up texlive-base (2017.20180305-1) ...\n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R... \n",
            "mktexlsr: Done.\n",
            "tl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\n",
            "tl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\n",
            "tl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\n",
            "tl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/config/pdftexconfig.tex\n",
            "Setting up texlive-fonts-extra-links (2017.20180305-2) ...\n",
            "Setting up texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Setting up texlive-plain-generic (2017.20180305-2) ...\n",
            "Setting up texlive-latex-base (2017.20180305-1) ...\n",
            "Setting up lmodern (2.004.5-3) ...\n",
            "Setting up texlive-latex-recommended (2017.20180305-1) ...\n",
            "Setting up texlive-fonts-extra (2017.20180305-2) ...\n",
            "Setting up texlive-pictures (2017.20180305-1) ...\n",
            "Setting up dvipng (1.15-1) ...\n",
            "Setting up tipa (2:1.3-20) ...\n",
            "Regenerating '/var/lib/texmf/fmtutil.cnf-DEBIAN'... done.\n",
            "Regenerating '/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST'... done.\n",
            "update-fmtutil has updated the following file(s):\n",
            "\t/var/lib/texmf/fmtutil.cnf-DEBIAN\n",
            "\t/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST\n",
            "If you want to activate the changes in the above file(s),\n",
            "you should run fmtutil-sys or fmtutil.\n",
            "Setting up cm-super-minimal (0.3.4-11) ...\n",
            "Setting up texlive-latex-extra (2017.20180305-2) ...\n",
            "Setting up cm-super (0.3.4-11) ...\n",
            "Creating fonts. This may take some time... done.\n",
            "Setting up rake (12.3.1-1ubuntu0.1) ...\n",
            "Setting up ruby2.5 (2.5.1-1ubuntu1.7) ...\n",
            "Setting up ruby (1:2.5.1) ...\n",
            "Setting up ruby-test-unit (3.2.5-1) ...\n",
            "Setting up libruby2.5:amd64 (2.5.1-1ubuntu1.7) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for tex-common (6.09) ...\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Building format(s) --all.\n",
            "\tThis may take some time... done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4dnerEv8ied"
      },
      "source": [
        "## PLOTTING: \n",
        "import matplotlib as mpl\n",
        "mpl.use('pgf')\n",
        "def figsize(scale, nplots = 1):\n",
        "    fig_width_pt = 390.0                          # Get this from LaTeX using \\the\\textwidth\n",
        "    inches_per_pt = 1.0/72.27                       # Convert pt to inch\n",
        "    golden_mean = (np.sqrt(5.0)-1.0)/2.0            # Aesthetic ratio (you could change this)\n",
        "    fig_width = fig_width_pt*inches_per_pt*scale    # width in inches\n",
        "    fig_height = nplots*fig_width*golden_mean              # height in inches\n",
        "    fig_size = [fig_width,fig_height]\n",
        "    return fig_size\n",
        "\n",
        "pgf_with_latex = {                      # setup matplotlib to use latex for output\n",
        "    \"pgf.texsystem\": \"pdflatex\",        # change this if using xetex or lautex\n",
        "    \"text.usetex\": True,                # use LaTeX to write all text\n",
        "    \"font.family\": \"serif\",\n",
        "    \"font.serif\": [],                   # blank entries should cause plots to inherit fonts from the document\n",
        "    \"font.sans-serif\": [],\n",
        "    \"font.monospace\": [],\n",
        "    \"axes.labelsize\": 10,               # LaTeX default is 10pt font.\n",
        "    \"font.size\": 10,\n",
        "    \"legend.fontsize\": 8,               # Make the legend/label fonts a little smaller\n",
        "    \"xtick.labelsize\": 8,\n",
        "    \"ytick.labelsize\": 8,\n",
        "    \"figure.figsize\": figsize(1.0),     # default fig size of 0.9 textwidth\n",
        "    \"pgf.preamble\": [\n",
        "        r\"\\usepackage[utf8x]{inputenc}\",    # use utf8 fonts becasue your computer can handle it :)\n",
        "        r\"\\usepackage[T1]{fontenc}\",        # plots will be generated using this preamble\n",
        "        ]\n",
        "    }\n",
        "mpl.rcParams.update(pgf_with_latex)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# I make my own newfig and savefig functions\n",
        "def newfig(width, nplots = 1):\n",
        "    fig = plt.figure(figsize=figsize(width, nplots))\n",
        "    ax = fig.add_subplot(111)\n",
        "    return fig, ax\n",
        "\n",
        "def savefig(filename, crop = True):\n",
        "    if crop == True:\n",
        "        plt.savefig('{}.png'.format(filename), bbox_inches='tight', pad_inches=0)\n",
        "        plt.savefig('{}.pdf'.format(filename), bbox_inches='tight', pad_inches=0)\n",
        "     #   plt.savefig('{}.eps'.format(filename), bbox_inches='tight', pad_inches=0)\n",
        "    else:\n",
        "        plt.savefig('{}.png'.format(filename))\n",
        "        plt.savefig('{}.pdf'.format(filename))\n",
        "     #   plt.savefig('{}.eps'.format(filename))\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89lKvjja8ieu",
        "outputId": "45ae6004-cc5d-473f-c754-782942456a74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "  ######################################################################\n",
        "    ############################# Plotting ###############################\n",
        "    ######################################################################    \n",
        "    \n",
        "fig, ax = newfig(2.0, 1)\n",
        "ax.axis('off')\n",
        "    \n",
        "    ######## Row 2: Pressure #######################\n",
        "    ########      Predicted p(t,x,y)     ########### \n",
        "gs = gridspec.GridSpec(1, 2)\n",
        "gs.update(top=0.8, bottom=0.2, left=0.1, right=0.9, wspace=0.5)\n",
        "ax = plt.subplot(gs[:, 0])\n",
        "h = ax.imshow(Exact_sol, interpolation='nearest', cmap='jet', \n",
        "                  extent=[lb_sol[0], ub_sol[0], lb_sol[1], ub_sol[1]],\n",
        "                  origin='lower', aspect='auto')\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "fig.colorbar(h, cax=cax)\n",
        "ax.set_xlabel('$t$')\n",
        "ax.set_ylabel('$x$')\n",
        "ax.set_title('Exact Dynamics', fontsize = 10)\n",
        "line = np.linspace(lb_sol[1], ub_sol[1], 2)[:,None]\n",
        "ax.plot(t_idn[index]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "    \n",
        "    ########     Exact p(t,x,y)     ########### \n",
        "ax = plt.subplot(gs[:, 1])\n",
        "h = ax.imshow(U_pred, interpolation='nearest', cmap='jet', \n",
        "                 extent=[lb_sol[0], ub_sol[0], lb_sol[1], ub_sol[1]],origin='lower', aspect='auto')\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "\n",
        "fig.colorbar(h, cax=cax)\n",
        "ax.set_xlabel('$t$')\n",
        "ax.set_ylabel('$x$')\n",
        "ax.set_title('Learned Dynamics', fontsize = 10)\n",
        "line = np.linspace(lb_sol[1], ub_sol[1], 2)[:,None]\n",
        "ax.plot(t_idn[index]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "savefig('/content/figures/Burgers')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 777.086x480.266 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
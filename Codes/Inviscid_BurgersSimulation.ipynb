{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.3 64-bit (conda)",
      "metadata": {
        "interpreter": {
          "hash": "51c008122401afe5535fd6c3a84bd5dd8b8bd079df3baf2c4d203d1ed6e4d4a5"
        }
      }
    },
    "colab": {
      "name": "Inviscid_BurgersSimulation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6hx4sG_8ieS"
      },
      "source": [
        "# Burgers Equation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub5oHbXH8pkf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccf4fa7b-b802-45d5-c5a6-b2ea83dfbfe3"
      },
      "source": [
        "!pip install pyDOE"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyDOE in /usr/local/lib/python3.7/dist-packages (0.3.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyDOE) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyDOE) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeH35EQU8ieb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3674c26b-07c0-4fc6-b3ba-c5e3418da343"
      },
      "source": [
        "%tensorflow_version 1.x ### to run on Google Colab: \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "from scipy.interpolate import griddata\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from pyDOE import lhs\n",
        "import time\n",
        "import matplotlib.gridspec as gridspec\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.x ### to run on Google Colab:`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioO_XM0H8iec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e4fdb83-8c38-4617-e02e-cef071660a98"
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5bGi5OH8iee"
      },
      "source": [
        "###############################################################################\n",
        "############################## Helper Functions ###############################\n",
        "###############################################################################\n",
        "\n",
        "def initialize_NN(layers):\n",
        "    weights = []\n",
        "    biases = []\n",
        "    num_layers = len(layers) \n",
        "    for l in range(0,num_layers-1):\n",
        "        W = xavier_init(size=[layers[l], layers[l+1]])\n",
        "        b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
        "        weights.append(W)\n",
        "        biases.append(b)\n",
        "    return weights, biases\n",
        "    \n",
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    out_dim = size[1]\n",
        "    xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
        "    return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev, dtype=tf.float32), dtype=tf.float32)\n",
        "\n",
        "def neural_net(X, weights, biases):\n",
        "    num_layers = len(weights) + 1\n",
        "    H = X\n",
        "    for l in range(0,num_layers-2):\n",
        "        W = weights[l]\n",
        "        b = biases[l]\n",
        "        H = tf.sin(tf.add(tf.matmul(H, W), b))\n",
        "    W = weights[-1]\n",
        "    b = biases[-1]\n",
        "    Y = tf.add(tf.matmul(H, W), b)\n",
        "    return Y\n",
        "\n",
        "###############################################################################\n",
        "################################ DeepHPM Class ################################\n",
        "###############################################################################\n",
        "\n",
        "class DeepHPM:\n",
        "    def __init__(self, t, x, u,\n",
        "                       x0, u0, tb, X_f,\n",
        "                       u_layers, pde_layers,\n",
        "                       layers,\n",
        "                       lb_idn, ub_idn,\n",
        "                       lb_sol, ub_sol):\n",
        "        \n",
        "        # Domain Boundary\n",
        "        self.lb_idn = lb_idn\n",
        "        self.ub_idn = ub_idn\n",
        "        \n",
        "        self.lb_sol = lb_sol\n",
        "        self.ub_sol = ub_sol\n",
        "        \n",
        "        # Init for Identification\n",
        "        self.idn_init(t, x, u, u_layers, pde_layers)\n",
        "        \n",
        "        # Init for Solution\n",
        "        self.sol_init(x0, u0, tb, X_f, layers)\n",
        "        \n",
        "        # tf session\n",
        "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
        "                                                     log_device_placement=True))\n",
        "        \n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess.run(init)\n",
        "    \n",
        "    ###########################################################################\n",
        "    ############################# Identifier ##################################\n",
        "    ###########################################################################\n",
        "        \n",
        "    def idn_init(self, t, x, u, u_layers, pde_layers):\n",
        "        # Training Data for Identification\n",
        "        self.t = t\n",
        "        self.x = x\n",
        "        self.u = u\n",
        "        \n",
        "        # Layers for Identification\n",
        "        self.u_layers = u_layers\n",
        "        self.pde_layers = pde_layers\n",
        "        \n",
        "        # Initialize NNs for Identification\n",
        "        self.u_weights, self.u_biases = initialize_NN(u_layers)\n",
        "        self.pde_weights, self.pde_biases = initialize_NN(pde_layers)\n",
        "        \n",
        "        # tf placeholders for Identification\n",
        "        self.t_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.x_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.u_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.terms_tf = tf.placeholder(tf.float32, shape=[None, pde_layers[0]])\n",
        "        \n",
        "        # tf graphs for Identification\n",
        "        self.idn_u_pred = self.idn_net_u(self.t_tf, self.x_tf)\n",
        "        self.pde_pred = self.net_pde(self.terms_tf)\n",
        "        self.idn_f_pred = self.idn_net_f(self.t_tf, self.x_tf)\n",
        "        \n",
        "        # loss for Identification\n",
        "        self.idn_u_loss = tf.reduce_sum(tf.square(self.idn_u_pred - self.u_tf))\n",
        "        self.idn_f_loss = tf.reduce_sum(tf.square(self.idn_f_pred))\n",
        "        \n",
        "        # Optimizer for Identification\n",
        "        self.idn_u_optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.idn_u_loss,\n",
        "                               var_list = self.u_weights + self.u_biases,\n",
        "                               method = 'L-BFGS-B',\n",
        "                               options = {'maxiter': 50000,\n",
        "                                          'maxfun': 50000,\n",
        "                                          'maxcor': 50,\n",
        "                                          'maxls': 50,\n",
        "                                          'ftol': 1.0*np.finfo(float).eps})\n",
        "    \n",
        "        self.idn_f_optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.idn_f_loss,\n",
        "                               var_list = self.pde_weights + self.pde_biases,\n",
        "                               method = 'L-BFGS-B',\n",
        "                               options = {'maxiter': 50000,\n",
        "                                          'maxfun': 50000,\n",
        "                                          'maxcor': 50,\n",
        "                                          'maxls': 50,\n",
        "                                          'ftol': 1.0*np.finfo(float).eps})\n",
        "    \n",
        "        self.idn_u_optimizer_Adam = tf.train.AdamOptimizer()\n",
        "        self.idn_u_train_op_Adam = self.idn_u_optimizer_Adam.minimize(self.idn_u_loss, \n",
        "                                   var_list = self.u_weights + self.u_biases)\n",
        "        \n",
        "        self.idn_f_optimizer_Adam = tf.train.AdamOptimizer()\n",
        "        self.idn_f_train_op_Adam = self.idn_f_optimizer_Adam.minimize(self.idn_f_loss, \n",
        "                                   var_list = self.pde_weights + self.pde_biases)  \n",
        "    \n",
        "    def idn_net_u(self, t, x):\n",
        "        X = tf.concat([t,x],1)\n",
        "        H = 2.0*(X - self.lb_idn)/(self.ub_idn - self.lb_idn) - 1.0\n",
        "        u = neural_net(H, self.u_weights, self.u_biases)\n",
        "        return u\n",
        "    \n",
        "    def net_pde(self, terms):\n",
        "        pde = neural_net(terms, self.pde_weights, self.pde_biases)\n",
        "        return pde\n",
        "    \n",
        "    def idn_net_f(self, t, x):\n",
        "        u = self.idn_net_u(t, x)\n",
        "        \n",
        "        u_t = tf.gradients(u, t)[0]\n",
        "        \n",
        "        u_x = tf.gradients(u, x)[0]\n",
        "        ### u_xx = tf.gradients(u_x, x)[0]\n",
        "        \n",
        "        terms = tf.concat([u,u_x],1)\n",
        "\n",
        "        \n",
        "        f = u_t - self.net_pde(terms)\n",
        "        \n",
        "        return f\n",
        "\n",
        "    def idn_u_train(self, N_iter):\n",
        "        tf_dict = {self.t_tf: self.t, self.x_tf: self.x, self.u_tf: self.u}\n",
        "        \n",
        "        start_time = time.time()\n",
        "        for it in range(N_iter):\n",
        "            \n",
        "            self.sess.run(self.idn_u_train_op_Adam, tf_dict)\n",
        "            \n",
        "            # Print\n",
        "            if it % 10 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                loss_value = self.sess.run(self.idn_u_loss, tf_dict)\n",
        "                print('It: %d, Loss: %.3e, Time: %.2f' % \n",
        "                      (it, loss_value, elapsed))\n",
        "                start_time = time.time()\n",
        "        \n",
        "        self.idn_u_optimizer.minimize(self.sess,\n",
        "                                      feed_dict = tf_dict,\n",
        "                                      fetches = [self.idn_u_loss],\n",
        "                                      loss_callback = self.callback)\n",
        "\n",
        "    def idn_f_train(self, N_iter):\n",
        "        tf_dict = {self.t_tf: self.t, self.x_tf: self.x}\n",
        "        \n",
        "        start_time = time.time()\n",
        "        for it in range(N_iter):\n",
        "            \n",
        "            self.sess.run(self.idn_f_train_op_Adam, tf_dict)\n",
        "            \n",
        "            # Print\n",
        "            if it % 10 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                loss_value = self.sess.run(self.idn_f_loss, tf_dict)\n",
        "                print('It: %d, Loss: %.3e, Time: %.2f' % \n",
        "                      (it, loss_value, elapsed))\n",
        "                start_time = time.time()\n",
        "        \n",
        "        self.idn_f_optimizer.minimize(self.sess,\n",
        "                                      feed_dict = tf_dict,\n",
        "                                      fetches = [self.idn_f_loss],\n",
        "                                      loss_callback = self.callback)\n",
        "\n",
        "    def idn_predict(self, t_star, x_star):\n",
        "        \n",
        "        tf_dict = {self.t_tf: t_star, self.x_tf: x_star}\n",
        "        \n",
        "        u_star = self.sess.run(self.idn_u_pred, tf_dict)\n",
        "        f_star = self.sess.run(self.idn_f_pred, tf_dict)\n",
        "        \n",
        "        return u_star, f_star\n",
        "    \n",
        "    def predict_pde(self, terms_star):\n",
        "        \n",
        "        tf_dict = {self.terms_tf: terms_star}\n",
        "        \n",
        "        pde_star = self.sess.run(self.pde_pred, tf_dict)\n",
        "        \n",
        "        return pde_star\n",
        "    \n",
        "    ###########################################################################\n",
        "    ############################### Solver ####################################\n",
        "    ###########################################################################\n",
        "    \n",
        "    def sol_init(self, x0, u0, tb, X_f, layers):\n",
        "        # Training Data for Solution\n",
        "        X0 = np.concatenate((0*x0, x0), 1) # (0, x0)\n",
        "        X_lb = np.concatenate((tb, 0*tb + self.lb_sol[1]), 1) # (tb, lb[1])\n",
        "        X_ub = np.concatenate((tb, 0*tb + self.ub_sol[1]), 1) # (tb, ub[1])\n",
        "                \n",
        "        self.X_f = X_f # Collocation Points\n",
        "        self.t0 = X0[:,0:1] # Initial Data (time)\n",
        "        self.x0 = X0[:,1:2] # Initial Data (space)\n",
        "        self.t_lb = X_lb[:,0:1] # Boundary Data (time) -- lower boundary\n",
        "        self.x_lb = X_lb[:,1:2] # Boundary Data (space) -- lower boundary\n",
        "        self.t_ub = X_ub[:,0:1] # Boundary Data (time) -- upper boundary\n",
        "        self.x_ub = X_ub[:,1:2] # Boundary Data (space) -- upper boundary\n",
        "        self.t_f = X_f[:,0:1] # Collocation Points (time)\n",
        "        self.x_f = X_f[:,1:2] # Collocation Points (space)\n",
        "        self.u0 = u0 # Boundary Data\n",
        "        \n",
        "        # Layers for Solution\n",
        "        self.layers = layers\n",
        "        \n",
        "        # Initialize NNs for Solution\n",
        "        self.weights, self.biases = initialize_NN(layers)\n",
        "        \n",
        "        # tf placeholders for Solution\n",
        "        self.t0_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.x0_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.u0_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.t_lb_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.x_lb_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.t_ub_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.x_ub_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.t_f_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        self.x_f_tf = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        \n",
        "        # tf graphs for Solution\n",
        "        self.u0_pred, _  = self.sol_net_u(self.t0_tf, self.x0_tf)\n",
        "        self.u_lb_pred, self.u_x_lb_pred = self.sol_net_u(self.t_lb_tf, self.x_lb_tf)\n",
        "        self.u_ub_pred, self.u_x_ub_pred = self.sol_net_u(self.t_ub_tf, self.x_ub_tf)\n",
        "        self.sol_f_pred = self.sol_net_f(self.t_f_tf, self.x_f_tf)\n",
        "        \n",
        "        # loss for Solution\n",
        "        self.sol_loss = tf.reduce_sum(tf.square(self.u0_tf - self.u0_pred)) + \\\n",
        "                        tf.reduce_sum(tf.square(self.u_lb_pred - self.u_ub_pred)) + \\\n",
        "                        tf.reduce_sum(tf.square(self.u_x_lb_pred - self.u_x_ub_pred)) + \\\n",
        "                        tf.reduce_sum(tf.square(self.sol_f_pred))\n",
        "        \n",
        "        # Optimizer for Solution\n",
        "        self.sol_optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.sol_loss,\n",
        "                             var_list = self.weights + self.biases,\n",
        "                             method = 'L-BFGS-B',\n",
        "                             options = {'maxiter': 50000,\n",
        "                                        'maxfun': 50000,\n",
        "                                        'maxcor': 50,\n",
        "                                        'maxls': 50,\n",
        "                                        'ftol': 1.0*np.finfo(float).eps})\n",
        "    \n",
        "        self.sol_optimizer_Adam = tf.train.AdamOptimizer()\n",
        "        self.sol_train_op_Adam = self.sol_optimizer_Adam.minimize(self.sol_loss,\n",
        "                                 var_list = self.weights + self.biases)\n",
        "    \n",
        "    def sol_net_u(self, t, x):\n",
        "        X = tf.concat([t,x],1)\n",
        "        H = 2.0*(X - self.lb_sol)/(self.ub_sol - self.lb_sol) - 1.0\n",
        "        u = neural_net(H, self.weights, self.biases)\n",
        "        u_x = tf.gradients(u, x)[0]\n",
        "        return u, u_x\n",
        "    \n",
        "    def sol_net_f(self, t, x):\n",
        "        u, _ = self.sol_net_u(t,x)\n",
        "        \n",
        "        u_t = tf.gradients(u, t)[0]\n",
        "        u_x = tf.gradients(u, x)[0]\n",
        "\n",
        "        #u_xx = tf.gradients(u_x, x)[0]\n",
        "        \n",
        "        terms = tf.concat([u,u_x],1)\n",
        "        \n",
        "        f = u_t - self.net_pde(terms)\n",
        "        \n",
        "        return f\n",
        "    \n",
        "    def callback(self, loss):\n",
        "        print('Loss: %e' % (loss))\n",
        "        \n",
        "    def sol_train(self, N_iter):\n",
        "        tf_dict = {self.t0_tf: self.t0, self.x0_tf: self.x0,\n",
        "                   self.u0_tf: self.u0,\n",
        "                   self.t_lb_tf: self.t_lb, self.x_lb_tf: self.x_lb,\n",
        "                   self.t_ub_tf: self.t_ub, self.x_ub_tf: self.x_ub,\n",
        "                   self.t_f_tf: self.t_f, self.x_f_tf: self.x_f}\n",
        "        \n",
        "        start_time = time.time()\n",
        "        for it in range(N_iter):\n",
        "            \n",
        "            self.sess.run(self.sol_train_op_Adam, tf_dict)\n",
        "            \n",
        "            # Print\n",
        "            if it % 10 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                loss_value = self.sess.run(self.sol_loss, tf_dict)\n",
        "                print('It: %d, Loss: %.5e, Time: %.2f' % \n",
        "                      (it, loss_value, elapsed))\n",
        "                start_time = time.time()\n",
        "                \n",
        "        self.sol_optimizer.minimize(self.sess,\n",
        "                                    feed_dict = tf_dict,\n",
        "                                    fetches = [self.sol_loss],\n",
        "                                    loss_callback = self.callback)\n",
        "    \n",
        "    def sol_predict(self, t_star, x_star):\n",
        "        \n",
        "        u_star = self.sess.run(self.u0_pred, {self.t0_tf: t_star, self.x0_tf: x_star})  \n",
        "        f_star = self.sess.run(self.sol_f_pred, {self.t_f_tf: t_star, self.x_f_tf: x_star})\n",
        "               \n",
        "        return u_star, f_star    "
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dJn1YsD8iem"
      },
      "source": [
        "## Problem Set-Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FFu1pR682CG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91dc54da-64b0-4d94-ecae-562e738362f7"
      },
      "source": [
        "import os\n",
        "cwd = os.getcwd()\n",
        "print(cwd)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLTVx4zY8iet"
      },
      "source": [
        "   # Doman bounds\n",
        "lb_idn = np.array([0.0, -8.0])\n",
        "ub_idn = np.array([2.0, 8.0])\n",
        "    \n",
        "lb_sol = np.array([0.0, -8.0])\n",
        "ub_sol = np.array([2.0, 8.0])\n",
        "    \n",
        "    ### Load Data ###    \n",
        "data_idn = scipy.io.loadmat('/content/Data/inv_burgers_sine.mat')\n",
        "t_idn = data_idn['t'].flatten()[:,None]\n",
        "x_idn = data_idn['x'].flatten()[:,None]\n",
        "Exact_idn = np.real(data_idn['usol'])    \n",
        "T_idn, X_idn = np.meshgrid(t_idn,x_idn)\n",
        "keep = 0.9\n",
        "index = int(keep*t_idn.shape[0])\n",
        "T_idn = T_idn[:,0:index]\n",
        "X_idn = X_idn[:,0:index]\n",
        "Exact_idn = Exact_idn[:,0:index]\n",
        "    \n",
        "t_idn_star = T_idn.flatten()[:,None]\n",
        "x_idn_star = X_idn.flatten()[:,None]\n",
        "X_idn_star = np.hstack((t_idn_star, x_idn_star))\n",
        "u_idn_star = Exact_idn.flatten()[:,None]\n",
        "    \n",
        "    # Data Solution: \n",
        "data_sol = scipy.io.loadmat('/content/Data/inv_burgers_sine.mat') \n",
        "t_sol = data_sol['t'].flatten()[:,None]\n",
        "x_sol = data_sol['x'].flatten()[:,None]\n",
        "Exact_sol = np.real(data_sol['usol'])\n",
        "T_sol, X_sol = np.meshgrid(t_sol,x_sol)\n",
        "t_sol_star = T_sol.flatten()[:,None]\n",
        "x_sol_star = X_sol.flatten()[:,None]\n",
        "X_sol_star = np.hstack((t_sol_star, x_sol_star))\n",
        "u_sol_star = Exact_sol.flatten()[:,None]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2NDTJCt8iet"
      },
      "source": [
        "## Training Process: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eEyOSPy8iet",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2068af79-3f7c-4515-b299-7cb2eecc49c3"
      },
      "source": [
        "    ### Training Data ###\n",
        "    \n",
        "    # For identification\n",
        "N_train = 10000\n",
        "idx = np.random.choice(t_idn_star.shape[0], N_train, replace=False)    \n",
        "t_train = t_idn_star[idx,:]\n",
        "x_train = x_idn_star[idx,:]\n",
        "u_train = u_idn_star[idx,:]\n",
        "noise =  0.00 #0.00 # 0.001, 0.002, 0.01\n",
        "u_train = u_train + noise*np.std(u_train)*np.random.randn(u_train.shape[0], u_train.shape[1])\n",
        "    \n",
        "# For solution\n",
        "N0 = Exact_sol.shape[0]\n",
        "N_b = Exact_sol.shape[1]\n",
        "N_f = 20000\n",
        "idx_x = np.random.choice(x_sol.shape[0], N0, replace=False)\n",
        "x0_train = x_sol[idx_x,:]\n",
        "u0_train = Exact_sol[idx_x,0:1]   \n",
        "idx_t = np.random.choice(t_sol.shape[0], N_b, replace=False)\n",
        "tb_train = t_sol[idx_t,:] \n",
        "X_f_train = lb_sol + (ub_sol-lb_sol)*lhs(2, N_f)\n",
        "        \n",
        "    # Layers\n",
        "u_layers = [2, 50, 50, 50, 50, 1]\n",
        "pde_layers = [2, 100, 100, 1]    \n",
        "layers = [2, 50, 50, 50, 50, 1]\n",
        "    # Model\n",
        "model = DeepHPM(t_train, x_train, u_train,x0_train, u0_train, tb_train, X_f_train,u_layers, pde_layers,\n",
        "                    layers,lb_idn, ub_idn,\n",
        "                    lb_sol,ub_sol)\n",
        "    # Train the identifier\n",
        "model.idn_u_train(N_iter=0)\n",
        "model.idn_f_train(N_iter=0)   \n",
        "u_pred_identifier, f_pred_identifier = model.idn_predict(t_idn_star, x_idn_star)  \n",
        "error_u_identifier = np.linalg.norm(u_idn_star-u_pred_identifier,2)/np.linalg.norm(u_idn_star,2)\n",
        "print('Error u: %e' % (error_u_identifier))\n",
        "\n",
        "    ### Solution ###\n",
        "    \n",
        "    # Train the solver\n",
        "model.sol_train(N_iter=0)\n",
        "u_pred, f_pred = model.sol_predict(t_sol_star, x_sol_star)   \n",
        "u_pred_idn, f_pred_idn = model.sol_predict(t_idn_star, x_idn_star)\n",
        "error_u = np.linalg.norm(u_sol_star-u_pred,2)/np.linalg.norm(u_sol_star,2)\n",
        "error_u_idn = np.linalg.norm(u_idn_star-u_pred_idn,2)/np.linalg.norm(u_idn_star,2)\n",
        "print('Error u: %e' % (error_u))\n",
        "print('Error u (idn): %e' % (error_u_idn))\n",
        "U_pred = griddata(X_sol_star, u_pred.flatten(), (T_sol, X_sol), method='cubic')\n",
        "    "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Loss: 1.131530e-03\n",
            "Loss: 1.131331e-03\n",
            "Loss: 1.131085e-03\n",
            "Loss: 1.130528e-03\n",
            "Loss: 1.129836e-03\n",
            "Loss: 1.129287e-03\n",
            "Loss: 1.128716e-03\n",
            "Loss: 1.128222e-03\n",
            "Loss: 1.127311e-03\n",
            "Loss: 1.127930e-03\n",
            "Loss: 1.126929e-03\n",
            "Loss: 1.126576e-03\n",
            "Loss: 1.126275e-03\n",
            "Loss: 1.126031e-03\n",
            "Loss: 1.125627e-03\n",
            "Loss: 1.125198e-03\n",
            "Loss: 1.124967e-03\n",
            "Loss: 1.124474e-03\n",
            "Loss: 1.124024e-03\n",
            "Loss: 1.123406e-03\n",
            "Loss: 1.122749e-03\n",
            "Loss: 1.122553e-03\n",
            "Loss: 1.121940e-03\n",
            "Loss: 1.121720e-03\n",
            "Loss: 1.121362e-03\n",
            "Loss: 1.121043e-03\n",
            "Loss: 1.120747e-03\n",
            "Loss: 1.120422e-03\n",
            "Loss: 1.119861e-03\n",
            "Loss: 1.119430e-03\n",
            "Loss: 1.118778e-03\n",
            "Loss: 1.118409e-03\n",
            "Loss: 1.118061e-03\n",
            "Loss: 1.117679e-03\n",
            "Loss: 1.116927e-03\n",
            "Loss: 1.116322e-03\n",
            "Loss: 1.115761e-03\n",
            "Loss: 1.115304e-03\n",
            "Loss: 1.115016e-03\n",
            "Loss: 1.114462e-03\n",
            "Loss: 1.113871e-03\n",
            "Loss: 1.113314e-03\n",
            "Loss: 1.112916e-03\n",
            "Loss: 1.112581e-03\n",
            "Loss: 1.112260e-03\n",
            "Loss: 1.111795e-03\n",
            "Loss: 1.111378e-03\n",
            "Loss: 1.110772e-03\n",
            "Loss: 1.110313e-03\n",
            "Loss: 1.109561e-03\n",
            "Loss: 1.109438e-03\n",
            "Loss: 1.108910e-03\n",
            "Loss: 1.108553e-03\n",
            "Loss: 1.108157e-03\n",
            "Loss: 1.108204e-03\n",
            "Loss: 1.107904e-03\n",
            "Loss: 1.107524e-03\n",
            "Loss: 1.106967e-03\n",
            "Loss: 1.106650e-03\n",
            "Loss: 1.106209e-03\n",
            "Loss: 1.105751e-03\n",
            "Loss: 1.105325e-03\n",
            "Loss: 1.104989e-03\n",
            "Loss: 1.104737e-03\n",
            "Loss: 1.104369e-03\n",
            "Loss: 1.104038e-03\n",
            "Loss: 1.103466e-03\n",
            "Loss: 1.102856e-03\n",
            "Loss: 1.102342e-03\n",
            "Loss: 1.101784e-03\n",
            "Loss: 1.101358e-03\n",
            "Loss: 1.101048e-03\n",
            "Loss: 1.100607e-03\n",
            "Loss: 1.100253e-03\n",
            "Loss: 1.099988e-03\n",
            "Loss: 1.099796e-03\n",
            "Loss: 1.099610e-03\n",
            "Loss: 1.099362e-03\n",
            "Loss: 1.098998e-03\n",
            "Loss: 1.098530e-03\n",
            "Loss: 1.097929e-03\n",
            "Loss: 1.097579e-03\n",
            "Loss: 1.097409e-03\n",
            "Loss: 1.097295e-03\n",
            "Loss: 1.096923e-03\n",
            "Loss: 1.096451e-03\n",
            "Loss: 1.096053e-03\n",
            "Loss: 1.095672e-03\n",
            "Loss: 1.095197e-03\n",
            "Loss: 1.094631e-03\n",
            "Loss: 1.093895e-03\n",
            "Loss: 1.093184e-03\n",
            "Loss: 1.092410e-03\n",
            "Loss: 1.092971e-03\n",
            "Loss: 1.092169e-03\n",
            "Loss: 1.092021e-03\n",
            "Loss: 1.091665e-03\n",
            "Loss: 1.091202e-03\n",
            "Loss: 1.090442e-03\n",
            "Loss: 1.089767e-03\n",
            "Loss: 1.089415e-03\n",
            "Loss: 1.089250e-03\n",
            "Loss: 1.089002e-03\n",
            "Loss: 1.088766e-03\n",
            "Loss: 1.088540e-03\n",
            "Loss: 1.088260e-03\n",
            "Loss: 1.087809e-03\n",
            "Loss: 1.087867e-03\n",
            "Loss: 1.087527e-03\n",
            "Loss: 1.087321e-03\n",
            "Loss: 1.087152e-03\n",
            "Loss: 1.086995e-03\n",
            "Loss: 1.086705e-03\n",
            "Loss: 1.086253e-03\n",
            "Loss: 1.086335e-03\n",
            "Loss: 1.086085e-03\n",
            "Loss: 1.085886e-03\n",
            "Loss: 1.085708e-03\n",
            "Loss: 1.085521e-03\n",
            "Loss: 1.085092e-03\n",
            "Loss: 1.084709e-03\n",
            "Loss: 1.084209e-03\n",
            "Loss: 1.083943e-03\n",
            "Loss: 1.083687e-03\n",
            "Loss: 1.083328e-03\n",
            "Loss: 1.083349e-03\n",
            "Loss: 1.082997e-03\n",
            "Loss: 1.082458e-03\n",
            "Loss: 1.082208e-03\n",
            "Loss: 1.081845e-03\n",
            "Loss: 1.081529e-03\n",
            "Loss: 1.081101e-03\n",
            "Loss: 1.080472e-03\n",
            "Loss: 1.080215e-03\n",
            "Loss: 1.079836e-03\n",
            "Loss: 1.079628e-03\n",
            "Loss: 1.079312e-03\n",
            "Loss: 1.078893e-03\n",
            "Loss: 1.078312e-03\n",
            "Loss: 1.080602e-03\n",
            "Loss: 1.078139e-03\n",
            "Loss: 1.077769e-03\n",
            "Loss: 1.077528e-03\n",
            "Loss: 1.077334e-03\n",
            "Loss: 1.077043e-03\n",
            "Loss: 1.076597e-03\n",
            "Loss: 1.076466e-03\n",
            "Loss: 1.075883e-03\n",
            "Loss: 1.075665e-03\n",
            "Loss: 1.075431e-03\n",
            "Loss: 1.075436e-03\n",
            "Loss: 1.075311e-03\n",
            "Loss: 1.075038e-03\n",
            "Loss: 1.074825e-03\n",
            "Loss: 1.074551e-03\n",
            "Loss: 1.074227e-03\n",
            "Loss: 1.073914e-03\n",
            "Loss: 1.073672e-03\n",
            "Loss: 1.073445e-03\n",
            "Loss: 1.073229e-03\n",
            "Loss: 1.073020e-03\n",
            "Loss: 1.072734e-03\n",
            "Loss: 1.072543e-03\n",
            "Loss: 1.072356e-03\n",
            "Loss: 1.072166e-03\n",
            "Loss: 1.071885e-03\n",
            "Loss: 1.071648e-03\n",
            "Loss: 1.071369e-03\n",
            "Loss: 1.071303e-03\n",
            "Loss: 1.071073e-03\n",
            "Loss: 1.070972e-03\n",
            "Loss: 1.070790e-03\n",
            "Loss: 1.070604e-03\n",
            "Loss: 1.070538e-03\n",
            "Loss: 1.070360e-03\n",
            "Loss: 1.069992e-03\n",
            "Loss: 1.069659e-03\n",
            "Loss: 1.069411e-03\n",
            "Loss: 1.069194e-03\n",
            "Loss: 1.068870e-03\n",
            "Loss: 1.068589e-03\n",
            "Loss: 1.068308e-03\n",
            "Loss: 1.068063e-03\n",
            "Loss: 1.067710e-03\n",
            "Loss: 1.067417e-03\n",
            "Loss: 1.067067e-03\n",
            "Loss: 1.066803e-03\n",
            "Loss: 1.066596e-03\n",
            "Loss: 1.066203e-03\n",
            "Loss: 1.065958e-03\n",
            "Loss: 1.065688e-03\n",
            "Loss: 1.065515e-03\n",
            "Loss: 1.065176e-03\n",
            "Loss: 1.064798e-03\n",
            "Loss: 1.064589e-03\n",
            "Loss: 1.064222e-03\n",
            "Loss: 1.064087e-03\n",
            "Loss: 1.063936e-03\n",
            "Loss: 1.063671e-03\n",
            "Loss: 1.063390e-03\n",
            "Loss: 1.063292e-03\n",
            "Loss: 1.062722e-03\n",
            "Loss: 1.062529e-03\n",
            "Loss: 1.062287e-03\n",
            "Loss: 1.062125e-03\n",
            "Loss: 1.061847e-03\n",
            "Loss: 1.061615e-03\n",
            "Loss: 1.061400e-03\n",
            "Loss: 1.061151e-03\n",
            "Loss: 1.060824e-03\n",
            "Loss: 1.060553e-03\n",
            "Loss: 1.060288e-03\n",
            "Loss: 1.060011e-03\n",
            "Loss: 1.059815e-03\n",
            "Loss: 1.059647e-03\n",
            "Loss: 1.059534e-03\n",
            "Loss: 1.059316e-03\n",
            "Loss: 1.059086e-03\n",
            "Loss: 1.058596e-03\n",
            "Loss: 1.058222e-03\n",
            "Loss: 1.057867e-03\n",
            "Loss: 1.057565e-03\n",
            "Loss: 1.057402e-03\n",
            "Loss: 1.057313e-03\n",
            "Loss: 1.057140e-03\n",
            "Loss: 1.056908e-03\n",
            "Loss: 1.056701e-03\n",
            "Loss: 1.056503e-03\n",
            "Loss: 1.056378e-03\n",
            "Loss: 1.056212e-03\n",
            "Loss: 1.056110e-03\n",
            "Loss: 1.056030e-03\n",
            "Loss: 1.055835e-03\n",
            "Loss: 1.055516e-03\n",
            "Loss: 1.055287e-03\n",
            "Loss: 1.054959e-03\n",
            "Loss: 1.054839e-03\n",
            "Loss: 1.054743e-03\n",
            "Loss: 1.054657e-03\n",
            "Loss: 1.054550e-03\n",
            "Loss: 1.054373e-03\n",
            "Loss: 1.054204e-03\n",
            "Loss: 1.054185e-03\n",
            "Loss: 1.053965e-03\n",
            "Loss: 1.053572e-03\n",
            "Loss: 1.053311e-03\n",
            "Loss: 1.052966e-03\n",
            "Loss: 1.052918e-03\n",
            "Loss: 1.052674e-03\n",
            "Loss: 1.052560e-03\n",
            "Loss: 1.052310e-03\n",
            "Loss: 1.052032e-03\n",
            "Loss: 1.051820e-03\n",
            "Loss: 1.051278e-03\n",
            "Loss: 1.050986e-03\n",
            "Loss: 1.050435e-03\n",
            "Loss: 1.050967e-03\n",
            "Loss: 1.050298e-03\n",
            "Loss: 1.050148e-03\n",
            "Loss: 1.050005e-03\n",
            "Loss: 1.049847e-03\n",
            "Loss: 1.049602e-03\n",
            "Loss: 1.049112e-03\n",
            "Loss: 1.049014e-03\n",
            "Loss: 1.048458e-03\n",
            "Loss: 1.048271e-03\n",
            "Loss: 1.048032e-03\n",
            "Loss: 1.047647e-03\n",
            "Loss: 1.047317e-03\n",
            "Loss: 1.046777e-03\n",
            "Loss: 1.046489e-03\n",
            "Loss: 1.046308e-03\n",
            "Loss: 1.046275e-03\n",
            "Loss: 1.045919e-03\n",
            "Loss: 1.045750e-03\n",
            "Loss: 1.045476e-03\n",
            "Loss: 1.045339e-03\n",
            "Loss: 1.045087e-03\n",
            "Loss: 1.044961e-03\n",
            "Loss: 1.044791e-03\n",
            "Loss: 1.044516e-03\n",
            "Loss: 1.044019e-03\n",
            "Loss: 1.043721e-03\n",
            "Loss: 1.043600e-03\n",
            "Loss: 1.043250e-03\n",
            "Loss: 1.043146e-03\n",
            "Loss: 1.043029e-03\n",
            "Loss: 1.042848e-03\n",
            "Loss: 1.042429e-03\n",
            "Loss: 1.042757e-03\n",
            "Loss: 1.042270e-03\n",
            "Loss: 1.041889e-03\n",
            "Loss: 1.041649e-03\n",
            "Loss: 1.041476e-03\n",
            "Loss: 1.041208e-03\n",
            "Loss: 1.040942e-03\n",
            "Loss: 1.040487e-03\n",
            "Loss: 1.040735e-03\n",
            "Loss: 1.040402e-03\n",
            "Loss: 1.040328e-03\n",
            "Loss: 1.040081e-03\n",
            "Loss: 1.039929e-03\n",
            "Loss: 1.039632e-03\n",
            "Loss: 1.039393e-03\n",
            "Loss: 1.039214e-03\n",
            "Loss: 1.039078e-03\n",
            "Loss: 1.038952e-03\n",
            "Loss: 1.038602e-03\n",
            "Loss: 1.038685e-03\n",
            "Loss: 1.038478e-03\n",
            "Loss: 1.038190e-03\n",
            "Loss: 1.037961e-03\n",
            "Loss: 1.037763e-03\n",
            "Loss: 1.037739e-03\n",
            "Loss: 1.037592e-03\n",
            "Loss: 1.037406e-03\n",
            "Loss: 1.036958e-03\n",
            "Loss: 1.036693e-03\n",
            "Loss: 1.036205e-03\n",
            "Loss: 1.036160e-03\n",
            "Loss: 1.035881e-03\n",
            "Loss: 1.035462e-03\n",
            "Loss: 1.034920e-03\n",
            "Loss: 1.034382e-03\n",
            "Loss: 1.033791e-03\n",
            "Loss: 1.033326e-03\n",
            "Loss: 1.033050e-03\n",
            "Loss: 1.032679e-03\n",
            "Loss: 1.032206e-03\n",
            "Loss: 1.031689e-03\n",
            "Loss: 1.031465e-03\n",
            "Loss: 1.031283e-03\n",
            "Loss: 1.031093e-03\n",
            "Loss: 1.030891e-03\n",
            "Loss: 1.030608e-03\n",
            "Loss: 1.030122e-03\n",
            "Loss: 1.029805e-03\n",
            "Loss: 1.029564e-03\n",
            "Loss: 1.029208e-03\n",
            "Loss: 1.029113e-03\n",
            "Loss: 1.028773e-03\n",
            "Loss: 1.028632e-03\n",
            "Loss: 1.028576e-03\n",
            "Loss: 1.028322e-03\n",
            "Loss: 1.027982e-03\n",
            "Loss: 1.027811e-03\n",
            "Loss: 1.027341e-03\n",
            "Loss: 1.027118e-03\n",
            "Loss: 1.026869e-03\n",
            "Loss: 1.026555e-03\n",
            "Loss: 1.026266e-03\n",
            "Loss: 1.025858e-03\n",
            "Loss: 1.025643e-03\n",
            "Loss: 1.025327e-03\n",
            "Loss: 1.024889e-03\n",
            "Loss: 1.024700e-03\n",
            "Loss: 1.024564e-03\n",
            "Loss: 1.024350e-03\n",
            "Loss: 1.024222e-03\n",
            "Loss: 1.024049e-03\n",
            "Loss: 1.023827e-03\n",
            "Loss: 1.023557e-03\n",
            "Loss: 1.023320e-03\n",
            "Loss: 1.023099e-03\n",
            "Loss: 1.022892e-03\n",
            "Loss: 1.022638e-03\n",
            "Loss: 1.022707e-03\n",
            "Loss: 1.022479e-03\n",
            "Loss: 1.022182e-03\n",
            "Loss: 1.021988e-03\n",
            "Loss: 1.021736e-03\n",
            "Loss: 1.021496e-03\n",
            "Loss: 1.021155e-03\n",
            "Loss: 1.021010e-03\n",
            "Loss: 1.020618e-03\n",
            "Loss: 1.020472e-03\n",
            "Loss: 1.020308e-03\n",
            "Loss: 1.020147e-03\n",
            "Loss: 1.019804e-03\n",
            "Loss: 1.019977e-03\n",
            "Loss: 1.019597e-03\n",
            "Loss: 1.019184e-03\n",
            "Loss: 1.018751e-03\n",
            "Loss: 1.018405e-03\n",
            "Loss: 1.018309e-03\n",
            "Loss: 1.017858e-03\n",
            "Loss: 1.017702e-03\n",
            "Loss: 1.017438e-03\n",
            "Loss: 1.017233e-03\n",
            "Loss: 1.017440e-03\n",
            "Loss: 1.017123e-03\n",
            "Loss: 1.016832e-03\n",
            "Loss: 1.016647e-03\n",
            "Loss: 1.016490e-03\n",
            "Loss: 1.016342e-03\n",
            "Loss: 1.016263e-03\n",
            "Loss: 1.016083e-03\n",
            "Loss: 1.015938e-03\n",
            "Loss: 1.015815e-03\n",
            "Loss: 1.015567e-03\n",
            "Loss: 1.015462e-03\n",
            "Loss: 1.015276e-03\n",
            "Loss: 1.015133e-03\n",
            "Loss: 1.014907e-03\n",
            "Loss: 1.014736e-03\n",
            "Loss: 1.014502e-03\n",
            "Loss: 1.014343e-03\n",
            "Loss: 1.014240e-03\n",
            "Loss: 1.014106e-03\n",
            "Loss: 1.014001e-03\n",
            "Loss: 1.013742e-03\n",
            "Loss: 1.013608e-03\n",
            "Loss: 1.013409e-03\n",
            "Loss: 1.013312e-03\n",
            "Loss: 1.013253e-03\n",
            "Loss: 1.013171e-03\n",
            "Loss: 1.013020e-03\n",
            "Loss: 1.012845e-03\n",
            "Loss: 1.012808e-03\n",
            "Loss: 1.012580e-03\n",
            "Loss: 1.012512e-03\n",
            "Loss: 1.012430e-03\n",
            "Loss: 1.012303e-03\n",
            "Loss: 1.011993e-03\n",
            "Loss: 1.012997e-03\n",
            "Loss: 1.011877e-03\n",
            "Loss: 1.011502e-03\n",
            "Loss: 1.011207e-03\n",
            "Loss: 1.010882e-03\n",
            "Loss: 1.010807e-03\n",
            "Loss: 1.010454e-03\n",
            "Loss: 1.010168e-03\n",
            "Loss: 1.009931e-03\n",
            "Loss: 1.009658e-03\n",
            "Loss: 1.008982e-03\n",
            "Loss: 1.009318e-03\n",
            "Loss: 1.008705e-03\n",
            "Loss: 1.008163e-03\n",
            "Loss: 1.007810e-03\n",
            "Loss: 1.007259e-03\n",
            "Loss: 1.006976e-03\n",
            "Loss: 1.006594e-03\n",
            "Loss: 1.006293e-03\n",
            "Loss: 1.005961e-03\n",
            "Loss: 1.005556e-03\n",
            "Loss: 1.006376e-03\n",
            "Loss: 1.005274e-03\n",
            "Loss: 1.005033e-03\n",
            "Loss: 1.004732e-03\n",
            "Loss: 1.004397e-03\n",
            "Loss: 1.004765e-03\n",
            "Loss: 1.004215e-03\n",
            "Loss: 1.003856e-03\n",
            "Loss: 1.003582e-03\n",
            "Loss: 1.003162e-03\n",
            "Loss: 1.002592e-03\n",
            "Loss: 1.002542e-03\n",
            "Loss: 1.001904e-03\n",
            "Loss: 1.001689e-03\n",
            "Loss: 1.001305e-03\n",
            "Loss: 1.000788e-03\n",
            "Loss: 1.001663e-03\n",
            "Loss: 1.000502e-03\n",
            "Loss: 9.999719e-04\n",
            "Loss: 9.996961e-04\n",
            "Loss: 9.994470e-04\n",
            "Loss: 9.991633e-04\n",
            "Loss: 9.988395e-04\n",
            "Loss: 9.983814e-04\n",
            "Loss: 9.980956e-04\n",
            "Loss: 9.979438e-04\n",
            "Loss: 9.978110e-04\n",
            "Loss: 9.976869e-04\n",
            "Loss: 9.975160e-04\n",
            "Loss: 9.971806e-04\n",
            "Loss: 9.972439e-04\n",
            "Loss: 9.969701e-04\n",
            "Loss: 9.966571e-04\n",
            "Loss: 9.964033e-04\n",
            "Loss: 9.960640e-04\n",
            "Loss: 9.957587e-04\n",
            "Loss: 9.955827e-04\n",
            "Loss: 9.954993e-04\n",
            "Loss: 9.953529e-04\n",
            "Loss: 9.951559e-04\n",
            "Loss: 9.948288e-04\n",
            "Loss: 9.944142e-04\n",
            "Loss: 9.947770e-04\n",
            "Loss: 9.942014e-04\n",
            "Loss: 9.938277e-04\n",
            "Loss: 9.936327e-04\n",
            "Loss: 9.933864e-04\n",
            "Loss: 9.929930e-04\n",
            "Loss: 9.936680e-04\n",
            "Loss: 9.928452e-04\n",
            "Loss: 9.925725e-04\n",
            "Loss: 9.923177e-04\n",
            "Loss: 9.920120e-04\n",
            "Loss: 9.916218e-04\n",
            "Loss: 9.912187e-04\n",
            "Loss: 9.908135e-04\n",
            "Loss: 9.905479e-04\n",
            "Loss: 9.902624e-04\n",
            "Loss: 9.902590e-04\n",
            "Loss: 9.901096e-04\n",
            "Loss: 9.898837e-04\n",
            "Loss: 9.896533e-04\n",
            "Loss: 9.894080e-04\n",
            "Loss: 9.891399e-04\n",
            "Loss: 9.887862e-04\n",
            "Loss: 9.886337e-04\n",
            "Loss: 9.882298e-04\n",
            "Loss: 9.877983e-04\n",
            "Loss: 9.872084e-04\n",
            "Loss: 9.867465e-04\n",
            "Loss: 9.863906e-04\n",
            "Loss: 9.860918e-04\n",
            "Loss: 9.857875e-04\n",
            "Loss: 9.853400e-04\n",
            "Loss: 9.851785e-04\n",
            "Loss: 9.848189e-04\n",
            "Loss: 9.846737e-04\n",
            "Loss: 9.844870e-04\n",
            "Loss: 9.843268e-04\n",
            "Loss: 9.841764e-04\n",
            "Loss: 9.839342e-04\n",
            "Loss: 9.840197e-04\n",
            "Loss: 9.838722e-04\n",
            "Loss: 9.837379e-04\n",
            "Loss: 9.836419e-04\n",
            "Loss: 9.834440e-04\n",
            "Loss: 9.832896e-04\n",
            "Loss: 9.833906e-04\n",
            "Loss: 9.831289e-04\n",
            "Loss: 9.828917e-04\n",
            "Loss: 9.827360e-04\n",
            "Loss: 9.824974e-04\n",
            "Loss: 9.822227e-04\n",
            "Loss: 9.822785e-04\n",
            "Loss: 9.819444e-04\n",
            "Loss: 9.815012e-04\n",
            "Loss: 9.810084e-04\n",
            "Loss: 9.805176e-04\n",
            "Loss: 9.798564e-04\n",
            "Loss: 9.799746e-04\n",
            "Loss: 9.794305e-04\n",
            "Loss: 9.789836e-04\n",
            "Loss: 9.787525e-04\n",
            "Loss: 9.785484e-04\n",
            "Loss: 9.783360e-04\n",
            "Loss: 9.774612e-04\n",
            "Loss: 9.781520e-04\n",
            "Loss: 9.770683e-04\n",
            "Loss: 9.763764e-04\n",
            "Loss: 9.758752e-04\n",
            "Loss: 9.752138e-04\n",
            "Loss: 9.744481e-04\n",
            "Loss: 9.742472e-04\n",
            "Loss: 9.734266e-04\n",
            "Loss: 9.730779e-04\n",
            "Loss: 9.727316e-04\n",
            "Loss: 9.722114e-04\n",
            "Loss: 9.714531e-04\n",
            "Loss: 9.715197e-04\n",
            "Loss: 9.710192e-04\n",
            "Loss: 9.705867e-04\n",
            "Loss: 9.700785e-04\n",
            "Loss: 9.703980e-04\n",
            "Loss: 9.697702e-04\n",
            "Loss: 9.696112e-04\n",
            "Loss: 9.691336e-04\n",
            "Loss: 9.688066e-04\n",
            "Loss: 9.682283e-04\n",
            "Loss: 9.677783e-04\n",
            "Loss: 9.669220e-04\n",
            "Loss: 9.665937e-04\n",
            "Loss: 9.660068e-04\n",
            "Loss: 9.655820e-04\n",
            "Loss: 9.651923e-04\n",
            "Loss: 9.650894e-04\n",
            "Loss: 9.646966e-04\n",
            "Loss: 9.644231e-04\n",
            "Loss: 9.641516e-04\n",
            "Loss: 9.638456e-04\n",
            "Loss: 9.632233e-04\n",
            "Loss: 9.641065e-04\n",
            "Loss: 9.630072e-04\n",
            "Loss: 9.626280e-04\n",
            "Loss: 9.623358e-04\n",
            "Loss: 9.618665e-04\n",
            "Loss: 9.611435e-04\n",
            "Loss: 9.634146e-04\n",
            "Loss: 9.609179e-04\n",
            "Loss: 9.603775e-04\n",
            "Loss: 9.597974e-04\n",
            "Loss: 9.591017e-04\n",
            "Loss: 9.585979e-04\n",
            "Loss: 9.584413e-04\n",
            "Loss: 9.578603e-04\n",
            "Loss: 9.576856e-04\n",
            "Loss: 9.575615e-04\n",
            "Loss: 9.573675e-04\n",
            "Loss: 9.570620e-04\n",
            "Loss: 9.578248e-04\n",
            "Loss: 9.568905e-04\n",
            "Loss: 9.565552e-04\n",
            "Loss: 9.562724e-04\n",
            "Loss: 9.558725e-04\n",
            "Loss: 9.555691e-04\n",
            "Loss: 9.551542e-04\n",
            "Loss: 9.547203e-04\n",
            "Loss: 9.541903e-04\n",
            "Loss: 9.538897e-04\n",
            "Loss: 9.536175e-04\n",
            "Loss: 9.533169e-04\n",
            "Loss: 9.530424e-04\n",
            "Loss: 9.530331e-04\n",
            "Loss: 9.528740e-04\n",
            "Loss: 9.526940e-04\n",
            "Loss: 9.523638e-04\n",
            "Loss: 9.521722e-04\n",
            "Loss: 9.516509e-04\n",
            "Loss: 9.530545e-04\n",
            "Loss: 9.514836e-04\n",
            "Loss: 9.512036e-04\n",
            "Loss: 9.510401e-04\n",
            "Loss: 9.508447e-04\n",
            "Loss: 9.507898e-04\n",
            "Loss: 9.502621e-04\n",
            "Loss: 9.498247e-04\n",
            "Loss: 9.500632e-04\n",
            "Loss: 9.495283e-04\n",
            "Loss: 9.492079e-04\n",
            "Loss: 9.489409e-04\n",
            "Loss: 9.485209e-04\n",
            "Loss: 9.479703e-04\n",
            "Loss: 9.476441e-04\n",
            "Loss: 9.472927e-04\n",
            "Loss: 9.468386e-04\n",
            "Loss: 9.465435e-04\n",
            "Loss: 9.462404e-04\n",
            "Loss: 9.456536e-04\n",
            "Loss: 9.453639e-04\n",
            "Loss: 9.447484e-04\n",
            "Loss: 9.447694e-04\n",
            "Loss: 9.444641e-04\n",
            "Loss: 9.442779e-04\n",
            "Loss: 9.440726e-04\n",
            "Loss: 9.436363e-04\n",
            "Loss: 9.435081e-04\n",
            "Loss: 9.427998e-04\n",
            "Loss: 9.426200e-04\n",
            "Loss: 9.422788e-04\n",
            "Loss: 9.417227e-04\n",
            "Loss: 9.420105e-04\n",
            "Loss: 9.414520e-04\n",
            "Loss: 9.409485e-04\n",
            "Loss: 9.406275e-04\n",
            "Loss: 9.402991e-04\n",
            "Loss: 9.400029e-04\n",
            "Loss: 9.396240e-04\n",
            "Loss: 9.400848e-04\n",
            "Loss: 9.393480e-04\n",
            "Loss: 9.387998e-04\n",
            "Loss: 9.381930e-04\n",
            "Loss: 9.375150e-04\n",
            "Loss: 9.366515e-04\n",
            "Loss: 9.395480e-04\n",
            "Loss: 9.363390e-04\n",
            "Loss: 9.357197e-04\n",
            "Loss: 9.352789e-04\n",
            "Loss: 9.348287e-04\n",
            "Loss: 9.342628e-04\n",
            "Loss: 9.339649e-04\n",
            "Loss: 9.331781e-04\n",
            "Loss: 9.328755e-04\n",
            "Loss: 9.324386e-04\n",
            "Loss: 9.319236e-04\n",
            "Loss: 9.315150e-04\n",
            "Loss: 9.307052e-04\n",
            "Loss: 9.303605e-04\n",
            "Loss: 9.299346e-04\n",
            "Loss: 9.296235e-04\n",
            "Loss: 9.294484e-04\n",
            "Loss: 9.291805e-04\n",
            "Loss: 9.290352e-04\n",
            "Loss: 9.284890e-04\n",
            "Loss: 9.278944e-04\n",
            "Loss: 9.274093e-04\n",
            "Loss: 9.267210e-04\n",
            "Loss: 9.264038e-04\n",
            "Loss: 9.260237e-04\n",
            "Loss: 9.256704e-04\n",
            "Loss: 9.253091e-04\n",
            "Loss: 9.246442e-04\n",
            "Loss: 9.239166e-04\n",
            "Loss: 9.231755e-04\n",
            "Loss: 9.225950e-04\n",
            "Loss: 9.222042e-04\n",
            "Loss: 9.219365e-04\n",
            "Loss: 9.214000e-04\n",
            "Loss: 9.210465e-04\n",
            "Loss: 9.207212e-04\n",
            "Loss: 9.202894e-04\n",
            "Loss: 9.199433e-04\n",
            "Loss: 9.195496e-04\n",
            "Loss: 9.192780e-04\n",
            "Loss: 9.189649e-04\n",
            "Loss: 9.184207e-04\n",
            "Loss: 9.180399e-04\n",
            "Loss: 9.179795e-04\n",
            "Loss: 9.176806e-04\n",
            "Loss: 9.169877e-04\n",
            "Loss: 9.162897e-04\n",
            "Loss: 9.154234e-04\n",
            "Loss: 9.148751e-04\n",
            "Loss: 9.150275e-04\n",
            "Loss: 9.144491e-04\n",
            "Loss: 9.137146e-04\n",
            "Loss: 9.132331e-04\n",
            "Loss: 9.125872e-04\n",
            "Loss: 9.121873e-04\n",
            "Loss: 9.117548e-04\n",
            "Loss: 9.111422e-04\n",
            "Loss: 9.104810e-04\n",
            "Loss: 9.096769e-04\n",
            "Loss: 9.089077e-04\n",
            "Loss: 9.081876e-04\n",
            "Loss: 9.071899e-04\n",
            "Loss: 9.058376e-04\n",
            "Loss: 9.049898e-04\n",
            "Loss: 9.044359e-04\n",
            "Loss: 9.038403e-04\n",
            "Loss: 9.031270e-04\n",
            "Loss: 9.025842e-04\n",
            "Loss: 9.023173e-04\n",
            "Loss: 9.017447e-04\n",
            "Loss: 9.014901e-04\n",
            "Loss: 9.012103e-04\n",
            "Loss: 9.010037e-04\n",
            "Loss: 9.008342e-04\n",
            "Loss: 9.005393e-04\n",
            "Loss: 9.003943e-04\n",
            "Loss: 9.000082e-04\n",
            "Loss: 8.998842e-04\n",
            "Loss: 8.995468e-04\n",
            "Loss: 8.992890e-04\n",
            "Loss: 8.990476e-04\n",
            "Loss: 8.986789e-04\n",
            "Loss: 8.984888e-04\n",
            "Loss: 8.980692e-04\n",
            "Loss: 8.978761e-04\n",
            "Loss: 8.974830e-04\n",
            "Loss: 8.971585e-04\n",
            "Loss: 8.972124e-04\n",
            "Loss: 8.969768e-04\n",
            "Loss: 8.966528e-04\n",
            "Loss: 8.964550e-04\n",
            "Loss: 8.961484e-04\n",
            "Loss: 8.958324e-04\n",
            "Loss: 8.955613e-04\n",
            "Loss: 8.953267e-04\n",
            "Loss: 8.951320e-04\n",
            "Loss: 8.949385e-04\n",
            "Loss: 8.947873e-04\n",
            "Loss: 8.946107e-04\n",
            "Loss: 8.941893e-04\n",
            "Loss: 8.937223e-04\n",
            "Loss: 8.932482e-04\n",
            "Loss: 8.928888e-04\n",
            "Loss: 8.925768e-04\n",
            "Loss: 8.922424e-04\n",
            "Loss: 8.925349e-04\n",
            "Loss: 8.920841e-04\n",
            "Loss: 8.918799e-04\n",
            "Loss: 8.917768e-04\n",
            "Loss: 8.916139e-04\n",
            "Loss: 8.912301e-04\n",
            "Loss: 8.906518e-04\n",
            "Loss: 8.912964e-04\n",
            "Loss: 8.903790e-04\n",
            "Loss: 8.897945e-04\n",
            "Loss: 8.894391e-04\n",
            "Loss: 8.891239e-04\n",
            "Loss: 8.886901e-04\n",
            "Loss: 8.881758e-04\n",
            "Loss: 8.878013e-04\n",
            "Loss: 8.874313e-04\n",
            "Loss: 8.870458e-04\n",
            "Loss: 8.867953e-04\n",
            "Loss: 8.864622e-04\n",
            "Loss: 8.860236e-04\n",
            "Loss: 8.859388e-04\n",
            "Loss: 8.855230e-04\n",
            "Loss: 8.853653e-04\n",
            "Loss: 8.850453e-04\n",
            "Loss: 8.846852e-04\n",
            "Loss: 8.844207e-04\n",
            "Loss: 8.840855e-04\n",
            "Loss: 8.838713e-04\n",
            "Loss: 8.837535e-04\n",
            "Loss: 8.834202e-04\n",
            "Loss: 8.830052e-04\n",
            "Loss: 8.835209e-04\n",
            "Loss: 8.827531e-04\n",
            "Loss: 8.823678e-04\n",
            "Loss: 8.820637e-04\n",
            "Loss: 8.816381e-04\n",
            "Loss: 8.811558e-04\n",
            "Loss: 8.804778e-04\n",
            "Loss: 8.799207e-04\n",
            "Loss: 8.795318e-04\n",
            "Loss: 8.792249e-04\n",
            "Loss: 8.789877e-04\n",
            "Loss: 8.787777e-04\n",
            "Loss: 8.786183e-04\n",
            "Loss: 8.782615e-04\n",
            "Loss: 8.786449e-04\n",
            "Loss: 8.780196e-04\n",
            "Loss: 8.777280e-04\n",
            "Loss: 8.772621e-04\n",
            "Loss: 8.769299e-04\n",
            "Loss: 8.767758e-04\n",
            "Loss: 8.765237e-04\n",
            "Loss: 8.764196e-04\n",
            "Loss: 8.762510e-04\n",
            "Loss: 8.759251e-04\n",
            "Loss: 8.755365e-04\n",
            "Loss: 8.758772e-04\n",
            "Loss: 8.753781e-04\n",
            "Loss: 8.750883e-04\n",
            "Loss: 8.749092e-04\n",
            "Loss: 8.745537e-04\n",
            "Loss: 8.738765e-04\n",
            "Loss: 8.730151e-04\n",
            "Loss: 8.726231e-04\n",
            "Loss: 8.721206e-04\n",
            "Loss: 8.719444e-04\n",
            "Loss: 8.717775e-04\n",
            "Loss: 8.714772e-04\n",
            "Loss: 8.711742e-04\n",
            "Loss: 8.709377e-04\n",
            "Loss: 8.707622e-04\n",
            "Loss: 8.705072e-04\n",
            "Loss: 8.700372e-04\n",
            "Loss: 8.697236e-04\n",
            "Loss: 8.692934e-04\n",
            "Loss: 8.689930e-04\n",
            "Loss: 8.687373e-04\n",
            "Loss: 8.684681e-04\n",
            "Loss: 8.682446e-04\n",
            "Loss: 8.679316e-04\n",
            "Loss: 8.677570e-04\n",
            "Loss: 8.676017e-04\n",
            "Loss: 8.673855e-04\n",
            "Loss: 8.672433e-04\n",
            "Loss: 8.666759e-04\n",
            "Loss: 8.661834e-04\n",
            "Loss: 8.657887e-04\n",
            "Loss: 8.653002e-04\n",
            "Loss: 8.650585e-04\n",
            "Loss: 8.647522e-04\n",
            "Loss: 8.643040e-04\n",
            "Loss: 8.638239e-04\n",
            "Loss: 8.634131e-04\n",
            "Loss: 8.633397e-04\n",
            "Loss: 8.630253e-04\n",
            "Loss: 8.629133e-04\n",
            "Loss: 8.627500e-04\n",
            "Loss: 8.626189e-04\n",
            "Loss: 8.624113e-04\n",
            "Loss: 8.621434e-04\n",
            "Loss: 8.620385e-04\n",
            "Loss: 8.618698e-04\n",
            "Loss: 8.617571e-04\n",
            "Loss: 8.616586e-04\n",
            "Loss: 8.613588e-04\n",
            "Loss: 8.614811e-04\n",
            "Loss: 8.612607e-04\n",
            "Loss: 8.610350e-04\n",
            "Loss: 8.607912e-04\n",
            "Loss: 8.605198e-04\n",
            "Loss: 8.602692e-04\n",
            "Loss: 8.600660e-04\n",
            "Loss: 8.598640e-04\n",
            "Loss: 8.597269e-04\n",
            "Loss: 8.595739e-04\n",
            "Loss: 8.592901e-04\n",
            "Loss: 8.588243e-04\n",
            "Loss: 8.582604e-04\n",
            "Loss: 8.581920e-04\n",
            "Loss: 8.580105e-04\n",
            "Loss: 8.577225e-04\n",
            "Loss: 8.575178e-04\n",
            "Loss: 8.573750e-04\n",
            "Loss: 8.571400e-04\n",
            "Loss: 8.568106e-04\n",
            "Loss: 8.564637e-04\n",
            "Loss: 8.561594e-04\n",
            "Loss: 8.556833e-04\n",
            "Loss: 8.555109e-04\n",
            "Loss: 8.553441e-04\n",
            "Loss: 8.551042e-04\n",
            "Loss: 8.547765e-04\n",
            "Loss: 8.544423e-04\n",
            "Loss: 8.542822e-04\n",
            "Loss: 8.540524e-04\n",
            "Loss: 8.539052e-04\n",
            "Loss: 8.537662e-04\n",
            "Loss: 8.535888e-04\n",
            "Loss: 8.534061e-04\n",
            "Loss: 8.530676e-04\n",
            "Loss: 8.528779e-04\n",
            "Loss: 8.527255e-04\n",
            "Loss: 8.524883e-04\n",
            "Loss: 8.530433e-04\n",
            "Loss: 8.523549e-04\n",
            "Loss: 8.520941e-04\n",
            "Loss: 8.519174e-04\n",
            "Loss: 8.516699e-04\n",
            "Loss: 8.514131e-04\n",
            "Loss: 8.509636e-04\n",
            "Loss: 8.542130e-04\n",
            "Loss: 8.508547e-04\n",
            "Loss: 8.506458e-04\n",
            "Loss: 8.504124e-04\n",
            "Loss: 8.503643e-04\n",
            "Loss: 8.501651e-04\n",
            "Loss: 8.500420e-04\n",
            "Loss: 8.498611e-04\n",
            "Loss: 8.496869e-04\n",
            "Loss: 8.495292e-04\n",
            "Loss: 8.492696e-04\n",
            "Loss: 8.491065e-04\n",
            "Loss: 8.489828e-04\n",
            "Loss: 8.488310e-04\n",
            "Loss: 8.485576e-04\n",
            "Loss: 8.482525e-04\n",
            "Loss: 8.488808e-04\n",
            "Loss: 8.481289e-04\n",
            "Loss: 8.479746e-04\n",
            "Loss: 8.477846e-04\n",
            "Loss: 8.476097e-04\n",
            "Loss: 8.473693e-04\n",
            "Loss: 8.471260e-04\n",
            "Loss: 8.469451e-04\n",
            "Loss: 8.469181e-04\n",
            "Loss: 8.468073e-04\n",
            "Loss: 8.466940e-04\n",
            "Loss: 8.466086e-04\n",
            "Loss: 8.464669e-04\n",
            "Loss: 8.462174e-04\n",
            "Loss: 8.466846e-04\n",
            "Loss: 8.460623e-04\n",
            "Loss: 8.458226e-04\n",
            "Loss: 8.456346e-04\n",
            "Loss: 8.453642e-04\n",
            "Loss: 8.450247e-04\n",
            "Loss: 8.452240e-04\n",
            "Loss: 8.448164e-04\n",
            "Loss: 8.444259e-04\n",
            "Loss: 8.442319e-04\n",
            "Loss: 8.441189e-04\n",
            "Loss: 8.439540e-04\n",
            "Loss: 8.437040e-04\n",
            "Loss: 8.433270e-04\n",
            "Loss: 8.430436e-04\n",
            "Loss: 8.426671e-04\n",
            "Loss: 8.423792e-04\n",
            "Loss: 8.421935e-04\n",
            "Loss: 8.416466e-04\n",
            "Loss: 8.414628e-04\n",
            "Loss: 8.412019e-04\n",
            "Loss: 8.409602e-04\n",
            "Loss: 8.405255e-04\n",
            "Loss: 8.404173e-04\n",
            "Loss: 8.400403e-04\n",
            "Loss: 8.399189e-04\n",
            "Loss: 8.396851e-04\n",
            "Loss: 8.393710e-04\n",
            "Loss: 8.389890e-04\n",
            "Loss: 8.386437e-04\n",
            "Loss: 8.384330e-04\n",
            "Loss: 8.382523e-04\n",
            "Loss: 8.380024e-04\n",
            "Loss: 8.377268e-04\n",
            "Loss: 8.375503e-04\n",
            "Loss: 8.373415e-04\n",
            "Loss: 8.371180e-04\n",
            "Loss: 8.368678e-04\n",
            "Loss: 8.367491e-04\n",
            "Loss: 8.365624e-04\n",
            "Loss: 8.362750e-04\n",
            "Loss: 8.358868e-04\n",
            "Loss: 8.358029e-04\n",
            "Loss: 8.354941e-04\n",
            "Loss: 8.353647e-04\n",
            "Loss: 8.351447e-04\n",
            "Loss: 8.348661e-04\n",
            "Loss: 8.344535e-04\n",
            "Loss: 8.341551e-04\n",
            "Loss: 8.339676e-04\n",
            "Loss: 8.337619e-04\n",
            "Loss: 8.335556e-04\n",
            "Loss: 8.332959e-04\n",
            "Loss: 8.330735e-04\n",
            "Loss: 8.328187e-04\n",
            "Loss: 8.324992e-04\n",
            "Loss: 8.321117e-04\n",
            "Loss: 8.317414e-04\n",
            "Loss: 8.314501e-04\n",
            "Loss: 8.309290e-04\n",
            "Loss: 8.321433e-04\n",
            "Loss: 8.307541e-04\n",
            "Loss: 8.304806e-04\n",
            "Loss: 8.302088e-04\n",
            "Loss: 8.299869e-04\n",
            "Loss: 8.298749e-04\n",
            "Loss: 8.296766e-04\n",
            "Loss: 8.294651e-04\n",
            "Loss: 8.292893e-04\n",
            "Loss: 8.289480e-04\n",
            "Loss: 8.288086e-04\n",
            "Loss: 8.286137e-04\n",
            "Loss: 8.284395e-04\n",
            "Loss: 8.282244e-04\n",
            "Loss: 8.278394e-04\n",
            "Loss: 8.274289e-04\n",
            "Loss: 8.269919e-04\n",
            "Loss: 8.267129e-04\n",
            "Loss: 8.264886e-04\n",
            "Loss: 8.262899e-04\n",
            "Loss: 8.261392e-04\n",
            "Loss: 8.257799e-04\n",
            "Loss: 8.255809e-04\n",
            "Loss: 8.253531e-04\n",
            "Loss: 8.248284e-04\n",
            "Loss: 8.245048e-04\n",
            "Loss: 8.241878e-04\n",
            "Loss: 8.239356e-04\n",
            "Loss: 8.236821e-04\n",
            "Loss: 8.234830e-04\n",
            "Loss: 8.232290e-04\n",
            "Loss: 8.228690e-04\n",
            "Loss: 8.225590e-04\n",
            "Loss: 8.219935e-04\n",
            "Loss: 8.216967e-04\n",
            "Loss: 8.212054e-04\n",
            "Loss: 8.209175e-04\n",
            "Loss: 8.205942e-04\n",
            "Loss: 8.202501e-04\n",
            "Loss: 8.197760e-04\n",
            "Loss: 8.193184e-04\n",
            "Loss: 8.187993e-04\n",
            "Loss: 8.181685e-04\n",
            "Loss: 8.177756e-04\n",
            "Loss: 8.174985e-04\n",
            "Loss: 8.172531e-04\n",
            "Loss: 8.169400e-04\n",
            "Loss: 8.166244e-04\n",
            "Loss: 8.163591e-04\n",
            "Loss: 8.161159e-04\n",
            "Loss: 8.157449e-04\n",
            "Loss: 8.153643e-04\n",
            "Loss: 8.151234e-04\n",
            "Loss: 8.149092e-04\n",
            "Loss: 8.147190e-04\n",
            "Loss: 8.144766e-04\n",
            "Loss: 8.142528e-04\n",
            "Loss: 8.140030e-04\n",
            "Loss: 8.141110e-04\n",
            "Loss: 8.139157e-04\n",
            "Loss: 8.137872e-04\n",
            "Loss: 8.136784e-04\n",
            "Loss: 8.134487e-04\n",
            "Loss: 8.133219e-04\n",
            "Loss: 8.130809e-04\n",
            "Loss: 8.129497e-04\n",
            "Loss: 8.128104e-04\n",
            "Loss: 8.126386e-04\n",
            "Loss: 8.123537e-04\n",
            "Loss: 8.121359e-04\n",
            "Loss: 8.118483e-04\n",
            "Loss: 8.115143e-04\n",
            "Loss: 8.112451e-04\n",
            "Loss: 8.110733e-04\n",
            "Loss: 8.108359e-04\n",
            "Loss: 8.106974e-04\n",
            "Loss: 8.104810e-04\n",
            "Loss: 8.101841e-04\n",
            "Loss: 8.100317e-04\n",
            "Loss: 8.096924e-04\n",
            "Loss: 8.095524e-04\n",
            "Loss: 8.093643e-04\n",
            "Loss: 8.091715e-04\n",
            "Loss: 8.092327e-04\n",
            "Loss: 8.090419e-04\n",
            "Loss: 8.087512e-04\n",
            "Loss: 8.085801e-04\n",
            "Loss: 8.084363e-04\n",
            "Loss: 8.082676e-04\n",
            "Loss: 8.082630e-04\n",
            "Loss: 8.081229e-04\n",
            "Loss: 8.079156e-04\n",
            "Loss: 8.077336e-04\n",
            "Loss: 8.075121e-04\n",
            "Loss: 8.072463e-04\n",
            "Loss: 8.078755e-04\n",
            "Loss: 8.070528e-04\n",
            "Loss: 8.065664e-04\n",
            "Loss: 8.061730e-04\n",
            "Loss: 8.058656e-04\n",
            "Loss: 8.056669e-04\n",
            "Loss: 8.054024e-04\n",
            "Loss: 8.050958e-04\n",
            "Loss: 8.047774e-04\n",
            "Loss: 8.047210e-04\n",
            "Loss: 8.045125e-04\n",
            "Loss: 8.043486e-04\n",
            "Loss: 8.040975e-04\n",
            "Loss: 8.037833e-04\n",
            "Loss: 8.038495e-04\n",
            "Loss: 8.035914e-04\n",
            "Loss: 8.033082e-04\n",
            "Loss: 8.031568e-04\n",
            "Loss: 8.029558e-04\n",
            "Loss: 8.027556e-04\n",
            "Loss: 8.024692e-04\n",
            "Loss: 8.020964e-04\n",
            "Loss: 8.019553e-04\n",
            "Loss: 8.017987e-04\n",
            "Loss: 8.016588e-04\n",
            "Loss: 8.014134e-04\n",
            "Loss: 8.011987e-04\n",
            "Loss: 8.010664e-04\n",
            "Loss: 8.009026e-04\n",
            "Loss: 8.008188e-04\n",
            "Loss: 8.005396e-04\n",
            "Loss: 8.002328e-04\n",
            "Loss: 7.999038e-04\n",
            "Loss: 8.000110e-04\n",
            "Loss: 7.997493e-04\n",
            "Loss: 7.996144e-04\n",
            "Loss: 7.995447e-04\n",
            "Loss: 7.993274e-04\n",
            "Loss: 7.990586e-04\n",
            "Loss: 7.988337e-04\n",
            "Loss: 7.986128e-04\n",
            "Loss: 7.988263e-04\n",
            "Loss: 7.985248e-04\n",
            "Loss: 7.985123e-04\n",
            "Loss: 7.982544e-04\n",
            "Loss: 7.980922e-04\n",
            "Loss: 7.978785e-04\n",
            "Loss: 7.977136e-04\n",
            "Loss: 7.976177e-04\n",
            "Loss: 7.974996e-04\n",
            "Loss: 7.972775e-04\n",
            "Loss: 7.980823e-04\n",
            "Loss: 7.972133e-04\n",
            "Loss: 7.970626e-04\n",
            "Loss: 7.968983e-04\n",
            "Loss: 7.966619e-04\n",
            "Loss: 7.962854e-04\n",
            "Loss: 7.960362e-04\n",
            "Loss: 7.955869e-04\n",
            "Loss: 7.952597e-04\n",
            "Loss: 7.950824e-04\n",
            "Loss: 7.949756e-04\n",
            "Loss: 7.948560e-04\n",
            "Loss: 7.946616e-04\n",
            "Loss: 7.943052e-04\n",
            "Loss: 7.940003e-04\n",
            "Loss: 7.936591e-04\n",
            "Loss: 7.941549e-04\n",
            "Loss: 7.935257e-04\n",
            "Loss: 7.931532e-04\n",
            "Loss: 7.926587e-04\n",
            "Loss: 7.921614e-04\n",
            "Loss: 7.920602e-04\n",
            "Loss: 7.914437e-04\n",
            "Loss: 7.913081e-04\n",
            "Loss: 7.911753e-04\n",
            "Loss: 7.909795e-04\n",
            "Loss: 7.914118e-04\n",
            "Loss: 7.908640e-04\n",
            "Loss: 7.906546e-04\n",
            "Loss: 7.904383e-04\n",
            "Loss: 7.903150e-04\n",
            "Loss: 7.902045e-04\n",
            "Loss: 7.900612e-04\n",
            "Loss: 7.899644e-04\n",
            "Loss: 7.897890e-04\n",
            "Loss: 7.896256e-04\n",
            "Loss: 7.895151e-04\n",
            "Loss: 7.893153e-04\n",
            "Loss: 7.892481e-04\n",
            "Loss: 7.891164e-04\n",
            "Loss: 7.890203e-04\n",
            "Loss: 7.888580e-04\n",
            "Loss: 7.887276e-04\n",
            "Loss: 7.885852e-04\n",
            "Loss: 7.883765e-04\n",
            "Loss: 7.880578e-04\n",
            "Loss: 7.883898e-04\n",
            "Loss: 7.878949e-04\n",
            "Loss: 7.877015e-04\n",
            "Loss: 7.875221e-04\n",
            "Loss: 7.873547e-04\n",
            "Loss: 7.871262e-04\n",
            "Loss: 7.869482e-04\n",
            "Loss: 7.867302e-04\n",
            "Loss: 7.866299e-04\n",
            "Loss: 7.864448e-04\n",
            "Loss: 7.861685e-04\n",
            "Loss: 7.860512e-04\n",
            "Loss: 7.857762e-04\n",
            "Loss: 7.856373e-04\n",
            "Loss: 7.854609e-04\n",
            "Loss: 7.851328e-04\n",
            "Loss: 7.846669e-04\n",
            "Loss: 7.866687e-04\n",
            "Loss: 7.844658e-04\n",
            "Loss: 7.841119e-04\n",
            "Loss: 7.837493e-04\n",
            "Loss: 7.833510e-04\n",
            "Loss: 7.834634e-04\n",
            "Loss: 7.832223e-04\n",
            "Loss: 7.828934e-04\n",
            "Loss: 7.826485e-04\n",
            "Loss: 7.824051e-04\n",
            "Loss: 7.821879e-04\n",
            "Loss: 7.818884e-04\n",
            "Loss: 7.815480e-04\n",
            "Loss: 7.812725e-04\n",
            "Loss: 7.810141e-04\n",
            "Loss: 7.807910e-04\n",
            "Loss: 7.806072e-04\n",
            "Loss: 7.802746e-04\n",
            "Loss: 7.800093e-04\n",
            "Loss: 7.797938e-04\n",
            "Loss: 7.795497e-04\n",
            "Loss: 7.793856e-04\n",
            "Loss: 7.792860e-04\n",
            "Loss: 7.790240e-04\n",
            "Loss: 7.790831e-04\n",
            "Loss: 7.789109e-04\n",
            "Loss: 7.787281e-04\n",
            "Loss: 7.785448e-04\n",
            "Loss: 7.783374e-04\n",
            "Loss: 7.780803e-04\n",
            "Loss: 7.779609e-04\n",
            "Loss: 7.776495e-04\n",
            "Loss: 7.775532e-04\n",
            "Loss: 7.773968e-04\n",
            "Loss: 7.772758e-04\n",
            "Loss: 7.771097e-04\n",
            "Loss: 7.769723e-04\n",
            "Loss: 7.767053e-04\n",
            "Loss: 7.767713e-04\n",
            "Loss: 7.766042e-04\n",
            "Loss: 7.764188e-04\n",
            "Loss: 7.762561e-04\n",
            "Loss: 7.760339e-04\n",
            "Loss: 7.758988e-04\n",
            "Loss: 7.757277e-04\n",
            "Loss: 7.756314e-04\n",
            "Loss: 7.755290e-04\n",
            "Loss: 7.754170e-04\n",
            "Loss: 7.752712e-04\n",
            "Loss: 7.748984e-04\n",
            "Loss: 7.746854e-04\n",
            "Loss: 7.744011e-04\n",
            "Loss: 7.742841e-04\n",
            "Loss: 7.740856e-04\n",
            "Loss: 7.736982e-04\n",
            "Loss: 7.739794e-04\n",
            "Loss: 7.735845e-04\n",
            "Loss: 7.733487e-04\n",
            "Loss: 7.732344e-04\n",
            "Loss: 7.731469e-04\n",
            "Loss: 7.729507e-04\n",
            "Loss: 7.727376e-04\n",
            "Loss: 7.725667e-04\n",
            "Loss: 7.722888e-04\n",
            "Loss: 7.719069e-04\n",
            "Loss: 7.716607e-04\n",
            "Loss: 7.713911e-04\n",
            "Loss: 7.712891e-04\n",
            "Loss: 7.710540e-04\n",
            "Loss: 7.708810e-04\n",
            "Loss: 7.705571e-04\n",
            "Loss: 7.703559e-04\n",
            "Loss: 7.701420e-04\n",
            "Loss: 7.698029e-04\n",
            "Loss: 7.694205e-04\n",
            "Loss: 7.691712e-04\n",
            "Loss: 7.689319e-04\n",
            "Loss: 7.687521e-04\n",
            "Loss: 7.683516e-04\n",
            "Loss: 7.686166e-04\n",
            "Loss: 7.681986e-04\n",
            "Loss: 7.680330e-04\n",
            "Loss: 7.678251e-04\n",
            "Loss: 7.677034e-04\n",
            "Loss: 7.674593e-04\n",
            "Loss: 7.675397e-04\n",
            "Loss: 7.673437e-04\n",
            "Loss: 7.671787e-04\n",
            "Loss: 7.670055e-04\n",
            "Loss: 7.667919e-04\n",
            "Loss: 7.665618e-04\n",
            "Loss: 7.663466e-04\n",
            "Loss: 7.661592e-04\n",
            "Loss: 7.659543e-04\n",
            "Loss: 7.655105e-04\n",
            "Loss: 7.658580e-04\n",
            "Loss: 7.653165e-04\n",
            "Loss: 7.650302e-04\n",
            "Loss: 7.648534e-04\n",
            "Loss: 7.647326e-04\n",
            "Loss: 7.643913e-04\n",
            "Loss: 7.641930e-04\n",
            "Loss: 7.639019e-04\n",
            "Loss: 7.637306e-04\n",
            "Loss: 7.635864e-04\n",
            "Loss: 7.633753e-04\n",
            "Loss: 7.632783e-04\n",
            "Loss: 7.631732e-04\n",
            "Loss: 7.630884e-04\n",
            "Loss: 7.629772e-04\n",
            "Loss: 7.626321e-04\n",
            "Loss: 7.624545e-04\n",
            "Loss: 7.621677e-04\n",
            "Loss: 7.620341e-04\n",
            "Loss: 7.619137e-04\n",
            "Loss: 7.616895e-04\n",
            "Loss: 7.616140e-04\n",
            "Loss: 7.614783e-04\n",
            "Loss: 7.614111e-04\n",
            "Loss: 7.613070e-04\n",
            "Loss: 7.611266e-04\n",
            "Loss: 7.610664e-04\n",
            "Loss: 7.607364e-04\n",
            "Loss: 7.606308e-04\n",
            "Loss: 7.605106e-04\n",
            "Loss: 7.603497e-04\n",
            "Loss: 7.601430e-04\n",
            "Loss: 7.598920e-04\n",
            "Loss: 7.596774e-04\n",
            "Loss: 7.594861e-04\n",
            "Loss: 7.593616e-04\n",
            "Loss: 7.593076e-04\n",
            "Loss: 7.590841e-04\n",
            "Loss: 7.589237e-04\n",
            "Loss: 7.588614e-04\n",
            "Loss: 7.586518e-04\n",
            "Loss: 7.585870e-04\n",
            "Loss: 7.584309e-04\n",
            "Loss: 7.582122e-04\n",
            "Loss: 7.585743e-04\n",
            "Loss: 7.580849e-04\n",
            "Loss: 7.579137e-04\n",
            "Loss: 7.577717e-04\n",
            "Loss: 7.575140e-04\n",
            "Loss: 7.571800e-04\n",
            "Loss: 7.572474e-04\n",
            "Loss: 7.570261e-04\n",
            "Loss: 7.568343e-04\n",
            "Loss: 7.566210e-04\n",
            "Loss: 7.563701e-04\n",
            "Loss: 7.560175e-04\n",
            "Loss: 7.560450e-04\n",
            "Loss: 7.558280e-04\n",
            "Loss: 7.556429e-04\n",
            "Loss: 7.554292e-04\n",
            "Loss: 7.552750e-04\n",
            "Loss: 7.550289e-04\n",
            "Loss: 7.549901e-04\n",
            "Loss: 7.547826e-04\n",
            "Loss: 7.547284e-04\n",
            "Loss: 7.546064e-04\n",
            "Loss: 7.544708e-04\n",
            "Loss: 7.545965e-04\n",
            "Loss: 7.543519e-04\n",
            "Loss: 7.541367e-04\n",
            "Loss: 7.539949e-04\n",
            "Loss: 7.538487e-04\n",
            "Loss: 7.536631e-04\n",
            "Loss: 7.536646e-04\n",
            "Loss: 7.535320e-04\n",
            "Loss: 7.533585e-04\n",
            "Loss: 7.532991e-04\n",
            "Loss: 7.532049e-04\n",
            "Loss: 7.530378e-04\n",
            "Loss: 7.529905e-04\n",
            "Loss: 7.527287e-04\n",
            "Loss: 7.526020e-04\n",
            "Loss: 7.524170e-04\n",
            "Loss: 7.522023e-04\n",
            "Loss: 7.517815e-04\n",
            "Loss: 7.519427e-04\n",
            "Loss: 7.516531e-04\n",
            "Loss: 7.515042e-04\n",
            "Loss: 7.513402e-04\n",
            "Loss: 7.510959e-04\n",
            "Loss: 7.507221e-04\n",
            "Loss: 7.509827e-04\n",
            "Loss: 7.505355e-04\n",
            "Loss: 7.501720e-04\n",
            "Loss: 7.499637e-04\n",
            "Loss: 7.499556e-04\n",
            "Loss: 7.498564e-04\n",
            "Loss: 7.497667e-04\n",
            "Loss: 7.495831e-04\n",
            "Loss: 7.493119e-04\n",
            "Loss: 7.490093e-04\n",
            "Loss: 7.488125e-04\n",
            "Loss: 7.486052e-04\n",
            "Loss: 7.483894e-04\n",
            "Loss: 7.481158e-04\n",
            "Loss: 7.480719e-04\n",
            "Loss: 7.477779e-04\n",
            "Loss: 7.476853e-04\n",
            "Loss: 7.475644e-04\n",
            "Loss: 7.474126e-04\n",
            "Loss: 7.471731e-04\n",
            "Loss: 7.470236e-04\n",
            "Loss: 7.467880e-04\n",
            "Loss: 7.465449e-04\n",
            "Loss: 7.479877e-04\n",
            "Loss: 7.464442e-04\n",
            "Loss: 7.461792e-04\n",
            "Loss: 7.460151e-04\n",
            "Loss: 7.458141e-04\n",
            "Loss: 7.454976e-04\n",
            "Loss: 7.454090e-04\n",
            "Loss: 7.450515e-04\n",
            "Loss: 7.449833e-04\n",
            "Loss: 7.448074e-04\n",
            "Loss: 7.446401e-04\n",
            "Loss: 7.444772e-04\n",
            "Loss: 7.443654e-04\n",
            "Loss: 7.441973e-04\n",
            "Loss: 7.439817e-04\n",
            "Loss: 7.437874e-04\n",
            "Loss: 7.436126e-04\n",
            "Loss: 7.435071e-04\n",
            "Loss: 7.434374e-04\n",
            "Loss: 7.433459e-04\n",
            "Loss: 7.431182e-04\n",
            "Loss: 7.432625e-04\n",
            "Loss: 7.430544e-04\n",
            "Loss: 7.428619e-04\n",
            "Loss: 7.426954e-04\n",
            "Loss: 7.425543e-04\n",
            "Loss: 7.424115e-04\n",
            "Loss: 7.423234e-04\n",
            "Loss: 7.422569e-04\n",
            "Loss: 7.421928e-04\n",
            "Loss: 7.420640e-04\n",
            "Loss: 7.418438e-04\n",
            "Loss: 7.415094e-04\n",
            "Loss: 7.418084e-04\n",
            "Loss: 7.413725e-04\n",
            "Loss: 7.411193e-04\n",
            "Loss: 7.409662e-04\n",
            "Loss: 7.410558e-04\n",
            "Loss: 7.408884e-04\n",
            "Loss: 7.407463e-04\n",
            "Loss: 7.405198e-04\n",
            "Loss: 7.403119e-04\n",
            "Loss: 7.404066e-04\n",
            "Loss: 7.401992e-04\n",
            "Loss: 7.400105e-04\n",
            "Loss: 7.398420e-04\n",
            "Loss: 7.397445e-04\n",
            "Loss: 7.395863e-04\n",
            "Loss: 7.394014e-04\n",
            "Loss: 7.392093e-04\n",
            "Loss: 7.390929e-04\n",
            "Loss: 7.389796e-04\n",
            "Loss: 7.388453e-04\n",
            "Loss: 7.387133e-04\n",
            "Loss: 7.385723e-04\n",
            "Loss: 7.384125e-04\n",
            "Loss: 7.382696e-04\n",
            "Loss: 7.380725e-04\n",
            "Loss: 7.381806e-04\n",
            "Loss: 7.378869e-04\n",
            "Loss: 7.377459e-04\n",
            "Loss: 7.376345e-04\n",
            "Loss: 7.375216e-04\n",
            "Loss: 7.371919e-04\n",
            "Loss: 7.373191e-04\n",
            "Loss: 7.369801e-04\n",
            "Loss: 7.367221e-04\n",
            "Loss: 7.365167e-04\n",
            "Loss: 7.363653e-04\n",
            "Loss: 7.361619e-04\n",
            "Loss: 7.359246e-04\n",
            "Loss: 7.357875e-04\n",
            "Loss: 7.354048e-04\n",
            "Loss: 7.350708e-04\n",
            "Loss: 7.346797e-04\n",
            "Loss: 7.345300e-04\n",
            "Loss: 7.341369e-04\n",
            "Loss: 7.339505e-04\n",
            "Loss: 7.336232e-04\n",
            "Loss: 7.333387e-04\n",
            "Loss: 7.330699e-04\n",
            "Loss: 7.328975e-04\n",
            "Loss: 7.327431e-04\n",
            "Loss: 7.324552e-04\n",
            "Loss: 7.322306e-04\n",
            "Loss: 7.320251e-04\n",
            "Loss: 7.318390e-04\n",
            "Loss: 7.314955e-04\n",
            "Loss: 7.311248e-04\n",
            "Loss: 7.307531e-04\n",
            "Loss: 7.303904e-04\n",
            "Loss: 7.305808e-04\n",
            "Loss: 7.301733e-04\n",
            "Loss: 7.298748e-04\n",
            "Loss: 7.296555e-04\n",
            "Loss: 7.295434e-04\n",
            "Loss: 7.293387e-04\n",
            "Loss: 7.292493e-04\n",
            "Loss: 7.290273e-04\n",
            "Loss: 7.287213e-04\n",
            "Loss: 7.286987e-04\n",
            "Loss: 7.285664e-04\n",
            "Loss: 7.283590e-04\n",
            "Loss: 7.282522e-04\n",
            "Loss: 7.281633e-04\n",
            "Loss: 7.280430e-04\n",
            "Loss: 7.279110e-04\n",
            "Loss: 7.277884e-04\n",
            "Loss: 7.276833e-04\n",
            "Loss: 7.274576e-04\n",
            "Loss: 7.269669e-04\n",
            "Loss: 7.275353e-04\n",
            "Loss: 7.267409e-04\n",
            "Loss: 7.262472e-04\n",
            "Loss: 7.258672e-04\n",
            "Loss: 7.258093e-04\n",
            "Loss: 7.253864e-04\n",
            "Loss: 7.252085e-04\n",
            "Loss: 7.249625e-04\n",
            "Loss: 7.247406e-04\n",
            "Loss: 7.243889e-04\n",
            "Loss: 7.238682e-04\n",
            "Loss: 7.235986e-04\n",
            "Loss: 7.230397e-04\n",
            "Loss: 7.240619e-04\n",
            "Loss: 7.228783e-04\n",
            "Loss: 7.226641e-04\n",
            "Loss: 7.221946e-04\n",
            "Loss: 7.218685e-04\n",
            "Loss: 7.214944e-04\n",
            "Loss: 7.212608e-04\n",
            "Loss: 7.210190e-04\n",
            "Loss: 7.208454e-04\n",
            "Loss: 7.206969e-04\n",
            "Loss: 7.205212e-04\n",
            "Loss: 7.202356e-04\n",
            "Loss: 7.198618e-04\n",
            "Loss: 7.195415e-04\n",
            "Loss: 7.191312e-04\n",
            "Loss: 7.187991e-04\n",
            "Loss: 7.185166e-04\n",
            "Loss: 7.180975e-04\n",
            "Loss: 7.177300e-04\n",
            "Loss: 7.174833e-04\n",
            "Loss: 7.170641e-04\n",
            "Loss: 7.166581e-04\n",
            "Loss: 7.162010e-04\n",
            "Loss: 7.157424e-04\n",
            "Loss: 7.157129e-04\n",
            "Loss: 7.156166e-04\n",
            "Loss: 7.154263e-04\n",
            "Loss: 7.153536e-04\n",
            "Loss: 7.152492e-04\n",
            "Loss: 7.151772e-04\n",
            "Loss: 7.149846e-04\n",
            "Loss: 7.147873e-04\n",
            "Loss: 7.146681e-04\n",
            "Loss: 7.145006e-04\n",
            "Loss: 7.143823e-04\n",
            "Loss: 7.141340e-04\n",
            "Loss: 7.149758e-04\n",
            "Loss: 7.140886e-04\n",
            "Loss: 7.139721e-04\n",
            "Loss: 7.137096e-04\n",
            "Loss: 7.132974e-04\n",
            "Loss: 7.128874e-04\n",
            "Loss: 7.124861e-04\n",
            "Loss: 7.124147e-04\n",
            "Loss: 7.122151e-04\n",
            "Loss: 7.121491e-04\n",
            "Loss: 7.120770e-04\n",
            "Loss: 7.119898e-04\n",
            "Loss: 7.119234e-04\n",
            "Loss: 7.118070e-04\n",
            "Loss: 7.116016e-04\n",
            "Loss: 7.114278e-04\n",
            "Loss: 7.113499e-04\n",
            "Loss: 7.111968e-04\n",
            "Loss: 7.111318e-04\n",
            "Loss: 7.109839e-04\n",
            "Loss: 7.108873e-04\n",
            "Loss: 7.106966e-04\n",
            "Loss: 7.105597e-04\n",
            "Loss: 7.104239e-04\n",
            "Loss: 7.102197e-04\n",
            "Loss: 7.098140e-04\n",
            "Loss: 7.104021e-04\n",
            "Loss: 7.096910e-04\n",
            "Loss: 7.094381e-04\n",
            "Loss: 7.092856e-04\n",
            "Loss: 7.091550e-04\n",
            "Loss: 7.089120e-04\n",
            "Loss: 7.087038e-04\n",
            "Loss: 7.084029e-04\n",
            "Loss: 7.082736e-04\n",
            "Loss: 7.080862e-04\n",
            "Loss: 7.079726e-04\n",
            "Loss: 7.077646e-04\n",
            "Loss: 7.075582e-04\n",
            "Loss: 7.073282e-04\n",
            "Loss: 7.069058e-04\n",
            "Loss: 7.065918e-04\n",
            "Loss: 7.062879e-04\n",
            "Loss: 7.060576e-04\n",
            "Loss: 7.058771e-04\n",
            "Loss: 7.058025e-04\n",
            "Loss: 7.054923e-04\n",
            "Loss: 7.054007e-04\n",
            "Loss: 7.052745e-04\n",
            "Loss: 7.051152e-04\n",
            "Loss: 7.046745e-04\n",
            "Loss: 7.055210e-04\n",
            "Loss: 7.045252e-04\n",
            "Loss: 7.042442e-04\n",
            "Loss: 7.040759e-04\n",
            "Loss: 7.039157e-04\n",
            "Loss: 7.036703e-04\n",
            "Loss: 7.035881e-04\n",
            "Loss: 7.032932e-04\n",
            "Loss: 7.031913e-04\n",
            "Loss: 7.030413e-04\n",
            "Loss: 7.027928e-04\n",
            "Loss: 7.025801e-04\n",
            "Loss: 7.023255e-04\n",
            "Loss: 7.020778e-04\n",
            "Loss: 7.019077e-04\n",
            "Loss: 7.017286e-04\n",
            "Loss: 7.017303e-04\n",
            "Loss: 7.015945e-04\n",
            "Loss: 7.014232e-04\n",
            "Loss: 7.013446e-04\n",
            "Loss: 7.012318e-04\n",
            "Loss: 7.011020e-04\n",
            "Loss: 7.009354e-04\n",
            "Loss: 7.008038e-04\n",
            "Loss: 7.004674e-04\n",
            "Loss: 7.004996e-04\n",
            "Loss: 7.003709e-04\n",
            "Loss: 7.002222e-04\n",
            "Loss: 7.000039e-04\n",
            "Loss: 6.997592e-04\n",
            "Loss: 6.995291e-04\n",
            "Loss: 6.993220e-04\n",
            "Loss: 6.991850e-04\n",
            "Loss: 6.991330e-04\n",
            "Loss: 6.990068e-04\n",
            "Loss: 6.988875e-04\n",
            "Loss: 6.986833e-04\n",
            "Loss: 6.984975e-04\n",
            "Loss: 6.983253e-04\n",
            "Loss: 6.981256e-04\n",
            "Loss: 6.979414e-04\n",
            "Loss: 6.977859e-04\n",
            "Loss: 6.975303e-04\n",
            "Loss: 6.974476e-04\n",
            "Loss: 6.970274e-04\n",
            "Loss: 6.967442e-04\n",
            "Loss: 6.971885e-04\n",
            "Loss: 6.966288e-04\n",
            "Loss: 6.962832e-04\n",
            "Loss: 6.960102e-04\n",
            "Loss: 6.955930e-04\n",
            "Loss: 6.958700e-04\n",
            "Loss: 6.955264e-04\n",
            "Loss: 6.953853e-04\n",
            "Loss: 6.950569e-04\n",
            "Loss: 6.946301e-04\n",
            "Loss: 6.943661e-04\n",
            "Loss: 6.941121e-04\n",
            "Loss: 6.939321e-04\n",
            "Loss: 6.936911e-04\n",
            "Loss: 6.935648e-04\n",
            "Loss: 6.933706e-04\n",
            "Loss: 6.931691e-04\n",
            "Loss: 6.931028e-04\n",
            "Loss: 6.930294e-04\n",
            "Loss: 6.929621e-04\n",
            "Loss: 6.928395e-04\n",
            "Loss: 6.926526e-04\n",
            "Loss: 6.923599e-04\n",
            "Loss: 6.924709e-04\n",
            "Loss: 6.922292e-04\n",
            "Loss: 6.920323e-04\n",
            "Loss: 6.918827e-04\n",
            "Loss: 6.917160e-04\n",
            "Loss: 6.919119e-04\n",
            "Loss: 6.916196e-04\n",
            "Loss: 6.914639e-04\n",
            "Loss: 6.912875e-04\n",
            "Loss: 6.911231e-04\n",
            "Loss: 6.908260e-04\n",
            "Loss: 6.912060e-04\n",
            "Loss: 6.907120e-04\n",
            "Loss: 6.904587e-04\n",
            "Loss: 6.903425e-04\n",
            "Loss: 6.902557e-04\n",
            "Loss: 6.901716e-04\n",
            "Loss: 6.900325e-04\n",
            "Loss: 6.899027e-04\n",
            "Loss: 6.898232e-04\n",
            "Loss: 6.897029e-04\n",
            "Loss: 6.896429e-04\n",
            "Loss: 6.894965e-04\n",
            "Loss: 6.894247e-04\n",
            "Loss: 6.893333e-04\n",
            "Loss: 6.891873e-04\n",
            "Loss: 6.891657e-04\n",
            "Loss: 6.888491e-04\n",
            "Loss: 6.887686e-04\n",
            "Loss: 6.885987e-04\n",
            "Loss: 6.885708e-04\n",
            "Loss: 6.883989e-04\n",
            "Loss: 6.883381e-04\n",
            "Loss: 6.882187e-04\n",
            "Loss: 6.880997e-04\n",
            "Loss: 6.879686e-04\n",
            "Loss: 6.877821e-04\n",
            "Loss: 6.876743e-04\n",
            "Loss: 6.876589e-04\n",
            "Loss: 6.875986e-04\n",
            "Loss: 6.874779e-04\n",
            "Loss: 6.873722e-04\n",
            "Loss: 6.872555e-04\n",
            "Loss: 6.870766e-04\n",
            "Loss: 6.870314e-04\n",
            "Loss: 6.868207e-04\n",
            "Loss: 6.867106e-04\n",
            "Loss: 6.865761e-04\n",
            "Loss: 6.865120e-04\n",
            "Loss: 6.863970e-04\n",
            "Loss: 6.862817e-04\n",
            "Loss: 6.861906e-04\n",
            "Loss: 6.860127e-04\n",
            "Loss: 6.858568e-04\n",
            "Loss: 6.856346e-04\n",
            "Loss: 6.853299e-04\n",
            "Loss: 6.851943e-04\n",
            "Loss: 6.850816e-04\n",
            "Loss: 6.849767e-04\n",
            "Loss: 6.848134e-04\n",
            "Loss: 6.849560e-04\n",
            "Loss: 6.847706e-04\n",
            "Loss: 6.846224e-04\n",
            "Loss: 6.845322e-04\n",
            "Loss: 6.843340e-04\n",
            "Loss: 6.841343e-04\n",
            "Loss: 6.840259e-04\n",
            "Loss: 6.837345e-04\n",
            "Loss: 6.836640e-04\n",
            "Loss: 6.835925e-04\n",
            "Loss: 6.835428e-04\n",
            "Loss: 6.834724e-04\n",
            "Loss: 6.833578e-04\n",
            "Loss: 6.832286e-04\n",
            "Loss: 6.830839e-04\n",
            "Loss: 6.828775e-04\n",
            "Loss: 6.826954e-04\n",
            "Loss: 6.823776e-04\n",
            "Loss: 6.844152e-04\n",
            "Loss: 6.822944e-04\n",
            "Loss: 6.821266e-04\n",
            "Loss: 6.819246e-04\n",
            "Loss: 6.817435e-04\n",
            "Loss: 6.815934e-04\n",
            "Loss: 6.813966e-04\n",
            "Loss: 6.812308e-04\n",
            "Loss: 6.811263e-04\n",
            "Loss: 6.808372e-04\n",
            "Loss: 6.806410e-04\n",
            "Loss: 6.804848e-04\n",
            "Loss: 6.803483e-04\n",
            "Loss: 6.801741e-04\n",
            "Loss: 6.800818e-04\n",
            "Loss: 6.799846e-04\n",
            "Loss: 6.798518e-04\n",
            "Loss: 6.798218e-04\n",
            "Loss: 6.797433e-04\n",
            "Loss: 6.796540e-04\n",
            "Loss: 6.794499e-04\n",
            "Loss: 6.795948e-04\n",
            "Loss: 6.793552e-04\n",
            "Loss: 6.791868e-04\n",
            "Loss: 6.790810e-04\n",
            "Loss: 6.789551e-04\n",
            "Loss: 6.787605e-04\n",
            "Loss: 6.786186e-04\n",
            "Loss: 6.785106e-04\n",
            "Loss: 6.784417e-04\n",
            "Loss: 6.783397e-04\n",
            "Loss: 6.781847e-04\n",
            "Loss: 6.780422e-04\n",
            "Loss: 6.778941e-04\n",
            "Loss: 6.777486e-04\n",
            "Loss: 6.776557e-04\n",
            "Loss: 6.774864e-04\n",
            "Loss: 6.773257e-04\n",
            "Loss: 6.772127e-04\n",
            "Loss: 6.770815e-04\n",
            "Loss: 6.769365e-04\n",
            "Loss: 6.766611e-04\n",
            "Loss: 6.762941e-04\n",
            "Loss: 6.759571e-04\n",
            "Loss: 6.757174e-04\n",
            "Loss: 6.754727e-04\n",
            "Loss: 6.754174e-04\n",
            "Loss: 6.752762e-04\n",
            "Loss: 6.753502e-04\n",
            "Loss: 6.751354e-04\n",
            "Loss: 6.748636e-04\n",
            "Loss: 6.745190e-04\n",
            "Loss: 6.743698e-04\n",
            "Loss: 6.741149e-04\n",
            "Loss: 6.739147e-04\n",
            "Loss: 6.737405e-04\n",
            "Loss: 6.733934e-04\n",
            "Loss: 6.758496e-04\n",
            "Loss: 6.732916e-04\n",
            "Loss: 6.730559e-04\n",
            "Loss: 6.728502e-04\n",
            "Loss: 6.725428e-04\n",
            "Loss: 6.722687e-04\n",
            "Loss: 6.720590e-04\n",
            "Loss: 6.717027e-04\n",
            "Loss: 6.714619e-04\n",
            "Loss: 6.713431e-04\n",
            "Loss: 6.710418e-04\n",
            "Loss: 6.710034e-04\n",
            "Loss: 6.708720e-04\n",
            "Loss: 6.712837e-04\n",
            "Loss: 6.708017e-04\n",
            "Loss: 6.706507e-04\n",
            "Loss: 6.704220e-04\n",
            "Loss: 6.702788e-04\n",
            "Loss: 6.700997e-04\n",
            "Loss: 6.697511e-04\n",
            "Loss: 6.696992e-04\n",
            "Loss: 6.693784e-04\n",
            "Loss: 6.693178e-04\n",
            "Loss: 6.691664e-04\n",
            "Loss: 6.690283e-04\n",
            "Loss: 6.688070e-04\n",
            "Loss: 6.686904e-04\n",
            "Loss: 6.685383e-04\n",
            "Loss: 6.684294e-04\n",
            "Loss: 6.681367e-04\n",
            "Loss: 6.701759e-04\n",
            "Loss: 6.680637e-04\n",
            "Loss: 6.678827e-04\n",
            "Loss: 6.676725e-04\n",
            "Loss: 6.674330e-04\n",
            "Loss: 6.671055e-04\n",
            "Loss: 6.674649e-04\n",
            "Loss: 6.669164e-04\n",
            "Loss: 6.666557e-04\n",
            "Loss: 6.663982e-04\n",
            "Loss: 6.662332e-04\n",
            "Loss: 6.658685e-04\n",
            "Loss: 6.654420e-04\n",
            "Loss: 6.651481e-04\n",
            "Loss: 6.648914e-04\n",
            "Loss: 6.647253e-04\n",
            "Loss: 6.645428e-04\n",
            "Loss: 6.640711e-04\n",
            "Loss: 6.648346e-04\n",
            "Loss: 6.638805e-04\n",
            "Loss: 6.635792e-04\n",
            "Loss: 6.633162e-04\n",
            "Loss: 6.630581e-04\n",
            "Loss: 6.628843e-04\n",
            "Loss: 6.627167e-04\n",
            "Loss: 6.625725e-04\n",
            "Loss: 6.623928e-04\n",
            "Loss: 6.622684e-04\n",
            "Loss: 6.620947e-04\n",
            "Loss: 6.619098e-04\n",
            "Loss: 6.617619e-04\n",
            "Loss: 6.615973e-04\n",
            "Loss: 6.614176e-04\n",
            "Loss: 6.611522e-04\n",
            "Loss: 6.609428e-04\n",
            "Loss: 6.607762e-04\n",
            "Loss: 6.605723e-04\n",
            "Loss: 6.603410e-04\n",
            "Loss: 6.602441e-04\n",
            "Loss: 6.600377e-04\n",
            "Loss: 6.599512e-04\n",
            "Loss: 6.597522e-04\n",
            "Loss: 6.594550e-04\n",
            "Loss: 6.592742e-04\n",
            "Loss: 6.590949e-04\n",
            "Loss: 6.588647e-04\n",
            "Loss: 6.585902e-04\n",
            "Loss: 6.584640e-04\n",
            "Loss: 6.583160e-04\n",
            "Loss: 6.582034e-04\n",
            "Loss: 6.579303e-04\n",
            "Loss: 6.580389e-04\n",
            "Loss: 6.578439e-04\n",
            "Loss: 6.577166e-04\n",
            "Loss: 6.575682e-04\n",
            "Loss: 6.574721e-04\n",
            "Loss: 6.572991e-04\n",
            "Loss: 6.574340e-04\n",
            "Loss: 6.572334e-04\n",
            "Loss: 6.570454e-04\n",
            "Loss: 6.569700e-04\n",
            "Loss: 6.568285e-04\n",
            "Loss: 6.566972e-04\n",
            "Loss: 6.567650e-04\n",
            "Loss: 6.566412e-04\n",
            "Loss: 6.565198e-04\n",
            "Loss: 6.562661e-04\n",
            "Loss: 6.560171e-04\n",
            "Loss: 6.558375e-04\n",
            "Loss: 6.556632e-04\n",
            "Loss: 6.553602e-04\n",
            "Loss: 6.551453e-04\n",
            "Loss: 6.547456e-04\n",
            "Loss: 6.543558e-04\n",
            "Loss: 6.548592e-04\n",
            "Loss: 6.541405e-04\n",
            "Loss: 6.539200e-04\n",
            "Loss: 6.537488e-04\n",
            "Loss: 6.536001e-04\n",
            "Loss: 6.534064e-04\n",
            "Loss: 6.530717e-04\n",
            "Loss: 6.528980e-04\n",
            "Loss: 6.526329e-04\n",
            "Loss: 6.524320e-04\n",
            "Loss: 6.522005e-04\n",
            "Loss: 6.518962e-04\n",
            "Loss: 6.514057e-04\n",
            "Loss: 6.526238e-04\n",
            "Loss: 6.512478e-04\n",
            "Loss: 6.508493e-04\n",
            "Loss: 6.506074e-04\n",
            "Loss: 6.503477e-04\n",
            "Loss: 6.500798e-04\n",
            "Loss: 6.499266e-04\n",
            "Loss: 6.497120e-04\n",
            "Loss: 6.495824e-04\n",
            "Loss: 6.495009e-04\n",
            "Loss: 6.494640e-04\n",
            "Loss: 6.493971e-04\n",
            "Loss: 6.492463e-04\n",
            "Loss: 6.490993e-04\n",
            "Loss: 6.488760e-04\n",
            "Loss: 6.486385e-04\n",
            "Loss: 6.484077e-04\n",
            "Loss: 6.482264e-04\n",
            "Loss: 6.480613e-04\n",
            "Loss: 6.479511e-04\n",
            "Loss: 6.477085e-04\n",
            "Loss: 6.472402e-04\n",
            "Loss: 6.472816e-04\n",
            "Loss: 6.470362e-04\n",
            "Loss: 6.466539e-04\n",
            "Loss: 6.464636e-04\n",
            "Loss: 6.461842e-04\n",
            "Loss: 6.466000e-04\n",
            "Loss: 6.460295e-04\n",
            "Loss: 6.458332e-04\n",
            "Loss: 6.456356e-04\n",
            "Loss: 6.454426e-04\n",
            "Loss: 6.452973e-04\n",
            "Loss: 6.448101e-04\n",
            "Loss: 6.444440e-04\n",
            "Loss: 6.439104e-04\n",
            "Loss: 6.435917e-04\n",
            "Loss: 6.434162e-04\n",
            "Loss: 6.430207e-04\n",
            "Loss: 6.427923e-04\n",
            "Loss: 6.426789e-04\n",
            "Loss: 6.425419e-04\n",
            "Loss: 6.424281e-04\n",
            "Loss: 6.422620e-04\n",
            "Loss: 6.421343e-04\n",
            "Loss: 6.420410e-04\n",
            "Loss: 6.419371e-04\n",
            "Loss: 6.418231e-04\n",
            "Loss: 6.417366e-04\n",
            "Loss: 6.415691e-04\n",
            "Loss: 6.415491e-04\n",
            "Loss: 6.412568e-04\n",
            "Loss: 6.411013e-04\n",
            "Loss: 6.408928e-04\n",
            "Loss: 6.406253e-04\n",
            "Loss: 6.405785e-04\n",
            "Loss: 6.402731e-04\n",
            "Loss: 6.401559e-04\n",
            "Loss: 6.400600e-04\n",
            "Loss: 6.398141e-04\n",
            "Loss: 6.395498e-04\n",
            "Loss: 6.393556e-04\n",
            "Loss: 6.392176e-04\n",
            "Loss: 6.390899e-04\n",
            "Loss: 6.388819e-04\n",
            "Loss: 6.385946e-04\n",
            "Loss: 6.384139e-04\n",
            "Loss: 6.381451e-04\n",
            "Loss: 6.378826e-04\n",
            "Loss: 6.375931e-04\n",
            "Loss: 6.377529e-04\n",
            "Loss: 6.374839e-04\n",
            "Loss: 6.372798e-04\n",
            "Loss: 6.371327e-04\n",
            "Loss: 6.369871e-04\n",
            "Loss: 6.367912e-04\n",
            "Loss: 6.364980e-04\n",
            "Loss: 6.365345e-04\n",
            "Loss: 6.363588e-04\n",
            "Loss: 6.361423e-04\n",
            "Loss: 6.359917e-04\n",
            "Loss: 6.358604e-04\n",
            "Loss: 6.355831e-04\n",
            "Loss: 6.364484e-04\n",
            "Loss: 6.354596e-04\n",
            "Loss: 6.352812e-04\n",
            "Loss: 6.350684e-04\n",
            "Loss: 6.347607e-04\n",
            "Loss: 6.344649e-04\n",
            "Loss: 6.343742e-04\n",
            "Loss: 6.341892e-04\n",
            "Loss: 6.341127e-04\n",
            "Loss: 6.340308e-04\n",
            "Loss: 6.338268e-04\n",
            "Loss: 6.336533e-04\n",
            "Loss: 6.334570e-04\n",
            "Loss: 6.333000e-04\n",
            "Loss: 6.331277e-04\n",
            "Loss: 6.328761e-04\n",
            "Loss: 6.327640e-04\n",
            "Loss: 6.325655e-04\n",
            "Loss: 6.322456e-04\n",
            "Loss: 6.321754e-04\n",
            "Loss: 6.317844e-04\n",
            "Loss: 6.315980e-04\n",
            "Loss: 6.313244e-04\n",
            "Loss: 6.312380e-04\n",
            "Loss: 6.310223e-04\n",
            "Loss: 6.309085e-04\n",
            "Loss: 6.307845e-04\n",
            "Loss: 6.305139e-04\n",
            "Loss: 6.303089e-04\n",
            "Loss: 6.300938e-04\n",
            "Loss: 6.299757e-04\n",
            "Loss: 6.298127e-04\n",
            "Loss: 6.296206e-04\n",
            "Loss: 6.294865e-04\n",
            "Loss: 6.292576e-04\n",
            "Loss: 6.292064e-04\n",
            "Loss: 6.290970e-04\n",
            "Loss: 6.290436e-04\n",
            "Loss: 6.288690e-04\n",
            "Loss: 6.287867e-04\n",
            "Loss: 6.287246e-04\n",
            "Loss: 6.285922e-04\n",
            "Loss: 6.284122e-04\n",
            "Loss: 6.282901e-04\n",
            "Loss: 6.280697e-04\n",
            "Loss: 6.279434e-04\n",
            "Loss: 6.278509e-04\n",
            "Loss: 6.276652e-04\n",
            "Loss: 6.275032e-04\n",
            "Loss: 6.274197e-04\n",
            "Loss: 6.273425e-04\n",
            "Loss: 6.272668e-04\n",
            "Loss: 6.270406e-04\n",
            "Loss: 6.269106e-04\n",
            "Loss: 6.268218e-04\n",
            "Loss: 6.267491e-04\n",
            "Loss: 6.267294e-04\n",
            "Loss: 6.266605e-04\n",
            "Loss: 6.266048e-04\n",
            "Loss: 6.264594e-04\n",
            "Loss: 6.264002e-04\n",
            "Loss: 6.262982e-04\n",
            "Loss: 6.261978e-04\n",
            "Loss: 6.260498e-04\n",
            "Loss: 6.258790e-04\n",
            "Loss: 6.257588e-04\n",
            "Loss: 6.253637e-04\n",
            "Loss: 6.256286e-04\n",
            "Loss: 6.252605e-04\n",
            "Loss: 6.251580e-04\n",
            "Loss: 6.250170e-04\n",
            "Loss: 6.247945e-04\n",
            "Loss: 6.245130e-04\n",
            "Loss: 6.247165e-04\n",
            "Loss: 6.244239e-04\n",
            "Loss: 6.242438e-04\n",
            "Loss: 6.240928e-04\n",
            "Loss: 6.238984e-04\n",
            "Loss: 6.237973e-04\n",
            "Loss: 6.235410e-04\n",
            "Loss: 6.234252e-04\n",
            "Loss: 6.233298e-04\n",
            "Loss: 6.231655e-04\n",
            "Loss: 6.230539e-04\n",
            "Loss: 6.229952e-04\n",
            "Loss: 6.229277e-04\n",
            "Loss: 6.228554e-04\n",
            "Loss: 6.227279e-04\n",
            "Loss: 6.226928e-04\n",
            "Loss: 6.225178e-04\n",
            "Loss: 6.224705e-04\n",
            "Loss: 6.223741e-04\n",
            "Loss: 6.223113e-04\n",
            "Loss: 6.222225e-04\n",
            "Loss: 6.221262e-04\n",
            "Loss: 6.220281e-04\n",
            "Loss: 6.218453e-04\n",
            "Loss: 6.216313e-04\n",
            "Loss: 6.213427e-04\n",
            "Loss: 6.210982e-04\n",
            "Loss: 6.208962e-04\n",
            "Loss: 6.206870e-04\n",
            "Loss: 6.205331e-04\n",
            "Loss: 6.204097e-04\n",
            "Loss: 6.203305e-04\n",
            "Loss: 6.201822e-04\n",
            "Loss: 6.200669e-04\n",
            "Loss: 6.198265e-04\n",
            "Loss: 6.195580e-04\n",
            "Loss: 6.195497e-04\n",
            "Loss: 6.193633e-04\n",
            "Loss: 6.191450e-04\n",
            "Loss: 6.188895e-04\n",
            "Loss: 6.186326e-04\n",
            "Loss: 6.189970e-04\n",
            "Loss: 6.185286e-04\n",
            "Loss: 6.183603e-04\n",
            "Loss: 6.182221e-04\n",
            "Loss: 6.180002e-04\n",
            "Loss: 6.177343e-04\n",
            "Loss: 6.174768e-04\n",
            "Loss: 6.171318e-04\n",
            "Loss: 6.169379e-04\n",
            "Loss: 6.168494e-04\n",
            "Loss: 6.166176e-04\n",
            "Loss: 6.165114e-04\n",
            "Loss: 6.163375e-04\n",
            "Loss: 6.161468e-04\n",
            "Loss: 6.158633e-04\n",
            "Loss: 6.162366e-04\n",
            "Loss: 6.157454e-04\n",
            "Loss: 6.156283e-04\n",
            "Loss: 6.154253e-04\n",
            "Loss: 6.152450e-04\n",
            "Loss: 6.153759e-04\n",
            "Loss: 6.151405e-04\n",
            "Loss: 6.149381e-04\n",
            "Loss: 6.148429e-04\n",
            "Loss: 6.147766e-04\n",
            "Loss: 6.147068e-04\n",
            "Loss: 6.145317e-04\n",
            "Loss: 6.142828e-04\n",
            "Loss: 6.140224e-04\n",
            "Loss: 6.138228e-04\n",
            "Loss: 6.136774e-04\n",
            "Loss: 6.135681e-04\n",
            "Loss: 6.134256e-04\n",
            "Loss: 6.133363e-04\n",
            "Loss: 6.132182e-04\n",
            "Loss: 6.131252e-04\n",
            "Loss: 6.129231e-04\n",
            "Loss: 6.124860e-04\n",
            "Loss: 6.125894e-04\n",
            "Loss: 6.122899e-04\n",
            "Loss: 6.120560e-04\n",
            "Loss: 6.118400e-04\n",
            "Loss: 6.116328e-04\n",
            "Loss: 6.113542e-04\n",
            "Loss: 6.111529e-04\n",
            "Loss: 6.109340e-04\n",
            "Loss: 6.106954e-04\n",
            "Loss: 6.102918e-04\n",
            "Loss: 6.103721e-04\n",
            "Loss: 6.101812e-04\n",
            "Loss: 6.099818e-04\n",
            "Loss: 6.098165e-04\n",
            "Loss: 6.096134e-04\n",
            "Loss: 6.093455e-04\n",
            "Loss: 6.094384e-04\n",
            "Loss: 6.091798e-04\n",
            "Loss: 6.089082e-04\n",
            "Loss: 6.087860e-04\n",
            "Loss: 6.086468e-04\n",
            "Loss: 6.085209e-04\n",
            "Loss: 6.083933e-04\n",
            "Loss: 6.082475e-04\n",
            "Loss: 6.081622e-04\n",
            "Loss: 6.079125e-04\n",
            "Loss: 6.076946e-04\n",
            "Loss: 6.074146e-04\n",
            "Loss: 6.071408e-04\n",
            "Loss: 6.072141e-04\n",
            "Loss: 6.069549e-04\n",
            "Loss: 6.068766e-04\n",
            "Loss: 6.067372e-04\n",
            "Loss: 6.066371e-04\n",
            "Loss: 6.064137e-04\n",
            "Loss: 6.061483e-04\n",
            "Loss: 6.058338e-04\n",
            "Loss: 6.056434e-04\n",
            "Loss: 6.054410e-04\n",
            "Loss: 6.052328e-04\n",
            "Loss: 6.048108e-04\n",
            "Loss: 6.047707e-04\n",
            "Loss: 6.045619e-04\n",
            "Loss: 6.043864e-04\n",
            "Loss: 6.041869e-04\n",
            "Loss: 6.039446e-04\n",
            "Loss: 6.037423e-04\n",
            "Loss: 6.035988e-04\n",
            "Loss: 6.033662e-04\n",
            "Loss: 6.032593e-04\n",
            "Loss: 6.031528e-04\n",
            "Loss: 6.029077e-04\n",
            "Loss: 6.033572e-04\n",
            "Loss: 6.028503e-04\n",
            "Loss: 6.025700e-04\n",
            "Loss: 6.024173e-04\n",
            "Loss: 6.021520e-04\n",
            "Loss: 6.019346e-04\n",
            "Loss: 6.017162e-04\n",
            "Loss: 6.014689e-04\n",
            "Loss: 6.011942e-04\n",
            "Loss: 6.010294e-04\n",
            "Loss: 6.008955e-04\n",
            "Loss: 6.007896e-04\n",
            "Loss: 6.005224e-04\n",
            "Loss: 6.003778e-04\n",
            "Loss: 6.002426e-04\n",
            "Loss: 6.001414e-04\n",
            "Loss: 6.000506e-04\n",
            "Loss: 5.999382e-04\n",
            "Loss: 5.998536e-04\n",
            "Loss: 5.997997e-04\n",
            "Loss: 5.997043e-04\n",
            "Loss: 5.994443e-04\n",
            "Loss: 5.994179e-04\n",
            "Loss: 5.991698e-04\n",
            "Loss: 5.990748e-04\n",
            "Loss: 5.989881e-04\n",
            "Loss: 5.989362e-04\n",
            "Loss: 5.988463e-04\n",
            "Loss: 5.987594e-04\n",
            "Loss: 5.986341e-04\n",
            "Loss: 5.985770e-04\n",
            "Loss: 5.984992e-04\n",
            "Loss: 5.983857e-04\n",
            "Loss: 5.983489e-04\n",
            "Loss: 5.982677e-04\n",
            "Loss: 5.981784e-04\n",
            "Loss: 5.980277e-04\n",
            "Loss: 5.989794e-04\n",
            "Loss: 5.979492e-04\n",
            "Loss: 5.978350e-04\n",
            "Loss: 5.977235e-04\n",
            "Loss: 5.976415e-04\n",
            "Loss: 5.974584e-04\n",
            "Loss: 5.972993e-04\n",
            "Loss: 5.971718e-04\n",
            "Loss: 5.970703e-04\n",
            "Loss: 5.969536e-04\n",
            "Loss: 5.967939e-04\n",
            "Loss: 5.966460e-04\n",
            "Loss: 5.965512e-04\n",
            "Loss: 5.964594e-04\n",
            "Loss: 5.963525e-04\n",
            "Loss: 5.961616e-04\n",
            "Loss: 5.959159e-04\n",
            "Loss: 5.955909e-04\n",
            "Loss: 5.954630e-04\n",
            "Loss: 5.953337e-04\n",
            "Loss: 5.952839e-04\n",
            "Loss: 5.951652e-04\n",
            "Loss: 5.950374e-04\n",
            "Loss: 5.949066e-04\n",
            "Loss: 5.947384e-04\n",
            "Loss: 5.945949e-04\n",
            "Loss: 5.945056e-04\n",
            "Loss: 5.944330e-04\n",
            "Loss: 5.941944e-04\n",
            "Loss: 5.942123e-04\n",
            "Loss: 5.940698e-04\n",
            "Loss: 5.939133e-04\n",
            "Loss: 5.937933e-04\n",
            "Loss: 5.936612e-04\n",
            "Loss: 5.934927e-04\n",
            "Loss: 5.932563e-04\n",
            "Loss: 5.931326e-04\n",
            "Loss: 5.930181e-04\n",
            "Loss: 5.929377e-04\n",
            "Loss: 5.927851e-04\n",
            "Loss: 5.927664e-04\n",
            "Loss: 5.927160e-04\n",
            "Loss: 5.926304e-04\n",
            "Loss: 5.925196e-04\n",
            "Loss: 5.924568e-04\n",
            "Loss: 5.922902e-04\n",
            "Loss: 5.923039e-04\n",
            "Loss: 5.922280e-04\n",
            "Loss: 5.921014e-04\n",
            "Loss: 5.919670e-04\n",
            "Loss: 5.919312e-04\n",
            "Loss: 5.917716e-04\n",
            "Loss: 5.916916e-04\n",
            "Loss: 5.916083e-04\n",
            "Loss: 5.915244e-04\n",
            "Loss: 5.913500e-04\n",
            "Loss: 5.911594e-04\n",
            "Loss: 5.909939e-04\n",
            "Loss: 5.909358e-04\n",
            "Loss: 5.908747e-04\n",
            "Loss: 5.907734e-04\n",
            "Loss: 5.906280e-04\n",
            "Loss: 5.904980e-04\n",
            "Loss: 5.904015e-04\n",
            "Loss: 5.902663e-04\n",
            "Loss: 5.901747e-04\n",
            "Loss: 5.901977e-04\n",
            "Loss: 5.901335e-04\n",
            "Loss: 5.900446e-04\n",
            "Loss: 5.899855e-04\n",
            "Loss: 5.899647e-04\n",
            "Loss: 5.899269e-04\n",
            "Loss: 5.898579e-04\n",
            "Loss: 5.897286e-04\n",
            "Loss: 5.896160e-04\n",
            "Loss: 5.895015e-04\n",
            "Loss: 5.894274e-04\n",
            "Loss: 5.893590e-04\n",
            "Loss: 5.892445e-04\n",
            "Loss: 5.891032e-04\n",
            "Loss: 5.890552e-04\n",
            "Loss: 5.889102e-04\n",
            "Loss: 5.888217e-04\n",
            "Loss: 5.887528e-04\n",
            "Loss: 5.885712e-04\n",
            "Loss: 5.884132e-04\n",
            "Loss: 5.882657e-04\n",
            "Loss: 5.881346e-04\n",
            "Loss: 5.879786e-04\n",
            "Loss: 5.877120e-04\n",
            "Loss: 5.875927e-04\n",
            "Loss: 5.874570e-04\n",
            "Loss: 5.873614e-04\n",
            "Loss: 5.872485e-04\n",
            "Loss: 5.870707e-04\n",
            "Loss: 5.868651e-04\n",
            "Loss: 5.867266e-04\n",
            "Loss: 5.866248e-04\n",
            "Loss: 5.864970e-04\n",
            "Loss: 5.863219e-04\n",
            "Loss: 5.864720e-04\n",
            "Loss: 5.862251e-04\n",
            "Loss: 5.860273e-04\n",
            "Loss: 5.859012e-04\n",
            "Loss: 5.856829e-04\n",
            "Loss: 5.856067e-04\n",
            "Loss: 5.854729e-04\n",
            "Loss: 5.854145e-04\n",
            "Loss: 5.852796e-04\n",
            "Loss: 5.851715e-04\n",
            "Loss: 5.850669e-04\n",
            "Loss: 5.849070e-04\n",
            "Loss: 5.847251e-04\n",
            "Loss: 5.845184e-04\n",
            "Loss: 5.842611e-04\n",
            "Loss: 5.841110e-04\n",
            "Loss: 5.839068e-04\n",
            "Loss: 5.838441e-04\n",
            "Loss: 5.837742e-04\n",
            "Loss: 5.836377e-04\n",
            "Loss: 5.834988e-04\n",
            "Loss: 5.833662e-04\n",
            "Loss: 5.832715e-04\n",
            "Loss: 5.831410e-04\n",
            "Loss: 5.830314e-04\n",
            "Loss: 5.828679e-04\n",
            "Loss: 5.827759e-04\n",
            "Loss: 5.826764e-04\n",
            "Loss: 5.826192e-04\n",
            "Loss: 5.825153e-04\n",
            "Loss: 5.824102e-04\n",
            "Loss: 5.822657e-04\n",
            "Loss: 5.821238e-04\n",
            "Loss: 5.819640e-04\n",
            "Loss: 5.817562e-04\n",
            "Loss: 5.816316e-04\n",
            "Loss: 5.815277e-04\n",
            "Loss: 5.813693e-04\n",
            "Loss: 5.812374e-04\n",
            "Loss: 5.810815e-04\n",
            "Loss: 5.810730e-04\n",
            "Loss: 5.810147e-04\n",
            "Loss: 5.809110e-04\n",
            "Loss: 5.808037e-04\n",
            "Loss: 5.807014e-04\n",
            "Loss: 5.806008e-04\n",
            "Loss: 5.804772e-04\n",
            "Loss: 5.803521e-04\n",
            "Loss: 5.801318e-04\n",
            "Loss: 5.800680e-04\n",
            "Loss: 5.799491e-04\n",
            "Loss: 5.798860e-04\n",
            "Loss: 5.798223e-04\n",
            "Loss: 5.797485e-04\n",
            "Loss: 5.796858e-04\n",
            "Loss: 5.795508e-04\n",
            "Loss: 5.793804e-04\n",
            "Loss: 5.793113e-04\n",
            "Loss: 5.791900e-04\n",
            "Loss: 5.791456e-04\n",
            "Loss: 5.790817e-04\n",
            "Loss: 5.790079e-04\n",
            "Loss: 5.789404e-04\n",
            "Loss: 5.787346e-04\n",
            "Loss: 5.784453e-04\n",
            "Loss: 5.789837e-04\n",
            "Loss: 5.783562e-04\n",
            "Loss: 5.781284e-04\n",
            "Loss: 5.780410e-04\n",
            "Loss: 5.779808e-04\n",
            "Loss: 5.778534e-04\n",
            "Loss: 5.777699e-04\n",
            "Loss: 5.776450e-04\n",
            "Loss: 5.776509e-04\n",
            "Loss: 5.776680e-04\n",
            "Loss: 5.776468e-04\n",
            "Loss: 5.776508e-04\n",
            "Loss: 5.776449e-04\n",
            "Loss: 5.776456e-04\n",
            "Loss: 5.776449e-04\n",
            "Loss: 5.776449e-04\n",
            "Loss: 5.776450e-04\n",
            "Loss: 5.776449e-04\n",
            "Loss: 5.776449e-04\n",
            "Loss: 5.776450e-04\n",
            "Loss: 5.776449e-04\n",
            "Loss: 5.776449e-04\n",
            "Loss: 5.776450e-04\n",
            "Loss: 5.776449e-04\n",
            "Loss: 5.776449e-04\n",
            "Loss: 5.776449e-04\n",
            "Loss: 5.776449e-04\n",
            "Loss: 5.776543e-04\n",
            "Loss: 5.776430e-04\n",
            "Loss: 5.776443e-04\n",
            "Loss: 5.775432e-04\n",
            "Loss: 5.774873e-04\n",
            "Loss: 5.773528e-04\n",
            "Loss: 5.772827e-04\n",
            "Loss: 5.772021e-04\n",
            "Loss: 5.770822e-04\n",
            "Loss: 5.769744e-04\n",
            "Loss: 5.768434e-04\n",
            "Loss: 5.767891e-04\n",
            "Loss: 5.767219e-04\n",
            "Loss: 5.766610e-04\n",
            "Loss: 5.765589e-04\n",
            "Loss: 5.764129e-04\n",
            "Loss: 5.762787e-04\n",
            "Loss: 5.762384e-04\n",
            "Loss: 5.761504e-04\n",
            "Loss: 5.760851e-04\n",
            "Loss: 5.760198e-04\n",
            "Loss: 5.759043e-04\n",
            "Loss: 5.758635e-04\n",
            "Loss: 5.758139e-04\n",
            "Loss: 5.756656e-04\n",
            "Loss: 5.755508e-04\n",
            "Loss: 5.753450e-04\n",
            "Loss: 5.751931e-04\n",
            "Loss: 5.751134e-04\n",
            "Loss: 5.750468e-04\n",
            "Loss: 5.749284e-04\n",
            "Loss: 5.746855e-04\n",
            "Loss: 5.747697e-04\n",
            "Loss: 5.745518e-04\n",
            "Loss: 5.743219e-04\n",
            "Loss: 5.741945e-04\n",
            "Loss: 5.740850e-04\n",
            "Loss: 5.740277e-04\n",
            "Loss: 5.738608e-04\n",
            "Loss: 5.737679e-04\n",
            "Loss: 5.736520e-04\n",
            "Loss: 5.735658e-04\n",
            "Loss: 5.734776e-04\n",
            "Loss: 5.734082e-04\n",
            "Loss: 5.733856e-04\n",
            "Loss: 5.733505e-04\n",
            "Loss: 5.732095e-04\n",
            "Loss: 5.730811e-04\n",
            "Loss: 5.729043e-04\n",
            "Loss: 5.728841e-04\n",
            "Loss: 5.727049e-04\n",
            "Loss: 5.726556e-04\n",
            "Loss: 5.725923e-04\n",
            "Loss: 5.724328e-04\n",
            "Loss: 5.727061e-04\n",
            "Loss: 5.723899e-04\n",
            "Loss: 5.722948e-04\n",
            "Loss: 5.722003e-04\n",
            "Loss: 5.720665e-04\n",
            "Loss: 5.721693e-04\n",
            "Loss: 5.719992e-04\n",
            "Loss: 5.719160e-04\n",
            "Loss: 5.717259e-04\n",
            "Loss: 5.716076e-04\n",
            "Loss: 5.714773e-04\n",
            "Loss: 5.715947e-04\n",
            "Loss: 5.713861e-04\n",
            "Loss: 5.712355e-04\n",
            "Loss: 5.710532e-04\n",
            "Loss: 5.708378e-04\n",
            "Loss: 5.706109e-04\n",
            "Loss: 5.702164e-04\n",
            "Loss: 5.707149e-04\n",
            "Loss: 5.700145e-04\n",
            "Loss: 5.697066e-04\n",
            "Loss: 5.694740e-04\n",
            "Loss: 5.692835e-04\n",
            "Loss: 5.696610e-04\n",
            "Loss: 5.691900e-04\n",
            "Loss: 5.689810e-04\n",
            "Loss: 5.686855e-04\n",
            "Loss: 5.684359e-04\n",
            "Loss: 5.683354e-04\n",
            "Loss: 5.681328e-04\n",
            "Loss: 5.680032e-04\n",
            "Loss: 5.678424e-04\n",
            "Loss: 5.677238e-04\n",
            "Loss: 5.676146e-04\n",
            "Loss: 5.674010e-04\n",
            "Loss: 5.671007e-04\n",
            "Loss: 5.673526e-04\n",
            "Loss: 5.669037e-04\n",
            "Loss: 5.665167e-04\n",
            "Loss: 5.662847e-04\n",
            "Loss: 5.660027e-04\n",
            "Loss: 5.658024e-04\n",
            "Loss: 5.656495e-04\n",
            "Loss: 5.654492e-04\n",
            "Loss: 5.652435e-04\n",
            "Loss: 5.648392e-04\n",
            "Loss: 5.649816e-04\n",
            "Loss: 5.646825e-04\n",
            "Loss: 5.642781e-04\n",
            "Loss: 5.642138e-04\n",
            "Loss: 5.639309e-04\n",
            "Loss: 5.638691e-04\n",
            "Loss: 5.636921e-04\n",
            "Loss: 5.634166e-04\n",
            "Loss: 5.644395e-04\n",
            "Loss: 5.633023e-04\n",
            "Loss: 5.630439e-04\n",
            "Loss: 5.629331e-04\n",
            "Loss: 5.628266e-04\n",
            "Loss: 5.627381e-04\n",
            "Loss: 5.626248e-04\n",
            "Loss: 5.625177e-04\n",
            "Loss: 5.624320e-04\n",
            "Loss: 5.622491e-04\n",
            "Loss: 5.621490e-04\n",
            "Loss: 5.620183e-04\n",
            "Loss: 5.618825e-04\n",
            "Loss: 5.617911e-04\n",
            "Loss: 5.617091e-04\n",
            "Loss: 5.615434e-04\n",
            "Loss: 5.612790e-04\n",
            "Loss: 5.614721e-04\n",
            "Loss: 5.611618e-04\n",
            "Loss: 5.609512e-04\n",
            "Loss: 5.608004e-04\n",
            "Loss: 5.606436e-04\n",
            "Loss: 5.604015e-04\n",
            "Loss: 5.604045e-04\n",
            "Loss: 5.602762e-04\n",
            "Loss: 5.600916e-04\n",
            "Loss: 5.600232e-04\n",
            "Loss: 5.599072e-04\n",
            "Loss: 5.597397e-04\n",
            "Loss: 5.595949e-04\n",
            "Loss: 5.594710e-04\n",
            "Loss: 5.593395e-04\n",
            "Loss: 5.591635e-04\n",
            "Loss: 5.590288e-04\n",
            "Loss: 5.588209e-04\n",
            "Loss: 5.587179e-04\n",
            "Loss: 5.585977e-04\n",
            "Loss: 5.585572e-04\n",
            "Loss: 5.584652e-04\n",
            "Loss: 5.583569e-04\n",
            "Loss: 5.581500e-04\n",
            "Loss: 5.578693e-04\n",
            "Loss: 5.576973e-04\n",
            "Loss: 5.575015e-04\n",
            "Loss: 5.573934e-04\n",
            "Loss: 5.572872e-04\n",
            "Loss: 5.571357e-04\n",
            "Loss: 5.568881e-04\n",
            "Loss: 5.566141e-04\n",
            "Loss: 5.565229e-04\n",
            "Loss: 5.562772e-04\n",
            "Loss: 5.561957e-04\n",
            "Loss: 5.561127e-04\n",
            "Loss: 5.559466e-04\n",
            "Loss: 5.557668e-04\n",
            "Loss: 5.556077e-04\n",
            "Loss: 5.553885e-04\n",
            "Loss: 5.555182e-04\n",
            "Loss: 5.552477e-04\n",
            "Loss: 5.550034e-04\n",
            "Loss: 5.547963e-04\n",
            "Loss: 5.546575e-04\n",
            "Loss: 5.544546e-04\n",
            "Loss: 5.542510e-04\n",
            "Loss: 5.541094e-04\n",
            "Loss: 5.539514e-04\n",
            "Loss: 5.540185e-04\n",
            "Loss: 5.539078e-04\n",
            "Loss: 5.537989e-04\n",
            "Loss: 5.536036e-04\n",
            "Loss: 5.534498e-04\n",
            "Loss: 5.532997e-04\n",
            "Loss: 5.532573e-04\n",
            "Loss: 5.531699e-04\n",
            "Loss: 5.530328e-04\n",
            "Loss: 5.529458e-04\n",
            "Loss: 5.529131e-04\n",
            "Loss: 5.527781e-04\n",
            "Loss: 5.526303e-04\n",
            "Loss: 5.528476e-04\n",
            "Loss: 5.525615e-04\n",
            "Loss: 5.524119e-04\n",
            "Loss: 5.522709e-04\n",
            "Loss: 5.521218e-04\n",
            "Loss: 5.518667e-04\n",
            "Loss: 5.516213e-04\n",
            "Loss: 5.513134e-04\n",
            "Loss: 5.511032e-04\n",
            "Loss: 5.508820e-04\n",
            "Loss: 5.510285e-04\n",
            "Loss: 5.508155e-04\n",
            "Loss: 5.507711e-04\n",
            "Loss: 5.506922e-04\n",
            "Loss: 5.506565e-04\n",
            "Loss: 5.505348e-04\n",
            "Loss: 5.504728e-04\n",
            "Loss: 5.504001e-04\n",
            "Loss: 5.503437e-04\n",
            "Loss: 5.502263e-04\n",
            "Loss: 5.501512e-04\n",
            "Loss: 5.500370e-04\n",
            "Loss: 5.498837e-04\n",
            "Loss: 5.498033e-04\n",
            "Loss: 5.497056e-04\n",
            "Loss: 5.495733e-04\n",
            "Loss: 5.495276e-04\n",
            "Loss: 5.494165e-04\n",
            "Loss: 5.493384e-04\n",
            "Loss: 5.492838e-04\n",
            "Loss: 5.492417e-04\n",
            "Loss: 5.491901e-04\n",
            "Loss: 5.490655e-04\n",
            "Loss: 5.489642e-04\n",
            "Loss: 5.489608e-04\n",
            "Loss: 5.487858e-04\n",
            "Loss: 5.487567e-04\n",
            "Loss: 5.486372e-04\n",
            "Loss: 5.486424e-04\n",
            "Loss: 5.485662e-04\n",
            "Loss: 5.484895e-04\n",
            "Loss: 5.483251e-04\n",
            "Loss: 5.483276e-04\n",
            "Loss: 5.482552e-04\n",
            "Loss: 5.481989e-04\n",
            "Loss: 5.481157e-04\n",
            "Loss: 5.480571e-04\n",
            "Loss: 5.479691e-04\n",
            "Loss: 5.478881e-04\n",
            "Loss: 5.478136e-04\n",
            "Loss: 5.477280e-04\n",
            "Loss: 5.476854e-04\n",
            "Loss: 5.476113e-04\n",
            "Loss: 5.474839e-04\n",
            "Loss: 5.474144e-04\n",
            "Loss: 5.473561e-04\n",
            "Loss: 5.472743e-04\n",
            "Loss: 5.472449e-04\n",
            "Loss: 5.471827e-04\n",
            "Loss: 5.470781e-04\n",
            "Loss: 5.469638e-04\n",
            "Loss: 5.468819e-04\n",
            "Loss: 5.467880e-04\n",
            "Loss: 5.467517e-04\n",
            "Loss: 5.467012e-04\n",
            "Loss: 5.465642e-04\n",
            "Loss: 5.464787e-04\n",
            "Loss: 5.463770e-04\n",
            "Loss: 5.463395e-04\n",
            "Loss: 5.463185e-04\n",
            "Loss: 5.462829e-04\n",
            "Loss: 5.462380e-04\n",
            "Loss: 5.461953e-04\n",
            "Loss: 5.461248e-04\n",
            "Loss: 5.460152e-04\n",
            "Loss: 5.458586e-04\n",
            "Loss: 5.457759e-04\n",
            "Loss: 5.456614e-04\n",
            "Loss: 5.456093e-04\n",
            "Loss: 5.456650e-04\n",
            "Loss: 5.455576e-04\n",
            "Loss: 5.454043e-04\n",
            "Loss: 5.453511e-04\n",
            "Loss: 5.452561e-04\n",
            "Loss: 5.452067e-04\n",
            "Loss: 5.451652e-04\n",
            "Loss: 5.451163e-04\n",
            "Loss: 5.450605e-04\n",
            "Loss: 5.449533e-04\n",
            "Loss: 5.450305e-04\n",
            "Loss: 5.448791e-04\n",
            "Loss: 5.447713e-04\n",
            "Loss: 5.446449e-04\n",
            "Loss: 5.444815e-04\n",
            "Loss: 5.444062e-04\n",
            "Loss: 5.442718e-04\n",
            "Loss: 5.441505e-04\n",
            "Loss: 5.440176e-04\n",
            "Loss: 5.439443e-04\n",
            "Loss: 5.438768e-04\n",
            "Loss: 5.438121e-04\n",
            "Loss: 5.437798e-04\n",
            "Loss: 5.437250e-04\n",
            "Loss: 5.438017e-04\n",
            "Loss: 5.436584e-04\n",
            "Loss: 5.436272e-04\n",
            "Loss: 5.435665e-04\n",
            "Loss: 5.434723e-04\n",
            "Loss: 5.433635e-04\n",
            "Loss: 5.434382e-04\n",
            "Loss: 5.432913e-04\n",
            "Loss: 5.432047e-04\n",
            "Loss: 5.431129e-04\n",
            "Loss: 5.430154e-04\n",
            "Loss: 5.428799e-04\n",
            "Loss: 5.427195e-04\n",
            "Loss: 5.426001e-04\n",
            "Loss: 5.424816e-04\n",
            "Loss: 5.423952e-04\n",
            "Loss: 5.423012e-04\n",
            "Loss: 5.422182e-04\n",
            "Loss: 5.421129e-04\n",
            "Loss: 5.420325e-04\n",
            "Loss: 5.419335e-04\n",
            "Loss: 5.418291e-04\n",
            "Loss: 5.417746e-04\n",
            "Loss: 5.417892e-04\n",
            "Loss: 5.416964e-04\n",
            "Loss: 5.416134e-04\n",
            "Loss: 5.415478e-04\n",
            "Loss: 5.414850e-04\n",
            "Loss: 5.413296e-04\n",
            "Loss: 5.411577e-04\n",
            "Loss: 5.415875e-04\n",
            "Loss: 5.410878e-04\n",
            "Loss: 5.410027e-04\n",
            "Loss: 5.409060e-04\n",
            "Loss: 5.408133e-04\n",
            "Loss: 5.407056e-04\n",
            "Loss: 5.405881e-04\n",
            "Loss: 5.403581e-04\n",
            "Loss: 5.407833e-04\n",
            "Loss: 5.403063e-04\n",
            "Loss: 5.402309e-04\n",
            "Loss: 5.401652e-04\n",
            "Loss: 5.400745e-04\n",
            "Loss: 5.399905e-04\n",
            "Loss: 5.398287e-04\n",
            "Loss: 5.397339e-04\n",
            "Loss: 5.395985e-04\n",
            "Loss: 5.394589e-04\n",
            "Loss: 5.392886e-04\n",
            "Loss: 5.389736e-04\n",
            "Loss: 5.388078e-04\n",
            "Loss: 5.386641e-04\n",
            "Loss: 5.385572e-04\n",
            "Loss: 5.384490e-04\n",
            "Loss: 5.383739e-04\n",
            "Loss: 5.381645e-04\n",
            "Loss: 5.380459e-04\n",
            "Loss: 5.380082e-04\n",
            "Loss: 5.378040e-04\n",
            "Loss: 5.376861e-04\n",
            "Loss: 5.376070e-04\n",
            "Loss: 5.374040e-04\n",
            "Loss: 5.373310e-04\n",
            "Loss: 5.372385e-04\n",
            "Loss: 5.371668e-04\n",
            "Loss: 5.371054e-04\n",
            "Loss: 5.369985e-04\n",
            "Loss: 5.368775e-04\n",
            "Loss: 5.366991e-04\n",
            "Loss: 5.365910e-04\n",
            "Loss: 5.363827e-04\n",
            "Loss: 5.362713e-04\n",
            "Loss: 5.361988e-04\n",
            "Loss: 5.363430e-04\n",
            "Loss: 5.361358e-04\n",
            "Loss: 5.360358e-04\n",
            "Loss: 5.359168e-04\n",
            "Loss: 5.357808e-04\n",
            "Loss: 5.356716e-04\n",
            "Loss: 5.354700e-04\n",
            "Loss: 5.353236e-04\n",
            "Loss: 5.352050e-04\n",
            "Loss: 5.351136e-04\n",
            "Loss: 5.349984e-04\n",
            "Loss: 5.347673e-04\n",
            "Loss: 5.346566e-04\n",
            "Loss: 5.343569e-04\n",
            "Loss: 5.341708e-04\n",
            "Loss: 5.338516e-04\n",
            "Loss: 5.337946e-04\n",
            "Loss: 5.335560e-04\n",
            "Loss: 5.334767e-04\n",
            "Loss: 5.333438e-04\n",
            "Loss: 5.333296e-04\n",
            "Loss: 5.331836e-04\n",
            "Loss: 5.330821e-04\n",
            "Loss: 5.329654e-04\n",
            "Loss: 5.328298e-04\n",
            "Loss: 5.325851e-04\n",
            "Loss: 5.327137e-04\n",
            "Loss: 5.324699e-04\n",
            "Loss: 5.322969e-04\n",
            "Loss: 5.321669e-04\n",
            "Loss: 5.321751e-04\n",
            "Loss: 5.320948e-04\n",
            "Loss: 5.319843e-04\n",
            "Loss: 5.318741e-04\n",
            "Loss: 5.318096e-04\n",
            "Loss: 5.317238e-04\n",
            "Loss: 5.316198e-04\n",
            "Loss: 5.316238e-04\n",
            "Loss: 5.315025e-04\n",
            "Loss: 5.313919e-04\n",
            "Loss: 5.312918e-04\n",
            "Loss: 5.311977e-04\n",
            "Loss: 5.310860e-04\n",
            "Loss: 5.309392e-04\n",
            "Loss: 5.306240e-04\n",
            "Loss: 5.305836e-04\n",
            "Loss: 5.303858e-04\n",
            "Loss: 5.303402e-04\n",
            "Loss: 5.302553e-04\n",
            "Loss: 5.301340e-04\n",
            "Loss: 5.299257e-04\n",
            "Loss: 5.297533e-04\n",
            "Loss: 5.294286e-04\n",
            "Loss: 5.292877e-04\n",
            "Loss: 5.292028e-04\n",
            "Loss: 5.290999e-04\n",
            "Loss: 5.288714e-04\n",
            "Loss: 5.290901e-04\n",
            "Loss: 5.288328e-04\n",
            "Loss: 5.287304e-04\n",
            "Loss: 5.286539e-04\n",
            "Loss: 5.286026e-04\n",
            "Loss: 5.285047e-04\n",
            "Loss: 5.284427e-04\n",
            "Loss: 5.283891e-04\n",
            "Loss: 5.282746e-04\n",
            "Loss: 5.282516e-04\n",
            "Loss: 5.281079e-04\n",
            "Loss: 5.279641e-04\n",
            "Loss: 5.278200e-04\n",
            "Loss: 5.277079e-04\n",
            "Loss: 5.275253e-04\n",
            "Loss: 5.274089e-04\n",
            "Loss: 5.272763e-04\n",
            "Loss: 5.271906e-04\n",
            "Loss: 5.271054e-04\n",
            "Loss: 5.270481e-04\n",
            "Loss: 5.269436e-04\n",
            "Loss: 5.268803e-04\n",
            "Loss: 5.268477e-04\n",
            "Loss: 5.267503e-04\n",
            "Loss: 5.267091e-04\n",
            "Loss: 5.266016e-04\n",
            "Loss: 5.264577e-04\n",
            "Loss: 5.264529e-04\n",
            "Loss: 5.263270e-04\n",
            "Loss: 5.262950e-04\n",
            "Loss: 5.262089e-04\n",
            "Loss: 5.261164e-04\n",
            "Loss: 5.260134e-04\n",
            "Loss: 5.258785e-04\n",
            "Loss: 5.257279e-04\n",
            "Loss: 5.256094e-04\n",
            "Loss: 5.254716e-04\n",
            "Loss: 5.252476e-04\n",
            "Loss: 5.250802e-04\n",
            "Loss: 5.248738e-04\n",
            "Loss: 5.248536e-04\n",
            "Loss: 5.247649e-04\n",
            "Loss: 5.246875e-04\n",
            "Loss: 5.246086e-04\n",
            "Loss: 5.245642e-04\n",
            "Loss: 5.244839e-04\n",
            "Loss: 5.243915e-04\n",
            "Loss: 5.243181e-04\n",
            "Loss: 5.241701e-04\n",
            "Loss: 5.239926e-04\n",
            "Loss: 5.238125e-04\n",
            "Loss: 5.236921e-04\n",
            "Loss: 5.234805e-04\n",
            "Loss: 5.233894e-04\n",
            "Loss: 5.232367e-04\n",
            "Loss: 5.231088e-04\n",
            "Loss: 5.230270e-04\n",
            "Loss: 5.229144e-04\n",
            "Loss: 5.227965e-04\n",
            "Loss: 5.226678e-04\n",
            "Loss: 5.225791e-04\n",
            "Loss: 5.224585e-04\n",
            "Loss: 5.223140e-04\n",
            "Loss: 5.222111e-04\n",
            "Loss: 5.220107e-04\n",
            "Loss: 5.219298e-04\n",
            "Loss: 5.218611e-04\n",
            "Loss: 5.217753e-04\n",
            "Loss: 5.216848e-04\n",
            "Loss: 5.215179e-04\n",
            "Loss: 5.213713e-04\n",
            "Loss: 5.211817e-04\n",
            "Loss: 5.210819e-04\n",
            "Loss: 5.210130e-04\n",
            "Loss: 5.209217e-04\n",
            "Loss: 5.207980e-04\n",
            "Loss: 5.206703e-04\n",
            "Loss: 5.205959e-04\n",
            "Loss: 5.205125e-04\n",
            "Loss: 5.204323e-04\n",
            "Loss: 5.203370e-04\n",
            "Loss: 5.202116e-04\n",
            "Loss: 5.200002e-04\n",
            "Loss: 5.198739e-04\n",
            "Loss: 5.197307e-04\n",
            "Loss: 5.195991e-04\n",
            "Loss: 5.195304e-04\n",
            "Loss: 5.193967e-04\n",
            "Loss: 5.193289e-04\n",
            "Loss: 5.191704e-04\n",
            "Loss: 5.190137e-04\n",
            "Loss: 5.188503e-04\n",
            "Loss: 5.187280e-04\n",
            "Loss: 5.186208e-04\n",
            "Loss: 5.185578e-04\n",
            "Loss: 5.185198e-04\n",
            "Loss: 5.184781e-04\n",
            "Loss: 5.184250e-04\n",
            "Loss: 5.183737e-04\n",
            "Loss: 5.183497e-04\n",
            "Loss: 5.182020e-04\n",
            "Loss: 5.181243e-04\n",
            "Loss: 5.179347e-04\n",
            "Loss: 5.178790e-04\n",
            "Loss: 5.177399e-04\n",
            "Loss: 5.176771e-04\n",
            "Loss: 5.175901e-04\n",
            "Loss: 5.177645e-04\n",
            "Loss: 5.175722e-04\n",
            "Loss: 5.175100e-04\n",
            "Loss: 5.173868e-04\n",
            "Loss: 5.172599e-04\n",
            "Loss: 5.171591e-04\n",
            "Loss: 5.171340e-04\n",
            "Loss: 5.170177e-04\n",
            "Loss: 5.169650e-04\n",
            "Loss: 5.169119e-04\n",
            "Loss: 5.168873e-04\n",
            "Loss: 5.168124e-04\n",
            "Loss: 5.168754e-04\n",
            "Loss: 5.167691e-04\n",
            "Loss: 5.167017e-04\n",
            "Loss: 5.166132e-04\n",
            "Loss: 5.165936e-04\n",
            "Loss: 5.165390e-04\n",
            "Loss: 5.164756e-04\n",
            "Loss: 5.163502e-04\n",
            "Loss: 5.162106e-04\n",
            "Loss: 5.163012e-04\n",
            "Loss: 5.161458e-04\n",
            "Loss: 5.159984e-04\n",
            "Loss: 5.159329e-04\n",
            "Loss: 5.158890e-04\n",
            "Loss: 5.157738e-04\n",
            "Loss: 5.156135e-04\n",
            "Loss: 5.156677e-04\n",
            "Loss: 5.155368e-04\n",
            "Loss: 5.154512e-04\n",
            "Loss: 5.153680e-04\n",
            "Loss: 5.152157e-04\n",
            "Loss: 5.150487e-04\n",
            "Loss: 5.149950e-04\n",
            "Loss: 5.148512e-04\n",
            "Loss: 5.147776e-04\n",
            "Loss: 5.147244e-04\n",
            "Loss: 5.145888e-04\n",
            "Loss: 5.144700e-04\n",
            "Loss: 5.144337e-04\n",
            "Loss: 5.143904e-04\n",
            "Loss: 5.143422e-04\n",
            "Loss: 5.142344e-04\n",
            "Loss: 5.142573e-04\n",
            "Loss: 5.141689e-04\n",
            "Loss: 5.141228e-04\n",
            "Loss: 5.140526e-04\n",
            "Loss: 5.139874e-04\n",
            "Loss: 5.139232e-04\n",
            "Loss: 5.138507e-04\n",
            "Loss: 5.138085e-04\n",
            "Loss: 5.137254e-04\n",
            "Loss: 5.136573e-04\n",
            "Loss: 5.135605e-04\n",
            "Loss: 5.134969e-04\n",
            "Loss: 5.134110e-04\n",
            "Loss: 5.133139e-04\n",
            "Loss: 5.132394e-04\n",
            "Loss: 5.131859e-04\n",
            "Loss: 5.130947e-04\n",
            "Loss: 5.129313e-04\n",
            "Loss: 5.130103e-04\n",
            "Loss: 5.128729e-04\n",
            "Loss: 5.127845e-04\n",
            "Loss: 5.127570e-04\n",
            "Loss: 5.127018e-04\n",
            "Loss: 5.126275e-04\n",
            "Loss: 5.125845e-04\n",
            "Loss: 5.125867e-04\n",
            "Loss: 5.125802e-04\n",
            "Loss: 5.125735e-04\n",
            "Loss: 5.125037e-04\n",
            "Loss: 5.124977e-04\n",
            "Loss: 5.125061e-04\n",
            "Loss: 5.124869e-04\n",
            "Loss: 5.124557e-04\n",
            "Loss: 5.124264e-04\n",
            "Loss: 5.123710e-04\n",
            "Loss: 5.123024e-04\n",
            "Loss: 5.126349e-04\n",
            "Loss: 5.122632e-04\n",
            "Loss: 5.121755e-04\n",
            "Loss: 5.120982e-04\n",
            "Loss: 5.120430e-04\n",
            "Loss: 5.119828e-04\n",
            "Loss: 5.119105e-04\n",
            "Loss: 5.118634e-04\n",
            "Loss: 5.117276e-04\n",
            "Loss: 5.116825e-04\n",
            "Loss: 5.115045e-04\n",
            "Loss: 5.114398e-04\n",
            "Loss: 5.113980e-04\n",
            "Loss: 5.113475e-04\n",
            "Loss: 5.111713e-04\n",
            "Loss: 5.115306e-04\n",
            "Loss: 5.111326e-04\n",
            "Loss: 5.109865e-04\n",
            "Loss: 5.109082e-04\n",
            "Loss: 5.108588e-04\n",
            "Loss: 5.108021e-04\n",
            "Loss: 5.107086e-04\n",
            "Loss: 5.106258e-04\n",
            "Loss: 5.105169e-04\n",
            "Loss: 5.104520e-04\n",
            "Loss: 5.103812e-04\n",
            "Loss: 5.102778e-04\n",
            "Loss: 5.101668e-04\n",
            "Loss: 5.108941e-04\n",
            "Loss: 5.101450e-04\n",
            "Loss: 5.100140e-04\n",
            "Loss: 5.099433e-04\n",
            "Loss: 5.098149e-04\n",
            "Loss: 5.096627e-04\n",
            "Loss: 5.097129e-04\n",
            "Loss: 5.095757e-04\n",
            "Loss: 5.094818e-04\n",
            "Loss: 5.093983e-04\n",
            "Loss: 5.093744e-04\n",
            "Loss: 5.093525e-04\n",
            "Loss: 5.093247e-04\n",
            "Loss: 5.092531e-04\n",
            "Loss: 5.092139e-04\n",
            "Loss: 5.091285e-04\n",
            "Loss: 5.090235e-04\n",
            "Loss: 5.089295e-04\n",
            "Loss: 5.087728e-04\n",
            "Loss: 5.087129e-04\n",
            "Loss: 5.086157e-04\n",
            "Loss: 5.085427e-04\n",
            "Loss: 5.084641e-04\n",
            "Loss: 5.083877e-04\n",
            "Loss: 5.082814e-04\n",
            "Loss: 5.081644e-04\n",
            "Loss: 5.080872e-04\n",
            "Loss: 5.080246e-04\n",
            "Loss: 5.079517e-04\n",
            "Loss: 5.078678e-04\n",
            "Loss: 5.077593e-04\n",
            "Loss: 5.076880e-04\n",
            "Loss: 5.076301e-04\n",
            "Loss: 5.075175e-04\n",
            "Loss: 5.073819e-04\n",
            "Loss: 5.072742e-04\n",
            "Loss: 5.072174e-04\n",
            "Loss: 5.071822e-04\n",
            "Loss: 5.070894e-04\n",
            "Loss: 5.070507e-04\n",
            "Loss: 5.069929e-04\n",
            "Loss: 5.069228e-04\n",
            "Loss: 5.069018e-04\n",
            "Loss: 5.067662e-04\n",
            "Loss: 5.066742e-04\n",
            "Loss: 5.065836e-04\n",
            "Loss: 5.065497e-04\n",
            "Loss: 5.065004e-04\n",
            "Loss: 5.064229e-04\n",
            "Loss: 5.063632e-04\n",
            "Loss: 5.063033e-04\n",
            "Loss: 5.062631e-04\n",
            "Loss: 5.061711e-04\n",
            "Loss: 5.060632e-04\n",
            "Loss: 5.059403e-04\n",
            "Loss: 5.059202e-04\n",
            "Loss: 5.058128e-04\n",
            "Loss: 5.057474e-04\n",
            "Loss: 5.057055e-04\n",
            "Loss: 5.056232e-04\n",
            "Loss: 5.054691e-04\n",
            "Loss: 5.053391e-04\n",
            "Loss: 5.052161e-04\n",
            "Loss: 5.051554e-04\n",
            "Loss: 5.050824e-04\n",
            "Loss: 5.050129e-04\n",
            "Loss: 5.048665e-04\n",
            "Loss: 5.051346e-04\n",
            "Loss: 5.048352e-04\n",
            "Loss: 5.047448e-04\n",
            "Loss: 5.046636e-04\n",
            "Loss: 5.045407e-04\n",
            "Loss: 5.044219e-04\n",
            "Loss: 5.043955e-04\n",
            "Loss: 5.042674e-04\n",
            "Loss: 5.042110e-04\n",
            "Loss: 5.041778e-04\n",
            "Loss: 5.041320e-04\n",
            "Loss: 5.041026e-04\n",
            "Loss: 5.040126e-04\n",
            "Loss: 5.039523e-04\n",
            "Loss: 5.038718e-04\n",
            "Loss: 5.037258e-04\n",
            "Loss: 5.039567e-04\n",
            "Loss: 5.036509e-04\n",
            "Loss: 5.035276e-04\n",
            "Loss: 5.034364e-04\n",
            "Loss: 5.033691e-04\n",
            "Loss: 5.032803e-04\n",
            "Loss: 5.032399e-04\n",
            "Loss: 5.031017e-04\n",
            "Loss: 5.030666e-04\n",
            "Loss: 5.029998e-04\n",
            "Loss: 5.029027e-04\n",
            "Loss: 5.029320e-04\n",
            "Loss: 5.028486e-04\n",
            "Loss: 5.027530e-04\n",
            "Loss: 5.026175e-04\n",
            "Loss: 5.024715e-04\n",
            "Loss: 5.022704e-04\n",
            "Loss: 5.020523e-04\n",
            "Loss: 5.018900e-04\n",
            "Loss: 5.016916e-04\n",
            "Loss: 5.015654e-04\n",
            "Loss: 5.013723e-04\n",
            "Loss: 5.013157e-04\n",
            "Loss: 5.011422e-04\n",
            "Loss: 5.010726e-04\n",
            "Loss: 5.009507e-04\n",
            "Loss: 5.008423e-04\n",
            "Loss: 5.006831e-04\n",
            "Loss: 5.005816e-04\n",
            "Loss: 5.005155e-04\n",
            "Loss: 5.004595e-04\n",
            "Loss: 5.003797e-04\n",
            "Loss: 5.002465e-04\n",
            "Loss: 5.000940e-04\n",
            "Loss: 5.003078e-04\n",
            "Loss: 5.000298e-04\n",
            "Loss: 4.998710e-04\n",
            "Loss: 4.998223e-04\n",
            "Loss: 4.997121e-04\n",
            "Loss: 4.996440e-04\n",
            "Loss: 4.995426e-04\n",
            "Loss: 4.994824e-04\n",
            "Loss: 4.993532e-04\n",
            "Loss: 4.992483e-04\n",
            "Loss: 4.990657e-04\n",
            "Loss: 4.990053e-04\n",
            "Loss: 4.989045e-04\n",
            "Loss: 4.988146e-04\n",
            "Loss: 4.987627e-04\n",
            "Loss: 4.986387e-04\n",
            "Loss: 4.985139e-04\n",
            "Loss: 4.984277e-04\n",
            "Loss: 4.983582e-04\n",
            "Loss: 4.982890e-04\n",
            "Loss: 4.981768e-04\n",
            "Loss: 4.980379e-04\n",
            "Loss: 4.979643e-04\n",
            "Loss: 4.978731e-04\n",
            "Loss: 4.978258e-04\n",
            "Loss: 4.977951e-04\n",
            "Loss: 4.976757e-04\n",
            "Loss: 4.976558e-04\n",
            "Loss: 4.975517e-04\n",
            "Loss: 4.975133e-04\n",
            "Loss: 4.975032e-04\n",
            "Loss: 4.974055e-04\n",
            "Loss: 4.973197e-04\n",
            "Loss: 4.971834e-04\n",
            "Loss: 4.976616e-04\n",
            "Loss: 4.971114e-04\n",
            "Loss: 4.969043e-04\n",
            "Loss: 4.967900e-04\n",
            "Loss: 4.968242e-04\n",
            "Loss: 4.967005e-04\n",
            "Loss: 4.965932e-04\n",
            "Loss: 4.964774e-04\n",
            "Loss: 4.963080e-04\n",
            "Loss: 4.961355e-04\n",
            "Loss: 4.961357e-04\n",
            "Loss: 4.960657e-04\n",
            "Loss: 4.960028e-04\n",
            "Loss: 4.959041e-04\n",
            "Loss: 4.957540e-04\n",
            "Loss: 4.956997e-04\n",
            "Loss: 4.955924e-04\n",
            "Loss: 4.955514e-04\n",
            "Loss: 4.955182e-04\n",
            "Loss: 4.954261e-04\n",
            "Loss: 4.953440e-04\n",
            "Loss: 4.952915e-04\n",
            "Loss: 4.952318e-04\n",
            "Loss: 4.952034e-04\n",
            "Loss: 4.951318e-04\n",
            "Loss: 4.950915e-04\n",
            "Loss: 4.950584e-04\n",
            "Loss: 4.950260e-04\n",
            "Loss: 4.949807e-04\n",
            "Loss: 4.949142e-04\n",
            "Loss: 4.949045e-04\n",
            "Loss: 4.948376e-04\n",
            "Loss: 4.947534e-04\n",
            "Loss: 4.946742e-04\n",
            "Loss: 4.945815e-04\n",
            "Loss: 4.944935e-04\n",
            "Loss: 4.944550e-04\n",
            "Loss: 4.943197e-04\n",
            "Loss: 4.944647e-04\n",
            "Loss: 4.942563e-04\n",
            "Loss: 4.942237e-04\n",
            "Loss: 4.941280e-04\n",
            "Loss: 4.940765e-04\n",
            "Loss: 4.939510e-04\n",
            "Loss: 4.942697e-04\n",
            "Loss: 4.938816e-04\n",
            "Loss: 4.938217e-04\n",
            "Loss: 4.937714e-04\n",
            "Loss: 4.937595e-04\n",
            "Loss: 4.936914e-04\n",
            "Loss: 4.936088e-04\n",
            "Loss: 4.935694e-04\n",
            "Loss: 4.935033e-04\n",
            "Loss: 4.934646e-04\n",
            "Loss: 4.934119e-04\n",
            "Loss: 4.933539e-04\n",
            "Loss: 4.932847e-04\n",
            "Loss: 4.931940e-04\n",
            "Loss: 4.931383e-04\n",
            "Loss: 4.931070e-04\n",
            "Loss: 4.930308e-04\n",
            "Loss: 4.930379e-04\n",
            "Loss: 4.930036e-04\n",
            "Loss: 4.929909e-04\n",
            "Loss: 4.929099e-04\n",
            "Loss: 4.928177e-04\n",
            "Loss: 4.927656e-04\n",
            "Loss: 4.927437e-04\n",
            "Loss: 4.926958e-04\n",
            "Loss: 4.926595e-04\n",
            "Loss: 4.926066e-04\n",
            "Loss: 4.925749e-04\n",
            "Loss: 4.925542e-04\n",
            "Loss: 4.924966e-04\n",
            "Loss: 4.924677e-04\n",
            "Loss: 4.924239e-04\n",
            "Loss: 4.923830e-04\n",
            "Loss: 4.923222e-04\n",
            "Loss: 4.922831e-04\n",
            "Loss: 4.922441e-04\n",
            "Loss: 4.922096e-04\n",
            "Loss: 4.921568e-04\n",
            "Loss: 4.920545e-04\n",
            "Loss: 4.920192e-04\n",
            "Loss: 4.918956e-04\n",
            "Loss: 4.918029e-04\n",
            "Loss: 4.917426e-04\n",
            "Loss: 4.916868e-04\n",
            "Loss: 4.916557e-04\n",
            "Loss: 4.915863e-04\n",
            "Loss: 4.915106e-04\n",
            "Loss: 4.914149e-04\n",
            "Loss: 4.913360e-04\n",
            "Loss: 4.912900e-04\n",
            "Loss: 4.912126e-04\n",
            "Loss: 4.911539e-04\n",
            "Loss: 4.910878e-04\n",
            "Loss: 4.910592e-04\n",
            "Loss: 4.910539e-04\n",
            "Loss: 4.909710e-04\n",
            "Loss: 4.909603e-04\n",
            "Loss: 4.908627e-04\n",
            "Loss: 4.908039e-04\n",
            "Loss: 4.906484e-04\n",
            "Loss: 4.906519e-04\n",
            "Loss: 4.905865e-04\n",
            "Loss: 4.904940e-04\n",
            "Loss: 4.904699e-04\n",
            "Loss: 4.904330e-04\n",
            "Loss: 4.903697e-04\n",
            "Loss: 4.903087e-04\n",
            "Loss: 4.902197e-04\n",
            "Loss: 4.901577e-04\n",
            "Loss: 4.901083e-04\n",
            "Loss: 4.900473e-04\n",
            "Loss: 4.899215e-04\n",
            "Loss: 4.902034e-04\n",
            "Loss: 4.898829e-04\n",
            "Loss: 4.897973e-04\n",
            "Loss: 4.897125e-04\n",
            "Loss: 4.896154e-04\n",
            "Loss: 4.894967e-04\n",
            "Loss: 4.893757e-04\n",
            "Loss: 4.893167e-04\n",
            "Loss: 4.892084e-04\n",
            "Loss: 4.891437e-04\n",
            "Loss: 4.890844e-04\n",
            "Loss: 4.890092e-04\n",
            "Loss: 4.889460e-04\n",
            "Loss: 4.889044e-04\n",
            "Loss: 4.888597e-04\n",
            "Loss: 4.888488e-04\n",
            "Loss: 4.887687e-04\n",
            "Loss: 4.886781e-04\n",
            "Loss: 4.885785e-04\n",
            "Loss: 4.885336e-04\n",
            "Loss: 4.884927e-04\n",
            "Loss: 4.884275e-04\n",
            "Loss: 4.883504e-04\n",
            "Loss: 4.882962e-04\n",
            "Loss: 4.882001e-04\n",
            "Loss: 4.883331e-04\n",
            "Loss: 4.881349e-04\n",
            "Loss: 4.880615e-04\n",
            "Loss: 4.879772e-04\n",
            "Loss: 4.878273e-04\n",
            "Loss: 4.880410e-04\n",
            "Loss: 4.877874e-04\n",
            "Loss: 4.876743e-04\n",
            "Loss: 4.875632e-04\n",
            "Loss: 4.874383e-04\n",
            "Loss: 4.873962e-04\n",
            "Loss: 4.872782e-04\n",
            "Loss: 4.872053e-04\n",
            "Loss: 4.871630e-04\n",
            "Loss: 4.870488e-04\n",
            "Loss: 4.871360e-04\n",
            "Loss: 4.869923e-04\n",
            "Loss: 4.869009e-04\n",
            "Loss: 4.868538e-04\n",
            "Loss: 4.867326e-04\n",
            "Loss: 4.867474e-04\n",
            "Loss: 4.866911e-04\n",
            "Loss: 4.865961e-04\n",
            "Loss: 4.864729e-04\n",
            "Loss: 4.863534e-04\n",
            "Loss: 4.862331e-04\n",
            "Loss: 4.861279e-04\n",
            "Loss: 4.859897e-04\n",
            "Loss: 4.859148e-04\n",
            "Loss: 4.858253e-04\n",
            "Loss: 4.856792e-04\n",
            "Loss: 4.855458e-04\n",
            "Loss: 4.854970e-04\n",
            "Loss: 4.853409e-04\n",
            "Loss: 4.852909e-04\n",
            "Loss: 4.851616e-04\n",
            "Loss: 4.851111e-04\n",
            "Loss: 4.848611e-04\n",
            "Loss: 4.849192e-04\n",
            "Loss: 4.847881e-04\n",
            "Loss: 4.846798e-04\n",
            "Loss: 4.846179e-04\n",
            "Loss: 4.845557e-04\n",
            "Loss: 4.844348e-04\n",
            "Loss: 4.843061e-04\n",
            "Loss: 4.842351e-04\n",
            "Loss: 4.841553e-04\n",
            "Loss: 4.840313e-04\n",
            "Loss: 4.838865e-04\n",
            "Loss: 4.838262e-04\n",
            "Loss: 4.837780e-04\n",
            "Loss: 4.837283e-04\n",
            "Loss: 4.836546e-04\n",
            "Loss: 4.835951e-04\n",
            "Loss: 4.837544e-04\n",
            "Loss: 4.835585e-04\n",
            "Loss: 4.834962e-04\n",
            "Loss: 4.834679e-04\n",
            "Loss: 4.834314e-04\n",
            "Loss: 4.833296e-04\n",
            "Loss: 4.833475e-04\n",
            "Loss: 4.832912e-04\n",
            "Loss: 4.832670e-04\n",
            "Loss: 4.831956e-04\n",
            "Loss: 4.831454e-04\n",
            "Loss: 4.831093e-04\n",
            "Loss: 4.830814e-04\n",
            "Loss: 4.830214e-04\n",
            "Loss: 4.829719e-04\n",
            "Loss: 4.830614e-04\n",
            "Loss: 4.829319e-04\n",
            "Loss: 4.828835e-04\n",
            "Loss: 4.828274e-04\n",
            "Loss: 4.827649e-04\n",
            "Loss: 4.827247e-04\n",
            "Loss: 4.825932e-04\n",
            "Loss: 4.825038e-04\n",
            "Loss: 4.823625e-04\n",
            "Loss: 4.823046e-04\n",
            "Loss: 4.822286e-04\n",
            "Loss: 4.822070e-04\n",
            "Loss: 4.821275e-04\n",
            "Loss: 4.820647e-04\n",
            "Loss: 4.819885e-04\n",
            "Loss: 4.818726e-04\n",
            "Loss: 4.819499e-04\n",
            "Loss: 4.817771e-04\n",
            "Loss: 4.816570e-04\n",
            "Loss: 4.815900e-04\n",
            "Loss: 4.814551e-04\n",
            "Loss: 4.813811e-04\n",
            "Loss: 4.813038e-04\n",
            "Loss: 4.811731e-04\n",
            "Loss: 4.811112e-04\n",
            "Loss: 4.810103e-04\n",
            "Loss: 4.809034e-04\n",
            "Loss: 4.808215e-04\n",
            "Loss: 4.807134e-04\n",
            "Loss: 4.806339e-04\n",
            "Loss: 4.805358e-04\n",
            "Loss: 4.803702e-04\n",
            "Loss: 4.807194e-04\n",
            "Loss: 4.802975e-04\n",
            "Loss: 4.802018e-04\n",
            "Loss: 4.801282e-04\n",
            "Loss: 4.800250e-04\n",
            "Loss: 4.799704e-04\n",
            "Loss: 4.800797e-04\n",
            "Loss: 4.799183e-04\n",
            "Loss: 4.798392e-04\n",
            "Loss: 4.797747e-04\n",
            "Loss: 4.796642e-04\n",
            "Loss: 4.795986e-04\n",
            "Loss: 4.804540e-04\n",
            "Loss: 4.795785e-04\n",
            "Loss: 4.794429e-04\n",
            "Loss: 4.793241e-04\n",
            "Loss: 4.792117e-04\n",
            "Loss: 4.791061e-04\n",
            "Loss: 4.791715e-04\n",
            "Loss: 4.790448e-04\n",
            "Loss: 4.789200e-04\n",
            "Loss: 4.788484e-04\n",
            "Loss: 4.787688e-04\n",
            "Loss: 4.787256e-04\n",
            "Loss: 4.786874e-04\n",
            "Loss: 4.786315e-04\n",
            "Loss: 4.785744e-04\n",
            "Loss: 4.785009e-04\n",
            "Loss: 4.783918e-04\n",
            "Loss: 4.782472e-04\n",
            "Loss: 4.781449e-04\n",
            "Loss: 4.780228e-04\n",
            "Loss: 4.778849e-04\n",
            "Loss: 4.779307e-04\n",
            "Loss: 4.778331e-04\n",
            "Loss: 4.777872e-04\n",
            "Loss: 4.777289e-04\n",
            "Loss: 4.776653e-04\n",
            "Loss: 4.775914e-04\n",
            "Loss: 4.774828e-04\n",
            "Loss: 4.774314e-04\n",
            "Loss: 4.773402e-04\n",
            "Loss: 4.772703e-04\n",
            "Loss: 4.771672e-04\n",
            "Loss: 4.770960e-04\n",
            "Loss: 4.769941e-04\n",
            "Loss: 4.769207e-04\n",
            "Loss: 4.767836e-04\n",
            "Loss: 4.767066e-04\n",
            "Loss: 4.766441e-04\n",
            "Loss: 4.765409e-04\n",
            "Loss: 4.763857e-04\n",
            "Loss: 4.762376e-04\n",
            "Loss: 4.767393e-04\n",
            "Loss: 4.761841e-04\n",
            "Loss: 4.760826e-04\n",
            "Loss: 4.760424e-04\n",
            "Loss: 4.760076e-04\n",
            "Loss: 4.759316e-04\n",
            "Loss: 4.758809e-04\n",
            "Loss: 4.758317e-04\n",
            "Loss: 4.757665e-04\n",
            "Loss: 4.757423e-04\n",
            "Loss: 4.756653e-04\n",
            "Loss: 4.756214e-04\n",
            "Loss: 4.755538e-04\n",
            "Loss: 4.754980e-04\n",
            "Loss: 4.754533e-04\n",
            "Loss: 4.754082e-04\n",
            "Loss: 4.753108e-04\n",
            "Loss: 4.752734e-04\n",
            "Loss: 4.752229e-04\n",
            "Loss: 4.751347e-04\n",
            "Loss: 4.751341e-04\n",
            "Loss: 4.749694e-04\n",
            "Loss: 4.749237e-04\n",
            "Loss: 4.748316e-04\n",
            "Loss: 4.747090e-04\n",
            "Loss: 4.747852e-04\n",
            "Loss: 4.746541e-04\n",
            "Loss: 4.744646e-04\n",
            "Loss: 4.743904e-04\n",
            "Loss: 4.743528e-04\n",
            "Loss: 4.743036e-04\n",
            "Loss: 4.742623e-04\n",
            "Loss: 4.742223e-04\n",
            "Loss: 4.741491e-04\n",
            "Loss: 4.739777e-04\n",
            "Loss: 4.739888e-04\n",
            "Loss: 4.738958e-04\n",
            "Loss: 4.737939e-04\n",
            "Loss: 4.737443e-04\n",
            "Loss: 4.737009e-04\n",
            "Loss: 4.736971e-04\n",
            "Loss: 4.736519e-04\n",
            "Loss: 4.736359e-04\n",
            "Loss: 4.735741e-04\n",
            "Loss: 4.735492e-04\n",
            "Loss: 4.735138e-04\n",
            "Loss: 4.734306e-04\n",
            "Loss: 4.733720e-04\n",
            "Loss: 4.732615e-04\n",
            "Loss: 4.732181e-04\n",
            "Loss: 4.731609e-04\n",
            "Loss: 4.733521e-04\n",
            "Loss: 4.731005e-04\n",
            "Loss: 4.730741e-04\n",
            "Loss: 4.729635e-04\n",
            "Loss: 4.728932e-04\n",
            "Loss: 4.728012e-04\n",
            "Loss: 4.727269e-04\n",
            "Loss: 4.726504e-04\n",
            "Loss: 4.725558e-04\n",
            "Loss: 4.725049e-04\n",
            "Loss: 4.723815e-04\n",
            "Loss: 4.727839e-04\n",
            "Loss: 4.723369e-04\n",
            "Loss: 4.722726e-04\n",
            "Loss: 4.722403e-04\n",
            "Loss: 4.721952e-04\n",
            "Loss: 4.722337e-04\n",
            "Loss: 4.721737e-04\n",
            "Loss: 4.721336e-04\n",
            "Loss: 4.720731e-04\n",
            "Loss: 4.719864e-04\n",
            "Loss: 4.719093e-04\n",
            "Loss: 4.720270e-04\n",
            "Loss: 4.718584e-04\n",
            "Loss: 4.717712e-04\n",
            "Loss: 4.716904e-04\n",
            "Loss: 4.716018e-04\n",
            "Loss: 4.715162e-04\n",
            "Loss: 4.714666e-04\n",
            "Loss: 4.714136e-04\n",
            "Loss: 4.712740e-04\n",
            "Loss: 4.711606e-04\n",
            "Loss: 4.710762e-04\n",
            "Loss: 4.710639e-04\n",
            "Loss: 4.710185e-04\n",
            "Loss: 4.709424e-04\n",
            "Loss: 4.709092e-04\n",
            "Loss: 4.708449e-04\n",
            "Loss: 4.708010e-04\n",
            "Loss: 4.706903e-04\n",
            "Loss: 4.706238e-04\n",
            "Loss: 4.705659e-04\n",
            "Loss: 4.704528e-04\n",
            "Loss: 4.703267e-04\n",
            "Loss: 4.701974e-04\n",
            "Loss: 4.701390e-04\n",
            "Loss: 4.700534e-04\n",
            "Loss: 4.699516e-04\n",
            "Loss: 4.704391e-04\n",
            "Loss: 4.699112e-04\n",
            "Loss: 4.697880e-04\n",
            "Loss: 4.696764e-04\n",
            "Loss: 4.695204e-04\n",
            "Loss: 4.696887e-04\n",
            "Loss: 4.694869e-04\n",
            "Loss: 4.694531e-04\n",
            "Loss: 4.693961e-04\n",
            "Loss: 4.693594e-04\n",
            "Loss: 4.692839e-04\n",
            "Loss: 4.692567e-04\n",
            "Loss: 4.691987e-04\n",
            "Loss: 4.691647e-04\n",
            "Loss: 4.691561e-04\n",
            "Loss: 4.691124e-04\n",
            "Loss: 4.690058e-04\n",
            "Loss: 4.689594e-04\n",
            "Loss: 4.688532e-04\n",
            "Loss: 4.687540e-04\n",
            "Loss: 4.686491e-04\n",
            "Loss: 4.688178e-04\n",
            "Loss: 4.686048e-04\n",
            "Loss: 4.685443e-04\n",
            "Loss: 4.684995e-04\n",
            "Loss: 4.684615e-04\n",
            "Loss: 4.683681e-04\n",
            "Loss: 4.682710e-04\n",
            "Loss: 4.681874e-04\n",
            "Loss: 4.681136e-04\n",
            "Loss: 4.680692e-04\n",
            "Loss: 4.680452e-04\n",
            "Loss: 4.679993e-04\n",
            "Loss: 4.679225e-04\n",
            "Loss: 4.678027e-04\n",
            "Loss: 4.677176e-04\n",
            "Loss: 4.675437e-04\n",
            "Loss: 4.674289e-04\n",
            "Loss: 4.672955e-04\n",
            "Loss: 4.672142e-04\n",
            "Loss: 4.670945e-04\n",
            "Loss: 4.670161e-04\n",
            "Loss: 4.668752e-04\n",
            "Loss: 4.668094e-04\n",
            "Loss: 4.667209e-04\n",
            "Loss: 4.666405e-04\n",
            "Loss: 4.664999e-04\n",
            "Loss: 4.664600e-04\n",
            "Loss: 4.663602e-04\n",
            "Loss: 4.663389e-04\n",
            "Loss: 4.662502e-04\n",
            "Loss: 4.661406e-04\n",
            "Loss: 4.661902e-04\n",
            "Loss: 4.661038e-04\n",
            "Loss: 4.660537e-04\n",
            "Loss: 4.660056e-04\n",
            "Loss: 4.659454e-04\n",
            "Loss: 4.658831e-04\n",
            "Loss: 4.659817e-04\n",
            "Loss: 4.658545e-04\n",
            "Loss: 4.657740e-04\n",
            "Loss: 4.657323e-04\n",
            "Loss: 4.657012e-04\n",
            "Loss: 4.656151e-04\n",
            "Loss: 4.655565e-04\n",
            "Loss: 4.654536e-04\n",
            "Loss: 4.653087e-04\n",
            "Loss: 4.651597e-04\n",
            "Loss: 4.654420e-04\n",
            "Loss: 4.650930e-04\n",
            "Loss: 4.650084e-04\n",
            "Loss: 4.649537e-04\n",
            "Loss: 4.649243e-04\n",
            "Loss: 4.648273e-04\n",
            "Loss: 4.647327e-04\n",
            "Loss: 4.647782e-04\n",
            "Loss: 4.646916e-04\n",
            "Loss: 4.646206e-04\n",
            "Loss: 4.645594e-04\n",
            "Loss: 4.645030e-04\n",
            "Loss: 4.644621e-04\n",
            "Loss: 4.644139e-04\n",
            "Loss: 4.643546e-04\n",
            "Loss: 4.642604e-04\n",
            "Loss: 4.641858e-04\n",
            "Loss: 4.641148e-04\n",
            "Loss: 4.640425e-04\n",
            "Loss: 4.639891e-04\n",
            "Loss: 4.639123e-04\n",
            "Loss: 4.638564e-04\n",
            "Loss: 4.637234e-04\n",
            "Loss: 4.636044e-04\n",
            "Loss: 4.635679e-04\n",
            "Loss: 4.634461e-04\n",
            "Loss: 4.634423e-04\n",
            "Loss: 4.633869e-04\n",
            "Loss: 4.632500e-04\n",
            "Loss: 4.630861e-04\n",
            "Loss: 4.629446e-04\n",
            "Loss: 4.628771e-04\n",
            "Loss: 4.628320e-04\n",
            "Loss: 4.627210e-04\n",
            "Loss: 4.626013e-04\n",
            "Loss: 4.625043e-04\n",
            "Loss: 4.624210e-04\n",
            "Loss: 4.623647e-04\n",
            "Loss: 4.622979e-04\n",
            "Loss: 4.621839e-04\n",
            "Loss: 4.622348e-04\n",
            "Loss: 4.621344e-04\n",
            "Loss: 4.620681e-04\n",
            "Loss: 4.620248e-04\n",
            "Loss: 4.619358e-04\n",
            "Loss: 4.618059e-04\n",
            "Loss: 4.616222e-04\n",
            "Loss: 4.617852e-04\n",
            "Loss: 4.614654e-04\n",
            "Loss: 4.612991e-04\n",
            "Loss: 4.611953e-04\n",
            "Loss: 4.611407e-04\n",
            "Loss: 4.610848e-04\n",
            "Loss: 4.609956e-04\n",
            "Loss: 4.609472e-04\n",
            "Loss: 4.608626e-04\n",
            "Loss: 4.607918e-04\n",
            "Loss: 4.610185e-04\n",
            "Loss: 4.607582e-04\n",
            "Loss: 4.606346e-04\n",
            "Loss: 4.605299e-04\n",
            "Loss: 4.603929e-04\n",
            "Loss: 4.602628e-04\n",
            "Loss: 4.607697e-04\n",
            "Loss: 4.602363e-04\n",
            "Loss: 4.601439e-04\n",
            "Loss: 4.600868e-04\n",
            "Loss: 4.599757e-04\n",
            "Loss: 4.598808e-04\n",
            "Loss: 4.597793e-04\n",
            "Loss: 4.597275e-04\n",
            "Loss: 4.596228e-04\n",
            "Loss: 4.595431e-04\n",
            "Loss: 4.594562e-04\n",
            "Loss: 4.593292e-04\n",
            "Loss: 4.592846e-04\n",
            "Loss: 4.591719e-04\n",
            "Loss: 4.590450e-04\n",
            "Loss: 4.589396e-04\n",
            "Loss: 4.587692e-04\n",
            "Loss: 4.586697e-04\n",
            "Loss: 4.585922e-04\n",
            "Loss: 4.585084e-04\n",
            "Loss: 4.584769e-04\n",
            "Loss: 4.583962e-04\n",
            "Loss: 4.582863e-04\n",
            "Loss: 4.582585e-04\n",
            "Loss: 4.581909e-04\n",
            "Loss: 4.581536e-04\n",
            "Loss: 4.581110e-04\n",
            "Loss: 4.580612e-04\n",
            "Loss: 4.582822e-04\n",
            "Loss: 4.580319e-04\n",
            "Loss: 4.579521e-04\n",
            "Loss: 4.578862e-04\n",
            "Loss: 4.578097e-04\n",
            "Loss: 4.577573e-04\n",
            "Loss: 4.577712e-04\n",
            "Loss: 4.577000e-04\n",
            "Loss: 4.576077e-04\n",
            "Loss: 4.574900e-04\n",
            "Loss: 4.573877e-04\n",
            "Loss: 4.573200e-04\n",
            "Loss: 4.572798e-04\n",
            "Loss: 4.571965e-04\n",
            "Loss: 4.571988e-04\n",
            "Loss: 4.572063e-04\n",
            "Loss: 4.572041e-04\n",
            "Loss: 4.572007e-04\n",
            "Loss: 4.571959e-04\n",
            "Loss: 4.571959e-04\n",
            "Loss: 4.572022e-04\n",
            "Loss: 4.571959e-04\n",
            "Loss: 4.571957e-04\n",
            "Loss: 4.572104e-04\n",
            "Loss: 4.571957e-04\n",
            "Loss: 4.571957e-04\n",
            "Loss: 4.572117e-04\n",
            "Loss: 4.571957e-04\n",
            "Loss: 4.571957e-04\n",
            "Loss: 4.572030e-04\n",
            "Loss: 4.571957e-04\n",
            "Loss: 4.571957e-04\n",
            "Loss: 4.572017e-04\n",
            "Loss: 4.571957e-04\n",
            "Loss: 4.571957e-04\n",
            "Loss: 4.572053e-04\n",
            "Loss: 4.571957e-04\n",
            "Loss: 4.571957e-04\n",
            "Loss: 4.571981e-04\n",
            "Loss: 4.571957e-04\n",
            "Loss: 4.571957e-04\n",
            "Loss: 4.572010e-04\n",
            "Loss: 4.571957e-04\n",
            "Loss: 4.571957e-04\n",
            "Loss: 4.571949e-04\n",
            "Loss: 4.571949e-04\n",
            "Loss: 4.571949e-04\n",
            "Loss: 4.572020e-04\n",
            "Loss: 4.571949e-04\n",
            "Loss: 4.571949e-04\n",
            "Loss: 4.571998e-04\n",
            "Loss: 4.571949e-04\n",
            "Loss: 4.571949e-04\n",
            "Loss: 4.571948e-04\n",
            "Loss: 4.571948e-04\n",
            "Loss: 4.572003e-04\n",
            "Loss: 4.571951e-04\n",
            "Loss: 4.572084e-04\n",
            "Loss: 4.571914e-04\n",
            "Loss: 4.571872e-04\n",
            "Loss: 4.571947e-04\n",
            "Loss: 4.571951e-04\n",
            "Loss: 4.571874e-04\n",
            "Loss: 4.571872e-04\n",
            "Loss: 8.307897e-04\n",
            "Loss: 4.578127e-04\n",
            "Loss: 4.571834e-04\n",
            "Loss: 4.571163e-04\n",
            "Loss: 4.570282e-04\n",
            "Loss: 4.570170e-04\n",
            "Loss: 4.569884e-04\n",
            "Loss: 4.569379e-04\n",
            "Loss: 4.568445e-04\n",
            "Loss: 4.568100e-04\n",
            "Loss: 4.567732e-04\n",
            "Loss: 4.567123e-04\n",
            "Loss: 4.566604e-04\n",
            "Loss: 4.565342e-04\n",
            "Loss: 4.564110e-04\n",
            "Loss: 4.562335e-04\n",
            "Loss: 4.562584e-04\n",
            "Loss: 4.561542e-04\n",
            "Loss: 4.560128e-04\n",
            "Loss: 4.559057e-04\n",
            "Loss: 4.558203e-04\n",
            "Loss: 4.557366e-04\n",
            "Loss: 4.556032e-04\n",
            "Loss: 4.555239e-04\n",
            "Loss: 4.553932e-04\n",
            "Loss: 4.552929e-04\n",
            "Loss: 4.551150e-04\n",
            "Loss: 4.552266e-04\n",
            "Loss: 4.550853e-04\n",
            "Loss: 4.549717e-04\n",
            "Loss: 4.548766e-04\n",
            "Loss: 4.547913e-04\n",
            "Loss: 4.549545e-04\n",
            "Loss: 4.547670e-04\n",
            "Loss: 4.546728e-04\n",
            "Loss: 4.546365e-04\n",
            "Loss: 4.545578e-04\n",
            "Loss: 4.544478e-04\n",
            "Loss: 4.543205e-04\n",
            "Loss: 4.541068e-04\n",
            "Loss: 4.539799e-04\n",
            "Loss: 4.538568e-04\n",
            "Loss: 4.537887e-04\n",
            "Loss: 4.536792e-04\n",
            "Loss: 4.535785e-04\n",
            "Loss: 4.535063e-04\n",
            "Loss: 4.534281e-04\n",
            "Loss: 4.533384e-04\n",
            "Loss: 4.532366e-04\n",
            "Loss: 4.531269e-04\n",
            "Loss: 4.529846e-04\n",
            "Loss: 4.529221e-04\n",
            "Loss: 4.528124e-04\n",
            "Loss: 4.527158e-04\n",
            "Loss: 4.525922e-04\n",
            "Loss: 4.524661e-04\n",
            "Loss: 4.527990e-04\n",
            "Loss: 4.524520e-04\n",
            "Loss: 4.523963e-04\n",
            "Loss: 4.523189e-04\n",
            "Loss: 4.522539e-04\n",
            "Loss: 4.521992e-04\n",
            "Loss: 4.521135e-04\n",
            "Loss: 4.520273e-04\n",
            "Loss: 4.519614e-04\n",
            "Loss: 4.519174e-04\n",
            "Loss: 4.518151e-04\n",
            "Loss: 4.517651e-04\n",
            "Loss: 4.517320e-04\n",
            "Loss: 4.516857e-04\n",
            "Loss: 4.515591e-04\n",
            "Loss: 4.514667e-04\n",
            "Loss: 4.514176e-04\n",
            "Loss: 4.513585e-04\n",
            "Loss: 4.513483e-04\n",
            "Loss: 4.512773e-04\n",
            "Loss: 4.512091e-04\n",
            "Loss: 4.512408e-04\n",
            "Loss: 4.511641e-04\n",
            "Loss: 4.511173e-04\n",
            "Loss: 4.510687e-04\n",
            "Loss: 4.509824e-04\n",
            "Loss: 4.509143e-04\n",
            "Loss: 4.508758e-04\n",
            "Loss: 4.508067e-04\n",
            "Loss: 4.507624e-04\n",
            "Loss: 4.507144e-04\n",
            "Loss: 4.506654e-04\n",
            "Loss: 4.506569e-04\n",
            "Loss: 4.506211e-04\n",
            "Loss: 4.505672e-04\n",
            "Loss: 4.505209e-04\n",
            "Loss: 4.504376e-04\n",
            "Loss: 4.503584e-04\n",
            "Loss: 4.503099e-04\n",
            "Loss: 4.502616e-04\n",
            "Loss: 4.501745e-04\n",
            "Loss: 4.501505e-04\n",
            "Loss: 4.500568e-04\n",
            "Loss: 4.499616e-04\n",
            "Loss: 4.499365e-04\n",
            "Loss: 4.498887e-04\n",
            "Loss: 4.498308e-04\n",
            "Loss: 4.497875e-04\n",
            "Loss: 4.497383e-04\n",
            "Loss: 4.496847e-04\n",
            "Loss: 4.495696e-04\n",
            "Loss: 4.494833e-04\n",
            "Loss: 4.494035e-04\n",
            "Loss: 4.493656e-04\n",
            "Loss: 4.493131e-04\n",
            "Loss: 4.492710e-04\n",
            "Loss: 4.492594e-04\n",
            "Loss: 4.492156e-04\n",
            "Loss: 4.491595e-04\n",
            "Loss: 4.491139e-04\n",
            "Loss: 4.490580e-04\n",
            "Loss: 4.490234e-04\n",
            "Loss: 4.489654e-04\n",
            "Loss: 4.489300e-04\n",
            "Loss: 4.488360e-04\n",
            "Loss: 4.487283e-04\n",
            "Loss: 4.486687e-04\n",
            "Loss: 4.486164e-04\n",
            "Loss: 4.485480e-04\n",
            "Loss: 4.485124e-04\n",
            "Loss: 4.484644e-04\n",
            "Loss: 4.484264e-04\n",
            "Loss: 4.483592e-04\n",
            "Loss: 4.482756e-04\n",
            "Loss: 4.481986e-04\n",
            "Loss: 4.481298e-04\n",
            "Loss: 4.481010e-04\n",
            "Loss: 4.480533e-04\n",
            "Loss: 4.479483e-04\n",
            "Loss: 4.479415e-04\n",
            "Loss: 4.478596e-04\n",
            "Loss: 4.478307e-04\n",
            "Loss: 4.477811e-04\n",
            "Loss: 4.477413e-04\n",
            "Loss: 4.477560e-04\n",
            "Loss: 4.477369e-04\n",
            "Loss: 4.476995e-04\n",
            "Loss: 4.476673e-04\n",
            "Loss: 4.476333e-04\n",
            "Loss: 4.475948e-04\n",
            "Loss: 4.475259e-04\n",
            "Loss: 4.474990e-04\n",
            "Loss: 4.474532e-04\n",
            "Loss: 4.474106e-04\n",
            "Loss: 4.474028e-04\n",
            "Loss: 4.473491e-04\n",
            "Loss: 4.473115e-04\n",
            "Loss: 4.472899e-04\n",
            "Loss: 4.472235e-04\n",
            "Loss: 4.471957e-04\n",
            "Loss: 4.471529e-04\n",
            "Loss: 4.471008e-04\n",
            "Loss: 4.470515e-04\n",
            "Loss: 4.469798e-04\n",
            "Loss: 4.468797e-04\n",
            "Loss: 4.467908e-04\n",
            "Loss: 4.467064e-04\n",
            "Loss: 4.466914e-04\n",
            "Loss: 4.466456e-04\n",
            "Loss: 4.466223e-04\n",
            "Loss: 4.466148e-04\n",
            "Loss: 4.465499e-04\n",
            "Loss: 4.464841e-04\n",
            "Loss: 4.463151e-04\n",
            "Loss: 4.462206e-04\n",
            "Loss: 4.460941e-04\n",
            "Loss: 4.460367e-04\n",
            "Loss: 4.459847e-04\n",
            "Loss: 4.458940e-04\n",
            "Loss: 4.458161e-04\n",
            "Loss: 4.457049e-04\n",
            "Loss: 4.456353e-04\n",
            "Loss: 4.455603e-04\n",
            "Loss: 4.454273e-04\n",
            "Loss: 4.453611e-04\n",
            "Loss: 4.452320e-04\n",
            "Loss: 4.451811e-04\n",
            "Loss: 4.450886e-04\n",
            "Loss: 4.450729e-04\n",
            "Loss: 4.450323e-04\n",
            "Loss: 4.449692e-04\n",
            "Loss: 4.448719e-04\n",
            "Loss: 4.448265e-04\n",
            "Loss: 4.447720e-04\n",
            "Loss: 4.447059e-04\n",
            "Loss: 4.446512e-04\n",
            "Loss: 4.445566e-04\n",
            "Loss: 4.444297e-04\n",
            "Loss: 4.475380e-04\n",
            "Loss: 4.443904e-04\n",
            "Loss: 4.443194e-04\n",
            "Loss: 4.442542e-04\n",
            "Loss: 4.441834e-04\n",
            "Loss: 4.441178e-04\n",
            "Loss: 4.440259e-04\n",
            "Loss: 4.439174e-04\n",
            "Loss: 4.438202e-04\n",
            "Loss: 4.436882e-04\n",
            "Loss: 4.435979e-04\n",
            "Loss: 4.434915e-04\n",
            "Loss: 4.433801e-04\n",
            "Loss: 4.432899e-04\n",
            "Loss: 4.432351e-04\n",
            "Loss: 4.431956e-04\n",
            "Loss: 4.431159e-04\n",
            "Loss: 4.430595e-04\n",
            "Loss: 4.429975e-04\n",
            "Loss: 4.429159e-04\n",
            "Loss: 4.428347e-04\n",
            "Loss: 4.428395e-04\n",
            "Loss: 4.428476e-04\n",
            "Loss: 4.428435e-04\n",
            "Loss: 4.428429e-04\n",
            "Loss: 4.428338e-04\n",
            "Loss: 4.428338e-04\n",
            "Loss: 4.428378e-04\n",
            "Loss: 4.428357e-04\n",
            "Loss: 4.428338e-04\n",
            "Loss: 4.428338e-04\n",
            "Loss: 4.428351e-04\n",
            "Loss: 4.428338e-04\n",
            "Loss: 4.428338e-04\n",
            "Loss: 4.428342e-04\n",
            "Loss: 4.428338e-04\n",
            "Loss: 4.428338e-04\n",
            "Loss: 4.428338e-04\n",
            "Loss: 4.428338e-04\n",
            "Loss: 4.590485e-04\n",
            "Loss: 4.428241e-04\n",
            "Loss: 4.427807e-04\n",
            "Loss: 4.427320e-04\n",
            "Loss: 4.426614e-04\n",
            "Loss: 4.426129e-04\n",
            "Loss: 4.424951e-04\n",
            "Loss: 4.424702e-04\n",
            "Loss: 4.423926e-04\n",
            "Loss: 4.423124e-04\n",
            "Loss: 4.422713e-04\n",
            "Loss: 4.421890e-04\n",
            "Loss: 4.421092e-04\n",
            "Loss: 4.419860e-04\n",
            "Loss: 4.420259e-04\n",
            "Loss: 4.419592e-04\n",
            "Loss: 4.419078e-04\n",
            "Loss: 4.418350e-04\n",
            "Loss: 4.417634e-04\n",
            "Loss: 4.416805e-04\n",
            "Loss: 4.418181e-04\n",
            "Loss: 4.416129e-04\n",
            "Loss: 4.415037e-04\n",
            "Loss: 4.414321e-04\n",
            "Loss: 4.413398e-04\n",
            "Loss: 4.411750e-04\n",
            "Loss: 4.408520e-04\n",
            "Loss: 4.406919e-04\n",
            "Loss: 4.405932e-04\n",
            "Loss: 4.405253e-04\n",
            "Loss: 4.404556e-04\n",
            "Loss: 4.404255e-04\n",
            "Loss: 4.403836e-04\n",
            "Loss: 4.403020e-04\n",
            "Loss: 4.402475e-04\n",
            "Loss: 4.401546e-04\n",
            "Loss: 4.400859e-04\n",
            "Loss: 4.399897e-04\n",
            "Loss: 4.399261e-04\n",
            "Loss: 4.397986e-04\n",
            "Loss: 4.397323e-04\n",
            "Loss: 4.396819e-04\n",
            "Loss: 4.395969e-04\n",
            "Loss: 4.395709e-04\n",
            "Loss: 4.395397e-04\n",
            "Loss: 4.394511e-04\n",
            "Loss: 4.395453e-04\n",
            "Loss: 4.394262e-04\n",
            "Loss: 4.393830e-04\n",
            "Loss: 4.392965e-04\n",
            "Loss: 4.392462e-04\n",
            "Loss: 4.391860e-04\n",
            "Loss: 4.391798e-04\n",
            "Loss: 4.391387e-04\n",
            "Loss: 4.390830e-04\n",
            "Loss: 4.391322e-04\n",
            "Loss: 4.390414e-04\n",
            "Loss: 4.389967e-04\n",
            "Loss: 4.389196e-04\n",
            "Loss: 4.388403e-04\n",
            "Loss: 4.388558e-04\n",
            "Loss: 4.388051e-04\n",
            "Loss: 4.387122e-04\n",
            "Loss: 4.386567e-04\n",
            "Loss: 4.385957e-04\n",
            "Loss: 4.385636e-04\n",
            "Loss: 4.385145e-04\n",
            "Loss: 4.384554e-04\n",
            "Loss: 4.384561e-04\n",
            "Loss: 4.384600e-04\n",
            "Loss: 4.384587e-04\n",
            "Loss: 4.384562e-04\n",
            "Loss: 4.384556e-04\n",
            "Loss: 4.384554e-04\n",
            "Loss: 4.384554e-04\n",
            "Loss: 4.384548e-04\n",
            "Loss: 4.384548e-04\n",
            "Loss: 4.384548e-04\n",
            "Loss: 4.384548e-04\n",
            "Loss: 4.384548e-04\n",
            "Loss: 4.384548e-04\n",
            "Loss: 4.384548e-04\n",
            "Loss: 4.384548e-04\n",
            "Loss: 4.384548e-04\n",
            "Loss: 4.384548e-04\n",
            "Loss: 4.384548e-04\n",
            "Loss: 4.385735e-04\n",
            "Loss: 4.384369e-04\n",
            "Loss: 4.383968e-04\n",
            "Loss: 4.383055e-04\n",
            "Loss: 4.382763e-04\n",
            "Loss: 4.382312e-04\n",
            "Loss: 4.380803e-04\n",
            "Loss: 4.380289e-04\n",
            "Loss: 4.379258e-04\n",
            "Loss: 4.378824e-04\n",
            "Loss: 4.377083e-04\n",
            "Loss: 4.376465e-04\n",
            "Loss: 4.375564e-04\n",
            "Loss: 4.374347e-04\n",
            "Loss: 4.373137e-04\n",
            "Loss: 4.372528e-04\n",
            "Loss: 4.371580e-04\n",
            "Loss: 4.370991e-04\n",
            "Loss: 4.370562e-04\n",
            "Loss: 4.370416e-04\n",
            "Loss: 4.369548e-04\n",
            "Loss: 4.368517e-04\n",
            "Loss: 4.367829e-04\n",
            "Loss: 4.366099e-04\n",
            "Loss: 4.364908e-04\n",
            "Loss: 4.363668e-04\n",
            "Loss: 4.362148e-04\n",
            "Loss: 4.360751e-04\n",
            "Loss: 4.358865e-04\n",
            "Loss: 4.358208e-04\n",
            "Loss: 4.357141e-04\n",
            "Loss: 4.356636e-04\n",
            "Loss: 4.355809e-04\n",
            "Loss: 4.354402e-04\n",
            "Loss: 4.354056e-04\n",
            "Loss: 4.352762e-04\n",
            "Loss: 4.352369e-04\n",
            "Loss: 4.351723e-04\n",
            "Loss: 4.350880e-04\n",
            "Loss: 4.349678e-04\n",
            "Loss: 4.347923e-04\n",
            "Loss: 4.347308e-04\n",
            "Loss: 4.346349e-04\n",
            "Loss: 4.345295e-04\n",
            "Loss: 4.344064e-04\n",
            "Loss: 4.344590e-04\n",
            "Loss: 4.343540e-04\n",
            "Loss: 4.342757e-04\n",
            "Loss: 4.341877e-04\n",
            "Loss: 4.340817e-04\n",
            "Loss: 4.339475e-04\n",
            "Loss: 4.340821e-04\n",
            "Loss: 4.338758e-04\n",
            "Loss: 4.337820e-04\n",
            "Loss: 4.337255e-04\n",
            "Loss: 4.336751e-04\n",
            "Loss: 4.336158e-04\n",
            "Loss: 4.335287e-04\n",
            "Loss: 4.334854e-04\n",
            "Loss: 4.334369e-04\n",
            "Loss: 4.333737e-04\n",
            "Loss: 4.333321e-04\n",
            "Loss: 4.332666e-04\n",
            "Loss: 4.331134e-04\n",
            "Loss: 4.334002e-04\n",
            "Loss: 4.330560e-04\n",
            "Loss: 4.329687e-04\n",
            "Loss: 4.328780e-04\n",
            "Loss: 4.328339e-04\n",
            "Loss: 4.327819e-04\n",
            "Loss: 4.327290e-04\n",
            "Loss: 4.326925e-04\n",
            "Loss: 4.326225e-04\n",
            "Loss: 4.325594e-04\n",
            "Loss: 4.324612e-04\n",
            "Loss: 4.323971e-04\n",
            "Loss: 4.323582e-04\n",
            "Loss: 4.322844e-04\n",
            "Loss: 4.322644e-04\n",
            "Loss: 4.321983e-04\n",
            "Loss: 4.321488e-04\n",
            "Loss: 4.320701e-04\n",
            "Loss: 4.319866e-04\n",
            "Loss: 4.319198e-04\n",
            "Loss: 4.318649e-04\n",
            "Loss: 4.317980e-04\n",
            "Loss: 4.317974e-04\n",
            "Loss: 4.316887e-04\n",
            "Loss: 4.316508e-04\n",
            "Loss: 4.315498e-04\n",
            "Loss: 4.315253e-04\n",
            "Loss: 4.314676e-04\n",
            "Loss: 4.314266e-04\n",
            "Loss: 4.313076e-04\n",
            "Loss: 4.312372e-04\n",
            "Loss: 4.311305e-04\n",
            "Loss: 4.310342e-04\n",
            "Loss: 4.309819e-04\n",
            "Loss: 4.309264e-04\n",
            "Loss: 4.308696e-04\n",
            "Loss: 4.307944e-04\n",
            "Loss: 4.307294e-04\n",
            "Loss: 4.306682e-04\n",
            "Loss: 4.306738e-04\n",
            "Loss: 4.305874e-04\n",
            "Loss: 4.305045e-04\n",
            "Loss: 4.304346e-04\n",
            "Loss: 4.303609e-04\n",
            "Loss: 4.302375e-04\n",
            "Loss: 4.301841e-04\n",
            "Loss: 4.301231e-04\n",
            "Loss: 4.300861e-04\n",
            "Loss: 4.299928e-04\n",
            "Loss: 4.299004e-04\n",
            "Loss: 4.297879e-04\n",
            "Loss: 4.297535e-04\n",
            "Loss: 4.295808e-04\n",
            "Loss: 4.295373e-04\n",
            "Loss: 4.294819e-04\n",
            "Loss: 4.293434e-04\n",
            "Loss: 4.293247e-04\n",
            "Loss: 4.291971e-04\n",
            "Loss: 4.291709e-04\n",
            "Loss: 4.290838e-04\n",
            "Loss: 4.289533e-04\n",
            "Loss: 4.287995e-04\n",
            "Loss: 4.290780e-04\n",
            "Loss: 4.287495e-04\n",
            "Loss: 4.286573e-04\n",
            "Loss: 4.286040e-04\n",
            "Loss: 4.285251e-04\n",
            "Loss: 4.284731e-04\n",
            "Loss: 4.283736e-04\n",
            "Loss: 4.283457e-04\n",
            "Loss: 4.282547e-04\n",
            "Loss: 4.282321e-04\n",
            "Loss: 4.281551e-04\n",
            "Loss: 4.281055e-04\n",
            "Loss: 4.280458e-04\n",
            "Loss: 4.279650e-04\n",
            "Loss: 4.279057e-04\n",
            "Loss: 4.278351e-04\n",
            "Loss: 4.278045e-04\n",
            "Loss: 4.277584e-04\n",
            "Loss: 4.276488e-04\n",
            "Loss: 4.277730e-04\n",
            "Loss: 4.275849e-04\n",
            "Loss: 4.275139e-04\n",
            "Loss: 4.273934e-04\n",
            "Loss: 4.273144e-04\n",
            "Loss: 4.271814e-04\n",
            "Loss: 4.275840e-04\n",
            "Loss: 4.271086e-04\n",
            "Loss: 4.270006e-04\n",
            "Loss: 4.269287e-04\n",
            "Loss: 4.268872e-04\n",
            "Loss: 4.268474e-04\n",
            "Loss: 4.267708e-04\n",
            "Loss: 4.267109e-04\n",
            "Loss: 4.266169e-04\n",
            "Loss: 4.270315e-04\n",
            "Loss: 4.265882e-04\n",
            "Loss: 4.264947e-04\n",
            "Loss: 4.263828e-04\n",
            "Loss: 4.262856e-04\n",
            "Loss: 4.262385e-04\n",
            "Loss: 4.261435e-04\n",
            "Loss: 4.261126e-04\n",
            "Loss: 4.260374e-04\n",
            "Loss: 4.259757e-04\n",
            "Loss: 4.258198e-04\n",
            "Loss: 4.257491e-04\n",
            "Loss: 4.255811e-04\n",
            "Loss: 4.255083e-04\n",
            "Loss: 4.253923e-04\n",
            "Loss: 4.252958e-04\n",
            "Loss: 4.252008e-04\n",
            "Loss: 4.251652e-04\n",
            "Loss: 4.251179e-04\n",
            "Loss: 4.250214e-04\n",
            "Loss: 4.249346e-04\n",
            "Loss: 4.248148e-04\n",
            "Loss: 4.246980e-04\n",
            "Loss: 4.246336e-04\n",
            "Loss: 4.245175e-04\n",
            "Loss: 4.246674e-04\n",
            "Loss: 4.244931e-04\n",
            "Loss: 4.244158e-04\n",
            "Loss: 4.243366e-04\n",
            "Loss: 4.242327e-04\n",
            "Loss: 4.242239e-04\n",
            "Loss: 4.241005e-04\n",
            "Loss: 4.240072e-04\n",
            "Loss: 4.239705e-04\n",
            "Loss: 4.238549e-04\n",
            "Loss: 4.237749e-04\n",
            "Loss: 4.236361e-04\n",
            "Loss: 4.235762e-04\n",
            "Loss: 4.235506e-04\n",
            "Loss: 4.234673e-04\n",
            "Loss: 4.233058e-04\n",
            "Loss: 4.231665e-04\n",
            "Loss: 4.230757e-04\n",
            "Loss: 4.229516e-04\n",
            "Loss: 4.228968e-04\n",
            "Loss: 4.227757e-04\n",
            "Loss: 4.226682e-04\n",
            "Loss: 4.228754e-04\n",
            "Loss: 4.225911e-04\n",
            "Loss: 4.224857e-04\n",
            "Loss: 4.224083e-04\n",
            "Loss: 4.223794e-04\n",
            "Loss: 4.223187e-04\n",
            "Loss: 4.222888e-04\n",
            "Loss: 4.221959e-04\n",
            "Loss: 4.221491e-04\n",
            "Loss: 4.221168e-04\n",
            "Loss: 4.220795e-04\n",
            "Loss: 4.220292e-04\n",
            "Loss: 4.219336e-04\n",
            "Loss: 4.222794e-04\n",
            "Loss: 4.219059e-04\n",
            "Loss: 4.217637e-04\n",
            "Loss: 4.216984e-04\n",
            "Loss: 4.215809e-04\n",
            "Loss: 4.214842e-04\n",
            "Loss: 4.214351e-04\n",
            "Loss: 4.213018e-04\n",
            "Loss: 4.212348e-04\n",
            "Loss: 4.211493e-04\n",
            "Loss: 4.210369e-04\n",
            "Loss: 4.209336e-04\n",
            "Loss: 4.209675e-04\n",
            "Loss: 4.208204e-04\n",
            "Loss: 4.207443e-04\n",
            "Loss: 4.206828e-04\n",
            "Loss: 4.206390e-04\n",
            "Loss: 4.205651e-04\n",
            "Loss: 4.205227e-04\n",
            "Loss: 4.204484e-04\n",
            "Loss: 4.202518e-04\n",
            "Loss: 4.201156e-04\n",
            "Loss: 4.200466e-04\n",
            "Loss: 4.199838e-04\n",
            "Loss: 4.199372e-04\n",
            "Loss: 4.198556e-04\n",
            "Loss: 4.197627e-04\n",
            "Loss: 4.201345e-04\n",
            "Loss: 4.197272e-04\n",
            "Loss: 4.196350e-04\n",
            "Loss: 4.195752e-04\n",
            "Loss: 4.194790e-04\n",
            "Loss: 4.193594e-04\n",
            "Loss: 4.194049e-04\n",
            "Loss: 4.192920e-04\n",
            "Loss: 4.191704e-04\n",
            "Loss: 4.190397e-04\n",
            "Loss: 4.190029e-04\n",
            "Loss: 4.189048e-04\n",
            "Loss: 4.188442e-04\n",
            "Loss: 4.187821e-04\n",
            "Loss: 4.187151e-04\n",
            "Loss: 4.185901e-04\n",
            "Loss: 4.185997e-04\n",
            "Loss: 4.184957e-04\n",
            "Loss: 4.183726e-04\n",
            "Loss: 4.181782e-04\n",
            "Loss: 4.180930e-04\n",
            "Loss: 4.180059e-04\n",
            "Loss: 4.179035e-04\n",
            "Loss: 4.176407e-04\n",
            "Loss: 4.175475e-04\n",
            "Loss: 4.174495e-04\n",
            "Loss: 4.173884e-04\n",
            "Loss: 4.173660e-04\n",
            "Loss: 4.172939e-04\n",
            "Loss: 4.171767e-04\n",
            "Loss: 4.171020e-04\n",
            "Loss: 4.170867e-04\n",
            "Loss: 4.170457e-04\n",
            "Loss: 4.169857e-04\n",
            "Loss: 4.169430e-04\n",
            "Loss: 4.168929e-04\n",
            "Loss: 4.167769e-04\n",
            "Loss: 4.166703e-04\n",
            "Loss: 4.166531e-04\n",
            "Loss: 4.165089e-04\n",
            "Loss: 4.164301e-04\n",
            "Loss: 4.163597e-04\n",
            "Loss: 4.162529e-04\n",
            "Loss: 4.161871e-04\n",
            "Loss: 4.160919e-04\n",
            "Loss: 4.160544e-04\n",
            "Loss: 4.159456e-04\n",
            "Loss: 4.158638e-04\n",
            "Loss: 4.159936e-04\n",
            "Loss: 4.158388e-04\n",
            "Loss: 4.157775e-04\n",
            "Loss: 4.157136e-04\n",
            "Loss: 4.156182e-04\n",
            "Loss: 4.156388e-04\n",
            "Loss: 4.155817e-04\n",
            "Loss: 4.155110e-04\n",
            "Loss: 4.154551e-04\n",
            "Loss: 4.153454e-04\n",
            "Loss: 4.152407e-04\n",
            "Loss: 4.151435e-04\n",
            "Loss: 4.150650e-04\n",
            "Loss: 4.150078e-04\n",
            "Loss: 4.149467e-04\n",
            "Loss: 4.148931e-04\n",
            "Loss: 4.147747e-04\n",
            "Loss: 4.147652e-04\n",
            "Loss: 4.147084e-04\n",
            "Loss: 4.146770e-04\n",
            "Loss: 4.146025e-04\n",
            "Loss: 4.145229e-04\n",
            "Loss: 4.144089e-04\n",
            "Loss: 4.143385e-04\n",
            "Loss: 4.142366e-04\n",
            "Loss: 4.141601e-04\n",
            "Loss: 4.140815e-04\n",
            "Loss: 4.139590e-04\n",
            "Loss: 4.138580e-04\n",
            "Loss: 4.137957e-04\n",
            "Loss: 4.137363e-04\n",
            "Loss: 4.137009e-04\n",
            "Loss: 4.135243e-04\n",
            "Loss: 4.159141e-04\n",
            "Loss: 4.135151e-04\n",
            "Loss: 4.134069e-04\n",
            "Loss: 4.132945e-04\n",
            "Loss: 4.132194e-04\n",
            "Loss: 4.131721e-04\n",
            "Loss: 4.130418e-04\n",
            "Loss: 4.129789e-04\n",
            "Loss: 4.128714e-04\n",
            "Loss: 4.127860e-04\n",
            "Loss: 4.126431e-04\n",
            "Loss: 4.125587e-04\n",
            "Loss: 4.125169e-04\n",
            "Loss: 4.124324e-04\n",
            "Loss: 4.123938e-04\n",
            "Loss: 4.123422e-04\n",
            "Loss: 4.122911e-04\n",
            "Loss: 4.122309e-04\n",
            "Loss: 4.120784e-04\n",
            "Loss: 4.121732e-04\n",
            "Loss: 4.119921e-04\n",
            "Loss: 4.118232e-04\n",
            "Loss: 4.117401e-04\n",
            "Loss: 4.116204e-04\n",
            "Loss: 4.115583e-04\n",
            "Loss: 4.114726e-04\n",
            "Loss: 4.114257e-04\n",
            "Loss: 4.113939e-04\n",
            "Loss: 4.113118e-04\n",
            "Loss: 4.114255e-04\n",
            "Loss: 4.112470e-04\n",
            "Loss: 4.111776e-04\n",
            "Loss: 4.111125e-04\n",
            "Loss: 4.110133e-04\n",
            "Loss: 4.109177e-04\n",
            "Loss: 4.108443e-04\n",
            "Loss: 4.106510e-04\n",
            "Loss: 4.106424e-04\n",
            "Loss: 4.105800e-04\n",
            "Loss: 4.105025e-04\n",
            "Loss: 4.104503e-04\n",
            "Loss: 4.103339e-04\n",
            "Loss: 4.104406e-04\n",
            "Loss: 4.102730e-04\n",
            "Loss: 4.102012e-04\n",
            "Loss: 4.100892e-04\n",
            "Loss: 4.100102e-04\n",
            "Loss: 4.099442e-04\n",
            "Loss: 4.098566e-04\n",
            "Loss: 4.097983e-04\n",
            "Loss: 4.097516e-04\n",
            "Loss: 4.096875e-04\n",
            "Loss: 4.096928e-04\n",
            "Loss: 4.096397e-04\n",
            "Loss: 4.095832e-04\n",
            "Loss: 4.095558e-04\n",
            "Loss: 4.094818e-04\n",
            "Loss: 4.094059e-04\n",
            "Loss: 4.094116e-04\n",
            "Loss: 4.093662e-04\n",
            "Loss: 4.093297e-04\n",
            "Loss: 4.092433e-04\n",
            "Loss: 4.091130e-04\n",
            "Loss: 4.090909e-04\n",
            "Loss: 4.090415e-04\n",
            "Loss: 4.089996e-04\n",
            "Loss: 4.089561e-04\n",
            "Loss: 4.088899e-04\n",
            "Loss: 4.087561e-04\n",
            "Loss: 4.088022e-04\n",
            "Loss: 4.087212e-04\n",
            "Loss: 4.086559e-04\n",
            "Loss: 4.086039e-04\n",
            "Loss: 4.085247e-04\n",
            "Loss: 4.085194e-04\n",
            "Loss: 4.084699e-04\n",
            "Loss: 4.084037e-04\n",
            "Loss: 4.082792e-04\n",
            "Loss: 4.081896e-04\n",
            "Loss: 4.080894e-04\n",
            "Loss: 4.079729e-04\n",
            "Loss: 4.078911e-04\n",
            "Loss: 4.077746e-04\n",
            "Loss: 4.077042e-04\n",
            "Loss: 4.076599e-04\n",
            "Loss: 4.075273e-04\n",
            "Loss: 4.074599e-04\n",
            "Loss: 4.073351e-04\n",
            "Loss: 4.072633e-04\n",
            "Loss: 4.071410e-04\n",
            "Loss: 4.070596e-04\n",
            "Loss: 4.070019e-04\n",
            "Loss: 4.068733e-04\n",
            "Loss: 4.066275e-04\n",
            "Loss: 4.065456e-04\n",
            "Loss: 4.063693e-04\n",
            "Loss: 4.062655e-04\n",
            "Loss: 4.061862e-04\n",
            "Loss: 4.061618e-04\n",
            "Loss: 4.060846e-04\n",
            "Loss: 4.059778e-04\n",
            "Loss: 4.058611e-04\n",
            "Loss: 4.057052e-04\n",
            "Loss: 4.055333e-04\n",
            "Loss: 4.054874e-04\n",
            "Loss: 4.053805e-04\n",
            "Loss: 4.053543e-04\n",
            "Loss: 4.052835e-04\n",
            "Loss: 4.052388e-04\n",
            "Loss: 4.051856e-04\n",
            "Loss: 4.051497e-04\n",
            "Loss: 4.050671e-04\n",
            "Loss: 4.050473e-04\n",
            "Loss: 4.049568e-04\n",
            "Loss: 4.049103e-04\n",
            "Loss: 4.048816e-04\n",
            "Loss: 4.047937e-04\n",
            "Loss: 4.050871e-04\n",
            "Loss: 4.047615e-04\n",
            "Loss: 4.047083e-04\n",
            "Loss: 4.046261e-04\n",
            "Loss: 4.045540e-04\n",
            "Loss: 4.044924e-04\n",
            "Loss: 4.043526e-04\n",
            "Loss: 4.042532e-04\n",
            "Loss: 4.040562e-04\n",
            "Loss: 4.039408e-04\n",
            "Loss: 4.038602e-04\n",
            "Loss: 4.037447e-04\n",
            "Loss: 4.040841e-04\n",
            "Loss: 4.037250e-04\n",
            "Loss: 4.036614e-04\n",
            "Loss: 4.035575e-04\n",
            "Loss: 4.034513e-04\n",
            "Loss: 4.033913e-04\n",
            "Loss: 4.032151e-04\n",
            "Loss: 4.031416e-04\n",
            "Loss: 4.030379e-04\n",
            "Loss: 4.029318e-04\n",
            "Loss: 4.028654e-04\n",
            "Loss: 4.027913e-04\n",
            "Loss: 4.027214e-04\n",
            "Loss: 4.026368e-04\n",
            "Loss: 4.024756e-04\n",
            "Loss: 4.026400e-04\n",
            "Loss: 4.023774e-04\n",
            "Loss: 4.022476e-04\n",
            "Loss: 4.021667e-04\n",
            "Loss: 4.021030e-04\n",
            "Loss: 4.020020e-04\n",
            "Loss: 4.018820e-04\n",
            "Loss: 4.017483e-04\n",
            "Loss: 4.016530e-04\n",
            "Loss: 4.015783e-04\n",
            "Loss: 4.014794e-04\n",
            "Loss: 4.014297e-04\n",
            "Loss: 4.013575e-04\n",
            "Loss: 4.013268e-04\n",
            "Loss: 4.012765e-04\n",
            "Loss: 4.011610e-04\n",
            "Loss: 4.009716e-04\n",
            "Loss: 4.009133e-04\n",
            "Loss: 4.006552e-04\n",
            "Loss: 4.006153e-04\n",
            "Loss: 4.005580e-04\n",
            "Loss: 4.004863e-04\n",
            "Loss: 4.003221e-04\n",
            "Loss: 4.002322e-04\n",
            "Loss: 4.000835e-04\n",
            "Loss: 3.999853e-04\n",
            "Loss: 3.998883e-04\n",
            "Loss: 3.998231e-04\n",
            "Loss: 4.002678e-04\n",
            "Loss: 3.997650e-04\n",
            "Loss: 3.996748e-04\n",
            "Loss: 3.995638e-04\n",
            "Loss: 3.995007e-04\n",
            "Loss: 3.994156e-04\n",
            "Loss: 3.993504e-04\n",
            "Loss: 3.992444e-04\n",
            "Loss: 3.991416e-04\n",
            "Loss: 3.990582e-04\n",
            "Loss: 3.989326e-04\n",
            "Loss: 3.988898e-04\n",
            "Loss: 3.987393e-04\n",
            "Loss: 3.986801e-04\n",
            "Loss: 3.985375e-04\n",
            "Loss: 3.983813e-04\n",
            "Loss: 3.983022e-04\n",
            "Loss: 3.981909e-04\n",
            "Loss: 3.981514e-04\n",
            "Loss: 3.980868e-04\n",
            "Loss: 3.980256e-04\n",
            "Loss: 3.979185e-04\n",
            "Loss: 3.978457e-04\n",
            "Loss: 3.977781e-04\n",
            "Loss: 3.977290e-04\n",
            "Loss: 3.976494e-04\n",
            "Loss: 3.976638e-04\n",
            "Loss: 3.975931e-04\n",
            "Loss: 3.975003e-04\n",
            "Loss: 3.974214e-04\n",
            "Loss: 3.973563e-04\n",
            "Loss: 3.972687e-04\n",
            "Loss: 3.971428e-04\n",
            "Loss: 3.970444e-04\n",
            "Loss: 3.969694e-04\n",
            "Loss: 3.968736e-04\n",
            "Loss: 3.966962e-04\n",
            "Loss: 3.965584e-04\n",
            "Loss: 3.964774e-04\n",
            "Loss: 3.963907e-04\n",
            "Loss: 3.963133e-04\n",
            "Loss: 3.962051e-04\n",
            "Loss: 3.960287e-04\n",
            "Loss: 3.960464e-04\n",
            "Loss: 3.959515e-04\n",
            "Loss: 3.958746e-04\n",
            "Loss: 3.958016e-04\n",
            "Loss: 3.957552e-04\n",
            "Loss: 3.956921e-04\n",
            "Loss: 3.956044e-04\n",
            "Loss: 3.956469e-04\n",
            "Loss: 3.955503e-04\n",
            "Loss: 3.955059e-04\n",
            "Loss: 3.954590e-04\n",
            "Loss: 3.954256e-04\n",
            "Loss: 3.953406e-04\n",
            "Loss: 3.953225e-04\n",
            "Loss: 3.951996e-04\n",
            "Loss: 3.951298e-04\n",
            "Loss: 3.950624e-04\n",
            "Loss: 3.950147e-04\n",
            "Loss: 3.948901e-04\n",
            "Loss: 3.952960e-04\n",
            "Loss: 3.948564e-04\n",
            "Loss: 3.948255e-04\n",
            "Loss: 3.947644e-04\n",
            "Loss: 3.946939e-04\n",
            "Loss: 3.945907e-04\n",
            "Loss: 3.948283e-04\n",
            "Loss: 3.945635e-04\n",
            "Loss: 3.944884e-04\n",
            "Loss: 3.944048e-04\n",
            "Loss: 3.942964e-04\n",
            "Loss: 3.942344e-04\n",
            "Loss: 3.941623e-04\n",
            "Loss: 3.941366e-04\n",
            "Loss: 3.940754e-04\n",
            "Loss: 3.940248e-04\n",
            "Loss: 3.939740e-04\n",
            "Loss: 3.938575e-04\n",
            "Loss: 3.938040e-04\n",
            "Loss: 3.937055e-04\n",
            "Loss: 3.936135e-04\n",
            "Loss: 3.935645e-04\n",
            "Loss: 3.935533e-04\n",
            "Loss: 3.935257e-04\n",
            "Loss: 3.934795e-04\n",
            "Loss: 3.934485e-04\n",
            "Loss: 3.933634e-04\n",
            "Loss: 3.932925e-04\n",
            "Loss: 3.931913e-04\n",
            "Loss: 3.931194e-04\n",
            "Loss: 3.930326e-04\n",
            "Loss: 3.929504e-04\n",
            "Loss: 3.928117e-04\n",
            "Loss: 3.929343e-04\n",
            "Loss: 3.927138e-04\n",
            "Loss: 3.926175e-04\n",
            "Loss: 3.925446e-04\n",
            "Loss: 3.924988e-04\n",
            "Loss: 3.923671e-04\n",
            "Loss: 3.923040e-04\n",
            "Loss: 3.921886e-04\n",
            "Loss: 3.920511e-04\n",
            "Loss: 3.919601e-04\n",
            "Loss: 3.920915e-04\n",
            "Loss: 3.919057e-04\n",
            "Loss: 3.918648e-04\n",
            "Loss: 3.918293e-04\n",
            "Loss: 3.917627e-04\n",
            "Loss: 3.917015e-04\n",
            "Loss: 3.916386e-04\n",
            "Loss: 3.915756e-04\n",
            "Loss: 3.916323e-04\n",
            "Loss: 3.915558e-04\n",
            "Loss: 3.915309e-04\n",
            "Loss: 3.914707e-04\n",
            "Loss: 3.914277e-04\n",
            "Loss: 3.912825e-04\n",
            "Loss: 3.912722e-04\n",
            "Loss: 3.911179e-04\n",
            "Loss: 3.910114e-04\n",
            "Loss: 3.909111e-04\n",
            "Loss: 3.907660e-04\n",
            "Loss: 3.908498e-04\n",
            "Loss: 3.907029e-04\n",
            "Loss: 3.905999e-04\n",
            "Loss: 3.905873e-04\n",
            "Loss: 3.904772e-04\n",
            "Loss: 3.903731e-04\n",
            "Loss: 3.902671e-04\n",
            "Loss: 3.901549e-04\n",
            "Loss: 3.900537e-04\n",
            "Loss: 3.899477e-04\n",
            "Loss: 3.898274e-04\n",
            "Loss: 3.897164e-04\n",
            "Loss: 3.896097e-04\n",
            "Loss: 3.894994e-04\n",
            "Loss: 3.894429e-04\n",
            "Loss: 3.893777e-04\n",
            "Loss: 3.892688e-04\n",
            "Loss: 3.892174e-04\n",
            "Loss: 3.890990e-04\n",
            "Loss: 3.890394e-04\n",
            "Loss: 3.889982e-04\n",
            "Loss: 3.889366e-04\n",
            "Loss: 3.889021e-04\n",
            "Loss: 3.888389e-04\n",
            "Loss: 3.888069e-04\n",
            "Loss: 3.887555e-04\n",
            "Loss: 3.886855e-04\n",
            "Loss: 3.886067e-04\n",
            "Loss: 3.885348e-04\n",
            "Loss: 3.884792e-04\n",
            "Loss: 3.884261e-04\n",
            "Loss: 3.883624e-04\n",
            "Loss: 3.883582e-04\n",
            "Loss: 3.882966e-04\n",
            "Loss: 3.882283e-04\n",
            "Loss: 3.881120e-04\n",
            "Loss: 3.880119e-04\n",
            "Loss: 3.879066e-04\n",
            "Loss: 3.880672e-04\n",
            "Loss: 3.878841e-04\n",
            "Loss: 3.878062e-04\n",
            "Loss: 3.877374e-04\n",
            "Loss: 3.876820e-04\n",
            "Loss: 3.876327e-04\n",
            "Loss: 3.875887e-04\n",
            "Loss: 3.875188e-04\n",
            "Loss: 3.874491e-04\n",
            "Loss: 3.873660e-04\n",
            "Loss: 3.872890e-04\n",
            "Loss: 3.872348e-04\n",
            "Loss: 3.871130e-04\n",
            "Loss: 3.872177e-04\n",
            "Loss: 3.870948e-04\n",
            "Loss: 3.870598e-04\n",
            "Loss: 3.870339e-04\n",
            "Loss: 3.870039e-04\n",
            "Loss: 3.869442e-04\n",
            "Loss: 3.868457e-04\n",
            "Loss: 3.868142e-04\n",
            "Loss: 3.866696e-04\n",
            "Loss: 3.866064e-04\n",
            "Loss: 3.865265e-04\n",
            "Loss: 3.865460e-04\n",
            "Loss: 3.864885e-04\n",
            "Loss: 3.864441e-04\n",
            "Loss: 3.863732e-04\n",
            "Loss: 3.863439e-04\n",
            "Loss: 3.862981e-04\n",
            "Loss: 3.862546e-04\n",
            "Loss: 3.862290e-04\n",
            "Loss: 3.861800e-04\n",
            "Loss: 3.860506e-04\n",
            "Loss: 3.865103e-04\n",
            "Loss: 3.860503e-04\n",
            "Loss: 3.859898e-04\n",
            "Loss: 3.859432e-04\n",
            "Loss: 3.858783e-04\n",
            "Loss: 3.858150e-04\n",
            "Loss: 3.857704e-04\n",
            "Loss: 3.857239e-04\n",
            "Loss: 3.856648e-04\n",
            "Loss: 3.859654e-04\n",
            "Loss: 3.856336e-04\n",
            "Loss: 3.855912e-04\n",
            "Loss: 3.855668e-04\n",
            "Loss: 3.855658e-04\n",
            "Loss: 3.856219e-04\n",
            "Loss: 3.855465e-04\n",
            "Loss: 3.855079e-04\n",
            "Loss: 3.854667e-04\n",
            "Loss: 3.854033e-04\n",
            "Loss: 3.853418e-04\n",
            "Loss: 3.852983e-04\n",
            "Loss: 3.852270e-04\n",
            "Loss: 3.851932e-04\n",
            "Loss: 3.851453e-04\n",
            "Loss: 3.850960e-04\n",
            "Loss: 3.850365e-04\n",
            "Loss: 3.849511e-04\n",
            "Loss: 3.848947e-04\n",
            "Loss: 3.848271e-04\n",
            "Loss: 3.847762e-04\n",
            "Loss: 3.846995e-04\n",
            "Loss: 3.848184e-04\n",
            "Loss: 3.846564e-04\n",
            "Loss: 3.845968e-04\n",
            "Loss: 3.845617e-04\n",
            "Loss: 3.845155e-04\n",
            "Loss: 3.844531e-04\n",
            "Loss: 3.843573e-04\n",
            "Loss: 3.842869e-04\n",
            "Loss: 3.842446e-04\n",
            "Loss: 3.841929e-04\n",
            "Loss: 3.841200e-04\n",
            "Loss: 3.840012e-04\n",
            "Loss: 3.839157e-04\n",
            "Loss: 3.838387e-04\n",
            "Loss: 3.837249e-04\n",
            "Loss: 3.836804e-04\n",
            "Loss: 3.836458e-04\n",
            "Loss: 3.835758e-04\n",
            "Loss: 3.834803e-04\n",
            "Loss: 3.833672e-04\n",
            "Loss: 3.835557e-04\n",
            "Loss: 3.833250e-04\n",
            "Loss: 3.831992e-04\n",
            "Loss: 3.831021e-04\n",
            "Loss: 3.830244e-04\n",
            "Loss: 3.829583e-04\n",
            "Loss: 3.828947e-04\n",
            "Loss: 3.828492e-04\n",
            "Loss: 3.828159e-04\n",
            "Loss: 3.826898e-04\n",
            "Loss: 3.826079e-04\n",
            "Loss: 3.825587e-04\n",
            "Loss: 3.824615e-04\n",
            "Loss: 3.823893e-04\n",
            "Loss: 3.822828e-04\n",
            "Loss: 3.822018e-04\n",
            "Loss: 3.821628e-04\n",
            "Loss: 3.820712e-04\n",
            "Loss: 3.820416e-04\n",
            "Loss: 3.820001e-04\n",
            "Loss: 3.819889e-04\n",
            "Loss: 3.819395e-04\n",
            "Loss: 3.819087e-04\n",
            "Loss: 3.818439e-04\n",
            "Loss: 3.817560e-04\n",
            "Loss: 3.817787e-04\n",
            "Loss: 3.817093e-04\n",
            "Loss: 3.816054e-04\n",
            "Loss: 3.815478e-04\n",
            "Loss: 3.814974e-04\n",
            "Loss: 3.814439e-04\n",
            "Loss: 3.813911e-04\n",
            "Loss: 3.813985e-04\n",
            "Loss: 3.814138e-04\n",
            "Loss: 3.814104e-04\n",
            "Loss: 3.813920e-04\n",
            "Loss: 3.813911e-04\n",
            "Loss: 3.813911e-04\n",
            "Loss: 3.813911e-04\n",
            "Loss: 3.813911e-04\n",
            "Loss: 3.813911e-04\n",
            "Loss: 3.813911e-04\n",
            "Loss: 3.813911e-04\n",
            "Loss: 3.813911e-04\n",
            "Loss: 3.813911e-04\n",
            "Loss: 3.813911e-04\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.000381\n",
            "  Number of iterations: 9715\n",
            "  Number of functions evaluations: 10470\n",
            "Error u: 1.659180e-03\n",
            "Error u (idn): 1.276261e-03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6erME2d8M1Jx"
      },
      "source": [
        "## Plotting: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4dnerEv8ied"
      },
      "source": [
        "## PLOTTING: \n",
        "import matplotlib as mpl\n",
        "mpl.use('pgf')\n",
        "def figsize(scale, nplots = 1):\n",
        "    fig_width_pt = 390.0                          # Get this from LaTeX using \\the\\textwidth\n",
        "    inches_per_pt = 1.0/72.27                       # Convert pt to inch\n",
        "    golden_mean = (np.sqrt(5.0)-1.0)/2.0            # Aesthetic ratio (you could change this)\n",
        "    fig_width = fig_width_pt*inches_per_pt*scale    # width in inches\n",
        "    fig_height = nplots*fig_width*golden_mean              # height in inches\n",
        "    fig_size = [fig_width,fig_height]\n",
        "    return fig_size\n",
        "\n",
        "pgf_with_latex = {                      # setup matplotlib to use latex for output\n",
        "    \"pgf.texsystem\": \"pdflatex\",        # change this if using xetex or lautex\n",
        "    \"text.usetex\": True,                # use LaTeX to write all text\n",
        "    \"font.family\": \"serif\",\n",
        "    \"font.serif\": [],                   # blank entries should cause plots to inherit fonts from the document\n",
        "    \"font.sans-serif\": [],\n",
        "    \"font.monospace\": [],\n",
        "    \"axes.labelsize\": 10,               # LaTeX default is 10pt font.\n",
        "    \"font.size\": 10,\n",
        "    \"legend.fontsize\": 8,               # Make the legend/label fonts a little smaller\n",
        "    \"xtick.labelsize\": 8,\n",
        "    \"ytick.labelsize\": 8,\n",
        "    \"figure.figsize\": figsize(1.0),     # default fig size of 0.9 textwidth\n",
        "    \"pgf.preamble\": [\n",
        "        r\"\\usepackage[utf8x]{inputenc}\",    # use utf8 fonts becasue your computer can handle it :)\n",
        "        r\"\\usepackage[T1]{fontenc}\",        # plots will be generated using this preamble\n",
        "        ]\n",
        "    }\n",
        "mpl.rcParams.update(pgf_with_latex)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# I make my own newfig and savefig functions\n",
        "def newfig(width, nplots = 1):\n",
        "    fig = plt.figure(figsize=figsize(width, nplots))\n",
        "    ax = fig.add_subplot(111)\n",
        "    return fig, ax\n",
        "\n",
        "def savefig(filename, crop = True):\n",
        "    if crop == True:\n",
        "        plt.savefig('{}.png'.format(filename), bbox_inches='tight', pad_inches=0)\n",
        "        plt.savefig('{}.pdf'.format(filename), bbox_inches='tight', pad_inches=0)\n",
        "     #   plt.savefig('{}.eps'.format(filename), bbox_inches='tight', pad_inches=0)\n",
        "    else:\n",
        "        plt.savefig('{}.png'.format(filename))\n",
        "        plt.savefig('{}.pdf'.format(filename))\n",
        "     #   plt.savefig('{}.eps'.format(filename))\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OIA8gDKNMV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bce332a7-40e5-47d1-b0e6-0467d9fbf085"
      },
      "source": [
        "from matplotlib import rc\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "rc('text', usetex=True)\n",
        "mpl.rcParams['text.latex.preamble'] = [r'\\usepackage{amsmath}']\n",
        "!apt-get update \n",
        "!apt install texlive-fonts-recommended texlive-fonts-extra cm-super dvipng"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Waiting for headers] [Co\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 2s (148 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "cm-super is already the newest version (0.3.4-11).\n",
            "dvipng is already the newest version (1.15-1).\n",
            "texlive-fonts-extra is already the newest version (2017.20180305-2).\n",
            "texlive-fonts-recommended is already the newest version (2017.20180305-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89lKvjja8ieu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "b1402f5e-ac2f-49ee-fbf5-e999054cf1e9"
      },
      "source": [
        "  ######################################################################\n",
        "    ############################# Plotting ###############################\n",
        "    ######################################################################    \n",
        "    \n",
        "fig, ax = newfig(1.5, 1)\n",
        "ax.axis('off')\n",
        "    \n",
        "    ######## Row 2: Pressure #######################\n",
        "    ########      Predicted p(t,x,y)     ########### \n",
        "gs = gridspec.GridSpec(1, 2)\n",
        "gs.update(top=0.8, bottom=0.2, left=0.1, right=0.9, wspace=0.5)\n",
        "ax = plt.subplot(gs[:, 0])\n",
        "h = ax.imshow(Exact_sol, interpolation='nearest', cmap='jet', \n",
        "                  extent=[lb_sol[0], ub_sol[0], lb_sol[1], ub_sol[1]],\n",
        "                  origin='lower', aspect='auto')\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "fig.colorbar(h, cax=cax)\n",
        "ax.set_xlabel('$t$')\n",
        "ax.set_ylabel('$x$')\n",
        "ax.set_title('Exact Dynamics', fontsize = 10)\n",
        "line = np.linspace(lb_sol[1], ub_sol[1], 2)[:,None]\n",
        "ax.plot(t_idn[index]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "    \n",
        "    ########     Exact p(t,x,y)     ########### \n",
        "ax = plt.subplot(gs[:, 1])\n",
        "h = ax.imshow(U_pred, interpolation='nearest', cmap='jet', \n",
        "                 extent=[lb_sol[0], ub_sol[0], lb_sol[1], ub_sol[1]],origin='lower', aspect='auto')\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "\n",
        "fig.colorbar(h, cax=cax)\n",
        "ax.set_xlabel('$t$')\n",
        "ax.set_ylabel('$x$')\n",
        "ax.set_title('Learned Dynamics', fontsize = 10)\n",
        "line = np.linspace(lb_sol[1], ub_sol[1], 2)[:,None]\n",
        "ax.plot(t_idn[index]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "savefig('/content/figures/Inv_Burgers_Sine')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 582.814x360.199 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}